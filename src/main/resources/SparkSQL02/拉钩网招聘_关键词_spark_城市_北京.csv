job_name,job_url,job_location,job_salary,job_company,job_experience,job_class,job_given,job_detail,company_type,company_person,search_key,city
Spark,https://www.lagou.com/jobs/7071586.html,海淀区,18k-36k,昆仑智汇数据科技（北京）有限公司,3-5年,不限,新基建 工业4.0 核心岗位,"职位诱惑：风口行业,大牛带路,扁平化,环境好   职位描述：工作职责：     本岗位将参与昆仑数据全新产品体系的研发工作，以客户价值为导向，为客户构建高效、强大的工业大数据分析产品。你将参与发掘和分析业务需求，系统方案设计和代码编写，确保性能、质量和安全。你将接触到最新的数据分析大师、资深工业领域专家的工业数据分析方法与实践，学到最严谨规范的开发技术与流程，发展你个人的技术能力，领导力和有效的项目管理能力。在这个大家庭里，我们不仅鼓励大家开发出有价值、有影响力的产品给用户，我们同样鼓励大家多学习，多分享，多创新，在工作中找到最大的乐趣！任职资格－计算机相关专业本科及以上，2年以上的系统或应用软件的开发经验。－熟练掌握Java语言和面向对象思想，能写出整洁、高质量的代码。－精通常用关系数据库（PG、MySQL等）和各种NoSQL数据库。－熟悉并实践过Hadoop、Spark、Flink、Kakfa等任意一种大数据分析框架，并理解一定的底层原理。－精通RESTfulAPI开发，具备良好的API设计风格。－熟练使用Linux，理解并熟练使用Docker容器部署方式。－具备良好的软件工程和质量意识，认同并实践过敏捷开发和DevOps方法。优先任职资格－具备在快节奏，敏捷模式下开发新产品的激情。－曾经Lead团队开发复杂的软件产品，并成功地交付给用户。－具备全栈工程能力，掌握多种语言开发，如js，python，golang等。－曾经参与分布式系统开发，熟悉多个大数据产品生态和相关技术。－Linux高手，熟练掌握shell编程。－有指导年轻工程师提高技术能力和开发效率的经验。",数据服务,150-500人,spark,北京
Spark SQL 开源大数据系统架构师/负责人,https://www.lagou.com/jobs/7168899.html,海淀区,40k-80k,北京字节跳动科技有限公司,不限,本科,"六险一金,股票期权,弹性工作,免费三餐",,文娱丨内容,2000人以上,spark,北京
spark开发工程师,https://www.lagou.com/jobs/6889060.html,海淀区,15k-30k,中科天玑数据科技股份有限公司,3-5年,本科,科学院孵化，福利待遇好，技术牛人多,"岗位职责：1. 负责公司机器学习平台算法组件设计、开发；2. 基于Spark框架的数据平台的设计，开发，维护。任职要求：1. 熟悉hadoop,Spark相关技术，至少有2年的Spark开发经验,熟悉Spark源码者优先；2. 熟悉Scala语言,熟悉Spark mllib和Spark SQL 模块；3. 有过海量数据系统开发经验者优先；4.良好的自我驱动与学习能力，具有优秀的分析问题和解决问题的能力；5.具备较强的学习能力，主动性、责任感强，具有团队合作精神。","移动互联网,数据服务",150-500人,spark,北京
搜狗金融—大数据开发工程师（spark方向）,https://www.lagou.com/jobs/4931677.html,海淀区,25k-40k,北京搜狗科技发展有限公司,5-10年,本科,"平台大,人脉广,技术牛,氛围好",项目介绍：搜狗金融，这是一款定位于服务平台互联网用户的金融产品，由搜狗公司内部孵化，深度挖掘搜狗在互联网端的用户规模优势以及多年的大数据能力积累。在当下大热的互联网金融领域，搜狗将发挥用户服务和智能算法优势，并结合平台的综合运营实力。如果你认同互联网金融、智能风控，大数据模型等概念，欢迎加入我们共同创造事业。岗位职责：1、负责数据平台开发及维护；2、 以flink为主建设实时数据仓库；3、 负责Hive相关离线数据仓库的ETL设计、开发、维护与优化；4、 对接并支撑相关的数据需求；5、 参与公司大数据处理理方向的技术拓展。任职条件：1、 统招本科及以上学历， 5年年以上工作经验；2、 熟悉python、 Java，熟练使用shell编写数据处理脚本；3、 熟练使用Hadoop、 Kafka、 Hive、 Flink、 Hbase、 ES、 Kylin等，熟悉hive、 mysql的SQL编写及优化；4、 熟悉数据仓库建模理理论，具备大中型数据仓库架构设计、模型设计、 ETL设计的相关经验；5、性格积极乐观、诚信、有较强的语言表达能力，具备强烈的进取心、求知欲及团队合作精神；6、 具备海量数据处理、有性能调优经验、金融、电商、电信、互联网行业数据模型经验者优先。,工具,2000人以上,spark,北京
大数据spark算法工程师,https://www.lagou.com/jobs/3972437.html,朝阳区,18k-35k,北京豆果信息技术有限公司,不限,本科,"专业培训,大咖云集,良好氛围,职业发展",岗位职责：1、负责公司广告、菜谱等业务个性化推荐系统的研发；2、分析APP用户行为数据，设计合理的推荐算法模型及策略，并优化推荐排序；3、通过用户行为数据的挖掘，能对用户进行建模并精确刻画用户各种属性。 任职要求：1. 熟练掌握各类个性化推荐算法，并有开发个性化推荐系统的实际项目经验；熟练掌握各类回归及排序算法，能够利用相关算法进行推荐排序的优化；2. 熟练掌握分类、聚类、回归、降维等经典机器学习算法和技术，能够根据实际问题选择合适的模型和算法并进行相应的开发；3. 熟悉Linux操作系统及常用Shell命令；有较强的工程架构和开发能力，能够实现支撑千万级用户和TB级用户行为数据的推荐系统或算法；4.熟悉SparkStreaming和SparkSQL，有Spark平台&hadoop平台开发经验；5. 精通Scala语言，对Scala原理底层技术有深入研究者优先；6. 熟悉hadoop、hive、Hbase等开源系统；熟悉各类数据挖掘工具（如weka、Mahout），能够快速建立模型并进行验证；7. 能快速理解业务场景，从具体问题中抽象出通用的解决方案；8. 对数据敏感，善于发现数据中的潜在规律，善于分析问题，了解业界的最新动态；9.有一线互联网公司推荐系统开发经验者优先；,"移动互联网,社交",50-150人,spark,北京
Spark专家工程师(J200223002),https://www.lagou.com/jobs/6830996.html,海淀区,40k-60k,北京嘀嘀无限科技发展有限公司,5-10年,本科,广阔平台；急速成长；诱人福利,,汽车丨出行,2000人以上,spark,北京
大数据开发工程师（spark）(J10392),https://www.lagou.com/jobs/7179929.html,东城区,20k-30k,北京腾云天下科技有限公司,3-5年,本科,"大数据,行业领先,领导靠谱,学习氛围",任职资格:,移动互联网,500-2000人,spark,北京
spark算法实习生,https://www.lagou.com/jobs/3693520.html,朝阳区,4k-5k,北京豆果信息技术有限公司,应届毕业生,本科,"spark,scala,数据,大咖云集","职位诱惑：实习生,可转正,大咖云集职位描述：职位描述：岗位职责：1、负责公司广告、菜谱等业务个性化推荐系统的研发；2、分析APP用户行为数据，设计合理的推荐算法模型及策略，并优化推荐排序；3、通过用户行为数据的挖掘，能对用户进行建模并精确刻画用户各种属性。 任职要求：1、熟练掌握各类个性化推荐算法，并有开发个性化推荐系统的实际项目经验；熟练掌握各类回归及排序算法，能够利用相关算法进行推荐排序的优化；。2、熟练掌握分类、聚类、回归、降维等经典机器学习算法和技术，能够根据实际问题选择合适的模型和算法并进行相应的开发；3、熟悉Linux操作系统及常用Shell命令；有较强的工程架构和开发能力，能够实现支撑千万级用户和TB级用户行为数据的推荐系统或算法；4、熟悉SparkStreaming和SparkSQL，有Spark平台&hadoop平台开发经验；5、精通Scala语言，对Scala原理底层技术有深入研究者优先；6、熟悉hadoop、hive、Hbase等开源系统；熟悉各类数据挖掘工具（如weka、Mahout），能够快速建立模型并进行验证7、能快速理解业务场景，从具体问题中抽象出通用的解决方案；8、对数据敏感，善于发现数据中的潜在规律，善于分析问题，了解业界的最新动态；9、有一线互联网公司推荐系统开发经验者优先。","移动互联网,社交",50-150人,spark,北京
Spark开发工程师,https://www.lagou.com/jobs/6865152.html,通州区,10k-20k,阳光人寿保险股份有限公司,1-3年,本科,"弹性办公,补充医疗,过节费,带薪假期",岗位职责：1、依据业务需求文档，完成软件模块的分析、设计、开发、测试，以保证能够按期交付，并稳定运行；2、分析数据及效率问题，并给出解决方案，及时修复；3、参与相关项目的设计、评审、开发，保障系统能够按照需求达到预期效果；4、跟踪了解业界发展、互联网相关最新技术，参与重点项目新技术研发工作；5、对低阶岗位人员进行技能培训、指导低阶岗位的技术开发工作；6、领导交代的其他任务。 任职资格：1、统招本科及以上学历，计算机相关专业，2年以上开发经验；2、熟练掌握Hadoop框架及技术，如Spark Core、Hbase、Hive、HDFS、Kudu、Impala、Yarn等3、熟悉大数据ETL工具及技术，如Sqoop、Spark Streaming、Kafka、Flink等；4、熟悉大数据常用开发语言，如Java、Scala、Python等；4、良好的团队合作精神、独立解决问题和沟通能力；5、正直诚实、有责任心，能够承受一定压力；6、对Hadoop性能调优有深入了解者优先；7、有大型Hadoop项目开发、实施经验者优先；8、有数据中台经验者优先；,其他,500-2000人,spark,北京
spark专家工程师,https://www.lagou.com/jobs/7190672.html,海淀区,50k-80k,青岛有住信息技术有限公司,5-10年,本科,大平台背景平台,"工作职责:1、管理、优化并维护集群Spark引擎,深入Spark源码研究和二次开发，解决各种线上问题，参与到开源社区建设和代码贡献;2、打造业界领先的大数据计算平台，为海量数据及其上的大规模数据挖掘、数据分析、机器学习业务系统提供可靠、高效的支持；3、研究业界最新的大数据技术，参与滴滴大数据平台的设计与开发，提供有前瞻性的大数据基础架构解决方案；4、乐于挑战没有明显答案的问题，快速理解业务场景，从具体问题中抽象出通用的解决方案。任职资格:1、计算机或相关专业本科以上，5年以上工作经验，不少于2年大数据架构经验；2、具备扎实的Scala语言编程基础，具备良好的编程习惯，较强独立解决问题的能力；3、精通Spark源码，对社区有贡献者加分4、参与过大型复杂分布式系统的设计、架构者优先；5、做事严谨踏实，责任心强，具有良好的沟通能力和团队意识；","房产家居,电商",50-150人,spark,北京
Spark,https://www.lagou.com/jobs/5914199.html,朝阳区,32k-40k,飞维美地信息技术（北京）有限公司,3-5年,本科,"全员持股，硅谷文化,福利优厚","Sr. Software Engineer (大数据平台基础架构-实时数据计算组) 职责描述：1. 公司海量数据实时计算平台的设计与实现，通过横向扩展与纵向优化保证系统的高吞吐和低延迟的能力.2. 在线实时查询平台的开发与优化, 提供业务方基于海量数据的高维度, 低延迟的查询分析服务.任职要求：1. 三年以上分布式流处理计算开发和优化经验,并能深入理解其中某个计算框架, 如Spark/Flink/Kafka;2. 三年以上OLAP查询分析框架的使用和优化经验, 并能深入理解其中某个框架, 如Druid/Kylin/Presto;3. 具备快速学习与解决问题的能力;4. 强烈的责任心和自我驱动意识;5. 良好的团队合作精神和沟通能力;6. 良好的英语听说读写能力。加分项:1. 有AWS开发经验;2. 对Hadoop/Spark/Druid/Presto相关组件的性能优化和补丁跟踪等有实际经验。","企业服务,数据服务",500-2000人,spark,北京
spark专家工程师,https://www.lagou.com/jobs/7193707.html,海淀区,40k-70k,青岛乾惠泽安全科技有限公司,5-10年,本科,发展前景 公司本身,"工作职责:1、管理、优化并维护集群Spark引擎,深入Spark源码研究和二次开发，解决各种线上问题，参与到开源社区建设和代码贡献;2、打造业界领先的大数据计算平台，为海量数据及其上的大规模数据挖掘、数据分析、机器学习业务系统提供可靠、高效的支持；3、研究业界最新的大数据技术，参与滴滴大数据平台的设计与开发，提供有前瞻性的大数据基础架构解决方案；4、乐于挑战没有明显答案的问题，快速理解业务场景，从具体问题中抽象出通用的解决方案。任职资格:1、计算机或相关专业本科以上，5年以上工作经验，不少于2年大数据架构经验；2、具备扎实的Scala语言编程基础，具备良好的编程习惯，较强独立解决问题的能力；3、精通Spark源码，对社区有贡献者加分4、参与过大型复杂分布式系统的设计、架构者优先；5、做事严谨踏实，责任心强，具有良好的沟通能力和团队意识；",信息安全,50-150人,spark,北京
资深大数据开发工程师-Spark,https://www.lagou.com/jobs/5741037.html,朝阳区,35k-50k,飞维美地信息技术（北京）有限公司,5-10年,本科,"大牛聚集,硅谷文化,福利优厚","Sr./Lead Software Engineer（大数据平台基础架构组） 职责描述：1.     公司级大数据平台的架构规划与设计，以提升平台的存储与计算能力;2.     大数据基础组件Kafka/HBase/YARN/Spark等的二次开发与性能优化;任职要求：1.     三年以上Hadoop及大数据生态圈产品实践经验，如Kafka/HBase/Presto/YARN/Spark等;2.     深入了解分布式系统、大数据平台、消息队列等高可用高弹性架构;3.     有志于建立大规模低延时数据处理系统，用于解决实际业务问题;4.     具备快速学习与解决问题的能力;5.     强烈的责任心和自我驱动意识;6.     良好的团队合作精神和沟通能力;7.     良好的英语听说读写能力。         加分项:1.     有 Golang 开发经验;2.     有AWS开发经验;3.     对HDFS/Yarn/HBase/Hive/Spark/Presto相关组件的性能优化和补丁跟踪等有实际经验。   Sr. Software Engineer (大数据平台基础架构-实时数据计算组) 职责描述：1. 公司海量数据实时计算平台的设计与实现，通过横向扩展与纵向优化保证系统的高吞吐和低延迟的能力.2. 在线实时查询平台的开发与优化, 提供业务方基于海量数据的高维度, 低延迟的查询分析服务.任职要求：1. 三年以上分布式流处理计算开发和优化经验,并能深入理解其中某个计算框架, 如Spark/Flink/Kafka;2. 三年以上OLAP查询分析框架的使用和优化经验, 并能深入理解其中某个框架, 如Druid/Kylin/Presto;3. 具备快速学习与解决问题的能力;4. 强烈的责任心和自我驱动意识;5. 良好的团队合作精神和沟通能力;6. 良好的英语听说读写能力。加分项:1. 有AWS开发经验;2. 对Hadoop/Spark/Druid/Presto相关组件的性能优化和补丁跟踪等有实际经验。","企业服务,数据服务",500-2000人,spark,北京
大数据开发（hadoop，hive，spark）,https://www.lagou.com/jobs/6891421.html,朝阳区,20k-35k,联储证券有限责任公司,5-10年,本科,五险一金、所有节假日休息、券商总部、,岗位职责：1. 根据需求设计开发大数据相关系统功能；2. 解决开发过程中技术难题；3. 撰写技术文档。岗位要求：1. 6年以上Java开发经验，3年以上Hadoop生态圈开发经验，熟悉TDH大数据平台者优先；2. 精通Java EE开发技术和主流框架，精通ECharts仪表盘开发，熟悉SmartBI开发技术者优先；3. 工作积极主动，做事细致认真，善于沟通，有团队合作精神，能承受较大压力；4. 有金融行业项目经验者优先。,金融,500-2000人,spark,北京
大数据算法工程师,https://www.lagou.com/jobs/7085643.html,海淀区,25k-45k,用友网络科技股份有限公司,5-10年,本科,稳定大平台，业务营收好，福利完善，股票,用友集团总部直招，非外包，非驻场；靠谱大平台，发展稳健，抗风险能力强；2个月年终奖，每月不晚于5号发工资；五险一金全额缴纳，班车篮球场健身房食堂宿舍。主要职责： 负责集团总部，数据运营中心大数据智能分析项目设计和研发。 任职资格：1、全日制统招本科及以上学历，计算机、通信、数学等相关专业，有5年以上大数据平台搭建及数据处理的工作经验。2、熟悉Linux操作系统MySQL等数据库，了解SQL优化，熟悉ER模型和相关据建模技术，能够熟练使用Java、Scala、Python、Shell。3、熟悉 Hadoop/Hive/Spark/Hbase/Kafka/Flink 的体系架构和运行原理，有大数据处理方面经验。4、具有大型数据仓库和ETL开发、HIVE经验优先。5、熟悉机器学习算法（决策树、回归、聚类、预测，文本挖掘等），有推荐系统算法相关算法项目经验。6. 有较强的自学能力、钻研精神和动手能力，具有良好的逻辑思维能力、沟通能力和团队协作能力，做事认真、踏实、负责。,企业服务,2000人以上,spark,北京
大数据技术负责人,https://www.lagou.com/jobs/6652412.html,朝阳区,45k-50k,北京五八到家信息技术有限公司,5-10年,本科,强大平台、优厚薪资、扁平管理、六险一金,"工作职责：1、使用机器学习算法解决常见的业务问题，工作内容可能包括但不限于：预测技术、推荐算法、运筹优化、机器学习、仿真系统等2、数据挖掘、分析，通过对复杂业务或系统问题进行建模，分析影响系统的关键因素，规划、设计和实现新的解决方案，评估并优化模型3、分析商家接单行为并进行策略优化4、设计匹配模型，大幅提升业务成单率岗位要求：1、具有调度、推荐等相关业务经验2、统招本科或以上学历，计算机、数据挖掘、统计学、运筹学、机器学习或其他相关专业3、丰富的数据分析技能和相关经验，具备较好的英文阅读能力4、熟悉R/Python等编程语言，熟悉Hadoop, spark, Hive等大数据处理工具5、优秀的团队合作精神、诚实、勤奋、严谨",消费生活,2000人以上,spark,北京
算法专家,https://www.lagou.com/jobs/6494416.html,朝阳区,45k-50k,北京五八到家信息技术有限公司,5-10年,本科,强大平台、优厚薪资、扁平管理、六险一金,"工作职责：1、使用机器学习算法解决常见的业务问题，工作内容可能包括但不限于：预测技术、推荐算法、运筹优化、机器学习、仿真系统等2、数据挖掘、分析，通过对复杂业务或系统问题进行建模，分析影响系统的关键因素，规划、设计和实现新的解决方案，评估并优化模型3、分析商家接单行为并进行策略优化4、设计匹配模型，大幅提升业务成单率岗位要求：1、具有调度、推荐等相关业务经验2、统招本科或以上学历，计算机、数据挖掘、统计学、运筹学、机器学习或其他相关专业3、丰富的数据分析技能和相关经验，具备较好的英文阅读能力4、熟悉R/Python等编程语言，熟悉Hadoop, spark, Hive等大数据处理工具5、优秀的团队合作精神、诚实、勤奋、严谨",消费生活,2000人以上,spark,北京
大数据分析专家,https://www.lagou.com/jobs/7181866.html,东城区,25k-50k,前锦网络信息技术（上海）有限公司北京分公司,3-5年,硕士,稳定，待遇福利好,大数据分析专家工作内容1. 负责移动通信行业的数据挖掘、数学建模和智能化分析工作，通过机器学习、深度学习等人工智能技术，进行投诉用户预测、用户满意度分析等用户感知评估，进行网络质量波动分析、网络容量预测等网络趋势预测，对网络问题进行智能化定位分析等工作，解决目前网络面临的业务问题，实现用户感知提升；2. 牵头人工智能数据挖掘项目相关的技术方案、分析报告等，负责数据分析、数据挖掘前瞻技术在理论及互联网应用的跟踪与研究；3.负责人工智能团队建设，指导搭建人工智能平台，明确团队阶段性目标方向。任职资格1. 研究生及以上学历，计算机科学与应用、软件工程或其它相关专业优先； 2.具有3年及以上工作经验，其中2年及以上的相关开发和项目管理工作经验者优先；3. 有良好数学背景，具备优秀的代码编写能力，掌握扎实的人工智能、数据挖掘理论基础，精通各种机器学习、深度学习的算法与模型，并有较丰富的机器学习、深度学习建模的项目研发经验。熟悉hadoop数据平台架构下的海量数据处理、数据分析挖掘等工作；4. 熟练使用Python，Java、C++语言进行数据挖掘及数学建模；熟练掌握Hbase、Hive等数据库技术； 熟悉Hadoop、Spark、Storm等大数据平台；5. 有责任心，工作热情、耐心、踏实、严谨，有团队合作精神； 具备有很好的学习和逻辑能力，强烈的探索和求知欲，能迅速进行机器学习研究或探索新框架使用；6. 具备较强的学习、分析问题的能力，良好的团队合作意识与跨部门沟通的能力； 具备一定的抗压能力。,"移动互联网,企业服务",500-2000人,spark,北京
自然语言处理算法工程师,https://www.lagou.com/jobs/6880315.html,朝阳区,25k-50k,北京三快在线科技有限公司,3-5年,本科,大平台 广阔空间 重点项目,,消费生活,2000人以上,spark,北京
数据挖掘算法工程师,https://www.lagou.com/jobs/6880318.html,朝阳区,25k-50k,北京三快在线科技有限公司,3-5年,本科,大平台 主要项目 广阔空间,,消费生活,2000人以上,spark,北京
数仓建模工程师,https://www.lagou.com/jobs/6668882.html,海淀区,30k-38k,乐元素科技（北京）股份有限公司,5-10年,本科,高福利 六险一金 扁平化 百亿级平台,"工作职责：1、负责数据仓库建设，构建统一的数据仓库2、负责数据集市搭建，跟进业务需求3、负责业务应用开发、实施与测试4、参与平台数据产品建设，为数据产品提供数据岗位要求：1、计算机或相关专业，7年以上工作经验2、熟悉数据仓库常用建模理论3、熟悉数据仓库架构、元数据、数据质量保障等数据仓库主要环节；4、具有丰富数据模型设计和ETL开发相关经验；5、负责业务体系指标的梳理和建立，形成业务指标体系。6、熟练掌握HiveQL,shell，有丰富的实践经验7、掌握一门编程语言（java、python），了解hadoop、MapReduce、hive、spark等开源技术框架；","移动互联网,游戏",500-2000人,spark,北京
平台工程师-日志方向,https://www.lagou.com/jobs/7065557.html,朝阳区,20k-40k,北京玉符飞扬科技有限公司,3-5年,本科,FB大牛，追求卓越，双休，10天带薪年假,工作职责参与设计和实现高性能，高可用的统一日志系统，承载公司全部日志采集与分析需求;负责底层基础服务的架构设计，搭建与运维;打造智能与实时的日志分析与监控服务;负责用户日志与报表系统的开发与日常迭代;任职要求计算机或相关专业本科及以上学历;对分布式系统，对可靠、可扩展、可监控等原则有深入理解;熟悉ELK，有大规模使用、运维与调优经验者优先，有Lucene、Solr等有开发经验者优先;熟悉缓存、MQ 等中间件原理、架构设计;掌握Spark、Flink、Hadoop、Hive等一项或多项大数据技术者优先;有大规模日志系统构建经验者优先;,"信息安全,企业服务",50-150人,spark,北京
java高级开发工程师,https://www.lagou.com/jobs/7046165.html,海淀区,26k-36k,海尔集团,5-10年,本科,物联网平台前景好、薪资福利好、项目激励高,岗位职责：1.配合架构师进行AIoT PAAS平台架构设计2.负责核心代码实现以及指导中级、初级工程师完成开发任务，负责代码的编写与检查3.帮助团队其他成员解决技术问题，参与代码Review工作4.参与技术难点的攻关工作岗位要求：1.JAVA基础扎实，理解io、多线程、集合等基础框架，对JVM原理有一定的了解；2.5年及以上使用JAVA开发的经验，对于用过的开源框架，能了解到它的原理和机制；3.对spring，mybatis，kafka，spark，elasticsearch等开源框架熟悉者优先； 4.熟悉分布式系统的设计和应用，能对分布式常用技术进行合理应用，解决问题；5.掌握多线程及高性能的设计与编码及性能调优；有高并发应用开发经验优先；6.学习能力强，适应能力好；具备耐心细心的品质；7.我们希望你喜欢去看及尝试最新的技术，追求编写优雅的代码，从技术趋势和思路上能影响技术团队,"物联网,电商",2000人以上,spark,北京
广告算法工程师-杭州-【商业化】,https://www.lagou.com/jobs/6671695.html,海淀区,30k-60k,北京达佳互联信息技术有限公司,3-5年,本科,期权激励、大牛云集,职位描述1、负责百亿级规模广告系统模型和数据研发；2、以算法为导向，通过基础架构设计、流程优化、性能优化等技术手段解决大规模数据计算、存储及时效性问题；3、运用算法和数据手段，结合广告策略机制，优化广告投放效果。任职要求1、工作年限3～5年；2、有广告或算法经验，对算法实现和优化有深入了解；3、有java系统开发经验，熟悉常用中间件使用，熟悉常见大数据处理平台使用（如Flink、Spark、Hive等）。加分项1、有广告系统开发经验或对某一方面有深入理解（如广告匹配、竞价、排序、计费等）；2、有数据产品研发经验，熟悉研发流程，善于分析和解决业务问题。,文娱丨内容,2000人以上,spark,北京
大数据架构工程师,https://www.lagou.com/jobs/6018059.html,海淀区,20k-40k,北京达佳互联信息技术有限公司,3-5年,本科,"带薪年假,年度体检,免费午餐,弹性工作",工作内容：1、Hadoop生态子系统的研发、测试与优化工作，解决实际业务需求与性能问题。子系统包括但不限于HDFS，HBASE，YARN，SPARK，KAFKA等。2、承担数千台规模Hadoop集群的管理工作，解决超大规模Hadoop集群在应用与运行过程中的出现各种问题，保证集群的高效稳定运行。3、和开源社区保持交流，从社区引入对公司业务场景有帮助的特性与系统，或将内部研发的功能贡献到社区。任职要求：1、计算机或相关专业本科及以上学历。2、思维活跃，熟悉Hadoop生态子系统（至少一个），精读过源代码者尤佳，所开发代码被开源社区接受者尤佳。3、优秀的设计与编码能力，工程质量自我要求高，针对业务需求与问题，可快速设计与实现解决方案。4、很强的问题分析与解决能力，强烈的责任心，对工作有激情，良好的沟通能力。,文娱丨内容,2000人以上,spark,北京
数据仓库开发工程师/专家,https://www.lagou.com/jobs/6829564.html,海淀区,25k-50k,北京百家互联科技有限公司,3-5年,本科,年底双薪,岗位职责：1、参与公司整体数据仓库的建设，包括数据模型、数据仓库设计、实现和维护2、负责重点业务的数据支持，指标体系建设任职要求：1、统招本科或以上学历，计算机相关专业，3年以上工作经验2、熟悉数据仓库建模理论，有数据治理经验3、熟悉hadoop平台，有离线计算或实时计算开发经验4、熟悉hive、spark、flink、kylin、druid等一种或多种技术5、掌握shell、python等一种或多种脚本语言6、有数据治理经验优先，熟悉元数据,"移动互联网,教育",2000人以上,spark,北京
数据仓库负责人,https://www.lagou.com/jobs/7090772.html,昌平区,60k-100k,北京世纪好未来教育科技有限公司,不限,本科,大平台、好福利、大牛云集,"1、负责学而思网校数据治理、数据资产和数据仓库的规划、设计及建设工作，向各决策团队和业务部门提供数据服务，支持业务高速前进；2、制定数据管理规范和流程，统筹实施；建设数据指标体系和经营分析模型，提升数据文化、实现数据价值；3、设计开发数据仓库模型和服务架构，不断优化数据计算和访问性能，保证服务高质量稳定运行。""岗位要求：1、5-10年数据仓库模型、ETL的设计和开发经验，3年以上团队和项目主管经验（团队管理经验针对经理方向的要求）；2、熟悉海量数据的处理，精通 Hadoop/Hive，熟练掌握 Hbase/Spark/Storm 的工作原理及应用；精通至少一门编程语言，如Java、Python；良好的数据建模能力；3、计划、推进能力突出，质量意识卓越，业务理解力强；4、本科以上学历，目标驱动，积极果断，善于沟通合作和思考总结。",教育,2000人以上,spark,北京
大数据应用开发工程师,https://www.lagou.com/jobs/6979040.html,朝阳区,20k-30k,深圳市赢时胜信息技术股份有限公司,3-5年,本科,优秀团队 办公环境优越 交通便利,岗位职责：1、基于大数据平台的应用系统设计、开发、维护；2、承担公司大数据相关项目的需求分析、开发、实施、现场支持。任职资格：1、计算机或相关专业本科及以上学历；2、3年以上相关工作经验，至少熟练掌握Java，Scala，Python中的一种或多种；3、熟练使用Hadoop、Spark、Storm、SparkStreaming、Hive、HBase进行应用开发；4、熟悉搜索引擎，例如Impala，Presto，Elasticsearch等；5、具备基本的Hadoop运行环境的运维管理经验；6、有实际的大数据应用工程开发经验；7、熟悉金融领域相关知识或有金融系统开发经验的优先。,金融,500-2000人,spark,北京
高级算法工程师,https://www.lagou.com/jobs/7021075.html,海淀区,25k-40k,北京世纪好未来教育科技有限公司,3-5年,本科,上市公司 六险一金 下午茶 晚餐,岗位职责:负责营销体系用户增长，基于用户标签库+其他事业部用户行为数据，利用数据科学方法提炼优质特征数据，结合当前正负样本极度不均衡条件下，训练出优质线索意向度模型并能快速工程化部署实际生产环境中基于落地页海量用户行为数据，挖掘优质线索提供给销售团队跟进，线索回捞率不低于10%以创新思路构建科学的销售能力模型，具备可解释性、灵活性，销售能力排名准确性>=0.90，快速解决badcase将推荐系统相关经验迁移至线索匹配模型中，从线索召回、粗排、精排等环节，充分利于自身工作经验和业务场景，科学化提升线索签单率任职资格:1. 211或985院校本科及以上学历毕业生，实际有4-6年以上数据挖掘、机器学习经验2. 熟悉常用的机器学习算法（不限于LR/GDBT/XGB/SVM等），要精通原理、参与调优、公式推导，并在实际工作中有扎实的机器学习使用经验，更有独到见解等，最好能精通推荐领域算法（cf、embedding、ranking等）或者深度学习经验4. 熟悉常用的数据结构和算法，具有扎实的代码基础和较强的代码能力，熟练掌握常用的编程语言（不限于python、c++、java等）5. 熟悉 Spark、MapReduce 等并行编程模型，优秀的SQL能力，有实际的海量数据处理和挖掘的经验6. 能够在项目中采用创造性方法解决技术难题，并在业务中落地，取得较好的业务效果7. 具有一种韧劲和顽强精神，能够做到优秀、严谨、皮实、乐观，对工作上的挑战充满激情；,教育,2000人以上,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7200591.html,海淀区,20k-40k,北京拉勾网络技术有限公司,5-10年,不限,"发展空间大,弹性工作制,领导Nice",岗位要求：1、计算机或相关专业本科及以上学历，5年以上大数据运维或开发工作经验；2、熟悉linux开发环境，熟练掌握JAVA/GO/Python语言中的一种;3、熟练掌握大数据常用开源组件的技术原理，有现网的hadoop、kafka等开源大数据组件运维或开发经验；4、有较强的逻辑思维能力，思想上开放，主动积极有责任感，能够承担工作压力；有hadoop、kafka、spark、flink等开源组件源码优化经验优先；岗位职责：负责大数据平台消息中间件/Hadoop/实时计算/OLAP的运营支撑和架构优化。,企业服务,500-2000人,spark,北京
高级大数据开发工程师,https://www.lagou.com/jobs/7195249.html,海淀区,35k-40k,北京拉勾网络技术有限公司,5-10年,本科,"发展空间大,弹性工作制,领导Nice",岗位要求：1、计算机或相关专业本科及以上学历，5年以上大数据运维或开发工作经验；2、熟悉linux开发环境，熟练掌握JAVA/GO/Python语言中的一种;3、熟练掌握大数据常用开源组件的技术原理，有现网的hadoop、kafka等开源大数据组件运维或开发经验；4、有较强的逻辑思维能力，思想上开放，主动积极有责任感，能够承担工作压力；有hadoop、kafka、spark、flink等开源组件源码优化经验优先；岗位职责：负责大数据平台消息中间件/Hadoop/实时计算/OLAP的运营支撑和架构优化。,企业服务,500-2000人,spark,北京
智能硬件-高级大数据开发工程师,https://www.lagou.com/jobs/7118196.html,海淀区,20k-40k,北京搜狗科技发展有限公司,5-10年,本科,明星业务 团队氛围好,项目背景   搜狗AI硬件致力于以搜狗AI能力延展多场景，落地多终端智能硬件产品。涉及AI能力包括麦克阵列、语音识别、自然语言处理、图像识别、翻译、语音合成、搜索和问答等。横跨场景有个人随身、居家、车载等场景。产品矩阵包括翻译产品线、AI录音产品线、AI耳机产品线、糖猫儿童产品线等。随着AI技术的日趋智能化和产品场景的深挖拓展，AI+硬件将推出更多有价值，让获取和表达信息更简单的产品。岗位职责1、负责AI硬件事业部相关业务线内数据需求评估、技术方案和架构设计2、相关业务建模与业务数据支撑，包括但不限于数据清洗、数据仓库构建、数据模型建立，数据报表等工作3、负责相关算法、用户画像等方面研究和实现4、关注业内技术动态，解决实际场景中的问题，优化技术方案任职资格1、统招本科及以上学历，计算机相关专业，4年以上大数据开发经验2、熟悉hadoop\hive\spark\flume\ES等相关大数据技术或组件3、熟悉java、python、sql、shell、scala等编程语言4、有大数据数据开发、数据分析相关项目经验5、有责任心和上进心，且比较细心6、有数据挖掘、算法、统计分析相关经验优先,工具,2000人以上,spark,北京
高级后台开发工程师,https://www.lagou.com/jobs/7085478.html,海淀区,30k-45k,腾讯科技（深圳）有限公司,3-5年,本科,大平台,1.职责：负责腾讯云-区块链业务后台开发，负责微服务架构及组件开发，高并发服务开发、监控系统开发、海量数据处理集群建设。2.要求：具备3年以上开发经验，本科以上学历；精通JAVA，C/C++开发；熟悉TCP/IP协议，Linux/Windows操作系统及常见应用层协议；理解微服务架构体系，具有传统架构向微服务改造的实践经验优先；对各种开源的框架如Spring、MyBatis等有深入的了解，对微服务、SOA、RPC等框架本身有过开发或重构者可优先考虑；对于Cache、消息中间件、队列、分布式锁、对象存储等组件框架有熟练的实践经验。有运维自动化、监控系统、发布系统、运营支撑系统等开发经验者优先；有海量数据处理相关开发经验者优先，如 Hadoop、Storm、Spark等；具有良好的学习能力、沟通能力、团队合作意识；强烈的责任心与主动性，对所负责工作有owner意识，并能自我驱动成长。,社交,2000人以上,spark,北京
自动驾驶仿真模拟系统后台开发,https://www.lagou.com/jobs/7102591.html,海淀区,40k-60k,腾讯科技（深圳）有限公司,5-10年,本科,领导nice 创新项目,"工作职责：参与仿真云平台的架构设计与研发工作,  开发与维护web端/数据处理端的核心代码；深入理解业务, 具有产品思维, 愿意从技术的角度和设计人员不断提升产品体验；持续提升系统在大规模分布式环境下的稳定性,安全性,性能以及架构, 对技术有追求, 愿意钻研技术；工作要求：计算机相关专业本科以上学历，3年以上开发工作经验；熟悉java，并至少熟悉一门脚本语言（python/shell/go）熟悉分布式业务系统的设计与开发，2年以上基于Spring、Dubbo、mybatis等主流框架开发经验；扎实的编程基础，对各层常用开源的框架有深入的了解，对框架本身有过开发或重构者可优先考虑；熟悉MySQL、Redis、HBase等主流数据库的使用；熟练使用分布式消息队列, 至少熟悉Kafka/RabbitMQ/RocketMQ/AWS SQS中的一种熟练使用分布式缓存系统, 至少熟悉Memcached/Redis/Ehcache中的一种熟悉常见大数据基础组件的使用、原理、调优者优先，如Flume、Hadoop、Hbase、Spark、Storm、ELK、ETL；熟悉k8s相关docker技术的优先；具备良好的分析解决问题能力，能独立承担任务和有系统进度把控能力，责任心强，良好的对外沟通和团队协作能力；",社交,2000人以上,spark,北京
高级Java开发工程师（监控）,https://www.lagou.com/jobs/6936312.html,西城区,25k-50k,网联清算有限公司,5-10年,本科,金融业务,岗位职责1、负责公司监控、流式计算、告警平台技术选型和底层架构设计的战略规划，带领团队完成有质变的技术解决方案和技术特性；2、负责开展监控、告警平台整体评估、架构和关键模块的开发；3、对实时流式计算平台建设有很深的理解，突破现有技术难题；4、负责新技术的调研，并能在团队进行推广应用；5、能进行组内外的合作协调。任职资格1、全日制本科及以上学历，计算机或相关专业，5年以上工作经验； 2、具有扎实的Java、大数据或python编程能力，精通数据结构和算法；3、熟悉分布式系统的监控、告警，高可用原理和设计理念；4、技术栈比较全面，精通流式计算spark streaming，包含flink，storm，kafka等，需要有对开源软件有二次开发经验；5、熟练掌握基本的Linux操作系统和某种脚本语言编程（如Shell等）；6、有丰富的团队管理经验；7、热爱技术专研探索，精读某些开源软件源码者优先；8、具有监控、告警、流式计算平台建设经验优先。,金融,150-500人,spark,北京
搜索算法专家,https://www.lagou.com/jobs/6820197.html,大兴区,40k-70k,达疆网络科技（上海）有限公司,5-10年,本科,五险一金；自带电脑有补贴；5-10天年假,工作职责： 1、负责公司搜索算法重构和优化工作，参与搜索框架设计与性能优化； 2、负责搜索意图识别优化，对query进行模型纠错、概率扩展、规范化改写并对意图识别有效性进行评估，对少结果无结果进行效果优化； 3、负责上位词、下位词、实体词挖掘并建立品牌、地址、类目、关键词词典。 4、 负责对商品进行匹配、分类、聚类，生成商品标签、推荐语等； 5、 参与ES索引性能优化 岗位要求： 1、计算机或相关专业，大学本科及以上学历； 2、4年及以上搜索业务开发经验，扎实算法基本功，熟悉主流机器学习和文本挖掘算法； 3、熟悉java、Python等流行编程语言，熟悉tf、pytorch等框架，编程能力强。 4、对大数据相关工具 Hadoop，Spark，Storm，Hbase等有实际使用经验； 5、有搜索、推荐或广告等行业背景优先。 6、具备机器学习、自然语言处理、深度学习和良好的实践经验背景者优先。,消费生活,2000人以上,spark,北京
推荐与搜索 Java 高级/资深工程师,https://www.lagou.com/jobs/6665768.html,大兴区,25k-50k,达疆网络科技（上海）有限公司,5-10年,本科,五险一金；自带电脑有补贴；5-10天年假,职位类型：推荐与搜索 Java 高级/资深工程师职位描述：1、负责推荐系统相关服务的开发和维护，负责重点项目的设计与评审，难点攻关。2、负责检索引擎架构设计与产品开发等工作，熟悉检索引擎es\solr等，具备一定使用经验。任职要求1，统招本科以上学历，计算机、软件相关专业；2、对hadoop、hbase、hive、spark、storm、flume等分布式计算框架或其它开源技术有实践经验；3、五年以上java开发的经验，精通aop、mvc等框架。4、具有较强的沟通能力、分析能力与学习能力，具有团队合作精神。具备团队管理经验优先。,消费生活,2000人以上,spark,北京
大数据算法工程师,https://www.lagou.com/jobs/6986339.html,东城区,30k-60k,北京默契破冰科技有限公司,5-10年,本科,"七险一金,弹性不打卡,免费午餐,季度旅游",岗位描述：1、基于大数据平台，挖掘用户相关的信息，构建用户数据服务平台；2、通过对用户行为数据的挖掘，对用户进行建模，精准刻画用户各种属性；3、负责用户画像方向的数据研发、算法研究、关键问题解决；4、负责个性化推荐系统的研发，构建基于用户行为和喜好的内容推荐系统；5、促进用户画像在公司各业务领域的应用，持续提升用户产品体验。岗位要求：1、本科学历，计算机、数据科学等相关专业，5年以上工作经验；2、熟练掌握数据挖掘、机器学习的基础理论和方法，有用户画像、推荐系统实战经验；3、有处理海量数据的丰富经验，能使用Hadoop、Spark系统进行海量数据处理，并完成性能调优；4、编程基础扎实，熟悉算法数据结构，有丰富的开发调试经验；,社交,150-500人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6986318.html,东城区,30k-60k,北京默契破冰科技有限公司,5-10年,本科,"七险一金,弹性不打卡,免费午餐,季度旅游",岗位描述：1、参与大数据平台建设，完成大规模数据存储设计、实现；2、负责大数据采集、处理、转换、分析、业务需求等相关开发；3、设计面向业务的OLAP，完成企业级数仓的建设；4、负责大数据作业优化及质量保障；5、参与大数据系统及应用架构设计及新技术调研。岗位要求：1、本科学历，计算机、数据科学等与大数据相关专业，5年以上工作经验；2、精通Hadoop相关技术，包括Spark，Hbase，HDFS，Hive，Yarn，Kafka，Flume，Spark、Flink，Storm等；3、精通java、scala开发语言，精通SQL，熟悉MySQL，熟悉shell，python等脚本语言，熟悉git，jira等工具；4、具有优秀的开发规范意识，对大数据技术和开发有热情，工作认真负责，有较强的学习能力和团队合作意识；5、参与过数据处理、分析、挖掘等相关项目，熟悉阿里云日志系统。,社交,150-500人,spark,北京
数据挖掘工程师（社交关系模型方向）,https://www.lagou.com/jobs/5824202.html,海淀区,15k-30k,北京微聚未来科技有限公司,1-3年,本科,七险一金、15-20薪、牛人团队,职位描述：  1. 基于微博复杂的社交关系数据，搭建微博用户的社交关系模型（包含但不限于TrustRank，图模型等），利用复杂网络知识，识别风险团伙、制定反欺诈规则或进行风险传播的量化评估；  2. 基于微博海量用户数据和特征，发现用户属性，建立数据挖掘模型，对用户进行评估，包括但不限于：用户风险评估、用户价值评估、用户偏好预测、用户个性化推荐等；  3. 评估数据源的质量和价值，能结合业务需求和场景，从各种数据维度中挖掘数据价值，并设计不同的模型，应用于不同的业务场景中。岗位要求：  1. 计算机，数学等相关专业本科及以上学历。 2年以上建数据挖掘相关工作经验，具有金融业或互联网信用风险、精准营销等数据挖掘完整项目经验者优先；  2. 熟悉基本的数据挖掘模型算法（如逻辑回归，GBDT等），熟悉图数据库，知识图谱，复杂网络相关知识和经验者优先；  3. 能熟练使用Java/Python/Scala等一门或多门语言，熟悉大数据分析平台及分布式计算，如Hive，Spark等；  4. 具备优秀的团队协作意识和沟通表达能力，有很强的自我驱动与结果导向意识。,"移动互联网,金融",500-2000人,spark,北京
大数据研发工程师,https://www.lagou.com/jobs/5623562.html,海淀区,20k-40k,北京微聚未来科技有限公司,3-5年,本科,"牛人团队,带薪年假,16薪考核,快速成长",1，主要负责用户画像、运营平台、推荐等相关数据应用产品设计、研发2，增强、完善大数据到数据价值应用的桥接功能3，保障系统高性能、高质量、完全运行4，提升数据对业务的价值产出和创新能力职位要求：1，精通java，熟悉java web开发；掌握scala、python等任一语言2，对开源框架Spring cloud、kafka、zk、redis、Hbase等有实际应用经验，并能熟练应用3，熟悉至少一种流计算框架，如Spark、Flink等4，熟悉主流基于大数据的sql引擎，如impala、presto、clickhouse、hive等5，有用户画像、BI平台、推荐系统实际项目研发经验优先6，能够自驱，有创新意识，对数据价值应用思路清晰,"移动互联网,金融",500-2000人,spark,北京
大数据平台研发工程师,https://www.lagou.com/jobs/6853021.html,朝阳区,20k-25k,奇虎360科技有限公司,3-5年,不限,发展空间,职位描述：• 负责数据仓库设计、数据梳理治理、流程优化和数据质量保障；• 参与大数据平台系统的搭建和重构，提高其易维护性、稳定性、可用性、吞吐量和效率等；• 满足上层数据运营体系、OLAP、数据挖掘等需求；职位要求：• 计算机或相关专业本科毕业，3年以上工作经验；• 熟悉Linux开发环境，掌握JAVA/GO/Python任意一门语言；• 熟悉Hadoop，Spark，Flink等大数据平台；• 有实际使用Hive/MR/Spark处理大数据相关问题的经验，具备丰富的性能调优经验；• 熟悉常见数据库的体系结构、存储架构等；对RDBS和Nosql有深刻的认识；• 具备较强的学习能力和自我管理能力，性格积极乐观，有一定的抗压能力；,信息安全,2000人以上,spark,北京
高级/资深大数据开发工程师,https://www.lagou.com/jobs/7029691.html,朝阳区,20k-40k,雪球（北京）技术开发有限公司,3-5年,本科,金融科技 年轻有活力 扁平化管理,1.大数据中台实时能力加强。2.大数据中台用户画像能力加强。3.大数据中台对外输出模型丰富，如漏斗，留存，多维数据集等。4.应用hadoop分布式技术解决性能，存储，计算等问题，具备通用能力抽取，设计和实现的技能。5.具备机器学习能力，能够沉淀简单的机器学习模型到数据中台，对外输出通用模型的分析数据，以供社区头条等提供二次机器学习加工的能力，简化机器学习里最为繁锁的数据清洗和基础特征挖掘的重复劳动，极大提高算法工程师效率。任职要求1.本科以上学历（211/985优先），计算机或数学相关专业，至少具备三年以上的工作经验。2.熟悉Java和python语言。3.熟悉Hadoop/HBase/Spark/Storm/Hive/flink/HDFS/presto/kafka等相关技术。4.聪明，积极，善于发现问题，并有独立解决问题的能力。5.精通数据结构和常用的算法，有很强的编程能力。6.对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先.。7.具备机器学习能力，数据平台，数据仓库经验优先。8.拥有实战大数据处理技术者优先。,金融,150-500人,spark,北京
广告算法工程师,https://www.lagou.com/jobs/6524785.html,朝阳区,35k-50k,奇虎360科技有限公司,3-5年,本科,核心团队，广告业务,关于360推广：为8亿用户提供更安全便捷的信息服务，为全球近百万领先企业实现营销效能的全面提升这就是全国领先的全场景智能营销平台-360推广，负责360集团商业化的全场景营销平台 360移动广告：360移动广告是360推广近几年重点发力方向，负责360集团所有移动端产品的流量变现，包括但不限于360手机卫士，360手机助手，360手机浏览器，清理大量，影视大全，花椒，快视频等App360移动广告每天负责百亿展示机会的变现，投放系统和算法模型在这里有足够的挑战，也有足够的优化空间。每天系统的投放都会影响上10亿用户的体验。所做的系统和算法的每次优化，都能产生巨大的价值 如果你对计算广告和商业变现有足够的兴趣，请加入我们：在这里，我们可以提供：1) 互联网最有影响力、也最有技术挑战性的商业项目，让你的想法能够落地，产生商业价值2) 百亿级展示，10亿级用户，海量数据处理，足够好玩的机会3) 行业非常资深的、有影响力的导师指导，很多非常优秀聪明的同事合作4) 广阔的发展空间，个人成长，薪资待遇，包括薪资、职位等 招聘需求：(一)高级算法工程师-广告推荐方向负责推荐算法设计及实现，对亿级用户精准推荐感兴趣的广告基本要求：1) 本科及以上学历，对推荐系统及广告触发有基本了解2) 掌握常用推荐算法，包括SVD/协同过滤等3) 了解用户行为分析，包括用户的分类，标签挖掘等4) 有过推荐算法实施经验优先5) 熟悉掌握 Spark/Hadoop 优先，熟悉Deep Learning及掌握TensorFlow，Caffe，MXNet等其一者优先 (二)高级算法工程师-广告点击率预估方向负责CTR Model设计和Feature 的挖掘，从海量数据中提取最相关的Feature刻画用户对广告点击的Probability的问题，负责广告排序及用户体验策略研究和实现基本要求：1) 本科及以上学历，对CTR/CVR等问题有基本的了解2) 有较为丰富的CTR feature engineering方面的经验3) 扎实的Machine Learning基本功，包括常用算法如：Logistic Regression、SVM、GBDT、Topic Model、L1/L2 等4) 对Optimization有一定的基础和了解，如SGD、 L-BFGS等5) 具备优秀的逻辑思维能力，对解决挑战性问题充满热情，善于解决问题和分析问题6) 熟悉掌握 Spark/Hadoop 优先，熟悉Deep Learning及掌握TensorFlow，Caffe，MXNet等其一者优先(三)算法工程师-广告反作弊方向负责广告反作弊系统的系统设计及策略优化，分析与挖掘各种潜在关联，从而不断优化反作弊效果，更好地识别作弊流量，保障客户利益和公司长远健康发展基本要求：1) 熟悉机器学习、数据挖掘、数据分析、分布式计算等某一方面，有理论研究和实践经验2) 熟悉随机过程以及概率分布，熟悉抽样理论3) 具备优秀的逻辑思维能力，对解决挑战性问题充满热情，善于解决问题和分析问题4) 本科及以上学历，有互联网相关反作弊工作经验者优先,信息安全,2000人以上,spark,北京
计算广告算法专家,https://www.lagou.com/jobs/6684490.html,海淀区,40k-50k,北京车之家信息技术有限公司,3-5年,本科,大平台 发展空间大,岗位职责：负责广告算法策略的研究、设计与实现，提升广告投放的效果。岗位要求：1. 计算机相关专业硕士研究生及以上学历，至少有3年的广告系统的相关技术经验；2. 具有扎实的数据结构和算法功底，熟悉自然语言处理、机器学习等AI技术；3. 有海量数据处理经验，熟悉Hadoop，Spark等；4. 有较强的学习能力，逻辑思维能力，具有良好的分析问题解决问题的能力；5. 善于沟通，责任心强，工作积极主动，有管理经验者优先。,汽车丨出行,2000人以上,spark,北京
平台工程师-日志方向,https://www.lagou.com/jobs/7065459.html,朝阳区,30k-40k,北京玉符飞扬科技有限公司,5-10年,本科,FB大牛，追求卓越，双休，10天带薪年假,工作职责参与设计和实现高性能，高可用的统一日志系统，承载公司全部日志采集与分析需求;负责底层基础服务的架构设计，搭建与运维;打造智能与实时的日志分析与监控服务;负责用户日志与报表系统的开发与日常迭代;任职要求计算机或相关专业本科及以上学历;对分布式系统，对可靠、可扩展、可监控等原则有深入理解;熟悉ELK，有大规模使用、运维与调优经验者优先，有Lucene、Solr等有开发经验者优先;熟悉缓存、MQ 等中间件原理、架构设计;掌握Spark、Flink、Hadoop、Hive等一项或多项大数据技术者优先;有大规模日志系统构建经验者优先;,"信息安全,企业服务",50-150人,spark,北京
推荐算法工程师（2020届校招）,https://www.lagou.com/jobs/6788302.html,海淀区,10k-18k,同方知网（北京）技术有限公司,不限,硕士,解决户口、提供食宿、六险二金,,"移动互联网,电商",2000人以上,spark,北京
广告算法工程师（策略机制）,https://www.lagou.com/jobs/6395697.html,朝阳区,20k-40k,OPPO广东移动通信有限公司,3-5年,本科,福利待遇好,1、负责OPPO用户画像体系构建、广告定向系统优化2、参与OPPO营销平台DMP系统的建设与优化 3、负责用户画像在产品运营/广告/大数据产品等场景的应用，如人群定向、lookalike人群扩展、数据分析等1、计算机或相关专业本科以上学历，熟练掌握数据挖掘、机器学习和深度学习的基础理论和方法，3年及以上工作经验；2、具备优秀的编码能力，有主导中型以上项目开发经验，语言不限； 3、熟悉hadoop大数据生态，掌握分布式计算框架（如map/reduce、RDD）思想，熟悉Spark ML开发优先； 4、熟悉常用数据挖掘和机器学习算法及应用实践，尤其熟悉深度学习在NLP上的应用者优先 5、参与过用户画像系统或广告DMP系统的开发，有大型广告系统的人群定向工作经验的优先；6、优秀的协作力、推动力、以及分析问题和解决问题的能力，对解决具有挑战性问题充满激情；,硬件,2000人以上,spark,北京
测试开发工程师-JS,https://www.lagou.com/jobs/5377638.html,东城区,15k-30k,北京轻松筹网络科技有限公司,3-5年,本科,技术大咖 五险一金 绩效奖金,职位描述：1. 参与产品需求与研发技术方案评审，从质量角度评估需求与整体技术架构的合理性以及相关的可测性；2. 参与制定测试计划，设计测试用例，组织测试用例评审，执行功能测试、自动化测试与性能测试；3. 制定合理高效的测试方案，按照测试管理流程，对产品进行测试，跟踪应用缺陷直至符合发布标准；4. 根据项目特点，不断优化测试方案及产品发布迭代流程，开发测试工具或自动化解决方案，提高测试效率和质量；任职要求：任职要求：1. 对软件测试有浓厚的兴趣和丰富的经验，有很强的分析能力和问题定位的能力，突出的沟通与推动能力；2. 有很强的质量改进意识，能针对质量问题进行调研、分析、设计、研发、评估3. 熟练地应用Python/GO/Java等开发语中的一种或多种语言进行开发的能力；4.熟悉Hadoop、Spark、HBase、Kafka等工作原理者优先；5. 熟悉LoadRunner、Jmeter等性能测试工具的原理，开发性能测试脚本，完成测试报告并对结果进行分析；6. 熟练使用MySQL/Redis等数据库，熟练掌握Linux操作命令，有shell脚本编写能力；7. 善于沉淀通用测试解决方案，有过测试框架开发或在某一测试领域如性能、自动化、大数据测试等具备很强的专业技能者优先；8. 较强的学习能力和技术钻研能力，积极主动，自驱力强，良好的沟通能力，善于团队合作,"移动互联网,金融",500-2000人,spark,北京
资深Java开发工程师,https://www.lagou.com/jobs/6936352.html,西城区,25k-40k,网联清算有限公司,5-10年,本科,团队氛围好、牛人、福利好,岗位职责     1、负责公司监控、流式计算、告警平台技术选型和底层架构设计的战略规划，带领团队完成有质变的技术解决方案和技术特性；     2、负责开展监控、告警平台整体评估、架构和关键模块的开发；     3、对实时流式计算平台建设有很深的理解，突破现有技术难题；     4、负责新技术的调研，并能在团队进行推广应用；     5、能进行组内外的合作协调。          任职资格     1、全日制统招本科及以上学历，985/211优先，计算机或相关专业，5年以上工作经验；      2、具有扎实的Java、大数据或python编程能力，精通数据结构和算法；     3、熟悉分布式系统的监控、告警，高可用原理和设计理念；     4、技术栈比较全面，精通流式计算spark streaming，包含flink，storm，kafka等，需要有对开源软件有二次开发经验；     5、熟练掌握基本的Linux操作系统和某种脚本语言编程（如Shell等）；     6、有丰富的团队管理经验；     7、热爱技术专研探索，精读某些开源软件源码者优先；     8、具有监控、告警、流式计算平台建设经验优先。,金融,150-500人,spark,北京
架构师java,https://www.lagou.com/jobs/7218760.html,朝阳区,30k-35k,奇秦科技（北京）股份有限公司,10年以上,本科,扁平化管理，团队年轻化，不用打卡,北京需求 （1）数据架构师（Data Architect） 职位描述：  负责客户大数据平台的咨询  负责大数据平台架构和方案的设计  负责大数据平台的开发指导 专业技能：  10年以上数据平台设计和开发经验  熟悉MDM、Data Governance、ESB等领域的项目实施，熟悉各类数主流据库平台的集成  熟悉Hadoop、Spark、Hive、Hbase、Storm、Kafka、Zookeeper、Linux、Java等  （2）CRM架构师（CRM Architect）职位描述：  负责CRM相关应用系统的咨询  负责技术架构和方案的设计  负责应用的开发指导专业技能：  10年以上Java应用设计和开发经验  具有5年以上客户管理、全渠道营销、会员积分和消费行为洞察、O2O等企业级应用系统的设计和开发经验  熟悉Linux、J2EE、javascript、HTML、XML、Web Services、RESTful、Spring、Hibernate、JSON等  熟悉MySql、Redis、MangoDB、或者其它主流据库平台等,软件开发,500-2000人,spark,北京
推荐算法工程师,https://www.lagou.com/jobs/6969644.html,海淀区,30k-60k,北京小米科技有限责任公司,5-10年,不限,"周末双休,餐补,弹性工作制，六险一金","工作职责1、通过数据挖掘和机器学习算法对用户兴趣偏好、画像建模，商品知识图谱，提升产品的用户体验，增加用户的粘性，提升用户价值；2、 广告机制的研究，广告转化和变现效果优化；3、 CTR,点击率预估、转化率预估和生态闭环建设；4、 深度神经网络、深度增强学习模型的设计、优化、应用和业界前沿算法研究；5、 参与项目产品设计以及代码review，指导初级工程师工作任职资格1、熟悉常用的机器学习算法，例如GBDT、LR、LTR，深度学习等；2、熟悉常用的特征工程方法；3、熟练掌握Python,Scala,C++ 中一门编程语言，有使用hadoop/spark/mpi 或其他类似系统的经验4、责任心强，有快速学习的能力。5、 熟悉Spark等分布式机器学习框架，熟悉Hadoop/HBase/Hive等大数据处理平台6、 优秀的沟通能力，有创新精神，乐于接受挑战，能承受工作压力工作地址",硬件,2000人以上,spark,北京
广告策略分析师/广告数据挖掘师,https://www.lagou.com/jobs/7213113.html,海淀区,25k-50k,北京小米科技有限责任公司,3-5年,本科,"六险一金,周末双休,餐补,弹性工作制",岗位描述：负责广告投放的策略、机制，以优化广告投放的效果，提升平台价值。针对不同广告主的差异，设计相应的策略，提升广告主获取流量的能力，提升广告主价值。分析广告投放的数据，建立优化的方法和策略效果的监控岗位要求：计算机相关专业，本科以上学历，有扎实的算法和数据结构等基础知识。熟悉机器学习、数据挖掘等理论知识，有大数据相关经验，熟悉spark/hadoop/hive中的至少一种。有广告行业相关经验优先。善于学习，有良好的逻辑能力、沟通能力。对数据敏感，了解业务需求，能够分析问题和数据，推进解决业务问题。,硬件,2000人以上,spark,北京
资深数据产品经理,https://www.lagou.com/jobs/7092656.html,海淀区,30k-50k,北京百家互联科技有限公司,5-10年,本科,免费班车；餐补；商业保险,岗位职责1.基于对业务的深入理解，为业务和产品提供数据决策支持和解决方案；2.通过对产品业务的研究分析，搭建相关数据指标体系，在业务洞察、用户洞察、结果归因、精细化运营等方面通过数据驱动产品业务发展；3.负责相关业务产品部门的数据工作，包括业务指标管理，元数据维护、数据可视化、数据质量监控、需求对接、数据提取和计算等；4.完成产品的策划、原型、流程和交互设计；协调业务部门、研发团队，推进产品化进程；关注产品的用户体验，掌握数据和场景的变化，持续优化已有的产品功能。任职资格： 1.本科及以上学历，5年及以上数据产品或数据分析经验；2.善于沟通，具有服务意识，良好的团队合作精神，具备较强的项目管理经验；3.对数据敏感，逻辑性强，有一定的数据统计和运营分析能力；4.熟悉运用SQL，对前端BI、底层DB有深入的了解，能够独立完成基础数据的探查工作，掌握Hive，spark等大数据工具者优先；5.熟练使用Axure，Xmind，Excel，PPT等产品工具。,"移动互联网,教育",2000人以上,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7005187.html,海淀区,20k-35k,北京音娱时光科技有限公司,3-5年,本科,团队优秀；海外市场；免费餐饮；租房津贴；,岗位职责：1、基于对公司业务的广泛理解，负责各个业务模块的数据提取和报表开发；2、跟进维护大数据平台软件栈的技术发展，围绕业务需求作合适的选型及开发；3、能够全局性地理解数据仓库及业务数据，整合需求，为业务方提供系统化、可持续的数据解决方案。任职资格:1、重点统招本科及以上学历; 2、有扎实的计算机基础，熟悉常用数据结构、算法、设计模式；3、熟悉hadoop、hive、hbase、spark等大数据开源工具的架构;了解数据仓库建设的基本思路; 4、精通hivesql，有丰富的hivesql性能调优经验;掌握python脚本语言; 5、具备出色的需求分析能力及快速学习能力，能深入理解复杂的业务逻辑; 6、具备良好的团队合作精神，具备出色的沟通能力。,移动互联网,50-150人,spark,北京
大数据开发工程师—基础研发 (MJ004565),https://www.lagou.com/jobs/7218199.html,海淀区,20k-35k,北京趣拿软件科技有限公司,3-5年,本科,十天年假、十天全薪病假,职位详情1. 负责去哪儿网大数据处理pipeline的开发和维护2. 负责业务实时数据的接入和数据服务的开发、多维度分析和展现任职要求1. 本科或以上，计算机或相关专业毕业2. 扎实的编程能力，熟悉算法和数据结构，熟悉计算机的基础理论3. 熟练使用Java，熟悉python、shell4. 熟练使用大数据处理组件，包括但不限于Flink，Spark，Kafka，Kylin，ES，Presto，Impala，Hadoop，Hive等组件5. 有实时大数据处理经验，并有深刻了解的优先6. 能有良好的产品思路，从技术角度解决产品问题,旅游,2000人以上,spark,北京
数据开发工程师,https://www.lagou.com/jobs/7218647.html,朝阳区,20k-30k,北京健康之家科技有限公司,3-5年,本科,千人规模、产品知名、定期体检、六险一金,"岗位职责：1. 负责大数据数仓工具建设：调度系统,元数据管理，数据质量2. 负责大数据基础设施建设：kafka管理工具，hbase管理工具，flink管理工具等3. 优化平台架构,提升平台稳定性任职资格：1. 统招本科以上，计算机相关专业，Java 基础扎实，强大的写码能力2. 精通面向对象设计开发，对部分 Java 技术有深入研究，研究过优秀开源软件的源码并有心得者优先3. 熟悉常见设计模式，精通 SpringBoot框架、熟练使用至少一种 ORM 框架如 Hibernate、MyBatis4. 了解Elasticsearch、Zookeeper、Hadoop、Hbase、Hive、kafka,hdfs原理及使用，有基于Zookeeper的分布式系统开发经验优先5. 有spark相关开发经验，有基于spark实现数据同步开发经验优先6. 3年以上数据开发经验，学习能力强，较好的沟通能力","移动互联网,医疗丨健康",2000人以上,spark,北京
研发工程师（大数据方向）(J10568),https://www.lagou.com/jobs/7048423.html,海淀区,15k-25k,北京易车互联信息技术有限公司,1-3年,本科,大平台，职业发展，福利,,"移动互联网,电商",2000人以上,spark,北京
高级/资深数据工程师,https://www.lagou.com/jobs/5081860.html,朝阳区,30k-60k,北京思维造物信息科技有限公司,3-5年,本科,"大咖云集,氛围极好,六险一金",1：参与得到大数据平台建设，包括技术选型、架构设计、工程开发、集群运维等；2：基于开源大数据架构定制开发，建立特定规划的大数据基础架构体系；3：参与OLAP/OLTP数据产品研发，提升数据产品性能和稳定性，跨团队协作，为上层应用和产品决策提供持续、高效、稳定的数据支撑职位要求：1：5年以上开发经验，3年以上大数据工程开发经验，深入理解数据工程全生命周期；2：掌握大数据生态圈主流技术，包括HDFS、YARN、HBase、Hive、Impala、Spark、Kafka、Zookeeper、Azkaban、ELK、Flink、Druid、Kudu、Presto等；3：对使用过的架构和技术有原理上的深度理解，对性能优化和稳定性提升有一线实战经验；4：具有扎实的Java基础，熟悉常用设计模式，掌握J2EE体系结构，熟练使用SpringBoot、SSM、Mysql、Redis、Docker等进行服务端开发；5：思维清晰，性格open，自我驱动。,"移动互联网,文娱丨内容",150-500人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7045440.html,海淀区,30k-60k,上海基分文化传播有限公司,3-5年,本科,领导nice ，氛围好,岗位名称：大数据开发工程师职位描述1、负责趣头条数据中台，全公司各类业务数据仓库的构建；2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；3、负责构建用户主题、各业务线主题、推荐主题、广告主题、数据门户系统；4、负责各产品线数据维护，提升数据资产质量。职位要求1、计算机、数学相关专业本科及以上学历，2年以上大数据开发工作经验；2、 深入理解常用的数据建模理论，可独立把控数据仓库的各层级设计；有数据挖掘，机器学习，推荐相关经验优先；3、熟悉Aerospike和Clickhouse的同学优先考虑，熟练掌握Hive/SQL，熟悉Spark/Map-Reduce分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；4、有产品sense，主动思考基于业务场景下的数据体系建设，而不单单只会做执行；5、工作认真，负责，良好的团队合作精神和解决问题分析能力，钻研技术克服困难，勇于挑战。,文娱丨内容,500-2000人,spark,北京
广告数据科学家,https://www.lagou.com/jobs/7174747.html,海淀区,25k-50k,北京字节跳动科技有限公司,3-5年,本科,"团队氛围好,扁平管理,用户过亿",,文娱丨内容,2000人以上,spark,北京
大数据LeaderG00069,https://www.lagou.com/jobs/7191384.html,朝阳区,50k-80k,北京莱熙科技有限公司,5-10年,本科,薪资高,建立全链路行为的数据采集分析平台，运用数据分析和数据挖掘技术，为公司产品和业务实现数据驱动、数据决策、数据赋能： 1、全面负责大数据平台的规划和搭建、平台的日常运营和优化、数据维护、数据产品、算法和计算 2、人工智能中数据平台的方案设计，能够基于用户数据对人物画像等提出独到的见解 3、参与基于大数据平台的创新业务场景、数据产品的设计，负责数据产品的研发交付 4、带领团队完成大数据平台的日常运营工作，为数据分析和展现提供支援 5、制订数据质量标准，管控数据变更流程，管理数据资产，确保数据安全 6、及时跟进大数据架构领域新技术并分享，带领团队成长 7、基于数据洞察和业务理解，制定和实施实现公司业务增长和用户增长的方案和策略，包括： • 优化营销策略，降低获客成本； • 优化运营策略，提升用户留存； • 提供产品改进策略和AB TEST方案，指导产品改造； • 优化用户匹配，推荐，提升产品收入； • 制定用户定价模型； • 构建用户画像；8、 团队成员的搭建与培养，任务划分，进度监控，代码规范，质量保证 岗位要求：1.计算机、数学、统计学相关专业本科或硕士以上学历，8年以上分布式系统及大数据相关研发经验经验，5年以上团队管理经验 2.熟悉大数据相关计算引擎，如 Spark，Mapreduce，Hive，Impala，Druid，kylin等等，有相关引擎的优化 3.拥有5年以上Hive/HBase开发设计和实施经验并具有至少3年以上产品项目应用研发实战经验4.业界领先的大数据方案，对源码的深入研究和开发优化，丰富的业务场景和挑战 5.有优秀的业务理解能力，能理解清楚业务并进行合理的模块和架构设计6.深度关注业务，强烈的责任感及owner意识,移动互联网,50-150人,spark,北京
大数据架构师-共享(J10558),https://www.lagou.com/jobs/7024784.html,海淀区,25k-45k,北京易车互联信息技术有限公司,5-10年,本科,平台大，福利待遇好；发展前景好,,"移动互联网,电商",2000人以上,spark,北京
大数据平台工程师,https://www.lagou.com/jobs/6246543.html,西城区,15k-30k,北京多来点信息技术有限公司,3-5年,本科,带薪年假 专业培训 五险 双休,大数据平台工程师职责描述：1、负责数据开发平台、数据运营平台、机器学习平台的开发与建设；2、负责大数据平台的稳定、安全、运维及优化；3、参与大数据相关技术的调研与调优，找到最合适业务发展的存储、计算解决方案；4、参与开发流程的讨论与优化，负责核心代码编写、代码审核和重构；任职要求：1、本科以上学历，计算机相关专业，基础扎实，3年以上工作经验，2年以上大数据相关开发经验；2、熟悉Linux，熟悉Java/Scala/Python语言中的一种或多种；3、熟悉大数据领域的技术栈，如Spark/Flink/Kafka/ES等，尤其对spark执行原理及使用调优有深入见解者优先；4、有数据平台工作经历者优先。 行业标杆，高速成长， 团队活跃，平台广阔，交通便利！前景，专注于本地生活的广泛领域——餐饮O2O；晋升，广阔的职业发展空间，越努力你就越幸运；氛围，那是年轻人的世界，公司营造各种交流机会；环境，舒适高大上的办公环境，西直门地标建筑，没有雾霾还可看见西山落日。哗啦啦（www.hualala.com）期待你的加入！,"移动互联网,消费生活",500-2000人,spark,北京
高级数据开发工程师,https://www.lagou.com/jobs/7125894.html,西城区,25k-35k,北京多来点信息技术有限公司,5-10年,本科,带薪年假 专业培训 五险 双休,职位描述1、负责服务运营侧数据开发框架和数据指标研发。2、开发并实现优秀的数据流、数据架构、数据工具/产品，提供高可用的数据产出，发挥数据价值。3、构建满足业务方数据需求的多元化数据服务体系，取数、智能模型、数据产品；4、负责数据开发平台中数据资产管理、数据质量管理、数据模型设计等功能的实现；任职资格：1、计算机或相关专业本科及以上学历，5年以上大数据开发经验，对数据和业务敏感，具备复杂业务需求梳理能力;2、熟练使用java/scala，对jvm，多线程，IO等有深入理解。熟悉Linux/Unix开发环境，具备Shell、Python等脚本开发能力;3、熟悉常用开源分布式系统，熟悉Hadoop/Hive/Spark/ElasticSearch一种或几种;5、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计;6、学习能力强，拥有优秀的逻辑思维能力，工作认真负责，谨慎，敬业，沟通能力好。行业标杆，高速成长， 团队活跃，平台广阔，交通便利！前景，专注于本地生活的广泛领域——餐饮O2O；晋升，广阔的职业发展空间，越努力你就越幸运；氛围，那是年轻人的世界，公司营造各种交流机会；环境，舒适高大上的办公环境，西直门地标建筑，没有雾霾还可看见西山落日。哗啦啦期待你的加入！,"移动互联网,消费生活",500-2000人,spark,北京
Java研发工程师,https://www.lagou.com/jobs/6959642.html,海淀区,30k-45k,神策网络科技（北京）有限公司,5-10年,本科,大数据产品 技术驱动 工程师氛围,工作职责:1、负责神策大数据产品 Web 后端的架构设计和开发工作；2、维护和升级现有技术框架，保证系统的稳定性和性能；3、理解大数据分析产品业务需求，负责新功能的技术开发；4、团队合作，参与大数据导入、存储与查询方向的技术调研和技术攻关。  职位要求:1、计算机或相关专业毕业，本科及以上学历，2年以上开发经验；2、精通 Java 语言，具有扎实的计算机技术基础和良好的编程习惯；3、熟悉 Spring/MyBatis/Netty/Nginx 等 Web 开源技术和框架；4、精通数据库设计（MySQL优先），优秀的SQL编写及调优能力，熟悉常见NoSQL存储，如Hbase/Kudu/Redis/Mongodb等；5、了解 Hadoop/Hive/Spark/Impala 等开源大数据技术优先；6、善于学习新知识，主动性强；7、良好的团队合作精神，较强的沟通能力。,数据服务,150-500人,spark,北京
Java Web 研发工程师,https://www.lagou.com/jobs/7030884.html,海淀区,25k-45k,神策网络科技（北京）有限公司,5-10年,本科,团队氛围好、成长空间大、六险一金、,"工作职责:
 负责神策大数据产品 Web 后端的架构设计和开发工作；
 理解大数据分析产品业务需求，负责新功能的技术开发；
团队合作，参与大数据导入、存储与查询方向的技术调研和技术攻关。  岗位要求:
 计算机或相关专业毕业，本科及以上学历，4年以上 Web 开发经验；
 精通 Java 语言，具有扎实的计算机技术基础、良好的代码风格、良好的接口设计规范；
 熟悉 Servlet / Spring / MyBatis / Netty / Nginx 等 Web 开源技术和框架；
 熟悉数据库设计（MySQL优先），优秀的 SQL 编写及调优能力，熟悉常见 NoSQL 存储，如 Redis / Kudu / HBase 等；
 有 Unix / Linux 下的开发的经验，对常用命令运用娴熟；
 了解 Hadoop / Impala / Hive / Flink / Spark 等开源大数据技术优先；
 善于学习新知识，主动性强；
 良好的团队合作精神，较强的沟通能力。",数据服务,150-500人,spark,北京
大数据架构师(RQKJ1),https://www.lagou.com/jobs/7018521.html,朝阳区,40k-70k,北京蓝城兄弟信息技术有限公司,10年以上,本科,"下午茶, 五险一金, 股票期权, 餐补",1. 负责大数据项目整体架构规划，包括应用架构、技术架构、物理架构和数据架构等；2. 负责指导工程师进行技术验证与实现，核心技术问题的攻关，解决项目开发过程中的技术难题；3. 负责项目对外技术沟通，具有较强的沟通，表达和文案能力；4. 根据公司项目和业务发展特点，负责研究相关大数据前沿技术；5. 负责营造团队技术氛围，推动技术能力的沉淀；1. 计算机、信息系统、数学或相近专业本科以上学历，7年以上相关研发经验经验，5年以上大数据研发和架构经验；2. 精通和全面掌握常用的软件设计方法、计算架构和解决方案；3. 拥有5年以上Hadoop开发设计和实施经验，精通Hadoop生态及相关的各种工具并有实战经验，包括但不限于hadoop/hive/spark/impala/presto/elasticsearch/druid/redis/hbase/kafka/flume等，能够熟练安装、配置、部署和优化大型Hadoop集群系统；4. 有超PB级别大数据处理实战经验，熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖掘和数据可视化，以及架构设计、开发、部署、自动化运维等工作；5. 有优秀的业务理解能力，能理解清楚业务并进行合理的模块和架构设计；6. 不怕困难，有关键技术攻关的决心和能力，能够适应和享受高压力的工作；7. 开源社区贡献者优先，请在简历上说明,"移动互联网,社交",150-500人,spark,北京
算法工程师(J2FK1),https://www.lagou.com/jobs/7018627.html,朝阳区,20k-40k,北京蓝城兄弟信息技术有限公司,3-5年,硕士,"下午茶, 五险一金, 股票期权",1、研究深度学习算法和自然语言处理，进行大规模文本特征分析提取建模2、利用NLP相关技术和方法解决实际问题，改进产品功能1、一年以上机器学习、NLP研发项目经验，有语义理解、推荐系统、知识图谱等项目经验者优先2、熟悉Hadoop、Hive、Spark等分布式计算架构3、熟悉Tensorflow、Keras等深度学习框架4、熟悉NLP、机器学习、深度学习、强化学习等算法，对NLP方向有较深和全面的认识5、具备研究探索精神和团队协作能力,"移动互联网,社交",150-500人,spark,北京
大数据/数据挖掘算法工程师,https://www.lagou.com/jobs/6059816.html,石景山区,20k-40k,盈嘉互联（北京）科技有限公司,不限,硕士,五险一金、期权奖励、各项补贴等,欢迎应届和实习生岗位职责：1、负责大数据技术平台开发；2、负责机器学习算法在线/离线系统实现；3、负责数据仓库和挖掘工具平台开发；4、 对大数据基础架构和平台有深刻理解和丰富开发经验，具备相关产品（Hadoop、Hive、HBase、Kafka、MapReduce、Spark、kudu、es等）项目应用研发经验5、 有大型分布式系统设计经验，负责过海量数据平台上高可用、高性能分布式系统的架构设计。任职资格:1、知名高校研究生学历，计算机或数学统计学等专业，3年以上工作经验；2、具备较强的编程能力，熟练掌握java,"移动互联网,企业服务",50-150人,spark,北京
机器学习算法工程师,https://www.lagou.com/jobs/3028089.html,朝阳区,15k-30k,北京玩在一起科技有限公司,1-3年,本科,"五险一金,弹性工作","工作职责：
 负责数据特征抽取、参数选择、算法实验、效果预估等相关的分析和建模；
 标签挖掘，分析并解决语义理解，信息抽取、统计、分类、检索等产品问题；
 新产品形态、产品排序、相关性、质量度算法的研究和优化；
 负责大规模机器学习算法设计及开发实现，数据实验评估反馈。
 工作要求：
 计算机相关专业，有较强学习能力和逻辑思维能力，具备良好的问题分析与解决能力；
 2年以上数据挖掘、机器学习、推荐系统等领域的研发经验；
 熟悉常用分类聚类算法，如朴素贝叶斯，KNN，SVM，逻辑回归等；
 熟练使用Python，熟悉sklearn、pandas、tensorflow、keras、pytorch等基础模块，有Spark(Streaming/MLlib)开发经验优先；
 善于沟通，工作积极主动，责任心强，具备良好的团队协作能力。","移动互联网,文娱丨内容",50-150人,spark,北京
搜索/推荐算法专家,https://www.lagou.com/jobs/5136634.html,海淀区,30k-60k,北京转转精神科技有限责任公司,3-5年,本科,"六险一金,弹性工作,成长空间大,薪酬高",工作职责负责转转二手交易搜索及个性化推荐相关的算法研发工作，提升点击转化率，优化用户体验。职位要求1.  熟练掌握C/C++、Python/Scalar/Java等语言编程、及数据结构基础算法2.  熟悉常用的数据挖掘和推荐算法，有搜索、个性化推荐、广告系统相关项目经验者优先3.  熟练掌握数理统计和机器学习的基础理论和方法，熟悉常用的机器学习模型：LR/GBDT/XGboost/DNN等4.  有大规模数据处理经验，熟悉hadoop，spark，熟练使用Scala进行分布式数据开发5.  优秀的分析及解决问题能力，责任心强，优秀的沟通能力和团队精神。,"移动互联网,消费生活",500-2000人,spark,北京
推荐引擎工程师,https://www.lagou.com/jobs/6705850.html,海淀区,28k-50k,安徽华米信息科技有限公司,3-5年,本科,弹性工作薪资open大牛云集班车接送,推荐工程师岗位职责： 1. 负责推荐引擎的研发； 2. 支持海量数据和请求，持续优化模型，提升业务效果 3. 挖掘用户行为数据，综合各种因素，持续提升推荐精准度  职位要求： 1. 本科及以上学历，至少2年推荐相关经验 2. 熟悉机器学习各类算法，有较强的数据结构基础，有golang项目经验 3. 具备良好的工程化实现能力 4. 有Spark/Hadoop/Kafka/Flink/Spark Streaming等分布式系统相关经验者优先 6. 强烈的责任心，良好的沟通能力，良好的团队合作精神,移动互联网,500-2000人,spark,北京
数据分析师,https://www.lagou.com/jobs/6701182.html,海淀区,18k-30k,安徽华米信息科技有限公司,1-3年,本科,弹性工作薪资open大牛云集班车接送,职位描述1、 对海量智能穿戴产品数据进行分析，驱动产品改进，业务增长2、 产出高水平的专题数据分析报告，为业务发展提供决策依据3、 构建全面的模块化、体系化的报表4、 支持公司相应业务模块的临时看数需求岗位要求1、1-3年数据分析相关工作经验；2、具备较强的分析能力，对数据较为敏感。对专题数据分析有较为成熟的经验，能够敏锐的识别问题，解决问题，并利用数据分析结论驱动业务增长；3、熟练掌握sql、 shell、python，对Hive、spark等较为熟悉；  4、具备良好的服务意识，善于主动思考，自我驱动力强，主观能动性好。有良好的沟通、协调能力，富有团队精神；,移动互联网,500-2000人,spark,北京
AI开发平台部_机器学习平台研发工程师,https://www.lagou.com/jobs/7045603.html,海淀区,18k-36k,百度在线网络技术（北京）有限公司,不限,本科,大牛云集，领导好，待遇优厚,工作职责-建设公司内部机器学习/深度学习平台，根据实际业务场景和需求，优化平台能力-建设强大的机器学习/深度学习开发环境-建设灵活易用的机器学习/深度学习组件，支持业务打造定制化AI应用/平台-建设丰富灵活的异构/混合云算力资源调度及工作流任务调度能力任职资格-计算机及相关专业本科及以上学历，具有扎实的代码功底，熟悉常用的算法和数据结构-精通python/php/C++中至少一种编程语言，具有良好的编程习惯，熟悉多线程编程，内存管理，设计模式和Linux/Unix开发环境-熟悉Hadoop/HIVE/MPI/Spark等分布式计算框架，了解常见深度学习框架引擎，熟悉Docker技术及Kubernetes容器调度系统-在机器学习、深度学习、大规模分布式机器学习以及在搜索、广告、推荐、机器翻译等领域有经验者优先-良好的团队合作和协调沟通能力，学习能力强，自我驱动力强，紧跟机器学习的发展动态,工具,2000人以上,spark,北京
大数据平台研发岗,https://www.lagou.com/jobs/6525898.html,丰台区,20k-40k,建信金融科技有限责任公司,不限,本科,初创团队，福利高，发展广,岗位职责1.负责大数据平台的架构、研发和持续优化。2.负责大数据的数据管理与调度，数据采集与集成，数据挖掘与可视化，数据计算与存储，数据开发与服务等相关组件的开发。3.负责理解业务需求，进行大数据建模与大数据分析。4.负责运维大数据等大数据应用的开发。5.参与解决大数据基础架构项目中的关键架构问题和技术难题，负责项目中关键技术难点的攻关。6.参与大数据的技术咨询和技术服务。岗位要求1.2年以上大数据相关领域工作经验。2.熟悉数据仓库概念，分布式计算技术理论，具有大数据系统架构设计与开发经验。3.掌握主流大数据工具/平台技术，具备Shell、Java或Python编程能力，至少具备Hadoop相关工具（Spark，Hadoop，Hive，Flume，Hbase，kafka，Flink等）、MPP数据库、Elasticsearch、图数据库、时序数据库中的2种以上大数据产品开发能力。4.具有海量数据处理、数据挖掘、数据分析等相关项目的工作经验者优先。其他要求1.具有全日制大学本科（含）以上学历及相应学位，年龄35周岁以下。2.有较强的动手能力和学习能力，具备实际问题解决能力。3.具有较强的风险意识，良好的协调、沟通与团队协作能力，能够适应压力环境中工作。4.薪酬根据工作能力协商确定，上不封顶。,"金融,软件开发",2000人以上,spark,北京
数据分析与测试专家,https://www.lagou.com/jobs/7064936.html,海淀区,30k-60k,建信金融科技有限责任公司,5-10年,本科,初创团队，福利高，发展广,岗位职责：1. 负责规划和建设企业级数据测试能力，研究数据能力建设与实施管理的结合方式方法；2. 负责各项数据类应用组件的质量保证、实施管理工作，探索数据质量测试方法和效率提升；3. 负责对重大数据类任务进行端到端过程管控，保证项目有质量的按时投产；4. 负责高阶数据统计分析工作，统计各类指标数据，研究和挖掘潜在关系，定期出具分析报告等。任职条件：1. 全日制大学本科及以上学历，软件工程类、电子信息类、计算机科学类等相关专业背景；2. 5年以上数据测试或实施管理经验；3. 熟练掌握SQL、Python等语言；4. 对数据仓库、关系型数据库有扎实的基础；熟练Hadoop、Spark、Hive等常用大数据技术；具有一定的数据分析技能和相关经验；5. 熟悉互联网微服务 Dubbo、Sofa 等框架，熟悉阿里云、腾讯云、AWS、Azure等云平台者优先; 6. 对数据敏感，具有良好的逻辑思维能力、分析能力、理解业务的能力、沟通能力和表达呈现能力，主动性强；7. 较强的学习能力，分析问题及解决问题能力，有团队精神。,"金融,软件开发",2000人以上,spark,北京
平台研发工程师（平台化方向）,https://www.lagou.com/jobs/6868865.html,海淀区,20k-40k,百度在线网络技术（北京）有限公司,不限,本科,**技术团队 成长空间大,工作职责               -负责搜索、推荐等trace/debug/调研环境平台方面功能开发-公司核心业务日志平台、及相关BI报表、Hadoop平台及架构相关平台化建设-结合业务产品逻辑、推动部门整体研发效率提升               任职资格               -本科及以上学历，计算机、软件工程或相关专业 -精通go或者PHP编程语言，熟悉MYSQL数据库 -熟悉Linux/Unix系统、熟悉网络编程、多线程编程技术 -对数据结构和算法设计具有深刻的理解 -有ElasterSearch、hadoop、spark、storm、hbase等大数据处理经验优先-熟悉web架构，熟悉web应用的数据库设计 -善于学习和运用新知识，具有良好的分析和解决问题能力 -具有良好的团队合作精神和积极主动的沟通意识,工具,2000人以上,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7056582.html,朝阳区,20k-30k,北京云保网络科技有限公司,3-5年,不限,移动互联网广告行业，拥有TB级数据,岗位职责：1、负责公司业务系统的数据加工、分析、处理工作；2、按照业务部门的要求加工数据，生成业务需要的分析数据，用于系统使用使用的用户标签数据；3、对业务数据进行优化，提升数据分析处理的效率；要求：1、精通Java或python其中一个语言及相关框架，能熟练掌握常用数据结构和算法；2、有实际的Hadoop生态系统HBbase/Hive/MP开发经验；3、熟悉Spark、Flink、Storm、Impala等计算和数据处理引擎的环境搭建、开发和管理；4、熟悉消息队列的原理，熟练使用Flink、Kafka、Activemq、Rabbitmq等常用的消息队列；5、掌握数据分析的基本流程，擅长数据采集、清洗、分析等环节，；6、具有较强的业务理解能力，并能快速应用于数据分析各阶段；7、能熟练掌握Linux的操作和使用；8、有云计算中心开发经验的优先；9、工作认真，负责，良好的团队合作精神和解决问题分析能力。钻研技术克服困难，勇于挑战；,移动互联网,50-150人,spark,北京
数据算法工程师,https://www.lagou.com/jobs/7206562.html,海淀区,15k-30k,北京融七牛信息技术有限公司,3-5年,本科,上市公司，七险一金，各种福利,岗位职责：1、基于各类用户信息，挖掘现有数据的价值，产出有效特征，满足模型迭代时特征更新的需求；2、根据实际业务需要开发贷前申请、准入，贷中提现、调额，贷后催收优化等各类模型； 3、负责模型全生命周期管理，包括开发、验证、部署、监控，根据模型预测结果，给予模型应用策略建议；4、持续监控特征和模型在线上的稳定性及效果，有能力排除线上问题，并持续优化特征及模型；5、优化提升建模自动化工具和平台，引入并验证新的建模及特征挖掘方法，优化监控体系，持续提升特征及模型效果和开发效率；任职要求：1、熟悉常用数据挖掘、机器学习算法，包括XGBoost、Logistic Regression、决策树、聚类、神经网络等；2、具备丰富的Python开发经验，熟练使用git管理代码库； 3、熟悉SQL及hive，并掌握Python数据分析能力；4、有责任心，注重细节，良好的团队合作精神和学习能力；5、加分项：具备MapReduce或spark数据处理和建模经验；6、加分项：熟悉线上小额贷款业务流程、了解风险评估体系；,金融,500-2000人,spark,北京
搜索推荐后台开发工程师,https://www.lagou.com/jobs/6580106.html,海淀区,30k-60k,北京转转精神科技有限责任公司,1-3年,本科,"六险一金,牛人共事,弹性工作,成长空间大","主要职责1. 负责搜索、推荐、商业广告等引擎研发工作。2. 负责大规模机器学习、检索，基础等平台研发工作，包括训练平台、预测平台、特征平台、条件检索、向量检索、AB实验等。3. 从业务中理解需求并能设计和实现通用框架，保障质量、提升效率、优化性能；岗位要求1. 热爱互联网行业，对工作有持续投入热情。 2. 熟练掌握Python/Scalar/Java等一门编程语言及基础数据结构。3. 符合下面任意条件优先i. 熟悉后端开发，有复杂系统架构或开发经验；ii.熟悉各类推荐/搜索/商业系统的设计和开发，有一线经验；iii. 熟悉Tensorflow/MXNET/CAFFE/Scikit-learn等主流机器学习框架, 掌握Hive、Flink、Spark、Hadoop或其他分布式数据处理框架；iv. 熟悉推荐系统相关经典算法（LR、GBDT、SVD/SVD++、FM/FFM等）工程实现，具体适用场景及常用变形；v. 熟悉索引技术，有es或faiss实战经验；","移动互联网,消费生活",500-2000人,spark,北京
搜索推荐工程师,https://www.lagou.com/jobs/6246630.html,朝阳区,25k-50k,北京欧应信息技术有限公司,3-5年,本科,"薪酬丰厚,带薪假期,福利多多,与大咖一起","岗位职责：1、负责搜索引擎及相关接口的研发、维护、改进2、负责智能推荐系统的研发、维护、改进任职资格：1、有搜索或推荐领域3年以上工作经验，兼顾者优先2、熟悉搜索推荐相关的算法3、熟悉 Linux/Unix 开发环境，熟练使用C/C++、Java、Python等一种编程语言，熟悉Spark/Hadoop/Storm等开源大数据生态者优先4、有 ElasticSearch, Solr 等开源搜索引擎经验者优先5、熟悉 MySQL, Redis 等 SQL 和 KV 数据库6、良好的沟通能力，工作积极主动，愿意接受挑战。",医疗健康,150-500人,spark,北京
高级运维工程师,https://www.lagou.com/jobs/3747312.html,朝阳区,15k-25k,北京欧应信息技术有限公司,5-10年,本科,全额五险一金，年终奖丰厚,岗位职责：1.对公司现有服务的优化及网站安全性的运维工作。2.负责系统的变更与发布工作，线上服务漏洞的排查，版本升级工作。3.负责运维相关工具及系统架构方面的调研、设计、实施等工作。4.负责公司大数据平台的建设与维护。5.负责公司自动化运维平台的建设。任职资格：1.熟练掌握linux系统管理，维护，具备大中型网站平台架构及运维管理经验。2.精通网站冗余及负载均衡架构，熟练掌握常用linux开源软件的工作原理及配置方法，。3.精通常用的服务的配置，部署，优化。4.熟练使用shell ，熟练使用python、perl之一。5.熟悉大数据相关服务，包括hadoop、storm、spark等。6.熟练掌握自动化运维工具ansible、puppet、saltstack中的一种或多种。7.良好的故障分析及排错能力，以应付突发事件。8.4年以上linux系统运维工作经验。,医疗健康,150-500人,spark,北京
数据研发工程师,https://www.lagou.com/jobs/7129880.html,海淀区,20k-40k,北京微方程科技有限公司,5-10年,本科,行业大牛 14薪 六险一金,职位描述:1、参与基于大数据仓库、大数据分析相关设计、研发、维护工作；2、参与运营产品需求的分析、处理与沟通。3、参与开发数据生产、分析工具，不断提高数据使用效率； 4、参与和业务部门紧密配合，构建丰富多样的数据应用，助力业务产品不断优化 职位要求:1、计算机或相关专业统招本科（或以上）学历；2、熟练掌握至少2种以下编程语言：JAVA、Scala、Python3、深入理解 Linux 操作系统，熟悉 Shell 脚本编程4、熟悉 Hadoop、HBase、Spark、Flink、Kafka 等技术，熟悉其运行机制和体系结构5、具备基于大数据平台的数据治理、作业调度、大数据开发套件等大数据平台应用组件的设计开发经验者优先6、良好的沟通能力和团队协作精神，严谨的工作态度与高质量意识7、做事认真负责，学习能力强，热爱技术，动手能力强，有进取心,"移动互联网,企业服务",50-150人,spark,北京
广告策略工程师,https://www.lagou.com/jobs/6691566.html,海淀区,15k-25k,北京微方程科技有限公司,3-5年,本科,"14薪,公积金全额,年两次涨薪,免费午餐",工作职责:1、深入了解和分析各客户投放情况及问题2、制定投放策略，优化投放效果3、支持广告投放日常运营4、发现产品现有不足，推动产品逻辑迭代升级任职资格:1、计算机相关专业本科以上学历2、具备广告变现、商业产品相关领域数据分析与优化经验；3、良好的逻辑思维能力，和数据敏感度，能够从海量数据中发现有价值的规律；4、优秀的分析和解决问题的能力，对挑战性问题充满激情；5、熟悉python、spark sql、编写简单shell,"移动互联网,企业服务",50-150人,spark,北京
高级算法工程师,https://www.lagou.com/jobs/7183916.html,海淀区,20k-40k,北京车之家信息技术有限公司,5-10年,本科,平台大 氛围好 福利优,岗位职责：1.参与之家商业化部门商业推荐算法工程化工作；2.负责CTR预估模型的有效特征提取，提升模型预估准确性；3.对模型效果进行优化，包括召回、排序、重排等策略设计、研发工作；4.负责DNN等深度学习算法的工程实现；5.了解行业前沿算法模型，引入广告和推荐业务中。 岗位要求：1.本科及以上学历，计算机、数学及相关专业，3年以上广告算法相关工作经验；2.较好的编程能力，熟练掌握C/C++，Python等开发语言；3.熟悉机器学习常用算法(LR，GBDT、FM、FFM、贝叶斯、深度学习等)；4.熟悉DSP广告竞价机制，召回、排序、重排等。有相关的项目经验；5.有Hadoop，MapReduce，Spark，Storm，HBase，Kafka，TensorFlow等开发经验；6.熟悉大规模数据挖掘、机器学习、深度学习等相关技术，有搜索引擎、广告、推荐等相关技术背景的优先；,汽车丨出行,2000人以上,spark,北京
Flink实时计算研发工程师,https://www.lagou.com/jobs/6687426.html,海淀区,30k-50k,欧科互动网络科技（北京）有限公司,5-10年,本科,大牛团队 发展前景 薪资客观,岗位职责：1.以Flink为主的实时计算大数据专家，精通数据采集、实时计算、图计算等；2.负责大数据海量数据采集和实时计算平台的设计、开发、维护与优化；3.参与实时计算平台的架构设计、开发、发布和运维等工作。任职要求：1.统招大学本科及其以上学历，计算机相关专业；2.3年以上Java或Scala开发经验；3.对Flink，Spark等流式计算框架有深入理解，尤其在flink方面有多年深耕优先；4.熟悉Hadoop、Kafka、ZK、Elasticsearch、Redis等的工作原理；5.具有存储系统读写优化、高并发服务相关工作经验优先;6.熟悉常用算法和数据结构，熟悉网络编程、多线程编程技术；7.思维敏捷，思路严谨，善于沟通，有过平台建设经验或运营经验者优先；8.具有较强的学习能力、自我管理能力、敢于挑战；9.性格积极乐观、诚信、有较强的语言表达能力，具备强烈的进取心、求知欲及团队合作精神；,金融,500-2000人,spark,北京
机器学习平台工程研发工程师,https://www.lagou.com/jobs/5926893.html,海淀区,15k-30k,微梦创科网络科技（中国）有限公司,不限,本科,"大平台,带薪年假,六险一金,免费班车",岗位职责1.     负责大规模机器学习平台/深度学习平台的架构设计、工程实施、及优化；2.     利用各种海量数据及行为日志，以目标及效果为导向，搭建在线/离线模型及策略系统，支撑基础算法工作的应用落地；3.     阶段性优化升级机器学习平台，保证稳定性及系统扩展能力。。岗位要求1.     计算机相关专业，本科或以上学历；2.     至少掌握一门主流的编程语言，如Java、Python、C++、Go等，熟悉Linux开发环境；3.     熟悉Docker/Docker-compose；4.     了解现有的机器学习或分布式平台框架，能够根据业务需求，设计开发相应的平台架构；5.     有较强的工程能力，能积极主动的完成各种工程任务。优先条件1.     具有Docker等容器开发运维经验；2.     具有Hadoop、Spark、Storm等分布式框架开发经验；3.     熟悉深度学习框架，如TensorFlow、DL4J、Caffe、scikit-learn等。,文娱丨内容,2000人以上,spark,北京
高级推荐算法工程师,https://www.lagou.com/jobs/6424096.html,海淀区,25k-40k,微梦创科网络科技（中国）有限公司,1-3年,硕士,产品好，成长快,"岗位职责1、负责超话社区推荐系统研发工作，维护线上相关服务的稳定运行2、结合实际业务场景，给出最优的算法解决方案并实施。能力要求1、精通python, 熟悉numpy、pandas、Scikit-Learn等，同时熟悉java更佳；2、熟悉常用算法和数据结构，具备Linux环境研发能力，熟悉SQL、Linux Shell脚本；3、熟悉数据挖掘相关算法，包括但不限于LR、SVM、聚类、决策树、GBDT、FM、wide&deep、DNN等；4、熟悉Spark,Hadoop,Hive,Storm，有NLP、CV、DeepLearning方面的项目经验更佳；5、具备良好的学习能力和沟通交流能力，能够迅速熟悉业务，融入团队；6、具备2年以上的数据挖掘/机器学习相关工作经验，有推荐系统经验者优先。7、对技术充满热情，能持续跟踪业内技术动向，并和现有工作做有效结合。",文娱丨内容,2000人以上,spark,北京
数据开发工程师,https://www.lagou.com/jobs/7215799.html,海淀区,23k-45k,北京氦图科技有限公司,1-3年,不限,硅谷团队 涨薪快,"【职位描述】1. 负责 7.5 亿份简历的存储和更新 (ElasticSearch, Canssandra, Redis)2. 支持 40+ 不同渠道的数据爬取和清洗(Python, Scrapy, Selenium)3. 为100TB+数据建立即时通道和线下通道4. 为产品研发提供数据策略支持5. 进行开源数据，文档及pdf的特征值提取，建立知识图谱及数据标签6. 与AI工程师和机器学习工程师合作，建立最大人才数据库和人工智能模型，实现数据渠道管理的自动化和智能化7. 为产品研发提供量化结果，实现数据驱动下的产品研发智能化 【任职资格】1. 非常熟练使用Python语言。2. 非常熟悉使用Linux的操作系统以及文件系统。3. 非常熟悉数据结构和基本算法，熟练运用队列，搜索策略，负载均衡等手段解决具体问题。4. 非常熟练使用某一种 db: MySQL, Mongodb, Redis, Cassandra。并了解不同数据库的优缺点以及应用场景。5. 对数据处理，特别是文本的处理有经验。6. 加分项：有数据抓取，写爬虫的经历。熟悉框架 例如scrapy, beautiful soup, selenium，会解析html/xpath。7. 加分项：有大数据处理的相关经验。了解bulk operation，multiprocessing programming，map/reduce, spark。8. 加分项: 有elasticsearch使用经历，理解index mapping，熟练运用接口。9. 加分项：有理解以及优化data pipeline/ETL的能力。10. 加分项：能使用Python，Java，Php中某一种语言写接口，为其他团队获取数据提供便利。11. 能够适应英语工作环境","企业服务,软件开发",50-150人,spark,北京
数据开发工程师（技术） (MJ000042),https://www.lagou.com/jobs/6629352.html,朝阳区,15k-30k,上海一起作业信息科技有限公司,3-5年,本科,薪资福利,"职位描述：能够快速理解数据分析和统计的相关需求，且参与平台的报表设计开发工作；负责优化公司相关业务下代码逻辑；负责数据平台下的业务开发设计工作；负责数据平台的功能开发与维护任职资格：1.计算机,数学,统计学等理工背景相关专业毕业,本科及以上学历；2.三年以上数据开发工作经验,掌握数据仓库(DW)/ 商业智能(BI)/ 数据统计理论，并灵活的应用，熟练掌握SQL技能，有较好的SQL性能调优经验，理解Hive/Mysql/Oracle 基本原理和调优策略；3.熟悉使用大数据处理相关技术.对 Hadoop/Spark/HIVE/HBase应用有一定的掌握理解；4.具备linux 下开发经验；5.具备数据仓库集市下数据统计开发经验，对java或者python其中一门精通（优先考虑）；6.具备良好的编码习惯，较好的数据敏感度和数据质量把控意识 7.高度的学习能力及适应力，能够快因工作内容的变化而拥抱变化。","移动互联网,教育",2000人以上,spark,北京
C#/.NET开发工程师,https://www.lagou.com/jobs/6542721.html,朝阳区,10k-20k,北京光启元数字科技有限公司,不限,本科,办公环境好 交通便利 不打卡,"我们需要你：1. 与项目小伙伴沟通，完成项目数据接入工作；2. 根据项目需求完成功能模块开发工作；3. 协助处理项目开发遇到的关键问题，对项目涉及的新技术能给予快速有效的支持。我们希望你:1.计算机相关专业，1-3年实际开发经验；2.熟练使用C#编程，熟悉面向对象编程；3.熟悉HTTP、TCP/IP、Socket、WebSocket等网络通信协议，对物联网相关通信技术有深入理解；4.熟练使用MySQL, Oracle等关系型数据库，了解kafka、Spark Streaming、Flume等；5.知识面广，思路开阔，创新能力强，乐于解决具有挑战性的问题，对新技术持有敏感性并愿意致力于新技术的探索和研究；6.普通话流利，良好的表达和沟通能力。","数据服务,企业服务",150-500人,spark,北京
大数据工程师,https://www.lagou.com/jobs/7061888.html,朝阳区,12k-24k,杭州半云科技有限公司,3-5年,本科,五险一金 带薪年假 定期体检 节日福利,"岗位职责：负责数据接入整合、纵向数据贯通，同时能基于大数据应用，开展数据挖掘算法开发。岗位要求：1、精通SQL语句，同时具备JAVA、Python等语言开发能力；2、熟悉阿里大数据组件开发流程；3、能够熟练使用DataWorksMaxCompute, DataWorks, StreamCompute，ECS， RDS等工具,能够基于该工具开展数据分析；4、能够熟练使用DataHub、DTS、Blink、Spark等阿里相关组件进行数据集成或开发，熟练使用OGG、Informatica ETL配置及开发；5、具有一定技术方案规划能力及文档编写能力；6、具有4年以上阿里云大数据开发工作经验；7、较好的沟通理解能力，性格乐观，态度踏实，积极上进；8、具备ACP大数据者优先。",移动互联网,150-500人,spark,北京
Senior Data Scientist,https://www.lagou.com/jobs/6778674.html,朝阳区,20k-35k,珐菲琦(上海)电子商务有限公司,3-5年,硕士,"弹性工作,股票期权,精英团队,工作氛围好","The roleFarfetch is building the next-generation intelligent platform for online luxury fashion, powered by large-scale data and state of the art Machine Learning, Deep Learning and Computer Vision algorithms. You will join a talented team of Data Scientists, Engineers and Product designers to help build and optimize, through research and experimentation, our data-driven products.What you'll do:
 Design and develop state of the art algorithms in one of these domains: Ranking, Natural Language Processing or Computer Vision;
 Conduct practical research with a scientific mindset, and a focus on delivery;
 Build large scale data pipelines;
 Work closely with the engineering team to integrate ML algorithms into the platform;
 Help in the design of new features in the product, and drive innovation inside the company through the use of disruptive technologies.
Who you are:
 MSc or PhD in related topics such as Machine Learning, Natural Language Processing, Computer Vision, Signal Processing or Optimization;
 We encourage applications also with background from the fields in Computer Science, Electrical Engineering, Physics, Biomedical Engineering, Statistics, Applied Mathematics;
 Knowledge in one of the following subjects:
       - Word Embeddings (e.g., GloVe, Word2Vec), Named                 Entity Recognition models;       - Information Retrieval, Learning to Rank (e.g., RankNet,           ListNet), algorithm performance metrics (e.g., NDCG);       - Convolutional Neural Networks (e.g., InceptionV3,                   RetinaNet), Image Segmentation (e.g., SLIC, Saliency               Maps, SuperVoxel), AutoEncoders, GANs;
 Fluent in Python and common numerical and Math & ML packages (NumPy, SciPy, sci-kit-learn, pandas, Keras, TensorFlow, PyTorch). R candidates are also encouraged to apply;
 Experience dealing with large amounts of data and building data pipelines;
 Knowledge of big data technologies is a plus (Hadoop, Spark, Hive);
 Non-relational databases (e.g., Cassandra) and streaming platforms know-how (e.g., Kafka) is a plus;
 Strong English skills, both written and spoken;
 Scientific and technical publications are possible and encouraged; Applicant should be interested to keep up to date with scientific advancements.
*We do appreciate all applicants, but only selected candidates will be contacted by us. And all information provided will be kept confidential.",电商,150-500人,spark,北京
数据开发工程师,https://www.lagou.com/jobs/6857346.html,朝阳区,25k-40k,珐菲琦(上海)电子商务有限公司,3-5年,本科,"弹性工作,股票期权,精英团队,工作氛围好","About the role:As a Data Engineer, you will have the opportunity to apply your strong technical experience on building data models and ETL processes to provide data for business use and building systems including tracking, attribution, data integration, analytics tools, experimentation platform, etc.You will be partnering with other tech teams, business teams, analytical teams, and data scientists across various initiatives. We hope you are motivated to solve challenging problems and willing to learn new technologies. You are able to take vague requirements and transform them into solid solutions.What you'll do:• Data extraction, preparation, and loading from a variety of sources using technology such as SQL, Hadoop and Spark.• Create and maintain optimal data pipeline architecture for large-scale data processing.• Implement data and analytics tools that will offer deeper insight.• Manage individual projects priorities, deadlines and deliverables with technical expertise.Who you are:• With a BS/MS degree in Computer Science or related.• Experienced with big data (batch or streaming): Hadoop, Spark, Kafka, Flink, etc.• Experienced writing SQL.• Experienced with data warehouse, OLAP or reporting systems.• A developer with strong programming skills in one or more of Java, Scala, Python or Pig.• Experienced with Elasticsearch or other indexing systems.• Experienced in information retrieval, data mining, machine learning.• Experienced in marketing, advertising, recommendation or search.*We do appreciate all applicants, but only selected candidates will be contacted by us. And all information provided will be kept confidential.",电商,150-500人,spark,北京
大数据开发工程师（北京）,https://www.lagou.com/jobs/4250492.html,朝阳区,20k-40k,上海倾听信息技术有限公司,3-5年,硕士,弹性工作,工作职责：负责蜻蜓大数据平台的研发，包含数据基础平台的搭建，业务数据ETL处理，批量数据报表，实时数据的开发。工作要求：1、计算机或相关专业；2、3年以上数据平台开发工作；3、熟悉Hadoop、Spark、Storm等大数据平台相关技术；4、熟练使用MapReduce、Hive、HDFS、Hbase、Redis、Kafka；5、精通Java、Python、Scala。,移动互联网,150-500人,spark,北京
资深大数据发开工程师（北京）,https://www.lagou.com/jobs/6768424.html,朝阳区,20k-40k,上海倾听信息技术有限公司,3-5年,不限,大平台 公司福利好,工作职责：负责蜻蜓大数据平台的研发，包含数据基础平台的搭建、升级和优化，业务数据ETL处理，批量数据报表，实时数据的开发。工作要求：1、计算机或相关专业，3年以上数据平台开发工作；2、精通Hadoop/MR/Spark/Hive/HBase/Kafka/Flume/DataX等技术，有丰富的多场景实操经验，掌握数据分析与各种算法与模型3、熟悉OLAP系统、常见的BI解决方案，并有一定的搭建和开发经验，对Kylin/Druid有深入使用和经验者优先4、精通Java、Python、Scala等5、具备优秀的系统架构设计能力，分析、解决问题能力和必要的产品意识；算法基础良好，编码能力优秀；执行力、沟通能力强，喜欢挑战，乐于团队合作,移动互联网,150-500人,spark,北京
数据仓库架构师,https://www.lagou.com/jobs/7028498.html,朝阳区,30k-60k,北京麒麟合盛科技有限公司,5-10年,本科,APUS独角兽 六险一金 租房补贴,岗位职责：    1、负责公司数据仓库建设（大数据平台的离线，实时数据仓库），主要从事数据仓库的基础架构、ETL设计、流程优化，元数据系统设计，整体管理数据的生产、建模、应用及监控体系建设；    2、负责DMP技术架构设计，构建DMP数据采集、存储及分析框架，设计数据处理的技术流程和规范；    3、开发挖掘用户各级标签，提升用户画像标签体系的覆盖度和准确性；    5、对各类数据整合分析，挖掘用户，产品及潜在数据信息，为运营决策体系提供充足的数据平台支持；技能要求：    1、5年以上完整实施DW/BI项目实施和开发经验，二年以上大数据相关软件架构的实际经验；    2、精通大数据处理技术，熟练掌握Spark、Hadoop、Hive、HBase、Druid等相关大数据技术，并有丰富的调优经验。    3、熟悉Flink、SparkStreaming实时计算框架，熟悉底层原理；    4、具有较强的架构能力，具有分布式计算、实时计算、数据仓库、数据挖掘系统的架构经历优先；    5、熟悉DMP/RTB技术原理，了解用户的行为分析及建模；有RTB/DSP/SSP/EXCHANGE/DMP等广告行业从业经历者优先。,移动互联网,150-500人,spark,北京
技术架构师,https://www.lagou.com/jobs/6940162.html,海淀区,40k-50k,北京国双科技有限公司,10年以上,本科,"发展空间大,牛人多,弹性工作制,福利好",岗位职责：1、负责国双数字营销平台的技术选型及架构设计，参与相关需求分析，规划完整的系统架构方案；2、参与国双数字营销平台重要模块组件的设计及开发实现，进行核心技术难题的攻关；3、负责打造可扩展的通用框架及中间件，对现有产品、模块进行梳理、整合；4、审阅各组件模块的设计及实现，提供方案设计、性能优化、安全性、扩展性等方面的建议。 任职要求：1、本科以上学历，八年以上研发经验，具有丰富的Java、.net等后端架构能力以及大数据领域技术经验；2、具备较强的软件研发背景，具有较完备的计算机知识体系，对网络、数据库、WEB、安全、CI\CD等均有一定深度的认识；3、有两年以上大中型业务系统或数据系统的架构经验，具有SOA架构或微服务架构经验，有数据总线或插件式系统设计经验者优先；4、熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息中间件等机制和实现；5、喜欢折腾并深入解剖每个技术问题背后的技术原理，愿意长期自主的对某一技术领域进行深入思考与实践；6、有较强的抽象能力与思考高度，能从整体思考端到端的解决方案；7、具备快速学习和较强的逻辑思维能力，有很强的分析解决问题的经验与能力；8、具有良好的技术表达沟通能力，愿意对技术经验和问题进行总结与分享；9、熟悉数据库及大数据生态，熟悉Spark、Hive、HBase、Impala等组件的应用设计及开发者优先。,"数据服务,企业服务",500-2000人,spark,北京
大数据架构师,https://www.lagou.com/jobs/7135194.html,海淀区,40k-50k,北京国双科技有限公司,10年以上,本科,"发展空间大,牛人多,弹性工作制,福利好",岗位职责：1、负责国双数字营销平台的技术选型及架构设计，参与相关需求分析，规划完整的系统架构方案；2、参与国双数字营销平台重要模块组件的设计及开发实现，进行核心技术难题的攻关；3、负责打造可扩展的通用框架及中间件，对现有产品、模块进行梳理、整合；4、审阅各组件模块的设计及实现，提供方案设计、性能优化、安全性、扩展性等方面的建议。 任职要求：1、本科以上学历，八年以上研发经验，具有丰富的Java、.net等后端架构能力以及大数据领域技术经验；2、具备较强的软件研发背景，具有较完备的计算机知识体系，对网络、数据库、WEB、安全、CI\CD等均有一定深度的认识；3、有两年以上大中型业务系统或数据系统的架构经验，具有SOA架构或微服务架构经验，有数据总线或插件式系统设计经验者优先；4、熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息中间件等机制和实现；5、喜欢折腾并深入解剖每个技术问题背后的技术原理，愿意长期自主的对某一技术领域进行深入思考与实践；6、有较强的抽象能力与思考高度，能从整体思考端到端的解决方案；7、具备快速学习和较强的逻辑思维能力，有很强的分析解决问题的经验与能力；8、具有良好的技术表达沟通能力，愿意对技术经验和问题进行总结与分享；9、熟悉数据库及大数据生态，熟悉Spark、Hive、HBase、Impala等组件的应用设计及开发者优先。,"数据服务,企业服务",500-2000人,spark,北京
资深算法工程师,https://www.lagou.com/jobs/6801885.html,海淀区,40k-50k,北京嘀嘀无限科技发展有限公司,3-5年,硕士,发展前景,岗位职责：1. 为国际市场设计和构建滴滴核心的补贴和定价策略；2. 帮助滴滴提升国际化业务核心OKR，助力滴滴在国际市场的成功；3. 构建高效率的算法平台，支持滴滴的全球业务，搭建策略的深度分析和可视化平台。任职资格：1. 计算机、运筹、统计、经济、数学等相关专业硕士及以上学历，博士优先；2. 在数据分析、数学建模、优化等方面有实践经验；3. 在机器学习或数据挖掘方向有较强的积累，熟悉经典的算法并有实践经验，包括但不限于LR/GBDT/Deep Learning/Reinforcement Learning；4. 熟练掌握海量数据处理技术，有使用Spark/Hive/Hadoop分析海量数据的能力和经验；5. 编程基础扎实，熟悉算法数据结构，有较好的Python开发经验；6. 有学习热情，关注业界前沿技术和人工智能国际会议研究动态，不断提升自己在机器学习、数据挖掘、运筹优化、机制设计、数理统计等方向的能力；,汽车丨出行,2000人以上,spark,北京
大数据架构师,https://www.lagou.com/jobs/3444271.html,朝阳区,50k-80k,北京易观智库网络科技有限公司,10年以上,本科,互联网大数据领先品牌 六险一金 弹性工作,岗位职责：1.负责公司大数据方向的整体架构设计，结合公司实际业务情况进行技术选型；2.负责数据平台产品的整体评估、设计、架构及关键模块的开发；3.负责架构优化及系统关键模块的设计开发，协助团队解决开发过程中的技术难题；4.参与数据开发规范制定。任职要求：1.本科以上学历，至少5年以上实际工作经验；2.负责过大型数据平台或数据仓库设计，具有扎实的大数据和数据仓库的理论功底；3.对Hadoop的大数据体系有深入认识，对Hadoop、Hive、HBase、Spark、Storm、 Kafka、ES等有实际应用研发经验，最好读过关键源码；4.很强的学习、分析和解决问题能力，良好的团队意识和协作精神，有较强的内外沟通能力；5.有分析类产品相关的的技术经验优先。,"移动互联网,数据服务",150-500人,spark,北京
解决方案架构师（技术售前）,https://www.lagou.com/jobs/6690351.html,朝阳区,25k-50k,北京易观智库网络科技有限公司,5-10年,本科,互联网大数据领先品牌 六险一金 期权激励,岗位职责：1.负责大数据产品行业技术售前、解决方案支持工作；2.配合销售负责人与用户进行沟通交流，通过前期售前咨询，依据项目要求引导用户需求，并提出相应项目建设方案；3.结合项目需求，编制项目所需的PPT文档、技术解决方案以及进行方案报告的演示、汇报和讲解；4.配合销售负责人进行招投标工作，负责编写项目标书、项目可行性研究报告、项目建设报告等；5.收集及分析来自客户的业务需求，业务痛点，推动内部产品&解决方案团队进行方案的优化，提升我司的产品&解决方案竞争优势；任职要求：1.本科及以上学历；计算机、软件工程相关专业。2.3年以上技术相关工作经验，1年以上数据产品售前顾问经验；具备企业管理咨询，云计算、BI、数据产品类售前工作经验者优先；3.学习能力强，可在短时间快速了解行业客户的商业模式和业务需求；4.具备较强的沟通和表达能力，能够独立面对客户技术、管理团队，精准理解客户需求；5.熟悉OLAP、BI、数据治理、数据仓库、数据挖掘技术和发展趋势，熟悉Hadoop、Spark、Hive、HBase、Prosto、kylin等主流的大数据技术，具备大型复杂BI，Hadoop数据平台的建设实施经验；6.具备良好心态、能承受工作压力，积极面对工作中遇到的难题，有强烈求知欲，做事高效认真。,"移动互联网,数据服务",150-500人,spark,北京
技术经理（Java+大数据）,https://www.lagou.com/jobs/7107613.html,海淀区,25k-40k,海致网络技术（北京）有限公司,5-10年,本科,金融大数据 独角兽 择优转正,岗位职责：1、负责技术开发团队管理，执行项目计划并实现项目目标；2、负责业务需求分析和架构设计工作；3、负责核心业务功能编码、单元测试工作；4、负责制定编码规范、流程规范、文档规范等。任职要求：1、统招本科及以上学历，计算机相关专业；2、6年以上Java与大数据开发经验，2年以上架构及团队管理经验；3、有扎实的Java编程功底，熟悉JVM底层原理及性能调优，具备高并发应用编程能力；4、具备较强的Trouble Shooting能力；5、熟练掌握主流的微服务框架，如Spring Cloud、Duddo等；6、对Spark、HBase、Kafka、Elasticsearch、Hive、Yarn、Zookeeper等大数据组件原理有深入了解及优化经验，有阅读过源码者优先；7、具备较强的推进能力和责任心，优秀的沟通能力和团队精神，热爱技术工作。,"移动互联网,企业服务",150-500人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7162506.html,海淀区,22k-32k,海致网络技术（北京）有限公司,5-10年,本科,金融大数据 独角兽 固定奖金+项目奖金,岗位职责：1、负责核心大数据业务功能开发及图算法挖掘工作；2、对系统的技术架构持续进行改进和优化。任职要求：1、统招本科及以上学历，计算机相关专业，三年以上大数据开发经验；2、使用过JanusGraph / ArangoDB／Neo4j／TigerGraph 等图数据库中的一种或者多种，并有性能优化经验者优先；3、有扎实的Java或Scala编程功底，熟练JVM原理及性能调优；4、对Spark、Flink、HBase、Kafka、Hive、Yarn、Elasticsearch等组件原理有深入了解，有PB级数据处理经验及优化经验者优先；5、有Spark Graphx图计算或Spark ML 机器学习项目经验者优先。,"移动互联网,企业服务",150-500人,spark,北京
推荐算法专家,https://www.lagou.com/jobs/7131683.html,东城区,50k-80k,北京圣达龙翔科技有限责任公司,5-10年,本科,薪资高，扁平化管理，期权可谈，大牛多,职位描述：1. 负责业务的算法设计与实现（分单、定价、增长等）。2. 负责排序&推荐引擎，用户画像，机器学习定价，智能补贴模型等机器学习模型的构建，算法模型每一点的提升都将带来业务增长和用户体验的提升。3.负责日常搜索产品质量相关的数据监测与分析，持续优化用户体验；4.协调多方资源，快速、高效推动产品功能落地。任职要求：1.计算机或者数学相关专业本科及以上学历；2.有机器学习、数据挖掘等相关项目实际经验，理解自然语言处理/搜索/推荐系统/用户数据分析和建模的基本概念和常用方法；3. 在机器学习或数据挖掘方向有较强的积累，熟悉经典的算法并有实践经验，包括但不限于LR、SVM、GBDT、Reinforcement Learning、Deep Learning；4.熟练掌握海量数据处理技术，有使用Hadoop/Hive/Spark分析海量数据的能力和经验；5.编程基础扎实，熟悉算法数据结构，有较好的C++/Python/Java/Scala开发经验；6.有学习热情，关注业界前沿技术和人工智能国际会议研究动态，不断提升自己在机器学习、数据挖掘，运筹优化、机制设计、数理统计等方向的能力，在人工智能相关**会议有论文发表者优先；7.优秀的分析和解决问题的能力，对挑战性问题充满激情，有较强的沟通能力，责任心和团队意识佳；,"硬件,数据服务",150-500人,spark,北京
高级搜索研发工程师,https://www.lagou.com/jobs/7197823.html,海淀区,20k-35k,厦门美图之家科技有限公司,3-5年,不限,大数据平台,"岗位职责:1、负责美图秀秀、美拍等产品搜索业务开发和优化；2、负责搜索系统架构建设，优化系统稳定性、性能和吞吐量；3、与团队紧密配合，制定有效策略，完成搜索业务目标；任职资格:-本科及以上学历，计算机相关专业；-扎实的编程基础，熟悉Linux开发环境，熟悉Java和Python开发；-熟悉Lucene、ES原理及相关技术，对索引、分词、排序等相关技术有较深的理解；-熟悉Redis，MongoDB，Mysql等存储中间件应用及优化；-善于解决问题和分析问题，有强烈的上进心和求知欲，喜欢学习新事物；-工作认真负责，良好的团队合作精神，较强的沟通能力；-了解分布式, 有过高并发场景/项目的优化经验者优先；-具备hadoop、spark或flink等大数据开发经验者优先。",硬件,2000人以上,spark,北京
系统工程师,https://www.lagou.com/jobs/6938520.html,海淀区,15k-25k,民生易贷（珠海）互联网金融信息服务有限公司,5-10年,本科,"补充医疗,定期体检,团队旅游,大咖团队","岗位职责：1. 负责公司产品线日常运维工作，支持公司业务的快速迭代，包括部署、变更、发布、故障处理等2. 负责搭建业务所需系统和平台，以及持续的调优3. 保障业务的高可用性，优化应用系统、完善监控、撰写各种预案等4. 参与公司整体运维体系的建设和自动化系统的建设任职要求：1. 本科以上学历，3年以上工作经验，计算机科学与技术、软件工程及相关专业；2. 熟悉Linux操作系统,能够熟悉完成Linux系统基本操作；3. 熟悉主流监控系统Zabbix/Cacti/Nagios等操作和配置；4. 熟悉Shell或python编程；5. 熟悉常见 Web 系统架构，熟练配置、管理及其优化，如 LVS, Nginx, Tomcat等相关；6. 熟悉中间件zookeeper、activemq等部署及维护调优，了解分布式存储fastdfs、ceph等；6. 熟悉相关NoSQL的应用场景及优化，如Redis等；7. 熟悉 MySQL 数据库安装、配置、调优，熟悉DB底层存储架构及不同存储引擎的工作原理；8.熟悉网络方面相关知识，懂得相关网络设备配置规划；9. 精通Linux系统及相关指令,具备分散式系统搭建维护如（hadoop, spark）；","移动互联网,金融",150-500人,spark,北京
数据库存储引擎研发,https://www.lagou.com/jobs/7012680.html,朝阳区,35k-55k,支付宝（杭州）信息技术有限公司,5-10年,本科,蚂蚁金服,岗位职责：- 负责分布式数据库OceanBase内核存储引擎研发，需要和团队成员一起讨论解决存储引擎中的各类技术难题，做方案设计、代码编写及功能性能测试。任职要求：1、计算机相关专业本科及以上学历，熟悉C/C++/java/python/go任意语言2、有大规模分布式存储/缓存/数据库系统开发设计经验，了解相关开源项目架构，熟悉Oracle/MySQL/Mariadb/PostgreSQL等优先3、熟悉hbase/spark/cockroachdb/tidb/kylin等开源分布式数据库项目的优先。4、熟悉redis/rocksdb/memcached/leveldb等开源kv数据库项目的优先。5、研读过lsm tree/f1/spanner/aurora/paxos/raft等相关论文的优先。6、良好的工程质量意识，熟悉单元测试、功能测试和系统测试；7、追求卓越，自我驱动，对代码工程质量有近乎洁癖的自我要求。8、良好的沟通能力与团队合作意识。,"金融,移动互联网",2000人以上,spark,北京
数据研发工程师,https://www.lagou.com/jobs/7154645.html,海淀区,20k-40k,北京一亩田新农网络科技有限公司,3-5年,本科,六险一金、 年终奖、 团建,"【岗位职责】1.负责搜索、广告投放、风控、推荐、用户画像等相关项目的数据研发工作；2.负责离线&实时相关的数据指标、固定报表、数据仓库主题ETL开发；3.负责用户行为数据采集、分析，配合产品部门使用数据优化产品功能，提升用户体验；4.负责数据平台、数据指标在公司内的推广、培训，不断提升其数据驱动的业务应用能力；【岗位要求】1. 5年以上工作经验，能独立完成数据研发项目任务；2. 具备基于Hadoop大数据处理及分析的多项技术应用技能，包括但不限于HDFS，ElasticSearch，Spark，Hbase；3. 熟练掌握python、hsql、sparkSQL、shell,java 3种以上语言开发;4. 熟练应用spark streaming、flink、storm,kafka大数据实时计算计术以及框架原理;5. 有电商业务项目经验，具备较强的业务理解力、主动性强、善于沟通；6. 了解数据仓库设计模式，对数据结构、算法设计有较为深刻的理解；",电商,500-2000人,spark,北京
高级测试工程师,https://www.lagou.com/jobs/6976552.html,海淀区,15k-30k,北京天融信网络安全技术有限公司,3-5年,本科,八险一金、股权激励、年终奖金、年度评优,工作职责：1）负责的大数据、态势感知、安全管理产品以及项目的黑盒测试和测试文档输出。2）负责对测试中发现的问题进行分析定位和跟踪，推动测试中发现的问题得到及时合理的解决。任职资格：1）计算机专业，本科以上学历，对软件测试有兴趣，文档撰写能力强，有大数据相关产品测试经验者优先。2）必须熟悉Linux操作系统，并熟悉一款主流数据库（Oracle/Mysql/Elasticsearch/HIVE）的基本操作和一定的SQL语言。3）有很强的分析能力和定位问题能力，快速学习能力强。4）具有良好的沟通能力、细心负责、有团队精神。5）有shell或python等使用经验者优先。6）熟悉hadoop、spark、hbase等分布式开源项目及工作原理者优先。,信息安全,2000人以上,spark,北京
资深数据研发工程师,https://www.lagou.com/jobs/6910799.html,朝阳区,25k-40k,掌阅科技股份有限公司,3-5年,本科,14薪，双休,"岗位职责：1、数仓例行计算，保证数据产出。能对在例行的任务提出可实行的优化建议。2，维护数仓之上产品,BI/DMP/数据分析平台/元数据等正常运行，并参与数据中台的搭建 岗位要求：1,精通分布式文件系统hdfs常用命令以及底层原理。2,yarn，datax，sqoop，hbase 等hadoop生态常用工具3,精通数仓常用计算引擎，hive/spark/kylin/impala 至少两种以上。4,精通常用数据库3种以上。mysql/redis/hbase/es5,对数仓之上的衍生产品(例：BI,DMP,数据分析平台,监控平台,调度平台等)有丰富经验，有过大厂经验最好。6,熟悉linux常用命令，熟悉至少一种脚本语言。shell/python7,熟悉实时计算引擎，sparkstreaming/flink。8,对自己使用过的组件看过源码者优先考虑。",文娱丨内容,500-2000人,spark,北京
运维开发工程师,https://www.lagou.com/jobs/7208122.html,朝阳区,16k-30k,北京仁科互动网络技术有限公司,3-5年,本科,腾讯投资 外企文化 扁平化管理 六险一金,岗位1大数据运维工程师工作职责:负责公司大数据集群的运维工作（Kafka/Hadoop/HBase/Spark/Flink/Clickhouse等）；负责集群性能优化，扩容负责hadoop集群的监控、数据备份、数据监控、报警、故障处理；研究运维相关技术，根据系统需求制定运维技术方案，开发自动化运维工具和运维辅助系统；深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技及发展方向；任职要求：有2年以上大数据集群运维经验；有实际部署经验，并能够独立排查及解决问题。熟悉hadoop在运行环境，任务调度，参数配置等方面的调优；精通Python、Shell、Java中任一语言，熟悉linux开发环境以及相应的配置、管理及优化；熟悉Hadoop生态圈，包含但不限于Hbase/Hadoop/Zookeeper/Spark/Kafka等，能够独立部署并上线运行；有流数据处理运维经验，ETL pipeline处理经验者优先考虑有Flink/Clickhouse运维经验的候选人优先有一定开发经验，能协助大数据环境下的性能问题定位和优化的候选人优先有在线实时获取、传输、计算、反馈相关系统部署经验；有创新精神和团队意识，可以将想法转化成行动。熟悉Docker；计算机及相关专业本科及以上学历，三年以上相关工作经验；优先条件：熟悉云计算相关技术，有2年腾讯云、阿里云或AWS使用经验，有AWS认证为佳；有Java开发背景最佳；岗位2 运维开发工程师岗位职责：1、负责编写系统安全类项目的实现方案；2、负责对操作系统级安全产品及模块的设计和规划;3、进行产品调研、需求分析、详细设计并协同团队完成研发工作。岗位要求：1、全日制硕士以上学历；计算机、信息技术等相关专业；2、熟悉Linux操作系统整体架构和原理;3. 精通主流Linux操作系统上已有的安全机制和技术;4. ５年以上Linux技术研发工作经验，对Linux操作系统有深入了解，熟悉CentOS、Fedora、Ubuntu等主流linux发行版，有安全操作系统研发经验者优先；5、对技术工作有热情，积极主动性强，文档能力强，团队协作能力强。,"移动互联网,数据服务",500-2000人,spark,北京
高级运维工程师,https://www.lagou.com/jobs/6434750.html,海淀区,15k-30k,汉熵通信有限公司,5-10年,本科,扁平管理，弹性办公，精英团队,,"信息安全,物联网",15-50人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6842342.html,海淀区,15k-30k,汉熵通信有限公司,3-5年,本科,扁平管理，弹性办公，精英团队,岗位职责：（1）负责行业应用的计算平台开发与应用； （2）负责行业应用相关的数据接入、采集、加工、清洗、处理程序的开发； （3）参与大数据平台的搭建、开发、维护、优化； （4）对业务部门的数据分析需求给予实现与支持；（5）不断解决规模增长带来的技术和业务问题，构造高度稳定可用的大数据分布式系统，支撑海量数据分析、数据挖掘、机器学习等场景。任职要求：（1）计算机相关专业，本科及以上学历，3年以上Java或Python开发工作经验，学习能力突出；（2）熟悉Linux/Unix系统环境下的操作，熟悉云计算集群环境，了解分布式任务调度，高可用和网络优化；（3）熟悉Hadoop生态系统内常见项目的使用（HDFS、Hive、HBase、Spark、ZooKeeper、yarn等），熟悉使用Python/Java 进行数据聚合清洗，数据分析ETL等的开发经验，熟悉Kafka/EMQ等消息队列和中间件，熟悉API接口开发，有实际大数据项目经验优先； 熟练掌握高性能数据仓库ClickHouse，内存数据库（Ignite）和其他主流数据库（MySQL/Oracle）的操作，包括数据的导出导入，集群同步，SQL的增删改查和各种查询优化等等；（4）能够独立开发设计数据仓库、ETL设计、Cube建模、OLAP开发、报表开发等；一定的应用系统分析与设计能力，有良好、规范的编程习惯和文档编写习惯； （5）熟练Python进行数据处理，网页爬取；（6）有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术、新理论、新开发实践的学习和实践。,"信息安全,物联网",15-50人,spark,北京
数据仓库开发工程师,https://www.lagou.com/jobs/6291491.html,海淀区,15k-25k,新浪网技术（中国）有限公司,3-5年,本科,技术氛围浓厚、大平台、六险一金,岗位职责：1、负责基于Hadoop平台的海量数据处理、数据计算、数据开发。2、负责数据可视化工具系统的开发，包括报表系统、自助工具系统。3、负责数据仓库的建设，包括业务对接、需求梳理及ETL开发和任务优化。4、负责数据产品和数据项目的相关开发支持。5、负责垂直领域的数据探索，价值数据提取。任职要求： 1、必备技能：JAVA、Hive、MR、spark、shell、awk、perl、Linux下的基本命令；对大数据 处理、数据仓库结构有一定认知； 2、至少精通一种关系型数据库，如MSSQL、MySQL、Oracle等； 3、熟悉互联网环境，了解互联网数据的基本概念； 4、工作态度端正，有较强的责任心及执行力，紧急工作能够快速响应；有较强的抗压 能力，能够适当加班； 5、至少2年实际工作经验，不含实习期。 6、以上要求与实际工作内容紧密相关，为岗位最低要求。,文娱丨内容,2000人以上,spark,北京
Java 研发工程师 - 大数据方向,https://www.lagou.com/jobs/6486711.html,海淀区,25k-40k,新浪网技术（中国）有限公司,3-5年,本科,技术氛围浓厚、大平台、六险一金,"【工作职责】：1、参与优化改进新浪集团数据平台基础服务，包括日传输量超过百TB的数据传输体系优化，日处理量超过几十PB级别的数据处理平台改进；2、参与 Hadoop、Spark、Flink 集群的开发、调优、监控等工作；3、参与开发优化分布式机器学习算法；4、为集群用户提供开发优化技术支持。【任职要求】：1、计算机相关专业本科及以上学历，有良好的数据结构、算法基础，熟悉Linux基本操作；2、熟练掌握Java 语言，了解Shell, Python等常用编程语言，有良好的代码习惯；3、有较多的性能优化经验；4、具备良好的学习能力、分析能力和解决问题的能力。【加分项】：1、了解大数据相关框架：Hadoop、Spark、Flink、HBASE 等；2、有开源项目开发维护经验。",文娱丨内容,2000人以上,spark,北京
java高级开发工程师,https://www.lagou.com/jobs/7071910.html,海淀区,30k-50k,贝壳找房（北京）科技有限公司,3-5年,本科,高期权 16薪 良好的技术氛围,【岗位职责】1、参与贝壳商业化/营销等相关项目的需求分析、设计、开发及优化；2、制定开发计划，保证系统的开发进度和质量，完成项目的核心编码；3、理解业务需求，能发现系统优化点并推动实现【岗位要求】1、3年以上Java研发工作经验，具有扎实计算机基础知识：IO、多线程；2、JVM：内存模型，能准确描述完整的对象生命周期；GC垃圾回收器类型和原理，能准确表述每个动作阶段；类加载机制，能描述类加载过程；3、Spring：能掌握Spring核心原理，熟悉Spring全家桶；掌握常用框架例如Shiro、Mybatis、Dubbo的基本原理，能准确表达使用场景；4、DB：Mysql、Redis、Mongodb等常规经验；5、技术解决方案：分布式事务、分布式缓存、分库分表等技术方案实施经验；【进阶加分】1、JVM：了解JavaAgent或字节码技术经验2、大数据：有大数据相关经验，例如Hadoop、Spark、Flink、Kylin、Druid、M3DB等运用经验；3、前端：了解HTML、CSS、JS、React、Vue等,房产家居,2000人以上,spark,北京
高级/资深java工程师,https://www.lagou.com/jobs/6815400.html,海淀区,25k-45k,贝壳找房（北京）科技有限公司,3-5年,本科,D+轮融资 福利待遇优渥,注意看，可在线深入聊以下内容：技术范围！！！职位要求！！！必备技能范围等等！！！小姐姐在线等撩！！！【岗位要求】1、3-6年Java研发工作经验，具有扎实计算机基础知识：IO、多线程；2、JVM：内存模型，能准确描述完整的对象生命周期；GC垃圾回收器类型和原理，能准确表述每个动作阶段；类加载机制，能描述类加载过程；3、Spring：能掌握Spring核心原理，熟悉Spring全家桶；掌握常用框架例如Shiro、Mybatis、Dubbo的基本原理，能准确表达使用场景；4、DB：Mysql、Redis、Mongodb等常规经验；5、技术解决方案：分布式事务、分布式缓存、分库分表等技术方案实施经验；6、基础Linux命令：能准确表达常见的使用过的命令；【进阶加分】1、JVM：了解JavaAgent或字节码技术经验2、大数据：有大数据相关经验，例如Hadoop、Spark、Flink、Kylin、Druid、M3DB等运用经验；3、前端：了解HTML、CSS、JS、React、Vue等4、网络拓扑：了解网络拓扑结构，有网络部署的经验；5、自动化：有自动化构建、测试、发布、部署流程经验；【岗位职责】1、参与贝壳商业化/营销等相关项目的需求分析、设计、开发及优化；2、制定开发计划，保证系统的开发进度和质量，完成项目的核心编码；3、进行技术调研和技术攻关，解决系统和项目中的技术难点；【岗位潜力】1、团队技术氛围浓烈，把各种技术应用在业务发展上，能快速提升技术水平；2、不管是技术产出还是业务产出，都有很多晋升机会Show出自己；,房产家居,2000人以上,spark,北京
数据仓库架构师（高级/资深）,https://www.lagou.com/jobs/7193412.html,海淀区,25k-50k,北京聪明核桃教育科技有限公司,5-10年,本科,互联网教育公司，少儿编程赛道****,职位描述：  - 负责数据仓库模型设计和开发，负责数据仓库规范建立的推动落地- 参与实时数据仓库开发，负责技术难题攻关，解决关键技术问题和性能问题等任职要求： - 至少5年以上数据仓库相关工作经验 - 熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，精通3NF和多维数据模型设计 - 精通数据仓库实施理论，具备大型数据仓库设计，模型设计能力 - 熟悉Hadoop生态圈组件，用Hive/MR/Spark处理大数据相关问题的经验，具备丰富的性能调优经验 - 熟悉flink，有实际flink项目开发经验，能解决关键技术问题- 掌握基本的数据结构、算法，依据实际的数据问题具备一定的算法调优能力 - 能熟练使用python/shell等脚本语言，解决日常工作问题- 具备海量数据处理、性能调优经验者优先;有互联网行业数据类工作经验者优先,教育,500-2000人,spark,北京
后端开发工程师,https://www.lagou.com/jobs/7174339.html,海淀区,18k-35k,北京智者天下科技有限公司,3-5年,本科,扁平管理；各项补助；弹性工作；多种福利,"岗位职责：
 负责知乎会员内容在知乎各场景下的分发
 设计和实现高并发、低延时的会员内容分发系统
 优化分发系统召回、排序、流量优化等策略
 分析和发掘现有系统的不足，定位系统瓶颈，提高系统性能/稳定性
任职要求：
 统招本科以上学历，计算机相关专业，拥有 2 年以上服务器后端开发经验
 熟练掌握 Python/Golang/C++/Java 两种以上编程语言，熟悉 MySQL、Redis、Elasticsearch、Kafka 等后端组件的使用，对高并发处理有一定的经验
 熟悉大数据开发工具，会使用 Hadoop/Spark 开发
 有一定的机器学习理论基础，有推荐、搜索算法经历优先
 善于思考和发现问题，并能提出改进方案",社交,500-2000人,spark,北京
后端开发工程师（分发策略） (MJ001248),https://www.lagou.com/jobs/7203737.html,海淀区,15k-30k,北京智者天下科技有限公司,3-5年,本科,扁平管理；各项补助；弹性工作；多种福利,岗位职责:1、负责知乎会员内容在知乎各场景下的分发2、优化分发系统召回、排序、流量优化等策略3：分析和发掘现有策略的不足，定位系统瓶颈，提高内容分发效率任职要求：1、统招本科以上学历，计算机相关专业，拥有 2 年以上算法或大数据工作经验2、熟练掌握 Python/Golang/Java 两种以上编程语言3、熟悉大数据开发工具，会熟练使用 Hadoop/Spark 开发4、有一定的机器学习理论基础，有推荐、搜索算法经验优先,社交,500-2000人,spark,北京
中级大数据开发,https://www.lagou.com/jobs/7111279.html,海淀区,18k-25k,北京广通信达软件股份有限公司杭州分公司,3-5年,本科,五险一金季度调薪年终奖团建节日礼品体检,岗位职责：1、基于Java相关技术的软件设计与开发；2、参与系统功APP应模块的分析设计和核心功能的开发；3、负责解决产品部署安装、配置实施过程中遇到的问题，并及时跟相关团队人员沟通解决处理问题。4、参与大数据存储系统、分布式计算系统、数据集成等的设计、研发、维护、优化工作；5、定期向上级主管汇报工作情况。任职要求：1、统招本科学历，3年以上大数据相关工作经验；2、熟悉Flume、Spark、Sparkstreaming、Flink、Kafka等主流大数据生态和相关开源项目；3、可对Elasticsearch进行安装维护，即基本的日志排查、restful api查询，分析；4、熟练使用kafka编程并有相关研发经验；5、优秀的沟通能力与团队协作能力。,"移动互联网,数据服务",500-2000人,spark,北京
高级大数据开发（teamleader）,https://www.lagou.com/jobs/7111236.html,海淀区,25k-35k,北京广通信达软件股份有限公司杭州分公司,5-10年,本科,五险一金季度调薪年终奖团建节日礼品体检,岗位职责：1、负责企业定制化大数据项目管理，数据应用场景落地工作。2、参与大数据平台建设、数据管理平台建设，以及基于平台上的大数据分析解决方案；3、负责项目用户数据需求梳理分析、根据客户业务痛点挖构建数据建模、促进数据应用场景落地，负责项目相关产出物、文档、汇报材料的统筹和质量把控工作；4、负责项目团队管理，可以带领项目成员按时完成设计及开发工作；5、负责项目开发进程管理，能够组织项目组技术选型攻关、组织技术团队完成技术工作；6、积极响应客户需求，提升客户满意度。任职要求：1、统招本科及以上学历，计算机软件相关专业，5年以上大数据相关工作经验；2、熟悉Flume、Spark、Sparkstreaming、Flink、Kafka、ElasticSearch等主流大数据生态和相关开源项目，需要具备大数据相关项目管理经验；3、优秀的沟通能力与团队协作能力，组织领导能力，良好的文档能力；4、具备运维或金融类大数据业务优先，有市场洞察、竞品分析、客群分析、相关项目经验优先。,"移动互联网,数据服务",500-2000人,spark,北京
高级数仓工程师,https://www.lagou.com/jobs/7045708.html,大兴区,25k-50k,北京京东世纪贸易有限公司,3-5年,本科,14薪、免费班车、餐补等,"岗位职责： 1、建设大规模数据的在线/离线基础架构，并根据上层业务需求和计算逻辑持续优化； 2、建设数据仓库架构的子系统，包括不限于：调度系统、元数据管理、数据质量监控、高效数据同步、流式数据采集、多维数据分析引擎等； 3、解决和优化业务人员在开发过程中遇到的计算平台优化、数据处理技术、基础工具使用等技术问题； 4、贴近业务方实现快速迭代开发。 职位要求： 1、统招本科以上学历，计算机相关专业； 2、熟悉Hadoop,Hive,Hbase,Spark,Flink,Flume等开源技术，有4年以上的实际工作经验，对相关系统源码有研究更佳； 3、熟悉分布式系统架构或模型，对资源管理、调度算法、并行数据处理有自己的理解； 4、熟悉Linux开发环境，熟练掌握至少一种编程语言(Java、Python、Scala)； 5、有互联网公司大规模数据平台建设经验者优先； 6、思维敏捷，对新技术敏感，有较强的钻研学习能力。",物流丨运输,2000人以上,spark,北京
大数据BI工程师,https://www.lagou.com/jobs/7083182.html,大兴区,20k-40k,北京京东世纪贸易有限公司,3-5年,本科,免费班车、年底双薪,岗位职责： 1、负责企业级数据仓库架构设计、业务大数据模型设计和开发、维护管理工作。 2、对数据进行多维度的分析汇总，支撑公司日常业务运营，有业务和数据敏感性。 任职要求： 1、2年以上基于Hadoop平台使用hive、Python、shell进行ETL数据开发，能够使用spark进行脚本工程化，熟悉Linux常用命令。 2、能够使用PowerDesigner、ER工具数仓模型设计。 3、能够对MapReduce过程和大数据计算任务进行调优。 4、了解mysql、es等数据库表操作工作原理。 5、对数据仓库方法论有自己的理解。,物流丨运输,2000人以上,spark,北京
JAVA开发工程师,https://www.lagou.com/jobs/7179363.html,朝阳区,15k-25k,北京游道易网络文化有限公司,3-5年,本科,五险一金 优惠午餐 年度体检,"岗位职责:1、负责公司平台系统的研发工作，并不断满足业务的变化和用户的需求;2、参与软件需求与设计审核系统分析与设计;3、根据开发规范与流程独立完成模块的设计、编码、测试以及相关文档;4、参与完成核心代码和代码审查;5、确保线上服务的稳定性和以及完善架构合理性  岗位要求：1、本科或以上学历，计算机相关专业，热爱互联网 2、具有5年以上Java研发经验 3、熟练编写SQL语句和进行数据库优化 ,同时了解nosql数据库4、熟悉SpringBoot,Dubbo,Redis,MQ,ES相关中间件,对底层实现有较为深入的理解;5、目标驱动,工作积极主动、勤恳踏实、具有责任感和团队精神6、有大规模项目架构设计经验者优先7、大流量高并发Web开发经验者优先 优先考虑·有游戏行业从业经验· 数据分析实践经验;· 熟悉大数据处理相关产品架构和技术（Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等）","移动互联网,游戏",50-150人,spark,北京
大数据研发工程师 (MJ004414),https://www.lagou.com/jobs/7026351.html,海淀区,25k-50k,小船出海教育科技（北京）有限公司,3-5年,本科,弹性工作,"岗位职责：1. 业务数据报表设计、开发及日常维护；2. 搭建项目的数据分析平台，并进行功能维护、性能优化和系统升级；3. 及时响应数据统计分析需求，并根据数据分析结果提出业务策略建议；4. 结合业务特点，探索并建立分析主题，对数据进行深度分析和挖掘。岗位要求：1. 本科或以上学历，计算机、统计、数学等相关专业毕业，一年以上工作经验；2、精通SQL，有较好的SQL性能调优经验，了解Hive/MySQL的基本原理和调优策略3、熟悉常用的数据挖掘、分析的工具和方法，熟悉linux平台，精通Golang/Python等语言的一种或多种，编码基本功扎实 ；4、熟悉大数据处理相关技术，包括不限于Flink，Hadoop, Hive, Spark, Kylin, Hbase等。5. 优秀的分析问题和解决问题的能力，能够把合理的思路成功应用于实践；6. 表达能力强，具备优秀的快速学习能力、沟通协调能力及团队精神；7. 有较强的责任心和学习积极性。",工具,2000人以上,spark,北京
推荐算法工程师（北京）,https://www.lagou.com/jobs/6357349.html,朝阳区,30k-60k,维沃移动通信有限公司,3-5年,本科,高激励 扁平化 福利好,"岗位职责：1.负责vivo互联网各产品推荐系统开发，开展线上算法实验2.对实验数据进行处理和分析，发现现有系统和算法的不足，提出改进并推动实现任职要求：1. 计算机或相关专业，本科以上学历，机器学习/数据挖掘/推荐系统3年以上经验2. 熟悉Hadoop, spark, Hive等大数据处理工具3. 熟悉linux环境，熟悉java/scala和python编程语言4. 熟悉用户画像，物品标签系统建设5. 熟悉协同过滤，矩阵分解等经典推荐算法6. 熟悉特征工程，多路召回，和ctr预估常用算法(LR/GBDT/FM/FFM)7. 有深度学习在推荐系统中应用经验者优先",硬件,2000人以上,spark,北京
算法工程师,https://www.lagou.com/jobs/7043122.html,朝阳区,15k-30k,北京密境和风科技有限公司,不限,硕士,福利好，空间大,"工作职责：1. 研究数据挖掘或统计学习领域的前沿技术,并用于实际问题的解决和优化2. 负责机器学习的算法和模型的开发，尤其是深度学习领域3. 开发算法应用于视频内容识别、内容精准推荐等领域，负责serving系统的高可用服务的搭建和维护岗位要求：1. 计算机、自动化、统计学、数学等相关专业本科及以上学历，硕博士优先2. 熟悉常用机器学习算法，尤其是深度学习相关领域，对模式识别，概率统计、智能推荐算法原理及应用，有扎实的基础，深入的理解和浓厚的兴趣，在相关期刊和会议上发表过论文的优先考虑3. 精通Python、Golang、C/C++、Java等至少一门编程语言，有较强动手能力，精通常用的算法和数据结构4. 了解目前常见的机器学习或者深度学习框架中的一个或者多个：Spark，XGBoost，Tensorflow，Caffe等5. 乐于动手，有良好的逻辑思维能力和数据敏感度，能够熟练阅读英文论文并且予以实践和改进，具有优秀的新技术研究和实现能力",社交,150-500人,spark,北京
搜索算法架构师,https://www.lagou.com/jobs/6962229.html,朝阳区,35k-65k,上海阅文信息技术有限公司,5-10年,本科,大平台、领导nice、福利好,,文娱丨内容,500-2000人,spark,北京
大数据开发工程师（北京）,https://www.lagou.com/jobs/6615079.html,朝阳区,25k-45k,上海阅文信息技术有限公司,5-10年,本科,大平台、领导nice、福利好,,文娱丨内容,500-2000人,spark,北京
数据仓库工程师,https://www.lagou.com/jobs/7218255.html,朝阳区,15k-30k,北京瓴岳信息技术有限公司,1-3年,本科,大牛团队 扁平化管理,岗位描述： 1、负责公司级的数据仓库平台相关产品的设计研发，服务于公司各个业务线； 2、负责大数据服务平台接口的迭代开发，构建离线&实时的数据仓库平台3、基于hadoop、spark、hive、hbase、flink等开源技术构建解决方案满足业务方需求4、构建设计良好的数据仓库、调度系统、查询引擎，数据服务、分析系统等，保证系统稳定高效运行，以实现数据的最大价值。 我们期望： 1、熟悉多项大数据处理分析相关的工具框架，e.g. Hadoop Mapreduce Hive flink Spark kylin kafka hbase canal etc；2、强悍的编码能力，生产环境快速 troubleshooting能力，对新技术有强烈的学习热情；3、优秀的理解沟通能力，能快速理解业务背景，对数据敏感，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值，有web应用开发能力者优先。4、熟练使用java语言，有大数据平台系统研发经验，熟悉Java\python开发经验优先。,"移动互联网,金融",150-500人,spark,北京
服务器leader,https://www.lagou.com/jobs/7105591.html,海淀区,30k-50k,北京艨艟信息技术有限公司,5-10年,本科,高成长，六险一金，年度体检，定期团建,岗位职责：1、负责web服务的开发，为上亿全球用户提供稳定可靠的服务；2、负责对上亿用户的行为分析，研发数据分析平台等；3、负责管理服务器团队，提升团队综合能力；4、负责服务器部门的技术架构、技术选型和技术方向的把握。任职要求：1、全日制本科以上学历；2、5年以上实际服务器项目开发实施工作经验，1年以上开发团队管理经验；3、熟悉JAVA，php，ruby， python，go，C#语言中的一种，愿意深入学习python；4、熟悉面向对象等编程思想，理解软件工程的思想以及常见的开发模式，了解敏捷开发；5、熟悉SQL、NOSQL等多种数据库类型，了解数据仓库，了解数据库缓存优化的常用技术方案；6、了解大数据相关技术的优先，包括但不限于Hadoop / Spark等；7、了解运维以及DevOps的概念，有Kubernates经验的优先；8、了解前端HTML，javascript技术；9、具备快速理解和把握新技术的能力；10、良好的沟通交流能力，优秀的解决问题的能力；11、良好的组织能力和管理能力，能帮助技术团队提升整体技术能力。,"游戏,软件开发",50-150人,spark,北京
服务器端负责人,https://www.lagou.com/jobs/7110919.html,海淀区,30k-50k,北京艨艟信息技术有限公司,5-10年,本科,下午茶 switch 弹性工时,岗位职责：1，负责web服务的开发，为上亿全球用户提供稳定可靠的服务；2，负责对上亿用户的行为分析，研发数据分析平台等。3，负责管理服务器团队，提升团队综合能力4，负责服务器部门的技术架构、技术选型和技术方向的把握任职要求：1，全日制本科以上学历；2，5年以上实际服务器项目开发实施工作经验，1年以上开发团队管理经验3，熟悉python，go，C#语言中的一种，愿意深入学习python；4，熟悉面向对象等编程思想，理解软件工程的思想以及常见的开发模式，了解敏捷开发；5，熟悉SQL、NOSQL等多种数据库类型，了解数据仓库，了解数据库缓存优化的常用技术方案6，了解大数据相关技术的优先，包括但不限于Hadoop / Spark等；7，了解运维以及DevOps的概念，有Kubernates经验的优先8，了解前端HTML，javascript技术；9，具备快速理解和把握新技术的能力10，良好的沟通交流能力，优秀的解决问题的能力11，良好的组织能力和管理能力，能帮助技术团队提升整体技术能力,"游戏,软件开发",50-150人,spark,北京
java开发工程师,https://www.lagou.com/jobs/6233465.html,朝阳区,30k-50k,瑞庭网络技术（上海）有限公司,3-5年,本科,有竞争力的薪酬，可爱的同事,"任职资格：""1）计算机及相关专业本科及以上学历，4年以上JAVA企业应用程序开发经验，熟悉软件开发流程，有良好的的编码习惯；2）熟悉Java，有良好的面向对象设计思想，熟悉设计模式、多线程编程，掌握主流web开发框架，能够独立搭建整体框架；3）熟练Jsp、Jdbc、Struts、Spring、Hibernate开发； 4）熟悉Oracle、MySQL等数据库开发，熟悉常用分库分表技术，熟练编写SQL以及调优； 5）熟悉JavaScript、Jquery、Ajax、ExtJs、JqueryEasyUI等前端开发语言或框架 ；6）参与过大型企业人事业务相关、BPM、办公自动化、企业信息门户、社区等系统开发者优先考虑；7）熟悉消息总线、网络爬虫、统一搜索引擎等工具优先；8）熟悉大数据开发相关技术，如hadoop、hive、spark、impala、storm、hbase、oozie、hue、zookeeper、kafka、flume等者优先；9）熟悉大数据仓库建设，有BI开发经验，对多维数据建模有深入理解，有kylin、cboard、druid经验的优先考虑；""",移动互联网,500-2000人,spark,北京
微服务架构师,https://www.lagou.com/jobs/6560085.html,海淀区,30k-60k,北京云思畅想科技有限公司,5-10年,本科,"**团队,扁平管理,产品领先,技术领先",岗位职责：1、负责时速云微服务产品的架构设计和开发工作；2、负责研究PaaS相关的各种技术，深入了解网络、存储、Docker、Kubernetes、日志监控等技术的一种或多种；3、和产品团队合作进行性能分析和架构优化，引入业界新技术改进云平台产品；4、通过时速云容器云产品为私有云用户提供技术服务和解决方案，帮助用户业务快速上云；5、参与开源社区贡献，和全球化团队协作开发。技能需求:1、熟悉云原生技术栈，如Kubernetes，DevOps，微服务等；2. 精通基于Spring boot、Spring Cloud或者Dubbo的微服务架构；3. 扎实的java编程基础，精通Java EE、SOA、OSGI等相关技术；对各种开源的框架如Spring、mybatis、spring boot、spring cloud、dubbo等有深入的了解，对框架本身有过开发或重构者可优先考虑；4. 熟悉redis、kafka、MariaDB、mongodb、hadoop、spark、ElasticSearch等大数据技术；5. 熟悉docker、kubernetes、mesos等容器技术并有实际使用经验；6. 至少5年以上工作经验， 必须具备项目实施经验，具有解决疑难问题的能力。,"企业服务,数据服务",150-500人,spark,北京
推荐算法工程师,https://www.lagou.com/jobs/7081459.html,海淀区,20k-40k,北京爱彩虹科技有限公司,3-5年,本科,有很多颜值高的同事,"岗位职责：1.深入理解业务和机器学习技术，优化模型策略，持续提升推荐效果；2.参与推荐系统架构设计与实现、核心代码编写、接口规范制定；岗位要求：1.从事推荐算法相关工作经验2年以上2.熟练掌握Python/Java 一种或多种语言, 具备强悍的编码能力和扎实的数据结构和算法功底.熟悉推荐系统常见的召回策略和模型包括不限于（CF, word2vec, contentbase, DNN）等召回算法，或者熟悉常见的CTR模型包括不限于(LR, GBDT, wide&deep, DNN，在线反馈算法) ;3.熟悉Hadoop, Spark/Flink/Storm/Hive/Hbase 的一种或多种开源大数据工具4.熟悉Tensorflow等深度学习工具并有实际落地项目4.学习能力强，自我驱动能力强，可以自我管理，有自我规划意识。 乐观开朗，抗压能力要强不反感LGBT文化","移动互联网,社交",50-150人,spark,北京
推荐系统工程,https://www.lagou.com/jobs/5299780.html,海淀区,30k-60k,北京快乐茄信息技术有限公司,不限,不限,年底双薪,"岗位职责：负责feed流的推荐结果召回策略/排序策略的研发。任职资格1. 熟练掌握python/c++/java 一种或多种, 具备强悍的编码能力和扎实的数据结构和算法功底；2. 熟悉推荐系统常见的召回策略和模型包括不限于（CF, 二分图，word2vec, contentbase, LSTM，DNN）等召回算法，或者熟悉常见的LTR模型包括不限于(LR, GBDT, wide&deep, DNN，在线反馈算法) ；3. 熟悉hadoop, spark, flink, storm， hive，hbase 等大计算工具优先；4. 熟悉tensorflow等深度学习工具并有实际落地项目者优先，有推荐，搜索相关项目研发经验者优先。",工具,150-500人,spark,北京
数据仓库开发工程师,https://www.lagou.com/jobs/6691003.html,朝阳区,25k-40k,北京小唱科技有限公司,5-10年,本科,年终奖 福利好 弹性工作时间,岗位职责： 1. 关注数据变化，负责数据仓库ETL开发，参与团队ETL流程的优化以及相关技术问题的解决； 2. 理解业务需求，建设面向主题的数据集市，支持公司的BI指标； 3. 参与唱吧实时/离线数据平台相关数据开发和管理工作； 4. 跟进数仓技术的演进，推动相关应用落地。  职位要求 1. 计算机/通信/电子/数学/物理等相关专业本科及以上学历 2. 具备数据仓库理论基础，在数据仓库相关领域有3年以上工作经验，在数据治理方面有一定产品化经历； 3. 熟悉数据仓库模型设计方法论，了解数据仓库数据分层架构，精通3NF和多维数据模型设计; 4. 熟悉仓库建设相关的技术栈，包括且不限于：SQL，Hive，Hadoop/Spark，Flume，Kafka，HBase等，精通HiveSQL优先； 5. 至少掌握一门开发语言，包括且不限于：JAVA、Python、Scala、PHP等，掌握UDF和Map-Reduce开发； 6. 具备数据挖掘和机器学习算法应用经验优先； 7. 具备良好的语言沟通、表达能力和学习能力；,"移动互联网,游戏",150-500人,spark,北京
物联网大数据架构师,https://www.lagou.com/jobs/5828005.html,海淀区,20k-40k,北京源清慧虹信息科技有限公司,3-5年,本科,二次医疗 绩效奖金 健身房,技能要求：数据架构，解决方案、分布式、微服务架构，大型分布式架构，Hadoop岗位职责：1. 负责物联网大数据平台系统的设计与实现，包括实时流和离线数据等相关功能的开发与实现。2. 负责完成核心代码技术攻坚。3. 根据开发规范与流程独立完成模块的设计、编码、测试以及相关文档。4. 负责物联网监测行业的算法工程化实现。任职资格1. 计算机相关专业本科及以上学历。2. 3年以上开发经验熟练掌握Python 、Go 、C++中的至少一种开发语言。3. 有相关的大数据系统架构经验，具有扎实的计算机科学功底，扎实的编程基础和数据结构算法基础，良好的工程素养，极强的问题解决能力。4. 熟练掌握Hadoop、Kafka、Spark、Storm等分布式框架原理，有相关的调优、运维、开发经验。5. 具有Postgresql、MySql、MongoDB，ClickHouse等其中一种数据库应用开发经验。6. 有物联网相关系统、可视化相关系统、微服务相关系统的设计和研发经验的优先考虑。7. 对技术有激情，有较强的独立、主动的学习能力，良好的沟通表达能力。8. 善于交流，有良好的团队合作精神和积极的工作态度，个人素养过硬。,"信息安全,数据服务",50-150人,spark,北京
后端开发工程师（广告）,https://www.lagou.com/jobs/7088969.html,海淀区,15k-25k,北京木瓜移动科技股份有限公司,3-5年,本科,国际化，大平台，产品好，有大牛,岗位职责：3、协助需求调研、竞品监控、数据分析等相关工作。,移动互联网,150-500人,spark,北京
java开发工程师,https://www.lagou.com/jobs/7055045.html,朝阳区,18k-28k,北京京东世纪贸易有限公司,3-5年,本科,世界500强股票期权带薪年假免费班车,"岗位职责：1、负责智能客服对话机器人的系统设计和研发工作；2、负责打造通用智能对话能力平台，提供各行业对话解决方案；3、对接前沿的NLP算法融合落地到智能对话平台；4、支持京东内外的对话项目在对话能力平台落地。任职要求：1、计算机等相关专业本科以上学历，扎实的计算机基础和丰富的研发经验；2、熟悉Java开发和相关JVM调优，对数据结构和算法设计具有深刻的理解；3、熟悉常见的分布式框架，如 Dubbo HSF,JSF 等；4、有对话系统研发经验和 NLP 相关背景的优先；5、有Hadoop 大数据处理经验，了解hive、spark等大数据核心技术的优先；6、具备良好的沟通能力，团队合作精神。",电商,2000人以上,spark,北京
后端开发工程师,https://www.lagou.com/jobs/7174143.html,海淀区,20k-30k,北京木瓜移动科技股份有限公司,1-3年,本科,发展成长快，技术氛围好,,移动互联网,150-500人,spark,北京
大数据架构师 (MJ000033),https://www.lagou.com/jobs/7077651.html,朝阳区,35k-55k,北京好赞移动科技有限公司,5-10年,本科,弹性工作 租房 交通 午餐 通讯补贴,岗位职责：1、负责公司内部大数据存储计算平台等基础设施的搭建、维护、优化、改造；2、负责建设基础数据流程，并提供稳定的基础数据服务。职位要求：1、重点本科或本科以上学历，计算机相关专业，3年以上的大数据平台开发经验；2、有TB以上数据量的处理、优化经验优先；2、熟悉hadoop、spark、hive等，对hadoop等源码有研究者优先；3、工程能力强，基础扎实，熟悉java、python、shell、scala等；4、对技术有持续追求，强烈的技术领导力和责任心；5、优秀的分析问题和解决问题的能力，对解决挑战性问题充满激情。,"移动互联网,社交",150-500人,spark,北京
资深算法工程师 (MJ000012),https://www.lagou.com/jobs/7090889.html,朝阳区,30k-55k,北京好赞移动科技有限公司,3-5年,本科,弹性工作 租房 交通 午餐 通讯补贴,"""1. 结合nice的业务特点，运用机器学习理论和方法，针对海量信息建模、挖掘潜在用户价值，从数据与技术的角度驱动产品与业务的迭代更新。2. 研究推荐系统领域的前沿理论与技术，参与推荐、搜索系统的构建，优化核心指标，提升用户体验，实现技术与产品的完美融合。  具体内容包括但不限于: 内容、用户标签体系的构建，推荐、搜索等业务算法模型的设计开发，推荐系统的效果分析及优化。/""""岗位要求1、数学或计算机科学等相关专业，有3年以上算法模型经验；2、熟悉推荐系统常见的召回策略和模型包括不限于(CF, word2vec, contentbase, LSTM，DNN等)召回算法，熟悉常见的LTR模型包括不限于(LR, GBDT, wide&deep, DeepFM等)；3. 扎实的算法和数据结构基础，至少熟练使用C/Java/python等其中一种编程语言 4. 熟练掌握海量数据处理技术，有使用Hadoop/Hive/Spark分析海量数据的能力和经验；5. 有大规模算法体系设计与实践经验，包括搜索系统、推荐系统、广告系统、自然语言处理、用户数据分析和建模等者优先。""","移动互联网,社交",150-500人,spark,北京
高级数据开发/仓库专家,https://www.lagou.com/jobs/7131819.html,朝阳区,35k-60k,北京圣达龙翔科技有限责任公司,5-10年,本科,年底双薪，股票期权，大牛多,岗位职责：1、搭建并优化数据体系，负责数据仓库方向、数据应用方向开发和管理工作；2、带领小伙伴构建金融及其各个业务线（包括但不限于：金融生态、支付平台、保险业务等）数据仓库（分层建设、主题模型、元数据管理、性能和效率优化）；3、参与/负责相关 BI 系统建设及其解决方案落地，规划并带领小伙伴试错、成长；4、负责数据仓库 OLAP 体系搭建，建设 PB 级高效、灵活的在线分析应用；5、受理数据日常需求开发，与分析师、PM、OP 一起感知变化，实现高效的数据运营；6、与团队一起调研和实践热门数据仓库组件和技术（kylin、spark、doris、storm、实时数仓......）。任职要求：1、4 年以上数据仓库(DW) / 商业智能(BI) / 数据统计相关工作经验；2、3 年以上数据团队管理经验优先考虑，有成功的案例和项目管理经验，能规划技术路线；3、有支付、金融、风控等系统数据建设经验优先；4、熟悉数据仓库建设方法论：a：熟悉 etl 分层（ODS、CWD、DWD、AWD）建设方法；b：熟悉主题建设方法，能独立抽象主题、建设模型、物理化并调整效率和性能；c：熟悉常用的 BI 系统建设方法，熟练使用主流 BI 工具，理解其实现原理、使用什么技术解决什么问题；5、熟练掌握 SQL，理解 Hive/MySQL/Oracle 原理和调优方法，有独立处理大规模数据/日志的经历；6、熟练掌握 Java / Python / PHP 中至少一种编程语言。,"硬件,数据服务",150-500人,spark,北京
后端研发工程师（AIDC）,https://www.lagou.com/jobs/7203562.html,朝阳区,25k-50k,北京京东世纪贸易有限公司,5-10年,本科,AI 智能云领域 IOT,1. 负责京东数据中心基础设施管理系统的后端设计研发。2. 负责智能数据中心、智慧园区等场景下，基于Lora、Nbiot等通讯协议的的物联网系统设计研发。3. 负责数据中心监控、物联网设备等数据的流式实时处理系统搭建。任职要求：1. 计算机或相关专业，本科或以上学历，5年以上后端产品研发经验。2. 熟悉多种编程语言，如 Java、Golang、Python 等等。3. 3年以上大型数据库MongoDB、mysql使用经验，精通大规模高并发访问的应用系统设计和开发经验，熟悉Redis，Kafka，ActiveMQ\Rabbit MQ\RocketMQ。4. 有Flink、spark、tensorflow相关项目经验优先。5. 具备良好的识别和设计通用框架及模块的能力。6. 具有良好的沟通理解能力和团队合作精神，可快速分析并解决问题，项目管理能力与执行力强。,电商,2000人以上,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7211887.html,海淀区,16k-30k,度小满科技（北京）有限公司,1-3年,本科,六险一金 班车接驳 健身房 免费水果,"工作职责- 负责度小满金融Growth Hacking团队的亿级别数据的仓储设计和构建；- 负责度小满新一代智能营销系统的设计和实现；- 负责用户增长团队的策略框架的设计和开发，支持模型自动迭代；职责要求-熟悉Hadoop/Kafka/Spark/Hive/Hbase等分布式开源项目及工作原理，并有实际开发经验-数据常见流计算框架如flink，storm等-熟悉常用脚本语言shell,python等-熟悉C/C++，Java编程语言，熟悉linux平台、shell脚本，对数据结构和算法设计有较深刻的理解等-熟悉TCP/IP HTTP等网络协议，有高并发服务开发经验者优先-熟悉Mysql、nosql等数据库-本科及以上相关专业学历，1年及以上工作经验",金融,2000人以上,spark,北京
大数据开发负责人,https://www.lagou.com/jobs/7184760.html,朝阳区,35k-50k,北京拉克沙网络科技有限公司,不限,本科,"业务全球化,无限下午茶,扁平化,股权激励","职位职责：1、负责 HOLLA Group 用户行为的理解和建模，帮助公司各项业务满足用户需求，提升用户覆盖；2、带领团队搭建数据治理、数据质量和元数据等规范体系，提升数据易用性及数据质量、准确度；3、优秀的业务理解和抽象能力，发挥数据价值，与业务团队紧密合作；4、能够根据公司和业务需要，有效规划技术选型和落实、团队建设与维护；职位要求：1、精通数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；2、拥有扎实的数学基础，具备较强的编码和架构能力，熟悉 SQL, Python, Hive, Spark, Kafka, Flink, Druid 中的多项，有至少 TB 以上级大数据处理经验；3、对数据敏感，认真细致，善于从数据中发现疑点；4、有成熟的团队管理和业务分配经验，具备优秀的技术与业务结合能力；5、加分项：对机器学习有一定了解，有海外项目开发经验；","移动互联网,社交",50-150人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6839321.html,朝阳区,20k-30k,北京拉克沙网络科技有限公司,3-5年,不限,"业务全球化,无限下午茶,扁平化,股权激励","1、负责 HOLLA Group 用户行为的理解和建模，帮助公司各项业务满足用户需求，提升用户覆盖； 2、参与数据治理工作，提升数据易用性及数据质量、准确度； 3、理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作； 职位要求： 1、精通数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景； 2、具备较强的编码能力，熟悉 SQL, Python, Hive, Spark, Kafka, Flink, Druid 中的多项，有至少 TB 以上级大数据处理经验； 3、对数据敏感，认真细致，善于从数据中发现疑点； 4、善于沟通，具备优秀的技术与业务结合能力； 5、加分项：对机器学习有一定了解，有海外项目开发经验；","移动互联网,社交",50-150人,spark,北京
大数据基础平台产品经理,https://www.lagou.com/jobs/7092719.html,海淀区,20k-25k,中科天玑数据科技股份有限公司,3-5年,本科,科学院孵化，福利待遇好，技术牛人多,工作职责：1、发起大数据基础平台客户和市场的需求分析，结合公司优势，针对特定领域制定产品短期和长期规划；2、负责产品需求调研，方案设计，跟进项目到产品最终上线所有流程；3、协调各团队的资源和支持，保障产品顺利上线；4、制定数据产品运营计划、市场计划，制定目标，做好资源协调；5、建立或优化，关注用户、市场的需求变化，制定改进方案。任职要求：1、计算机相关专业背景，熟悉大数据平台产品研发过程，3年以上大数据平台相关产品或大数据项目经验，对大数据产品有浓厚的兴趣和意愿；2、熟悉主流开源各类大数据组件基本原理和应用场景，包括Hadoop、Hbase、Spark、Kafka、Elasticsearch等；3、有面向企业大数据平台建设相关的产品经验；4、对云原生有一定了解，熟悉docker和kubernetes相关技术者优先；4、熟悉ETL过程，熟悉数据治理，有实际项目实施经验优先；4、有很强的产品意识，能主动发起产品的改进和优化，有执行力。,"移动互联网,数据服务",150-500人,spark,北京
机器学习平台架构师,https://www.lagou.com/jobs/6829339.html,海淀区,20k-40k,北京金山云网络技术有限公司,5-10年,本科,三餐，七险一金，大平台,岗位职责：负责机器学习平台整体架构设计，该平台汇聚多种AI能力，提高用户AI开发效率、降低使用AI技术的门槛；负责具体业务场景中机器学习算法和深度学习模型的研发工作；负责部分团队管理及人才培养工作；岗位要求：统招本科以上学历，5年以上工作经验，知名互联网从业经历者优先。精通Python、Java、Go语言中的一种或多种，熟悉Linux环境下系统开发；具有高性能分布式后台系统架构设计、开发、运维经验；扎实的编程能力，熟悉算法和数据结构，熟悉操作系统、数据库、网络等计算机基础理论；熟悉常见机器学习开发框架，包括spark、Xgboost、TensorFlow、PyTorch等，利用其进行模型开发、训练、优化、服务部署等AI全流程；熟悉Docker等容器化相关技术及kubernetes等云原生开源技术；熟悉常用机器学习和深度学习算法者优先；熟悉AI平台开源系统，如kubeflow、Mlflow等优先；有强烈上进心，自我驱动，学习适应能力强；,"移动互联网,数据服务",2000人以上,spark,北京
高级java工程师,https://www.lagou.com/jobs/6829583.html,海淀区,20k-40k,北京金山云网络技术有限公司,5-10年,本科,三餐，七险一金，大平台,"岗位描述(包括但不限于)：1. 能独立负责内部任务调度平台的开发、维护工作；2. 能独立负责大数据平台权限体系、项目系统的架构设计、开发工作；2. 按照项目计划，带领团队保质保量完成开发任务；3. 核心代码编写、指导和培训工程师、不断进行系统优化任职资格：1. 大学本科以上学历，计算机或相关专业；6年以上Java实际项目开发经验；2. Java基础扎实，理解IO、多线程、集合等基础框架，对JVM原理有了解；3. 熟悉SpringMVC、SpringBoot、Mybatis等开源框架，了解其原理机制；4. 熟练使用RocketMQ、Redis、ZooKeeper、等开源组件；5. 熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息等机制；能对分布式常用技术进行合理应用，解决问题；6. 熟悉Hadoop、Hbase、Spark、ElasticSearch等大数据相关技术优先""","移动互联网,数据服务",2000人以上,spark,北京
大数据计算与调度平台开发工程师,https://www.lagou.com/jobs/6996549.html,朝阳区,30k-50k,北京自如生活企业管理有限公司,3-5年,本科,1 六险一金 2 建立业界领先大数据平台,岗位职责：1. 负责自如大数据计算与调度平台的运维、开发、监控2. 负责大数据管理平台的运维、开发、监控，包括元数据管理、权限管控、血缘分析等任职要求：1. 本科以上学历，计算机相关专业优先，5年以上⼯作经验2. 精通主流大数据批和流处理技术，如Hive、Spark、Flink、Tez、MapReduce等3. 精通主流大数据管理与调度处理技术，如Ambari、Yarn、Atlas、Ranger、Hue、Airflow、Jenkins等4. 熟悉基于Springboot的Java后端开发5. 扎实的计算机基础和算法数据结构功底，掌握Java或Scala，具备并发编程和JVM调优能力6. 良好的团队沟通协调能力和英文阅读能力加分项：1. 对主流大数据处理组件做过二次开发，参与过某些大数据组件的社区开发，附上Github地址或者Blog地址2. 熟悉k8s,房产家居,2000人以上,spark,北京
Java研发架构师,https://www.lagou.com/jobs/7214710.html,朝阳区,35k-45k,北京自如生活企业管理有限公司,5-10年,本科,六险一金，周末双休，租房福利,【岗位职责】1. 带领团队，负责自如 定价、指标、风控 等核心基础平台的设计研发；2. 带领团队，负责自如 算法服务中台的设计研发；【岗位要求】1．统招大学本科及以上学历；2. 5年以上java研发经验，有团队管理经验；3．较强的自驱力、沟通能力，能带领团队进化；【技术能力】1. 熟练掌握 JAVA 和 设计模式，5年及以上J2EE开发经验，熟练使用SpringBoot、SpringCloud、SpringMVC框架；2. 熟练掌握 分布式/高并发/高性能/高可用系统 设计、开发，有相关经验；3. 掌握mysql/oracle等关系数据库基本操作，有SQL查询、索引优化经验；4. 熟悉Redis/Memcache/MongoDB、主流MQ、ElasticSearch，有相关经验者优先；5. 了解Hadoop、spark基本原理，有大数据处理经验者优先；6. 了解前端开发技术，有数据可视化经验者优先；,房产家居,2000人以上,spark,北京
大数据研发工程师,https://www.lagou.com/jobs/6458967.html,海淀区,15k-30k,深圳市顺丰同城物流有限公司,3-5年,本科,弹性工作时间。环境福利待遇好。团队领导好,工作职责:    -负责构建大数据分析平台以及数据分析和挖掘工作    -负责基于顺丰同城数据的离线和实时流分析    -参与支撑业务的数据模型建设及数据指标的计算和分析    -参与海量数据的存储、查询和运营数据分析体系搭建    -运用Hadoop、Spark、ES等分布式计算和存储平台        职责要求:    -计算机相关专业应届毕业生    -对Spark及Hadoop技术有深入了解    -熟悉Python/Java/Scala/Php等编程语言，熟练使用SQL，有良好的编码习惯，对分布式有深刻理解    -了解Windows、Unix、Linux等主流操作系统原理，熟练运用系统层支持应用开发    -技术视野开阔，有强烈的上进心和求知欲，善于学习和运用新知识，勇于解决难题    -善于沟通和逻辑表达，拥有优秀的分析问题和解决问题的能力，良好的团队合作精神和积极主动的沟通意识    -有激情，具有自我驱动力，追求卓越        具有以下条件者优先：    -计算机领域相关的编程大赛获奖、专业期刊发表文章或者有发明专利等    -具备大数据云平台、计算存储平台、可视化开发平台经验，熟悉软件工程开发流程    -具备专业领域的计算机知识和技能： Storm/Hive/Hbase/Storm/Kafka等,消费生活,2000人以上,spark,北京
BI工程师,https://www.lagou.com/jobs/7024318.html,朝阳区,20k-40k,百合佳缘网络集团股份有限公司,3-5年,本科,全景式福利、高成长职业发展路径、职业大牛,"职责描述：1.负责从数据集取、转换、清洗数据到数仓系统，以及数据处理功能的开发，编写相关文档；2.BI报表的日常维护、开发及测试，项目的数据处理、抽取、转换、可视化展现等工作；3.参与数据映射、数据质量分析、数据差异分析；任职要求：1.3年以上数据仓库项目实施经验，独立完成数据处理开发工作，负责过一个完整项目；2.数据仓库领域知识和技能者优先，包括元数据管理、数据开发测试工具与方法、数据质量、主数据管理等；3.精通SQLServer、MySql等主流数据库，熟练掌握上述数据库的开发；4.具有优秀的编程能力，精通Python/PHP以及常用脚本语言；5.熟悉Hadoop、Spark等大数据相关技术,熟悉至少一种以上ETL、BI等相关工具。","移动互联网,社交",2000人以上,spark,北京
IT数据平台架构师,https://www.lagou.com/jobs/6853131.html,海淀区,40k-55k,广州市信创电子科技有限公司,10年以上,本科,薪酬福利好，稳定,"l  负责大数据基础平台的架构设计和优化，灵活支撑业务的创新和探索，体现数据价值；l  根据业务需求搭建项目框架和实施方案，并进行任务分配l  与公司其他架构设计团队合作, 并了解相应的BI 需求l  管理项目团队整体技术，规划团队的大数据技术体系和团队成员的技术成长；l  大数据行业内新技术的攻关和创新技术的引入，提升产品竞争力。 任职资格l  全日制本科及以上学历，具有5年以上大数据研发或2年以上大数据平台架构经验；l  熟悉大数据组建的开发、搭建、维护及调优，精通Java，熟悉Scala、Python语言加分；l  熟悉大数据架构体系，对Hadoop、Hbase、Hdfs、MapReduce、Yarn、Hive、Tez、Spark、Kafka、Flume、Fluentd等组件/技术中的一个或者多个有深入理解；l  较强的开发能力，掌握相关开发语言（Java等）、框架、数据库等相关 知识，能够独立完成并领导团队完成大数据相关的应用实现；l  扎实的独立分析问题、解决问题的能力，具备良好的需求理解能力、沟通协调能力和团队合作精神；有很强的数据设计抽象能力，善于从复杂的数据问题中找到关键路径，并且擅于跟业务团队就业务问题进行良好的沟通，能推动业务的指标化、量化；l  具有高度的责任感和耐心细致的工作态度；能够承受较大工作压力；l  喜欢尝试新技术，追求编写优雅的代码，从技术趋势和思路上能影响技术团队。","电商,企业服务",50-150人,spark,北京
高级BI工程师,https://www.lagou.com/jobs/6884575.html,昌平区,20k-40k,北京太初弈宪科技有限公司,3-5年,硕士,五险一金全额，领导nice，年底14薪,"岗位职责：1.建设游戏行业数据仓库2.为业务部门提供数据报表和分析报告，支撑运营需求3.建立用户画像，精准挖掘用户真实需求任职要求：1.计算机或数学相关专业，本科以上学历，985,211优先2.1年以上大数据开发经验3.熟悉Hadoop Spark和非关系型数据库相关技术4.熟练掌握Linux操作系统，熟悉python和Scala5.良好的学习和逻辑能力",人工智能、软件开发,15-50人,spark,北京
大数据架构师（北京） (MJ000390),https://www.lagou.com/jobs/7135995.html,通州区,20k-40k,杭州玳数科技有限公司,5-10年,本科,阿里系创业、云计算生态、餐补、双休,职位诱惑：挑战，激情，技术大牛，扁平管理，弹性工作1、负责数据中台项目规划、技术架构等工作，包括数据采集、模型、网络、安全、质量等架构设计；2、和产品经理一起推进项目需求落地，将业务和产品需求转变成为技术实现方案；3、深入理解产品的需求、场景，参与核心模块代码开发；4、协同开发工作，确保项目开发的正常进行；5、作为关键技术攻坚人员，解决重大项目的技术疑难问题。并能有效地对新人进行辅导，带领团队快速提升；6、能从技术视角对项目边界、项目投入成本给出合理判断，控制项目风险。  岗位要求：1、本科及以上学历，5年及以上大数据开发经验，精通数据建模理论，丰富的数据仓库设计和大数据项目实施经验；2、熟悉常见的关系型、非关系型数据库的使用，熟悉分布式计算框架Hadoop/Spark/Fink中的至少一种，有Flink开发经验优先考虑，熟悉大数据其他技术栈；3、Java/Python等开发语言至少掌握一种；4、具有良好的沟通、组织能力，强烈的进取心和优秀团队合作精神，接受出差。,数据服务,150-500人,spark,北京
大数据架构师（北京） (MJ000392),https://www.lagou.com/jobs/7153400.html,朝阳区,20k-40k,杭州玳数科技有限公司,5-10年,不限,阿里系创业、云计算生态、餐补、双休,职位诱惑：挑战，激情，技术大牛，扁平管理，弹性工作1、负责数据中台项目规划、技术架构等工作，包括数据采集、模型、网络、安全、质量等架构设计；2、和产品经理一起推进项目需求落地，将业务和产品需求转变成为技术实现方案；3、深入理解产品的需求、场景，参与核心模块代码开发；4、协同开发工作，确保项目开发的正常进行；5、作为关键技术攻坚人员，解决重大项目的技术疑难问题。并能有效地对新人进行辅导，带领团队快速提升；6、能从技术视角对项目边界、项目投入成本给出合理判断，控制项目风险。  岗位要求：1、本科及以上学历，5年及以上大数据开发经验，精通数据建模理论，丰富的数据仓库设计和大数据项目实施经验；2、熟悉常见的关系型、非关系型数据库的使用，熟悉分布式计算框架Hadoop/Spark/Fink中的至少一种，有Flink开发经验优先考虑，熟悉大数据其他技术栈；3、Java/Python等开发语言至少掌握一种；4、具有良好的沟通、组织能力，强烈的进取心和优秀团队合作精神，接受出差。,数据服务,150-500人,spark,北京
数据开发工程师(J10017),https://www.lagou.com/jobs/6783536.html,朝阳区,15k-25k,北京创业光荣信息科技有限责任公司,3-5年,本科,领导好 发展空间大 六险一金,"职位描述：工作职责:· 负责鲸准数据仓库设计、建模和ETL开发，构建灵活的数据解决方案；· 与各业务线及数据运营团队沟通需求；· 了解旧数据系统，与团队一起制定迁移方案；· 优化数据平台，构建公司级别的数据服务体系；任职资格:· 2年以上DW/ETL项目经验;· 熟悉大数据技术栈，熟悉hadoop/spark生态圈；· 熟悉Hive等分布式数据库，熟练编写SQL脚本并具备一定的SQL性能调优经验；· 熟练使用Python，Shell，java或其他语言进行过复杂业务逻辑的数据处理工作；· 具备海量数据处理以及性能优化的能力；· 具备大型数据仓库架构设计、模型设计、数据治理、数据资产管理等相关经验者优先；· 优秀的沟通理解能力，能快速理解业务，用数据解读业务· 熟悉阿里云大数据开发服务优先(Maxcompute, DataWorks)· 熟悉用过elasticsearch，neo4j等优先考虑","数据服务,企业服务",150-500人,spark,北京
hadoop,https://www.lagou.com/jobs/7071618.html,海淀区,18k-36k,昆仑智汇数据科技（北京）有限公司,5-10年,不限,新基建 工业4.0 核心岗位,"职位诱惑：风口行业,大牛带路,扁平化,环境好   职位描述：工作职责：     本岗位将参与昆仑数据全新产品体系的研发工作，以客户价值为导向，为客户构建高效、强大的工业大数据分析产品。你将参与发掘和分析业务需求，系统方案设计和代码编写，确保性能、质量和安全。你将接触到最新的数据分析大师、资深工业领域专家的工业数据分析方法与实践，学到最严谨规范的开发技术与流程，发展你个人的技术能力，领导力和有效的项目管理能力。在这个大家庭里，我们不仅鼓励大家开发出有价值、有影响力的产品给用户，我们同样鼓励大家多学习，多分享，多创新，在工作中找到最大的乐趣！任职资格－计算机相关专业本科及以上，2年以上的系统或应用软件的开发经验。－熟练掌握Java语言和面向对象思想，能写出整洁、高质量的代码。－精通常用关系数据库（PG、MySQL等）和各种NoSQL数据库。－熟悉并实践过Hadoop、Spark、Flink、Kakfa等任意一种大数据分析框架，并理解一定的底层原理。－精通RESTfulAPI开发，具备良好的API设计风格。－熟练使用Linux，理解并熟练使用Docker容器部署方式。－具备良好的软件工程和质量意识，认同并实践过敏捷开发和DevOps方法。优先任职资格－具备在快节奏，敏捷模式下开发新产品的激情。－曾经Lead团队开发复杂的软件产品，并成功地交付给用户。－具备全栈工程能力，掌握多种语言开发，如js，python，golang等。－曾经参与分布式系统开发，熟悉多个大数据产品生态和相关技术。－Linux高手，熟练掌握shell编程。－有指导年轻工程师提高技术能力和开发效率的经验。",数据服务,150-500人,spark,北京
数据平台架构师,https://www.lagou.com/jobs/6910611.html,昌平区,20k-30k,泰康在线财产保险股份有限公司,5-10年,本科,七险一金、年终奖、过节福利、定期团建,,"移动互联网,金融",500-2000人,spark,北京
测试工程师（数据方向）,https://www.lagou.com/jobs/6887165.html,朝阳区,15k-30k,北京酷得少年科技有限公司,3-5年,本科,大牛团队、六险一金、弹性工作,职位职责：1、负责少年得到旗下各项业务数据质量保证工作，以及各类数据质量测试方法探索和效率提升；2、根据实际测试业务需求进行各类数据的测试工作，并持续进行已有数据质量的优化验证；3、能够根据实际业务需求产出完备的测试方案并制定可执行测试计划，保证数据的正确性以及合理性。职位要求：1、本科或以上学历，1年以上数据测试经验；2、熟悉安卓和iOS客户端打点；3、熟练掌握SQL等语言；4、熟练Hadoop、Spark、Hive等常用大数据技术；5、对数据敏感，具有良好的逻辑思维能力、分析能力、理解业务的能力、沟通能力和表达呈现能力，主动性强；6、具有一定的数据分析技能和相关经验；7、良好的团队沟通和协作能力。,"移动互联网,教育",150-500人,spark,北京
c#开发工程师,https://www.lagou.com/jobs/7200581.html,朝阳区,10k-20k,北京光启元数字科技有限公司,3-5年,大专,平台大，氛围好，核心产品,"我们需要你：1. 与项目小伙伴沟通，完成项目数据接入工作；2. 根据项目需求完成功能模块开发工作；3. 协助处理项目开发遇到的关键问题，对项目涉及的新技术能给予快速有效的支持。我们希望你:1.计算机相关专业，1-3年实际开发经验；2.熟练使用C#编程，熟悉面向对象编程；3.熟悉HTTP、TCP/IP、Socket、WebSocket等网络通信协议，对物联网相关通信技术有深入理解；4.熟练使用MySQL, Oracle等关系型数据库，了解kafka、Spark Streaming、Flume等；5.知识面广，思路开阔，创新能力强，乐于解决具有挑战性的问题，对新技术持有敏感性并愿意致力于新技术的探索和研究；6.普通话流利，良好的表达和沟通能力。","数据服务,企业服务",150-500人,spark,北京
DevOps 工程师,https://www.lagou.com/jobs/6552398.html,朝阳区,20k-30k,北京易数科技有限公司,1-3年,不限,"五险一金,地铁周边,不打卡,包餐","工作职责：1、保证大数据系统以及线上业务 7*24 小时提供服务2、负责维护 AWS 等相关云计算平台、数据仓库以及海量的数据系统3、用数据驱动的方式度量线上服务的稳定性、效率以及质量、参与系统平台的搭建、功能设计以及编码工作4、与产品、开发、测试等团队共同合作达成项目的目标，并保证其线上的稳定性、安全性以及可维护性职位要求：1、熟悉 Linux/Unix 系统、网络、安全等相关知识2、熟悉 Docker 工作原理，至少熟悉一种容器编排工具3、熟悉 Hadoop、Hive、HBase、Spark 等相关服务及其原理，从事过海量数据的分布式存储、计算等相关工作4、至少熟悉一种 SQL/NoSQL 数据库，如 PostgreSQL、MySQL5、至少熟悉一种 Infrastructure as Code 的工具，如 Ansible、SaltStack6、至少熟悉一种编程语言，如 Java、Scala、Go、Python、Ruby7、具备良好的数据结构与算法基础，追求简洁高效的编程风格, 至少有一个独立设计实现过的系统8、具备很强的求知欲与学习能力，有极客精神，能够适应高强度和高压力的工作环境，能够在不受监督的情况下独立完成工作加分项：1、熟悉容器编排工具及其原理，如 Kubernetes2、熟悉机器学习框架，如 TensorFlow3、熟悉前端开发框架，如 React、Vue4、有 Github 开源项目","企业服务,数据服务",150-500人,spark,北京
项目实施工程师,https://www.lagou.com/jobs/6205139.html,朝阳区,10k-20k,北京易数科技有限公司,3-5年,本科,硅谷文化,工作职责:1、负责统一处理解决非标准化客户需求2、协助销售、CSM 评估非标准化客户需求的可行性与工作量3、统一收集、记录、处理就、解决所有非标准化客户需求4、定期对所有的非标准化客户需求进行评估，整理出有价值的部分作为产品需求输出5、不断提升非标准化客户需求的工具化、自动化以及稳定性任职资格:1、3年项目实施经验，有扎实的运维基础，对网络、linux系统熟练的使用，并且具备基于linux进行编程的能力。2、具有较好的学习、沟通能力和较好的客户服务意识；3、熟练使用Python（或其他类型脚本语言）。4、熟练使用SQL语言在关系型数据库和Hive中操作。5、熟练使用Java/Scala 优先。6、熟悉Hadoop、Hive、Spark的使用者优先。,"企业服务,数据服务",150-500人,spark,北京
大数据架构师,https://www.lagou.com/jobs/7218684.html,海淀区,15k-30k,北京蓝色曙光信息技术有限公司,5-10年,本科,五险一金 加班补助 带薪年假,1、参与数据中台建设、在线、离线、流处理等大数据场景应用设计2、结合业务进行实时、离线数据仓库设计、进行数据流计分析场景的方案设计和架构调优3、大数据技术研究和核心模块研发、大数据平台的搭建、系统调优、集成与实施4、建立和维护大数据技术标准规范、指导开发人员编写、优化相关代码 岗位要求：1、计算机或相关专业统招本科以上学历、4年以上大数据开发经验。2、熟悉数据仓库模型设计方法论、并有实际模型设计及ETL开发经验，灵活运用SQL实现海量数据ETL加工处理与查询性能调优。3、熟悉Linux、精通java语言、熟悉Java技术栈，有大型工程项目开发经验者优先。4、对大数据组件的部署资源评估、压力测试有很深刻理解（如 2w TPS的数据量，各个组件如flink需要的机器配置评估方法）5、熟悉大数据领域的技术栈、如flink/spark/storm/hadoop/hive等，有flink实际开发经验，尤其对flink执行原理及使用调优有深入见解者优先。6、熟悉logstash/flume，elasticsearch、hbase、openTSDB等大数据采集和存储分许工具的优先考虑。7、具体数据平台/数据产品的完整搭建经验，实时大数据经验，大规模开发请求经验。8、良好的团队精神和合作意识，良好的问题是分析能力和沟通表达能力，强烈的责任心。9、加分项：有银行数据中心领域相关经验。,"企业服务,教育",15-50人,spark,北京
架构师,https://www.lagou.com/jobs/7122589.html,朝阳区,30k-50k,北京深演智能科技股份有限公司,5-10年,本科,升职加薪快 扁平管理,,"移动互联网,广告营销",150-500人,spark,北京
Java高级开发工程师,https://www.lagou.com/jobs/7114565.html,朝阳区,20k-40k,北京深演智能科技股份有限公司,3-5年,本科,升职加薪快 扁平管理,工作职责:1.开发承载百亿流量的广告应用平台；2. 开发基于数据驱动决策的全链路人工智能营销云平台；3. 负责技术选型，架构设计，对现存或未来系统进行规划；4. 负责基础类库、核心代码的开发工作，解决产品研发中的关键问题，对疑难问题进行排查并解决； 5. 制定技术文档和开发规范，进行代码质量审核和指导，协助团队完成CodeReview，确保代码的有效性和正确性；6. 研究系统架构，优化各种技术方案，持续对系统进行架构升级和性能优化，提升时效性、扩展性和稳定性；7. 负责高效高质的完成产品和业务的技术实现，持续提升研发效率，实现业务成果。任职资格:1、教育背景：计算机相关专业，本科以上学历；2、经验背景：3年以上的软件项目系统分析和架构设计经验； 能独立编写软件项目，具备良好的系统分析及构建能力，有平台化系统研发经验；熟悉缓存技术和分布式系统理论，有相关项目实战经验；有大数据量、大型分布式、高并发、高负载、高可用性和高稳定性系统设计经验；对Storm、Flink、Hadoop、Spark等大数据平台有所了解，有机器学习算法应用经验者优先；有较大型互联网公司营销系统/推荐系统/广告系统经验者优先。3、岗位能力：计算机基础扎实，熟悉数据结构与算法，有ACM竞赛经验者优先；精通主流的开源框架，热爱技术，对新技术有好奇心，了解最新的技术及发展趋向；熟悉Java或C++或Python编程任意一种，熟悉多线程编程，内存管理，设计模式；熟悉主流应用服务器架构体系、常用中间件及数据库如Tomcat、ActiveMQ、Redis、Memcached、HBase、MySQL；编程习惯良好，代码结构清晰、命名规范、逻辑性强、冗余率低，习惯重构，对代码质量和服务性能有天生的追求；关注业务，关注用户视角，具备产品思维者优先。4、软性能力：良好的沟通、组织协调、推动能力；责任心强，做事积极主动、执行力强；学习能力强，逻辑思维清晰，能够独立思考、擅于归纳总结； 能快速定位问题并利用现有资源寻找最优解。2008年，我们由三位北大青年，前宝洁、麦肯锡、Google高管联合创立而成，目前是一家分布于北京、上海、广州、西雅图、伦敦、新加坡、香港7个地区的国际性创新型人工智能公司，我们将致力于通过人、信息和决策场景的智慧连接，让人工智能真正赋能决策者，助力企业与社会数字化、智能化，加入我们你将获得：无限广阔的行业前景： 让人工智能技术真实地应用和落地，横跨数据智能、智能营销多个万亿级别市场**领先的行业地位：营销决策智能化行业****，占有59.8%的中国程序化广告市场份额简单公平的职场环境：简单的人际关系、公平的晋升机制，我们相信每个人的努力都应该被看到牛人聚集的精英团队：来自麦肯锡、宝洁、Google、微软的核心团队，来自哈佛、哥伦比亚、清华、北大的骨干精英，与牛人同行，让自己变得更加优秀充满挑战的工作内容：拒绝面试造火箭、入职拧螺丝，在深演新人也能承担千万级别的项目全面健全的福利体系：六险一金、企业年金、员工宿舍、购房无息贷款、各种节日福利、再学习成长基金、国际交流学习机会,"移动互联网,广告营销",150-500人,spark,北京
大数据架构师,https://www.lagou.com/jobs/6968717.html,海淀区,30k-60k,用友网络科技股份有限公司,5-10年,本科,"精英团队,团队大牛多,知识分享,福利待遇","岗位优势：1、公司TOB端海量的数据2、向AI方向成长3、未来独立带团队的机会岗位职责：1、负责基于Hadoop/Spark等生态系统的大数据平台的架构设计、技术选型、搭建、开发、管理、监控和性能调优，保证集群高效稳定运行，对数据应用提供数据存储、查询引擎、实时计算、元数据管理的架构设计；2、系统核心部分代码编写、指导和培训工程师、不断进行系统优化；3、跨团队/部门协作，系统分析并解决各类大数据平台相关的运行或数据问题；4、打造有行业竞争力的系统，能够支撑快速发展的数据业务。岗位要求：1、本科及以上学历，5年以上的大数据从业经验。2、有大型分布式系统设计经验，负责过海量数据平台上高可用、高性能分式系统的架构设计。3、精通任意一门编程语言，对大数据基础架构和平台底层原理有深度理解和丰富开发经验, 对复杂系统的性能优化和稳定性提升有一线实战经验，具备相关产品（Hadoop、Hive、HBase、Kafka、MapReduce、Spark等）项目应用研发经验；对开源社区有贡献者优先；4、熟悉Greenplum、TiDB数据库技术有实际生产项目应用经验者优先； 5、具有一定的项目规划和决策能力，善于捕捉业务需求、架构设计存在的问题，并给出有效的解决措施和方法；""",企业服务,2000人以上,spark,北京
大数据研发专家,https://www.lagou.com/jobs/7107741.html,海淀区,25k-50k,北京必示科技有限公司,不限,本科,人工智能，大数据，五险一金，奖金，福利,主要职责：   负责智能运维大数据的研发和测试，撰写相关文档   负责高性能、高可用的大数据平台的设计和优化，制定技术演进路线   负责大数据计算资源的监控、管理和优化   负责大数据应用产品的代码研发、重构和优化   对产品实施交付过程中遇到的技术问题提供支持   关注并研究大数据生态最新的前沿技术，推动产品技术革新 职位要求：   本科及以上学历，计算机相关专业，3年及以上工作经验   扎实的计算机基础，掌握常用的数据结构及算法，熟练掌握Java/Golang/Scala/Python 中的一项或多项   了解分布式系统，大数据平台，有完整的数据工程项目经验，具备一定的框架设计以及抽象能力   熟悉Hadoop生态体系，包括但不限于：Hadoop、Hive、HBase、Spark、Flink、Kafka、Beam等   良好的团队精神以及合作意识，热爱技术，高度自驱，追求卓越，对数据敏感   对批量计算，流式计算，时序数据处理，存储引擎，资源调度等一项或多项有深入理解优先   有ES经验优先,人工智能,50-150人,spark,北京
智能运维交付工程师,https://www.lagou.com/jobs/7197552.html,海淀区,15k-30k,北京必示科技有限公司,不限,不限,人工智能，大数据，五险一金，奖金，福利,此职位可base：北京/上海/广州/深圳/佛山⼯作职责: 负责智能运维产品在客户现场的实施交付以及效果调优 负责客户现场的场景设计及数据分析、对接 负责客户后期的技术培训及⽀持职位要求: 计算机相关专业，本科及以上学历，3年以上相关工作经验 熟悉 Linux 操作系统，精通 Shell、Python 脚本编程语⾔ 掌握⼤数据（hadoop、spark）相关知识，会部署、维护及使⽤常⻅的⾼可⽤⼤数据集群 掌握kafka、zookeeper相关知识，会部署及使⽤对应集群 掌握logstash、elasticsearch相关知识，可编写logstash脚本清洗数据，会部署维护elasticsearch集群 熟悉 inflfluxdb、mongodb、redis和neo4j等数据库 熟悉docker、kubernetes容器化应⽤ 了解机器学习，有运维产品交付经验者优先 性格乐观、开朗，善于与⼈沟通合作，善于发现并解决问题，能承受⼀定的⼯作压⼒ 极强的敬业精神和开拓进取能⼒，动⼿能⼒强，有进取⼼，有团队精神,人工智能,50-150人,spark,北京
搜索推荐算法工程师,https://www.lagou.com/jobs/5042972.html,东城区,25k-50k,北京儒博科技有限公司,不限,硕士,"人工智能,独角兽,工程师文化","职位诱惑：独角兽创业公司，弹性上班，福利多职位描述：岗位职责：负责公司内部各资源模块下资源召回、排序算法研究、优化，及工程落地。岗位要求 1.良好的数理基础和编码能力，熟练掌握c++, java, python3, go等至少一门语言2.熟悉常用机器学习算法及推荐排序算法，有过特征工程经验3.熟悉数据挖掘方法，对数据敏感，能从数据中发现问题，有相关领域经验4.熟悉es、solr等文本检索工具5.熟悉hadoop，spark，hive，mapreduce6.有相关领域大型项目经验者优先7.熟悉深度学习并至少掌握一种深度学习开源框架者优先",硬件,150-500人,spark,北京
自然语言处理算法工程师,https://www.lagou.com/jobs/5042934.html,东城区,25k-50k,北京儒博科技有限公司,不限,硕士,"人工智能,独角兽,工程师文化","岗位职责：负责nlp各模块机器学习算法实现及服务搭建，通过精准高效的算法实现提高公司整体语音识别各任务的准确性和效率。岗位要求 1.良好的数理基础和编码能力，熟练掌握c++, java, go等至少一门高级语言，并熟练掌握python32.熟悉常用机器学习算法及nlp相关深度学习算法，至少熟练使用一种深度学习开源框架，tensorflow优先3.熟悉分词，语义分析，信息抽取等自然语言处理基础算法和应用4.熟悉数据挖掘方法，对数据敏感，能从数据中发现问题，有相关领域经验5.能够关注领域前沿发展，能够快速落地新算法新想法6.有相关领域大型项目经验者优先7.熟悉hadoop，spark，hive，mapreduce等相关计算平台优先8.在**会议发表过论文的同学优先",硬件,150-500人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7048961.html,西城区,20k-40k,苏州精正信息科技有限公司,5-10年,本科,背景雄厚 技术大牛,"职位描述:1、参与分布式大数据处理系统和数据服务基础设施的架构设计和开发；2、和产品经理一起梳理和完善系统功能需求；3、改进系统性能；任职要求:1、了解分布式、微服务、传统关系型数据库、常用NoSQL开源系统、RESTful、基本的信息安全领域知识2、精通Java代码，其他语言不限制具体要求：1、本科及以上学历，5年以上大型互联网产品或分布式系统开发设计经验；2、丰富的Java研发经验,精通Java, 熟悉Shell或Python等一种或几种脚本语言者优先；3、熟悉常用分布式系统相关理论基础，有一定的分布式系统开发经验，有互联网公司中大型分布式系统经验优先4、具备Spring Cloud等微服务设计和开发经验和能力；5、熟悉大数据技术栈,对Hadoop、Hive、Spark、Hbase、Kafka、ELK等开源组件有使用及优化经验者优先 。","企业服务,金融",少于15人,spark,北京
产品实施技术经理,https://www.lagou.com/jobs/7182900.html,海淀区,25k-35k,秒针信息技术有限公司,5-10年,本科,六险一金，扁平化管理，年终奖丰厚,岗位职责：1、负责项目产品侧范围、进度、质量的把控；负责产品二次开发2、负责项目现场小组管理工作，以及与现场各团队的协调及衔接工作； 3、负责与产品团队的沟通与交流，能够准确传递项目侧信息和需求；4、负责与客户沟通和交流，与客户保持良好的沟通关系； 5、负责项目侧的技术架构需求讨论和架构设计工作；6、负责项目现场相关技术解决方案的编写工作；7、负责指导项目现场实施人员的产品使用工作；8、负责产品在项目使用过程中问题的梳理、沟通及解决；9、参与概要设计、详细设计及相关技术侧文档的编写工作；10、负责公司相关产品在项目侧的部署实施工作；任职要求：1、计算机或相关专业统招本科以上学历；2、五年及以上软件实施或数仓项目的管理和设计经验；3、熟悉 oracle、sql server、mysql等关系型数据库技术；4、熟悉 hadoop、spark、elasticsearch、hbase等大数据存储和计算的相关技术；5、熟悉 java、scala、sql等编程语言，熟悉linux、windows等常用操作系统；6、能快速掌握项目相关的业务场景和相关技术，有数字城市和政务行业经验者优先考虑；7、具备良好的沟通能力，优秀的协调能力，能有效协调各种资源；8、具备团队合作意识，能接受出差。,"数据服务,广告营销",2000人以上,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7172364.html,海淀区,20k-30k,秒针信息技术有限公司,3-5年,本科,六险一金，扁平化管理，年终奖丰厚,岗位职责：负责数据中台的汇聚和采集ETL详细设计和开发工作；参与专题库/主题库的模型设计，并负责模型开发；参与数据标准化和数据治理模型的设计，并负责落地开发；负责数据分析需求的模型开发和实现；负责数据中台技术的优化和质量改进；任职要求：1.精通SQL语言，具备存储过程开发能力，能熟练进行SQL查询优化；熟悉Hive数据仓库设计，了解数据仓库模型及思想、维度建模思想，了解数据仓库相关应用；2.熟悉Hadoop、Spark、Sqoop、Hive、Flume、Kafka、 HBase等技术，使用过ETL相关技术进行数据交换工作；3.了解数据调度平台的设计思想，良好的数据批处理 、调度、异常处理等经验，熟悉shell、python、java等语言；4.具备较强的语言表达能力，能与客户顺畅沟通或产品介绍；具有良好的逻辑分析能力、需求理解能力和解决问题的能力；具有一定的文档编写能力；5.具有良好服务意识，工作态度端正，耐心、细致、热情，抗压力强，对工作专注、投入，有很好的职业素养 。6.具有5年及以上数据仓库相关项目工作经验，有电子政务行业项目经验优先；7. 具备一定的组织领导能力，能妥善组织安排并指导组员工作；,"数据服务,广告营销",2000人以上,spark,北京
数据仓库工程师,https://www.lagou.com/jobs/7152737.html,朝阳区,12k-20k,北京密境和风科技有限公司,1-3年,本科,通勤班车，360食堂，交通补助，健身房,"工作职责：1.负责直播业务数据仓库、数据集市的数据模型设计；2.负责原始数据的ETL规则设计和开发，数据产品研发；3.负责数据仓库需求调研和需求分析；4.为数据分析人员提供技术支持；5.满足业务线数据需求；岗位要求：1、数据仓库2年以上工作经验，规范的代码编写能力；2、熟悉仓库数据分层架构、ETL、数据建模，精通多维数据模型设计；3、熟练掌握msyql,hadoop,hive,MR,spark等，具备海量数据处理和性能调优经验，对Hadoop、Hive源码有研究更佳；4、熟悉unix/linux，熟悉java、python、shell编程中的一种，会java优先；5、学习能力强，有较强的业务理解能力、良好的数据敏感度。",社交,150-500人,spark,北京
算法负责人（推荐）,https://www.lagou.com/jobs/6185870.html,朝阳区,45k-70k,厦门美柚股份有限公司,3-5年,本科,六险一金，姨妈假，福利多,岗位职责：1、负责美柚推荐方向的策略优化，用户画像构建和优化；2、维护和改进文本挖掘的算法及应用；3、应用机器学习等技术，为用户提供推荐和排序，提升推荐效果，改进用户体验；4、熟悉深度学习框架，比如tensorflow/pytorch，了解分布式模型训练PS/Kubeflow等。有至少百万量级数据处理、模型训练优化经验，做过数据实时处理与模型实时更新任职要求：1. 计算机，机器学习，模式识别等相关专业，本科学历，硕士及以上优先2. 3年以上互联网公司数据挖掘/机器学习项目经验，有lead一个项目或者一个方向的经验，有较强的沟通能力和项目推动能力。3.有丰富的数据挖掘、机器学习（svm、神经网络、随机森林等）、分布式计算（eg. mapreduce、spark等）的实际工作经验。,移动互联网,500-2000人,spark,北京
推荐算法专家,https://www.lagou.com/jobs/5839176.html,朝阳区,25k-50k,厦门美柚股份有限公司,3-5年,本科,团队氛围好,岗位职责：1、负责美柚推荐方向的策略优化，用户画像构建和优化；2、维护和改进文本挖掘的算法及应用；2、应用机器学习等技术，为用户提供推荐和排序，提升推荐效果，改进用户体验；任职要求：1. 计算机，机器学习，模式识别等相关专业，本科学历，硕士及以上优先2. 3年以上互联网公司数据挖掘/机器学习项目经验，有lead一个项目或者一个方向的经验，有较强的沟通能力和项目推动能力。3.有丰富的数据挖掘、机器学习（svm、神经网络、随机森林等）、分布式计算（eg. mapreduce、spark等）的实际工作经验。,移动互联网,500-2000人,spark,北京
AI负责人,https://www.lagou.com/jobs/7088465.html,海淀区,50k-89k,北京力拓飞远科技有限公司,5-10年,本科,五险一金 13-16薪 每年调薪,岗位职责：1、负责公司AI业务的推进和落地；2、负责公司整体数据平台的建设；3、负责基于统计学方法的A/B实验平台建设；4、对海量数据进行分析挖掘，改进推荐技术，优化推荐算法，提升用户体验和业务价值；5、组织技术攻关，并对技术选型和具体技术问题进行指导。岗位要求:1、计算机、数学、统计学、模式识别等相关专业，211、985院校研究生及以上学历；2、熟悉常见的数据挖掘、机器学习、深度学习相关算法，有推荐系统、机器学习及深度学习相关商业项目经验；有大型推荐系统架构经验优先；3、有五年及以上面向产品的算法熟悉Hadoop、Spark、Flink等大数据开源框架；4、有良好的表达沟通能力，在技术和产品上均有热情，愿意跳出纯技术范畴考虑问题；5、具有项目管理、团队管理经验，能推动公司AI项目落地上线,"移动互联网,消费生活",50-150人,spark,北京
后端开发工程师,https://www.lagou.com/jobs/6762594.html,海淀区,25k-40k,北京深睿博联科技有限责任公司,5-10年,本科,"大牛,行业前景行,福利好,氛围好","岗位描述：1.负责泛影像产品及基础平台的架构规划以及研发工作；2.针对业务需求进行系统设计，主导完成架构设计、详细设计和编码。3.保持一定的业务和技术前瞻性，持续优化系统的架构和模型设计，在系统的灵活性、扩展性、质量等方面持续提升；岗位要求：1.计算机相关专业重点本科，具有扎实的计算机基础，3年以上研发工作经验；2.精通JAVA及相关框架，spring boot， spring cloud，mybatis， kafka， Hadoop， Spark等；3.熟悉一种或多种关系数据库，如Mysql，Oracle，熟悉一种或多种非关系数据库，如MongoDB， redis等 ；4.熟悉医学影像相关开发，数字图像处理，数字图像存储（seaweedfs, fastdfs, ceph）优先；5.熟悉docker，虚拟化，GPU调度及使用、存储技术者优先6.了解项目中的进度、依赖、风险管理，具备项目管理经验者优先；","移动互联网,医疗丨健康",150-500人,spark,北京
数据开发工程师（数仓方向）,https://www.lagou.com/jobs/6928983.html,东城区,25k-50k,紫梧桐（北京）资产管理有限公司,3-5年,本科,知名平台，上市公司，个人发展空间大,工作职责： 1、蛋壳公寓数据仓库和业务数据集市建设；2、业务模型抽象、数据模型设计开发；3、支持业务的数据需求，跟PM及业务方一起完善业务的数据分析体系和工具；4、ETL、数据应用和服务的设计开发； 5、积累数据生产、分析工具，不断提高数据生产效率； 6、实时数据仓库设计、开发与服务；岗位要求： 1、国家统招本科及以上学历，计算机相关专业背景，4年以上互联网背景数据开发、数据仓库相关从业经验；2、快速的业务学习和理解能力，有良好的自驱能力，对工作充满热情；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，熟悉3NF和多维数据模型设计；4、具备大型数据仓库架构设计、模型设计、ETL设计的相关经验；5、熟悉MySQL、Oracle、Greenplum等主流数据库技术，有较好的SQL能力；6、具备Hadoop、Hive、HBase，Spark等大数据技术背景，并具有开发经验者优先。,消费生活,2000人以上,spark,北京
推荐算法,https://www.lagou.com/jobs/7034216.html,海淀区,30k-60k,北京快乐茄信息技术有限公司,3-5年,本科,薪资open可谈,"岗位职责： 负责feed流的推荐结果召回策略/排序策略的研发。 岗位要求： 1. 熟练掌握python/c++/java 一种或多种, 具备强悍的编码能力和扎实的数据结构和算法功底； 2. 熟悉推荐系统常见的召回策略和模型包括不限于（CF, 二分图，word2vec, contentbase, LSTM，DNN）等召回算法，或者熟悉常见的LTR模型包括不限于(LR, GBDT, wide&deep, DNN，在线反馈算法) ； 3. 熟悉hadoop, spark, flink, storm， hive，hbase 等大计算工具优先； 4. 熟悉tensorflow等深度学习工具并有实际落地项目者优先，有推荐，搜索相关项目研发经验者优先。",工具,150-500人,spark,北京
大数据平台开发/专家,https://www.lagou.com/jobs/6832962.html,东城区,30k-50k,北京睿企信息科技有限公司,3-5年,本科,五险一金,大数据平台研发工程师/专家/负责人 职位描述：研发高可靠、高可扩展、易用的公司统一的大数据平台．包括大规模工作流调度、异构数据交换和同步、数据服务化、统一指标模型管理和服务等核心大数据平台和工具链的研发和性能优化。任职要求：1.有Hive、Clickhouse、Presto、Impala、Airflow、Kafka、Sqoop、MapReduce、Spark、Flink 等两种以上1年以上使用和优化经验；2.参与或主导过大型数据平台建设项目．对大数据平台有一定的整体感知和把控能力； 3.熟悉分布式基本原理．对高可靠．高并发．高吞吐系统特性有一定理解： 4.精通Java、具备较强的分布式架构和研发实现能力； 5．本科及以上学历，计算机相关专业，三年以上工作经验。 符合以下条件优先： 研究过开源代码并有代码贡献。,"移动互联网,信息安全",50-150人,spark,北京
高级数据研发工程师,https://www.lagou.com/jobs/7028342.html,东城区,20k-40k,北京睿企信息科技有限公司,1-3年,本科,五险一金,1、计算机、数学或统计学相关专业本科以上学历；2、3年以上数据开发工作经验，熟悉Python或Java语言；3、精通SQL/Hive，有较好的SQL性能调优经验；熟练掌握storm或spark流计算开发技术，熟悉hbase数据库，有实时数据应用开发经验；4、良好的编码习惯和算法基础者优先；5、熟悉数据分析经验者优先,"移动互联网,信息安全",50-150人,spark,北京
高精地图平台架构师-ZNYF,https://www.lagou.com/jobs/7027660.html,海淀区,25k-40k,北京四维图新科技股份有限公司,5-10年,不限,自动驾驶领域、A股上市公司、地图领域龙头,1. 参与高精度地图生产系统业务平台、数据平台的架构设计、落地及调优工作；2. 参与构建数据仓库体系和数据指标体系，为各项业务提供数据支撑。3. 深度参与业务，助力业务快速发展。跟踪技术前沿，探寻业务与新技术的快速融合，完善整个基础研发体系；4. 负责全程跟进重要新产品、新项目的快速验证和开发落地。1. 计算机、数学、统计学及相关专业本科以上学历，5年以上系统设计、架构经验；3年以上大数据系统设计、架构经验；2. 有扎实的编程能力，优秀的设计品位，成熟的架构方法论；3. 熟悉大数据相关技术栈，有Spark、Flink实践经验，贡献过相关项目源码者优先；4. 具备大规模分布式计算、存储、可视化开发、数据管理平台开发经验，对大数据处理及应用有浓厚兴趣；5. 设计、管理过千级以上节点的大数据集群者优先；6. 优秀的理解、沟通能力，良好的团队协作和表达能力，对解决挑战性的问题充满激情，具备强烈的进取心和过人的学习能力。,"移动互联网,消费生活",2000人以上,spark,北京
地图算法专家,https://www.lagou.com/jobs/6815267.html,朝阳区,40k-60k,拼途（北京）信息技术有限公司,3-5年,本科,平台大，福利好，领导nice,职位描述：1、基于海量轨迹数据进行路网智能生成方面的前沿研究；2、基于轨迹数据进行道路缺失、权重、可行性等道路信息的挖掘；3、结合轨迹数据设计算法策略、打造业内领先的路径规划服务；4、结合轨迹数据对底图进行高精编辑，进行车道规划和区分底图层级；5、对GIS技术有较深刻的了解和认识职位要求：1、3年以上互联网研发工作经验；2、全日制统招本科及以上学历；3、深刻理解机器学习、数据挖掘相关算法，精通Python/Go/C++之一；4、熟练掌握海量数据处理技术，具备Hadoop/Hive/Spark分析海量数据的能力和经验；5、具备很强的工程架构能力；6、熟悉数据结构，最优路径规划，决策树模型，优化理论等相关算法优先；7、带领团队提升公司的整体LBS能力,汽车丨出行,150-500人,spark,北京
数据挖掘工程师-基础机器学习方向,https://www.lagou.com/jobs/4799681.html,朝阳区,20k-30k,拼途（北京）信息技术有限公司,3-5年,本科,"用户画像,反作弊",工作内容：1、    参与用户画像体系构建，完成相关用户标签的模型设计及计算落地；2、    负责反作弊相关算法的模型构建、调优升级；3、    负责数据挖掘平台构建。任职要求：1、    计算机、数学相关专业，本科及以上学历；2、    3年以上数据挖掘相关工作经验；3、    优秀的编程能力，精通至少一门语言。熟悉大规模数据处理平台hadoop/spark等，熟悉主流深度学习框架；4、    精通数据挖掘项目的流程和思路，熟悉常用的机器学习算法；5、    对反作弊和用户画像体系有一定的经验；6、    有良好的数学基础，有强烈的责任感和优秀的学习能力。,汽车丨出行,150-500人,spark,北京
资深系统架构师,https://www.lagou.com/jobs/7044011.html,东城区,25k-50k,杉数科技（北京）有限公司,5-10年,本科,"精英团队,福利多多,大牛带",资深系统架构师【岗位职责】1.通过客户业务梳理，设计匹配架构方案，把握企业级系统设计，从技术决策、选型、架构到风险评估，挖掘新技术在业务中的应用并确保架构质量；2.深入理解公司产品能力和最佳场景，并参与核心模块的设计和新产品落地等工作，以及技术预研与攻关；3.和产品经理一起推进项目需求落地，将业务和产品需求转变成为技术实现方案；4.对现存或未来系统进行宏观的思考，规划形成统一的框架、平台或组件；5.为团队引入创新的技术、解决方案，责任心强，良好的服务意识、良好的沟通能力和团队协作；【岗位要求】1.计算机相关专业本科及以上学历，5年以上软件设计开发经验，3年以上架构设计经验；2.有企业级大型系统的架构设计和实施能力，对系统抽象有丰富经验，熟悉大流量、高并发、高性能的设计及应用，有平台，中台型系统的设计及落地经验者优先3.善于分析问题、解决问题，在开发效率、架构前瞻性、适应性上具有较强的能力，需要较强的逻辑分析、数据分析、问题排查能力，沟通能力；4. Java基础扎实、熟悉Python等其他开发语言，熟悉SpringCloud微服务开发框架，熟悉主流数据库，熟悉主流前后端框架，熟悉常用的分布式缓存、消息队列等，精通高并发下的性能优化等；5.熟悉Airflow、EMR、Hadoop、Spark大数据生态系列产品，熟悉Linux操作，熟悉主要的云平台（AWS、微软、阿里等）；6.熟悉SOA架构相关技术，熟悉Domain-Driven Design，并有相关的架构设计经验；7.具备良好的文档撰写能力、编写习惯，良好的抽象思维和逻辑思维能力，独立分析问题、解决问题的能力具有TOGAF认证资格优先,"数据服务,移动互联网",50-150人,spark,北京
数据开发工程师（数据仓库方向）,https://www.lagou.com/jobs/7089283.html,海淀区,20k-40k,北京搜狐新媒体信息技术有限公司,3-5年,本科,大平台、团队优秀、发展空间大,工作职责：1.负责数据接入、清洗、底层重构，业务主题建模工作；2.围绕数据分析搭建完善的数据服务，驱动业务的发展；3.参与工具、平台建设，维护数据仓库的稳定、高效、安全运行。岗位要求：1.统招本科及以上学历，计算机相关专业，至少3年数仓开发经验；2.精通Hive、MySQL，有一定的SQL调优经验，熟悉Hadoop、Spark、Kafka、Storm、Flink等一项或多项大数据处理技术；3.熟悉Java、Python、Scala至少一门开发语言，熟悉Shell、Perl等脚本语言；4.熟悉数据仓库建模理论，有ETL、建模或数据分析相关经验；5.善于沟通，喜欢挑战性的工作，有责任心，有较强的学习能力、执行力和问题解决能力。       加分项：1.有OLAP系统（Greenplum，Druid，Kylin，Kudu，Presto，Impala等）开发和运维经验优先；2.对开源数据类产品有源码级研究优先。,"移动互联网,广告营销",2000人以上,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6176433.html,海淀区,20k-40k,北京搜狐新媒体信息技术有限公司,3-5年,本科,广告平台，大数据平台,岗位职责：1.负责广告创意推荐类服务的研发；2.负责广告业务DMP数据平台产品研发；3.负责用户画像后台数据仓库的架构设计与研发；任职要求：1. 计算机相关专业，本科及以上学历，三年以上服务端开发经验；2. 熟练掌握PHP/Python/Golang，编程技术扎实，熟悉Laravel/Lumen等开源框架；3. 熟悉Linux/Unix平台上的开发环境，有较好的Shell脚本编程功底；4. 熟悉业务开发相关技术：常见数据库和协议，架构，存储，缓存，消息队列，API设计理念等；5. 熟悉主流的云计算、大数据技术，包括但不限于hadoop/hive/hbase/spark/kafka/flume/storm等；6. 对数据敏感，具有优秀的团队合作意识及分析问题、解决问题能力。加分项：1. 熟悉数据仓库架构/设计，以及任务调度，在用户行为日志采集、海量数据处理及用户画像方面有相关经验优先；2. 有NLP、机器学习背景，对开源的机器学习框架/模型有线上项目实践经验优先。,"移动互联网,广告营销",2000人以上,spark,北京
数据仓库工程师,https://www.lagou.com/jobs/6964166.html,朝阳区,15k-30k,阳光保险集团股份有限公司,3-5年,不限,五险一金、餐补、交通补、通讯补,"岗位职责：1、建设保险行业数据仓库，并基于数据对业务提供深入有效的支持。2、负责信保数据仓库的开发与优化。3、能基于一致性、及时性、准确性的要求不断提高仓库质量。任职资格：1、有数据仓库需求调研和需求分析经验，能根据业务需求设计数据仓库模型，并对数据仓库数据模型进行管理，保证数据质量。2、熟悉数据仓库技术，了解 ETL 生产流程，对ORACLE数据库有深入的掌握，精通sql开发。 3、熟练使用ERWIN,KETTLE等产品设计工具。4、有HBase、MapReduce生产环境工作经验优先考虑。5、有Hadoop/Storm/Spark/Hive等系统的开发经验者优先。6、工作认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧。",金融,2000人以上,spark,北京
大数据平台开发工程师,https://www.lagou.com/jobs/4989370.html,朝阳区,15k-30k,阳光保险集团股份有限公司,5-10年,本科,"五险一金,节日福利,绩效奖金,医疗保险","岗位职责：1、参与数据平台相关业务的设计和大数据平台开发 2、保障和提升数据平台业务支撑能力3、负责相关模块的研发，保证系统性能、稳定和安全4、基于Hadoop生态系统相关开源技术的开发和优化等工作5、完成领导交办的其他工作职位要求：  1. 互联网或金融行业5年以上java/scala项目开发经验，JVM内存模型、对gc性能调优有一定经验  2. 熟悉常用设计模式、IO编程、多线程开发、常用算法、数据结构等，熟悉http/https、tcp/ip等通讯协议  3.  熟悉分布式工作原理，其中3~4年以上大数据平台或项目开发经验。。有金融类项目经验者优先4. 熟练掌握hadoop/zookeeper/kafka/hive/flume/es/spark/spark streaming/flink等大数据生态圈开源技术5. 熟练掌握mysql或oracle, 至少掌握以下主流nosql中的1种:　redis/mongodb/hbase 6.  有Linux下开发、部署和调试能力。熟练掌握常用Linux命令，具备shell编程能力 7.  熟练掌握git/svn 版本管理工具, maven构建工具。Eclipse、IDEA等开发工具8.  有较强的责任心和良好的沟通能力，有独立解决问题的能力和排查分析定位问题的能力9.  关注大数据生态圈和开源论坛社区，有开源代码贡献者优先岗位任职条件：1、学历与专业：计算机相关专业2、年龄与性别：35以内3、工作经验：5年以上java/scala等项目开发经验，其中需包含3~4年以上大数据4、行业背景：互联网、金融、IT等5、计算机使用技能：java hadoop spark Kafka es等6、素质能力及性格特征：有团队意识 积极主动 热爱钻研技术7、其他：英语良好",金融,2000人以上,spark,北京
大数据运维工程师,https://www.lagou.com/jobs/7103196.html,朝阳区,15k-25k,北京聚云数字信息技术有限公司,3-5年,本科,弹性工作、五险一金、免费午餐、加班补助,岗位职责：1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/spark／Kafka /Flink等集群服务、业务监控、持续交付、应急响应、容量规划等。5、负责大数据各个组件上线流程。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Flume/Impala/Hue/Sqoop/Elasticsearch/kibana/MySQL/Kudu/Flink等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafan/openfalcon等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、运维过 CDH、HDP集群,广告营销,50-150人,spark,北京
资深软件开发工程师,https://www.lagou.com/jobs/7066778.html,朝阳区,35k-58k,北京神州祥龙投资管理有限公司,3-5年,本科,跨国平台 大牛同事 不加班 假期多,"FBA中国研发团队负责的业务涉及到整个亚马逊物流的所有关键环节。IUP团队负责对卖家入库的数据进行核实，减少因为卖家或者亚马逊操作错误带来的损失。Inventory  Health 团队帮助卖家管理自己的库存，为他们提供库存报表，帮助卖家提高货物吞吐量。Reverse  Logistic团队帮助卖家处理退货，降低卖家因为退货造成的损失。除此以外，Reverse  Logistic团队还提供卖家出库和批发业务的支持。Profitability团队帮助卖家计算亚马逊物流的各项收费，辅助卖家进行商业决策。想要体验大数据和机器学习？每周我们有百亿级的数据被自动分析和处理。你可以体验流数据和批量加工，同时玩转 AWS 的最新大数据服务。千百种可能任你挑选，Tensorflow, MXnet, Spark, Presto, Streaming, Athena, Glue 等等。职位要求：计算机 /电子 /通信 /数学等相关专业本科及以上学历；3年及以上的工作经验；扎实掌握常用算法、数据结构和计算机基础知识；深入理解面向对象和设计模式；至少熟练掌握一门编程语言 Java/C++等","移动互联网,电商",2000人以上,spark,北京
自然语言处理实习生,https://www.lagou.com/jobs/6533439.html,朝阳区,4k-6k,北京陌陌科技有限公司,不限,本科,核心团队,职位描述：岗位职责：1、参与陌陌平台文本spam识别的开发，参与优化文本分类、聚类，文本相似性，语言模型，情感分析，用户行为分析等工作，持续改进和升级现有产品；2、跟进文本挖掘、NLP和机器学习领域的前沿技术，将前沿技术应用于实际业务。岗位要求：1、在以下至少一个领域有一定了解：(1)统计机器学习相关方法，如深度神经网络、概率图模型，最优化方法等；(2)语义理解技术，如知识图谱、语义解析、知识挖掘等；2、良好的分析问题与发现问题的能力，善于归纳技术方案的特性，并找出其不足与改进方法；3、有一定编程能力，熟悉Hadoop、Spark等分布式计算框架者更佳；4、具有良好的沟通能力，和良好的团队合作精神；5、要求2021届及以后在校生，可连续实习三个月及以上。,社交,500-2000人,spark,北京
数据平台实习生,https://www.lagou.com/jobs/6551832.html,朝阳区,4k-6k,北京陌陌科技有限公司,不限,本科,核心团队 良好工作环境,"职位描述：岗位职责：1、建设陌陌大规模数据的在线/离线基础架构，并根据上层业务需求和计算逻辑持续优化；2、建设陌陌数据仓库架构的子系统，包括不限于：调度系统、元数据管理、数据质量监控、高效数据同步、流式数据采集、多维数据分析引擎等；3、解决和优化业务人员在开发过程中遇到的计算平台优化、数据处理技术、基础工具使用等技术问题；4、研究大数据前沿技术，探索应用于各系统和产品。岗位要求：1、统招本科以上学历，计算机相关专业；2、熟悉Hadoop / Hive / Hbase / Spark / Storm / Flume等开源技术，有1年以上的实际工作经验，对相关系统源码有研究更佳；3、熟悉分布式系统架构或模型，对资源管理、调度算法、并行数据处理有自己的理解；4、熟悉Linux开发环境，熟练掌握至少一种编程语言，C++、Java、Python、Scala；5、有互联网公司大规模数据平台建设经验者优先；6、有数据仓库架构的开发经验者优先，例如元数据管理、OLAP引擎、数据同步等；7、善于学习新的知识，动手能力强，有进取心；8、具有良好的沟通能力、团队合作精神、时间和流程意识。9,20届毕业生可提供转正名额",社交,500-2000人,spark,北京
新兴大数据技术及相关课程研究员（J12084）,https://www.lagou.com/jobs/7175573.html,昌平区,30k-50k,北京传智播客教育科技有限公司,5-10年,本科,13薪，五险一金，寒假，各种津贴,工作职责:1. 负责新兴大数据技术的调研、研发、原理研究工作，让其成为课程产品的基础素材；2. 负责参与课程体系的规划建设，包括数据采集、ETL处理、数据仓库、数据可视化相关模块的研发。任职资格:1.具备大专及以上学历，统招本科优先，年龄在30-39岁；2.具备7年以上的研发经验，其中大数据研发经验不少于5年；3. 具备从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop、Spark生态相关技术并有相关开发经验，有Flink的开发经验优先；4. 具备较为丰富的数据仓库及数据平台的架构经验，精通数据仓库建模及ETL设计开发；有较为系统的海量数据性能处理经验；在大数据资产管理与治理有一定成功产品化经验；5. 具备丰富的大型互联网日志采集系统设计或架构经验，或大数据风控、用户画像、推荐系统相关开发经验；6. 具备Java、Scala，Python三种语言中的两种；7. 具备互联网、金融、电信等行业的从业经验优先；8. 具备对行业、新技术较高的敏感度，有个人技术博客优先；9. 具备良好的思维逻辑性、语言表达能力。,教育,500-2000人,spark,北京
高级java架构师,https://www.lagou.com/jobs/6810498.html,海淀区,18k-30k,北京商越网络科技有限公司,5-10年,本科,阿里系创业，空间大，待遇优厚，五险一金,"岗位要求:1、本科以上学历，计算机专业背景，扎实的数据结构、操作系统、编译原理等2、负责Elasticsearch管理平台的架构设计与开发,负责基于ES数据检索产品的架构的设计与开发3、至少5年JAVA以上及3年以上ElasticSearch开发经验，熟悉ES部署、监控及性能调优4、熟悉盘古、ICTCLAS、IK等常用词库，对分词算法有深入的研究，能设计垂直行业的分词算法和规则、熟悉搜索引擎原理，熟悉Spark和ES、Hadoop者优先5、善于分析总结问题,热衷技术,精益求精,喜欢研究开源代码,有高并发、大数据处理实际项目产品经验者优先 6、负责Elasticsearch管理平台的架构设计与开发,负责基于ES数据检索产品的架构的设计与开发7、具有一定的系统设计和架构能力，能够独立完成系统的设计和实现8、具有ES/Solr/Lucene等相关开发经验者优先具有搜索、推荐系统开发经验者优先。9、学习并参与体系化的核心搜索系统建设，包括分布式检索引擎、实时数据引擎、在线特征计算与模型预估框架等，研发高可用、高稳定、高吞吐、低延迟的搜索系统；工作地址","移动互联网,企业服务",50-150人,spark,北京
数据挖掘工程师,https://www.lagou.com/jobs/7038299.html,海淀区,18k-25k,北京励立长平教育科技有限公司,3-5年,本科,六险一金、节假日福利、生日礼品等,"技能要求：数据挖掘一 岗位职责：1、研究数据挖掘或统计学习领域的前沿技术，针对海量用户行为和内容信息，构建和优化用户画像以及用户标签体系；2、基于对用户理解和大量数据特征，参与精准营销、个性化推荐定价等模型建设和领域研究，提升产品效果；3、根据公司需要寻找和采集相关数据，对原始数据进行清理、甄别、归类和整合，并实现流程自动化。二 职位要求：1、机器学习、数据挖掘相关，3年以上工作经验，对用户画像/分层/推荐系统有经验者优先考虑；2、熟悉主流数据挖掘方法与技术，能独立完成数据挖掘任务；3、熟悉C/C++语言、Python、Java任意一种语言，较强的算法和数据结构功底；熟悉大规模数据挖掘、机器学习等相关技术,熟悉Hadoop/Spark/Hive技术优先；4、良好的逻辑思维能力,优秀的分析和解决问题的能力,对挑战性问题充满激情；5、良好的团队合作精神,较强的沟通能力。三、工作时间：因公司所处教育行业，该岗位的工作时间稍特殊，为周三-周日10:00-19:00，周一、周二休息。",教育,500-2000人,spark,北京
大数据运维工程师,https://www.lagou.com/jobs/7031090.html,海淀区,25k-45k,北京趣加科技有限公司,3-5年,本科,头部大厂，优秀团队，15薪，六险一金,岗位职责：  1. 数据增长部门大数据数据仓库、ETL、调度系统、数据质量以及PB级数据存储的管理和运维；2. 负责数据增长部门负责的商业化产品的SLA保障，不断优化系统降低故障率，降低系统成本；3. 负责数据管理后台系统的开发，提升数据接入和管理流程的自动化水平。岗位要求  1. 熟悉Spark、HBase、Hive、Kafka等大数据生态相关产品的管理优化、问题排查等，具有AWS、aliyun等至少一家云服务运维经验；2. 有Mysql、Redis、ES等大数据周边系统的运维经验，掌握系统的工作原理，并对系统的HA、高并发支持有一定理解；3. 熟练使用shell及python，并有一定开发经验，有spark开发经验者优先；4. 精通基于Linux系统的常用服务的安装配置，快速部署，熟练掌握系统性能诊断工具。,游戏,500-2000人,spark,北京
算法工程师,https://www.lagou.com/jobs/7030950.html,海淀区,30k-50k,北京趣加科技有限公司,3-5年,本科,头部大厂，优秀团队，15薪，六险一金,岗位职责：利用机器学习和数据挖掘的方式帮助解决游戏发行侧人工智能难题，改善用户体验。任职资格：1. 3年以上开发经验，1年以上人工智能开发经验；2. 优秀的代码能力，掌握常用编程语言，深度学习，Tensorflow；3. 熟悉推荐算法、协同过滤、特征工程等常用算法模型原理，具备相应工程能力;4. 熟练掌握海量数据处理技术，有使用Hadoop/Hive/Spark分析海量数据的能力和经验；5. 有用深度学习解决过相关问题者优先；6. 优秀的分析及解决问题的能力，责任心强，细心耐心。,游戏,500-2000人,spark,北京
大数据开发实习生 (MJ004488),https://www.lagou.com/jobs/7150873.html,海淀区,3k-4k,北京趣拿软件科技有限公司,应届毕业生,不限,一对一指导,工作职责：1、基于PB级别数据和上万张表的复杂业务来建设、优化机票数据仓库2、参与数据底层的工具、平台等技术体系的建设与研发3、根据不同业务场景，能够及时、准确的构建业务指标数据 岗位要求：1、计算机相关专业本科或研究生在校生2、熟悉SQL，了解大数据开源工具HDFS、Spark、Kafka、Hive、Sqoop等；3、熟悉yarn、shuffle的机制，能够对一些常见的hive问题进行优化4、至少熟练使用Shell/Python/java一种，有过web开发经验优先5、业务理解力强，对数据、新技术敏感，对大数据技术充满热情6、积极乐观、诚信、有责任心；具备强烈的进取心、求知欲及团队合作精神7、实习期6个月以上，一周4天以上,旅游,2000人以上,spark,北京
高级/资深算法工程师--推荐算法,https://www.lagou.com/jobs/6904217.html,东城区,30k-55k,北京高因科技有限公司,3-5年,硕士,行业领跑 体系成熟,工作职责：1.  参与相关模型开发和优化工作，负责模型在业务端落地。2.  跟踪前沿的算法理论，并且将优秀的算法应用到业务场景中，通过技术创新提升业务价值。职位要求：1.  深刻理解深度学习、统计机器学习等理论，并且在风控、文本、搜索、推荐、广告等一个或多个领域上有一定经验； 2.  算法工程基础扎实，熟悉Java/Python/Shellscript，对常用机器学习算法技术栈有较为深刻的理解； 3.  熟悉基本大数据环境基础工具的使用，熟悉Spark、 Hive、ES、HBase等，有基于这些工具进行数据处理、分析的数学模型能力；4.  有大规模算法落地经验者优先考虑；,移动互联网,2000人以上,spark,北京
大数据技术专家,https://www.lagou.com/jobs/6952474.html,朝阳区,30k-50k,北京聚通达科技股份有限公司,10年以上,本科,数据仓库 yarn,岗位职责：1.负责大数据平台架构的规划设计与优化，包括数据建设、数据质量治理、数据应用和数据产品；2.主导数据应用体系迭代，包括数据产品构建、数据分析需求响应、数据集市；3.制定数据架构规范，构建包括全流程监控、预警和数据快速恢复、数据质量评估为一体的数据质量保障体系；4.负责大数据技术团队搭建和管理，指导初、中级大数据开发人员完成项目研发，与团队成员分享技术成果，带领团队成长；5.负责大数据平台技术框架的选型与技术难点攻关，参与大数据核心架构研发；6.研究未来数据模型和计算框架的创新和落地，包括但不限于以下领域：大规模数据实时化、研发模式敏捷化、数据计算框架轻量化、数据模型组织方式业务化等方面，引领大数据技术发展路线。任职要求：1. 本科以上学历，计算机科学与技术类相关专业，硕士学历尤佳，35岁以内，工作稳定性较强；2. 8年以上大数据技术研发相关经验，3年以上大数据技术总监任职经验，能够独立带领大数据技术团队，具备海量数据实践经验，主导过大型核心系统大数据架构设计、开发、性能调优、项目管理等，具备大型互联网公司背景；3. 精通Linux/Unix平台上的JAVA编程，熟悉Python、Shell任意一种脚本语言，精通大数据相关框架和组件，如Hadoop (HDFS、YARN)、Hive、Spark、Storm、Zookeeper、Kafka等原理和应用场景，熟悉CDH或HDP框架，擅长大数据处理、解析分析工具，掌握数据可视化工具；4.关注开源技术发展趋势，可快速深入理解相关产品业务场景和关键需求，对大数据开发技术的未来发展趋势有自己的理解和预判。,"移动互联网,数据服务",150-500人,spark,北京
推荐系统工程师,https://www.lagou.com/jobs/7029941.html,朝阳区,20k-40k,抱抱（北京）信息技术有限公司,3-5年,本科,弹性工作、福利丰厚、百度背景、技术大咖,职位职责：1.负责推荐平台分布式系统的设计，开发和性能调优等工作；2.技术预研和技术难点攻关，保障系统可用性，稳定性，扩展性；3.研究海量数据存储，高并发计算，实时计算，优化系统架构，不断提升系统时效性，扩展性，性能；4.深度参与业务，助力业务快速发展，探索新技术方向支持业务快速需求响应。完善整个基础服务和数据服务的技术体系。职位要求：1.具备扎实的计算机理论基础，对数据结构及算法有很好的功底，有系统分析和设计经验；2.精通java， python等语言，熟悉 io、网络、多线程等编程，有良好的编程习惯；3.熟悉hadoop/hive/spark等分布式系统，有分布式开发经验者优先，熟悉elasticsearch 开发者优先；4.强烈的责任心，良好的沟通能力，良好的团队合作精神。,移动互联网,50-150人,spark,北京
算法工程师,https://www.lagou.com/jobs/6618602.html,大兴区,20k-35k,京东数字科技控股有限公司,1-3年,硕士,提供班车，三餐,1、基于京东海量的数据基础，通过机器学习等手段，研发或优化现有推荐模型，为打造具备良好用户体验的产品推荐体系做好准备；2、深入地挖掘分析京东电商、消费金融、京东支付等客户属性及行为数据，进行特征加工，构架有效的特征体系；3、在一定程度上负责相关项目的研发工作，包括特征和模型的设计、开发、测试、上线、维护。任职资格：1、优秀的分析和解决问题能力，有机器学习实际项目经验；2、扎实的代码能力，精通至少一门主流语言Python/Scala/Java/C++；3、熟悉大数据分析工具Spark/Hive/Hadoop；4、扎实的理论和算法基础，出色的机器学习理论基础；5、熟悉深度学习、强化学习并有相关项目经验者优先；6、有大规模计算广告或推荐系统策略研发经验者优先；,金融,2000人以上,spark,北京
联邦学习算法科学家,https://www.lagou.com/jobs/7166708.html,大兴区,25k-50k,京东数字科技控股有限公司,5-10年,硕士,三餐,工作内容：1、主导并负责联邦学习框架的设计与开发；2、开发基于机器学习的联邦学习算法；3、持续优化基于机器学习、分布式存储与计算、RPC通信、加密等技术的联邦学习框架；4、负责市场上各大联邦学习框架的跟踪调研及落地。任职资格：1、计算机或其它相关专业本科及以上学历，3年以上算法设计与开发相关经验；2、精通Java、python或c++，精通数据结构与算法；3、熟悉常用的机器学习算法，包括LR、xgboost、SVM、决策树、随机森林等，了解联邦学习算法；4、有规范的代码编写能力，及优秀的架构设计能力，能熟练地使用设计模式；5、熟悉FATE框架，或者其他联邦学习框架；6、熟悉分布式计算与存储原理，了解分布式机器学习；7、熟悉spark、flink、storm等至少一个分布式计算项目源代码；  8、熟悉GRPC等RPC通信框架、Docker容器，了解kubernates。,金融,2000人以上,spark,北京
信息安全工程师,https://www.lagou.com/jobs/7056660.html,海淀区,20k-35k,北京中经惠众科技有限公司,5-10年,本科,"扁平管理,、发展空间大、福利多、五险一金","岗位职责：1.规划、制定及推动全公司范围建立健全数据安全管控体系，包括数据安全架构、流程制度及技术工具2.完善应用安全开发、上线渗透测试流程，协调开发、运维团队及时修复应用及各种系统漏洞3.了解当前最新的信息安全威胁和趋势，熟悉最新的安全解决方案/供应商产品，并制定具体落地实施方案4.保障公司的终端、系统、网络与信息的安全性、完整性和可用性，消除安全隐患。及时进行各种安全应急处理、安全事故处理5.跟踪审计数据安全体系日常落地工作，包括：数据安全风险发现的整改落地推进、日常数据安全事件响应、数据安全意识提升与培训等；岗位要求：1.至少3年以上信息安全工作经验，具备网络安全规划设计和安全运维经验2.熟悉金融科技公司数据安全整套流程和常见的信息安全体系建设方法论。善于根据企业核心业务和价值所在制定适宜的信息安全策略。3.熟悉ISO27001及其它国内外相关安全标准与规范，熟悉国家信息安全等级保护标准及涉密信息系统建设标准;具备丰富的面向监管及审计的技术汇报经验。熟悉内部人员、操作流程风险点，以及适宜的规避、管理手段。4.熟悉防火墙、IDS/IPS/UTM、防**、安全攻防、漏扫、渗透、身份认证、代码审计、密码学算法、PKI系统、SDL等安全技术架构知识，熟悉各类网络攻击方法，如逆向工程、重放攻击等5.深入了解企业级信息系统和技术架构，网络安全专业知识，加密，虚拟化和云安全问题6.熟悉大数据平台技术，如Hadoop,Spark,Hive,MySQL等7.持有CISSP、CISP、ISO27001LA、CISP-A、CCSP认证资格者优先；","金融,企业服务",50-150人,spark,北京
推荐算法/数据挖掘/广告算法工程师,https://www.lagou.com/jobs/6944111.html,朝阳区,20k-40k,瑞庭网络技术（上海）有限公司,1-3年,本科,绩效奖金 弹性工时 免费班车 综合补助,"岗位描述：1. 针对核心业务的大量内容及行为数据，应用NLP、数据挖掘、大数据等技术，构建迭**聘标签体系、用户画像、知识图谱、反作弊、自然语言生成NLG，开展实体识别、实体关系挖掘、新词发现、长短期画像等项目，支持招聘策略体系完善，探索创新落地；2. 针对业务应用场景，设计并实现推荐算法（包括推荐召回模型、转化预估模型等），提升推荐匹配精准度，推进业务增长；3. 针对招聘业务，探索商业化增长，构建优化CPC/CPT/CPA算法策略，包括点击率预估、投递预估、预算建议、定价机制等，支持长远商业增长4. 针对业务搜索场景，应用自然语言处理、数据挖掘、机器学习等技术，实现包括但不局限于搜索suggestion、关键词推荐、搜索匹配、核心摘要抽取等功能，优化搜索体验； 岗位要求：1. 本科及以上学历，计算机、数学相关专业，3年以上的相关经验最佳；2. 对常用的NLP/推荐/搜索/商业广告算法有较深入了解，有实际算法调优及大数据建模经验；3. 有丰富的数据挖掘（word2vec、LDA、RNN、LSTM等）、机器学习（逻辑回归、神经网络、随机森林、深度学习等）、分布式计算（eg. mapreduce、spark, kafka等）的实际工作经验，参与过诸如广告点击率预估、个性化推荐模型、搜索排序等项目或在国际期刊发表过机器学习相关论文者优先；4. 具备强悍的编码能力、扎实的数据结构和算法功底，熟悉linux开发环境，熟练应用Hadoop、spark大数据平台，熟悉java语言最佳；5. 良好的团队合作和沟通能力，责任心强。 我们能提供：1. 业内有竞争力的薪酬福利，激励机制和长期的培养机制；2. 核心团队，负责公司重点业务线增长业务，大数据复杂业务场景，技术挑战大；3. 良好的工作氛围，强调数据驱动，鼓励工程师主动发现及解决问题，达成技术突破业务贡献。",移动互联网,500-2000人,spark,北京
推荐算法专家,https://www.lagou.com/jobs/6674825.html,海淀区,30k-50k,北京奇艺世纪科技有限公司,3-5年,本科,核心团队 精英文化 优秀的团队氛围,"工作职责：1.     从事深度学习相关领域的研究，包括算法理解、实现，优化等工作；2.     参与长/短视频推荐算法相关研发工作，负责基于大数据个性化推荐的开发和优化；3.     承担模型调优和实际业务场景中落地的工作。任职要求：1.     本科及以上学历，计算机、数学相关专业，3年以上开发工作经验；2.     对常用算法如：LR、GBDT、SVM、LDA、CRF、HMM等任意一种的模型原理以及工程实践上有较多经验；3.     熟悉深度学习算法如：CNN、DNN、RNN等模型原理，具有一定的实践经验，熟练使用Tensorflow,Spark MLib, Caffe，Sklearn等一种以上机器学习工具框架；4.     熟练使用python/java/scala/shell等一种以上工程语言，有扎实的编程基础和工程实践；5.     善于思考和学习，对算法落地有充分的理解，对有挑战性的问题充满激情，具有良好的团队合作精神和较强的沟通能力以及抗压能力。温馨提示：如果7天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可。",文娱丨内容,2000人以上,spark,北京
智能运维算法工程师,https://www.lagou.com/jobs/7073949.html,海淀区,15k-30k,联通云数据有限公司,3-5年,本科,央企、高薪酬、高福利,岗位职责：1、负责云平台智能运维研发，涉及故障预测、智能告警管理，故障根因定位方向；2、负责云平台运维数据分析处理、AI模型训练、数据挖掘工作；3、负责AI平台建设和运维工作。任职资格：1、本科以上学历，计算机/软件工程专业优先；2、至少熟悉Java、Python、Scala中一种；3、熟悉Tensorflow框架，具备机器学习、深度学习、自然语言处理等相关从业经验；4、熟悉常见算法，如SVM、CNN、RNN、神经网络、随机森林等；5、熟悉Hadoop、Spark等大数据框架者优先；6、能在高压力情况下快速解决问题，具备出色的团队管理能力、逻辑思维能力及学习能力，具备出色的沟通力、需求分析能力及执行力；7、良好的团队合作精神和沟通能力，愿意学习并应用业界新知识。,硬件,500-2000人,spark,北京
风控算法工程师,https://www.lagou.com/jobs/6819244.html,东城区,30k-60k,北京欧非科技有限公司,5-10年,本科,大平台；独栋办公；一日三餐,岗位职责1、 负责平台风险策略的规划与实现，包括反垃圾、信用风险评估、投放反作弊等相关风险方向；2、 参与特征工程的建设，包括业务数据、用户数据等的收集、分析和挖掘； 负责模型验证，撰写验证报告；3、深入理解业务和机器学习技术，优化模型&策略，持续提升风控效果； 职位描述1、 计算机、统计、数学、金融等相关专业背景，本科以上学历；2、 在信贷评分卡、反欺诈、机器学习、深度学习、数据挖掘、推荐系统等一个或多个相关方向有五年以上项目经验，有很好的算法功底，对数据敏感；3、熟练掌握SQL、R、Python以及相关进行分析的工具或Hadoop/Spark/Cosmos/ODPS等大数据分布式平台，Coding能力较强，有C++和Java语言编程经验的优先，熟悉分布式机器学习框架和流行的深度学习开源工具的优先4、 有分期贷款、小额贷款、信用卡分期、消费金融风控模型开发经验5、 拥有技术激情、创新意识、协同落地能力，表达能力优秀，乐观向上，自我驱动力强，具备很强抗压能力，有自我反省意识。,电商,500-2000人,spark,北京
数据平台开发工程师,https://www.lagou.com/jobs/7134274.html,海淀区,18k-26k,北京环球兴学科技发展有限公司,3-5年,本科,五险一金、平台大、行业前景好,岗位职责：1. 负责大数据平台的搭建、完成数据平台各功能组件设计和开发工作，解决数据平台搭建过程中遇到的技术难题。2. 负责数据采集、处理、存储、应用过程中技术方案的选型和实施。3. 负责数据产品相关的开发工作。4. 对大数据平台相关组件的进行持续运维和优化。任职要求：1 熟练掌握Java语言，具备扎实的程序设计基本功及编码能力。2. 有过Web项目的开发经验，熟悉Spring、 mybatis等框架。3. 具备大数据平台的开发经验，熟悉至少一种大数据相关组件，例如Hadoop、Spark、Flink、Hbase、Clickhouse、Druid、Kafka等。4. 熟悉Linux环境，具备在linux下定位、调试、优化平台组件运行过程中遇到的问题的能力5. 主动性强，具有良好的沟通、协调能力6. 具备良好的文档编写能力，能够准确理解业务需求，并转化成系统设计文档。,"移动互联网,教育",500-2000人,spark,北京
数据产品经理,https://www.lagou.com/jobs/7126381.html,海淀区,15k-25k,北京环球兴学科技发展有限公司,3-5年,本科,五险一金、平台大、行业前景好,岗位职责： 1、基于对业务的深入理解，为业务和产品提供数据决策支持和解决方案； 2、通过对产品业务的研究分析，搭建相关数据指标体系，在业务洞察、用户洞察、精细化运营等方面通过数据驱动产品业务发展； 3、制定和把控数据产品方案，包括但不限于智能BI系统、用户画像系统、风控系统、元数据管理系统； 4、重点负责用户标签体系、用户分层模型、用户画像系统的建设，深入精细化运营过程，不断基于数据驱动业务优化； 5、与业务、分析师、产品、技术开发等团队密切合作，参与到整个需求调研、产品原型设计、文档编纂，开发跟进、功能测试、系统推广使用、用户反馈、迭代优化环节。任职要求： 1、本科及以上学历数学、统计、计算机相关专业优先，3年及以上数据产品或数据分析经验，有互联网、在线教育从业经验者优先； 2、具备独立数据体系或数据产品的搭建，有较好的需求抽象能力和产品设计能力； 3、对数据敏感，逻辑性强，有一定的数据统计和运营分析能力； 4、熟练运用SQL，对前端BI、数仓有深入的了解，能够独立完成基础数据的探查工作，掌握Hive，spark等大数据工具者优先； 5、熟悉数据建模知识或具有数仓建模经验者优先； 6、熟练使用Axure，Xmind，Excel，PPT等产品工具。,"移动互联网,教育",500-2000人,spark,北京
数据架构师,https://www.lagou.com/jobs/6819560.html,朝阳区,25k-35k,狮桥融资租赁（中国）有限公司,5-10年,本科,"绩效奖金,节日福利,团队建设,生活补贴",【岗位职责】为提高数据团队技术架构能力，配合公司以数据为驱动的数字化业务需求，为数据团队在产品开发过程中提供数据产品技术架构与服务产品技术架构设计，提供技术选型的方案以及对选型进行评估，辅助团队其他技术同事进行代码走查，技术优化以及技术创新，实现数据团队A（AI），B（Bigdata），C（Cloud Computing）技术架构的最终目标。1、数据团队数据网关技术调查2、了解现有产品体系与架构、云原生平台、大数据平台建设3、参与大屏blueprint项目架构设计与优化【任职要求】1、热爱软件研发，热爱技术，有强烈的求知欲与对掌握技术的渴求度2、扎实的java基础知识，了解jvm底层原理，善于调优。如精通掌握其他语言为加分项，如go，python等。3、 熟练基于Spring的云原生web开发，丰富的产品或项目经验，可快速构建微服务架构服务，并根据业务特性进行微服务模块的技术拆解4、 熟练掌握Mysql postgresql TiDB等RDB的使用，可进行调优并进行服务层链接池的调优于设计5、熟练掌握基于Hadoop生态的大数据开发体系，可快速搭建分布式大数据开发平台，熟练使用但不限于spark，sqoop，Hive等开源框架，并可进行调优；熟练使用scala语言。6、具备一定的数仓设计能力，了解数仓分层的原理以及ETL的工作流程7、掌握Docker等CNCF容器操作，掌握k8s的基础使用，理解kik架构体系模型原理8、 具备卓越的自驱力，超强技术学习、调查能力，可无障碍阅读英文原文文档，可独立对未知技术做破冰式的调研，并形成know how文档，并可在规定时间内交付所需价值,"金融,物流丨运输",2000人以上,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7106218.html,朝阳区,20k-35k,元保数科（北京）科技有限公司,3-5年,本科,大厂团队班底 定期分享 技术氛围浓厚,岗位职责：1. 参与大数据系统的设计与研发；2. 负责面向业务的数据平台的研发；3. 负责业务数据采集、传输、清洗、格式化存储、数据分析与数据挖掘的设计和工程实现4. 负责数据产出的稳定性5. 负责数据团队其它数据分析及数据处理工作 职位要求：1. 计算机或相关专业本科以上学历 3年以上开发工作经验；2. 熟练使用hbase hive flume spark mrstorm kafka中的一种以上大数据组件；3. 精通MySQL数据库  熟悉hive SQL优化4. 能使用 Java、scala语言进行相应的开发工作；  5. 熟悉Python、shell中的一种；6. 了解数据分析技术（机器学习）并具有相关项目经验优先7. 有ACM、kaggle比赛经验优先8. 熟悉流式计算框架 如spark、spark streaming、spark SQL等技术优先 9. 对源码有研究优先 10. 熟悉阿里Quick BI的优先11. 热情开朗、善于沟通，工作责任心强，思路敏捷清晰、抗压能力强，良好的学习能力、有较好的创新精神。,"电商,金融",50-150人,spark,北京
高级Java工程师,https://www.lagou.com/jobs/4581124.html,东城区,15k-25k,中诚信征信有限公司,3-5年,本科,"行业领导者,周五7小时,午餐,俱乐部",岗位职责：1、 配合产品经理和技术经理，完成系统模块的需求分析和功能设计；2、 负责系统搭建、数据库的设计开发等工作；3、 解决项目开发实施过程中遇到的技术问题；4、 进行软件代码的维护和改进工作；5、 完成相关技术文档；6、 参与或组织相关的技术研究、头脑风暴等讨论工作； 岗位要求：1、 计算机软件相关专业，4年以上JAVA顶目开发经验，深入理解面向对象思想，具有根据业务需求进行独立设计、分析、搭建的能力。；2、 精通java语言，熟练掌握SpringBoot/Struts/Spring/Hibernate/mybatis等技术框架，熟练运用常见的微服务框架进行开发，如Dubbo，Spring Cloud等;；3、 熟悉JavaScript、CSS、HTML等WEB 开发相关技术，熟悉Bootstrap、Vue或其他UI框架，熟练使用jQuery或其他js库；4、 掌握MySQL、Oracle等数据库，熟练使用SQL语言及相关优化；5、 熟练使用及搭建缓存（Redis、memcached等）、各类MQ（Kafka、RabbitMQ）等中间件；6、 熟练使用IDEA开发工具、Tomcat、JBoss、Apache、nginx的开发、环境部署和配置；7、 了解TCP/IP协议、java网络编程、NIO及使用相关框架，如Netty、Mina等；8、 有分布式开源项目经验，能独立部署相关环境，使用过ELK、Flume、Spark、Storm、Hadoop、HBase、Hive等技术者优先；9、 有团队管理经验优先；公司简介：（ http://www.ccxcredit.com.cn/）       中诚信征信有限公司（简称“中诚信征信”）隶属于中诚信集团。在企业征信、个人征信、商业信息服务、市场调研咨询等领域，拥有十余年的丰富经验。公司始终坚守中立、客观、公正的理念，秉持专业、诚信、严谨的操守，做市场认可的独立第三方征信机构。      中诚信征信于 2014 年 6 月，率先获得全国企业征信业务经营备案资质，并于 2015 年 1 月，成为首批获准开展个人征信业务准备工作的独立第三方征信机构。作为**批央行获得批准开展个人征信准备工作的民间征信机构，中诚信征信在商业利益驱动以外，希望能通过市场化行为和生活化应用让更多的人更好的了解个人信用的价值，促进我国社会化信用体系建设良性发展。我们的优势 ：中立：坚持独立第三方定位，秉持客观、公正原则，专注于机构服务。领先：首推互联网大数据征信平台，首创信用科技理念。专业：26年信用风险管理经验沉淀，复杂关系网、自动机器学习等技术自主研发创新。全面：覆盖90%以上互联网人群，近千家付费客户，大型银行客户覆盖率超过75%。安全：数据安全合规，两地三中心自动化运维。创新：中国首批互联网大数据征信的践行者。我们的福利：我们不仅为员工提供优厚的福利保障，还致力于打造轻松、愉快的团队环境：——按国家标准缴纳社保、公积金；——扁平化管理，平易近人的领导团队；——每周五７小时工作制，开启各类俱乐部活动（篮球、游泳、健身、K歌等等应有尽有）；——弹性的工作时间；——免费优质午餐、生日礼物及各种节日party；——年度免费体检；——位于东二环环境优美的独立四合院，紧邻地铁5、6号线东四站。,"数据服务,人工智能",150-500人,spark,北京
数据建模经理（评分产品&amp;画像标签方向）,https://www.lagou.com/jobs/7121833.html,东城区,25k-40k,中诚信征信有限公司,3-5年,本科,周五7小时、紧邻地铁、免费午餐,岗位职责：1、与产品部门配合进行评分产品的设计，负责评分模型的开发，包括且不限于信用评分、风险评分、反欺诈评分、营销分、行为分等；2、了解各种三方数据源，负责数据源的评估，并提出使用方案，应用于评分产品和画像标签产品；3、对有价值的数据源底层数据进行挖掘，形成标签类数据产品；4、协同产品部门对数据和模型进行系统化管理、监测和及时报警，跟进落实相关产品落地与部署、跟踪、监控表现，根据监控结果对产品进行优化，确保对客户提供的数据产品的稳定性和有效性。5、带领小组完成上述工作，负责组员的工作指导和安排以及日常管理等；6、根据业务需求，跟进业界相关技术领域前沿进展，做出前瞻性规划和实践。 岗位要求：1、 统招本科以上学历，硕士以上学历优先，数学、统计、计量经济、计算机专业优先；2、 4年以上评分建模、数据分析和挖掘相关工作经验；3、 掌握常用的数据分析、统计建模和机器学习方法，包括且不限于逻辑回归评分卡、树模型、神经网络等；3、 熟练使用Python/R、SQL等编程语言，有hive、spark使用经验者优先；4、 具有评分产品研发经验者优先，熟悉各种三方数据源者优先；5、较强的解决问题的能力、沟通能力和跨团队合作能力，有一定管理经验者优先。,"数据服务,人工智能",150-500人,spark,北京
大数据研发工程师,https://www.lagou.com/jobs/6998715.html,朝阳区,18k-25k,深圳市赢时胜信息技术股份有限公司,3-5年,本科,晋升空间大 团队氛围好 技术提升,技能要求：java，Hadoop，SCALA，Hive，Flink岗位职责：1、基于大数据平台的应用系统设计、开发、维护；2、承担公司大数据相关项目的需求分析、开发、实施、现场支持。任职资格：1、计算机或相关专业本科及以上学历；2、3年以上相关工作经验，至少熟练掌握Java，Scala，Python中的一种或多种；3、熟练使用Hadoop、Spark、Storm、SparkStreaming、Hive、HBase进行应用开发；4、熟悉搜索引擎，例如Impala，Presto，Elasticsearch等；5、具备基本的Hadoop运行环境的运维管理经验；6、有实际的大数据应用工程开发经验；7、熟悉金融领域相关知识或有金融系统开发经验的优先。,金融,500-2000人,spark,北京
数据挖掘工程师,https://www.lagou.com/jobs/7154433.html,海淀区,15k-25k,北京一亩田新农网络科技有限公司,不限,不限,五险一金，弹性工作,"职位描述：1.负责业务用户画像构建2.综合运用统计和数据挖掘/机器学习的方法，挖掘目标用户。3.分析某种行为用户所具备的特性信息，根据特征信息挖掘共性用户。4.负责部门数据建设工作，对数据建设结果负责。 任职资格：1. 本科及以上学历，2年以上相关工作经验;2. 熟练掌握python、java等开发语言，对数据结构和算法设计有较为深刻的理解;3. 具备基于Hadoop大数据处理及分析的多项技术应用技能，包括但不限于HDFS，ElasticSearch，Spark，Hbase；4. 熟练应用spark streaming、storm等大数据实时计算技术;5. 理解机器学习基本算法的设计思想和求解手段，如SVM, LR, RF, Boosting等;6. 具备较强的业务理解力、主动性强、善于沟通；",电商,500-2000人,spark,北京
推荐系统工程师,https://www.lagou.com/jobs/7188901.html,朝阳区,28k-56k,北京展心展力信息科技有限公司,3-5年,本科,房补 饭补 健身房,岗位职责：  0.  负责个性化推荐系统的系统设计，开发和迭代，不断提升推荐效果；  0.  负责高并发推荐引擎的研发，优化引擎的计算和存储性能；  0.  负责在线大数据引擎的研发和优化，不断提升性能和稳定性； 任职要求：1. 计算机软件相关专业本科及以上学历，2年以上相关工作经验；2. 有高并发、分布式在线系统的java/golang/C开发经验，熟悉常用的开源框架，并深入理解其实现原理和机制；3. 有丰富的Hadoop、Spark、Flink等大数据组件的使用和研发经验；4. 为结果负责，主观能动性强，能创造性地独立解决复杂问题；,"移动互联网,游戏",150-500人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6761981.html,朝阳区,18k-25k,北京亿玛创新网络科技有限公司,3-5年,本科,"扁平管理,地铁附近,福利佳",工作职责: 1.负责海量用户行为数据的接入和整合，多维度建设用户画像； 2.负责数据采集、存储、分析、挖掘工作，丰富用户画像； 3.基于数据管理平台指导数据决策并输出解决方案；任职资格: 1.熟悉Linux系统环境，精通Java/Scala/Python等大数据领域常用开发语言的一种或多种；2.熟练掌握主流大数据常用框架，如：Hadoop、Hbase、Hive、Spark、ES、Kafka等; 3.具备使用Spark Streaming实时引擎进行数据流开发和调优的经验; 4.具备海量数据处理经验，有互联网行业数据挖掘经验；5.具备DMP系统建设和机器学习成功应用经验者优先。6.工作严谨负责，较强的学习能力、沟通能力和抗压能力。,"移动互联网,电商",500-2000人,spark,北京
风控模型分析师,https://www.lagou.com/jobs/6222549.html,海淀区,15k-30k,北京众信利民信息技术有限公司,1-3年,本科,领导大牛，高尖精团队,职责描述：1、负责金融风险管理相关的数据分析，对风险预警异常情况进行深入分析，对业务风险指标进行跟踪分析及优化；2、负责机器学习模型的构建、维护、和评估，上线模型，拟写模型报告；3、开发预警系统，负责贷后规则、预警规则的提炼，将其应用到模型中，提升预警、贷中和贷后的精准率；5、根据数据现状，业务运营规划和发展目标，负责BI数据服务业务的规划设计，需求分析和工作流程； 6、负责落地全面数据治理，包括数据资产管理、数据质量管理、数据指标开发及体系化建设；职位要求：1、统计、数学、计算机等理工科相关专业本科及以上学历；2、熟悉常用数据挖掘算法与模型，熟悉逻辑回归、神经网络、决策树、聚类等建模方法；3、熟练使用Python、R等语言，熟悉SQL、hive、spark，Hadoop，具备扎实的数据分析功底；4、注重团队协作，有独立承担项目的经验和能力，具有优秀的职业素养和抗压能力；5、对数据敏感且对处理大量数据有强烈兴趣，具备较强的逻辑思维及语言沟通能力；6、思维活跃，有创新思考能力，具有良好的逻辑分析能力，能够快速学习新方法，责任心强；,"金融,数据服务",150-500人,spark,北京
风控算法工程师,https://www.lagou.com/jobs/6222446.html,海淀区,15k-30k,北京众信利民信息技术有限公司,1-3年,本科,领导大牛，高尖精团队,职责描述：1. 运用NLP、关系网络、知识图谱等技术，从海量的非结构化数据中挖掘出个体以及网络群体的特征，搭建完善的用户画像特征体系，综合衡量用户的信用风险、欺诈风险和金融需求。2. 通过机器学习、深度学习等算法技术，搭建信用风险模型、反欺诈模型，并参与制定相应的风控策略，控制金融业务风险。3. 对模型、特征、业务进行可视化监控预警，发现风险点与增长点，对线上模型和策略及时优化迭代，以数据驱动的方式提升业务风险控制能力。4. 独立完成第三方数据源的测试评估，以及相应的数据源对接、风控产品输出等项目的全流程设计与实现。5. 深入了解各个业务，应用创新的人工智能算法技术解决业务实际问题。职位要求：1. 计算机、统计学、数学、自动化等相关专业本科及以上学历，1年左右工作经验。2. 熟练使用MySQL、Hive，熟悉常用的数据结构，熟练掌握Python，R，SAS中的一种或多种建模与数据分析工具。3. 掌握NLP、关系网络、知识图谱等技术原理，实际运用相关算法技术完成过数据挖掘任务；有大数据分布式处理经验，如Hadoop、Spark等，有良好的逻辑思维能力，能够从海量数据中发现关键特征。4. 对常用的机器学习、深度学习算法原理理解透彻，如：LR、Naive Bayes、RF、GBDT、XGBboost、CNN、GNN等，有常见深度学习框架（如Tensorflow/Caffe/Pytorch等）使用经验，能够针对具体任务调优算法模型。5. 有良好的主动性、自驱力，优秀的分析问题和解决问题的能力，具有良好的沟通能力和团队合作精神，对解决具有挑战性问题充满激情，抗压能力强。6. 能支持短期的出差驻场建模工作,"金融,数据服务",150-500人,spark,北京
Java开发工程师,https://www.lagou.com/jobs/6391156.html,朝阳区,20k-40k,安讯达盛（北京）科技有限公司,1-3年,硕士,五险一金、免费用餐、节日福利、定期团建,岗位职责1.负责需求分析和功能应用设计。2.负责根据项目进度及质量管理体系要求，完成项目开发工作，完成系统编码及单元测试等相关工作。3.配合完成测试相关工作。4.参与系统推广工作，保证系统顺利投产运行。5.负责系统试运行期间的缺陷修复工作，保证系统正常运行。6.负责系统优化工作 ，参与项目技术攻关工作。7.完成上级领导交办的其他工作。任职要求1.硕士以上学历。计算机类、电子信息类、自动化等相关专业优先。2.具备3年及以上相关岗位工作经历。3.Java基础扎实，熟悉Hadoop MR/Hive/Spark、熟悉Python、R、Scala、MatLab等优先。4.熟悉数据库应用开发（Oracle、MySQL等），熟悉PostgreSQL、Vertica优先。5.熟悉Linux操作系统，了解主流中间件产品（WebLogic、Tuxedo等）。6.具有良好的需求理解能力。7.熟悉软件开发过程和软件测试流程。8.具有良好沟通能力、问题解决能力，能够承担较强的工作压力。,移动互联网 医疗健康,15-50人,spark,北京
大数据工程师,https://www.lagou.com/jobs/6432870.html,朝阳区,15k-30k,安讯达盛（北京）科技有限公司,不限,硕士,免费早午餐，社保公积金、节日福利,"岗位职责：
 大数据处理框架设计与实现；
 数据挖掘/图挖掘，解决产品业务需求；
 统计/可视化分析；
 跟踪大数据技术前沿驱动产品研发。
任职要求：
 计算机等相关专业硕士以上学历；
 熟悉docker/spark/openstack/nosq1数据库；
 编程熟练，有数据挖掘经验。",移动互联网 医疗健康,15-50人,spark,北京
高级大数据研发工程师,https://www.lagou.com/jobs/5893151.html,东城区,25k-40k,北京影谱科技股份有限公司,3-5年,本科,"13薪,交通餐补，餐补,全勤奖,七险一金",岗位职责1、负责大数据数据平台建设，带领团队建设数据采集平台及计算平台；2、负责分布式数据平台框架下，大数据开发和应用架构的研究和设计；3、理解用户数据分析和挖掘应用场景，抽象为数据产品需求，不断完善基础数据的建设。任职要求1、3年以上大数据开发经验，具备较强的数据抽象能力和架构设计能力；2、熟悉大数据平台生态如hadoop、spark、kalfa、flume等；3、有丰富的大型平台的架构及研发经验，了解数据结构和NLP算法，如聚类分类、协同过滤等常用算法；4、对技术有持续追求，强烈的技术领导力和责任心。,"文娱丨内容,广告营销",50-150人,spark,北京
高级大数据工程师,https://www.lagou.com/jobs/6255263.html,东城区,25k-30k,北京影谱科技股份有限公司,5-10年,本科,七险一金，国内外团建,岗位职责：1、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；2、负责Hadoop、HBase、Hive、Spark、Kafka等集群的维护、优化工作；3、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；4、了解产品业务，加入产品从原型设计到正式上线的整个过程，基于对产品的理解，从技术架构的角度给予持续的优化意见；5、开发大数据自动化运维、监控、故障处理工具，监控所有基础设施组件、应用程序，提供紧急应急措施；6、持续的创新和优化能力，提升产品整体质量，改善用户体验，控制系统成本；   任职要求：1、本科以上学历，计算机，通讯相关专业，5年以上工作经验。 2、深入理解linux系统，运维体系结构，精于容量规划、架构设计、性能优化，专家优先；3、精通至少一门编程语言(java/python/scala)，熟练运用各种常用算法和数据结构，有独立的实现能力4、熟悉Hadoop、HBase、Kafka、Hive、Spark等组件的工作原理，并有3年以上Hadoop生态系统维护与调优经验；5、具备故障排查能力，有很好的技术敏感度和风险识别能力；6、良好的服务意识，善于团队协作，项目管理，主动思考，自我驱动力强；,"文娱丨内容,广告营销",50-150人,spark,北京
NLP/机器学习/自然语言处理工程师,https://www.lagou.com/jobs/4754888.html,西城区,20k-40k,北京左医科技有限公司,1年以下,本科,"七险一金,餐补,15.5薪,技术大牛","职位诱惑：技术大牛多,公司氛围好,15.5薪,七险一金，职位描述：岗位职能：通过NLP信息抽取、数据挖掘等技术，从海量病历、论文、医学电子书籍、网页中进行知识挖掘，根据应用需求设计并完善医学知识图谱。技能需求：（1）熟悉linux开发环境；（2）熟悉常用基本数据结构、算法；（3）熟练使用python语言(生物信息方向 perl语言也可)；  (4) 熟悉常用机器学习、数据挖掘、NLP相关应用与算法  (5) 熟练使用hadoop、spark等分布式存储计算工具加分项： (1) 具有医学信息学/生物信息学/临床医学学历背景； (2) 具有一年以上医学文本信息挖掘工作经验； (包括住院病历、医学文献、基因、蛋白结构等文本/字符序列信息挖掘) (3) 具有NLP信息抽取、知识图谱构建、工作背景；我们的亮点：1、 技术背景：多位百度NLP大牛，内功深厚，领跑行业；2、 医学背景：北大医学专业团队，从业多年，精准把握医疗痛点；3、 资金背景：数千万A轮融资，未来几年吃喝不愁；4、 薪资待遇：年中奖励，年底三薪，股票期权；5、 团队氛围：人少精悍，低调务实，充分信任，珍惜人才；6、 公司未来：人工智能+全科医生，热门中的热门。我们给优秀的你提供了：七险一金、无限免费零食＆饮料＆水果、带薪年假、餐补、年底15.5薪等所有你能想到和想不到的福利！","移动互联网,医疗丨健康",50-150人,spark,北京
高级运维工程师,https://www.lagou.com/jobs/7184641.html,海淀区,20k-35k,北京市商汤科技开发有限公司,5-10年,本科,"AI独角兽,发展空间大",岗位职责： 1、负责IT项目运维；2、严格按照制定的流程及规范实行运维操作；3、负责系统部署上线、系统优化；4、负责运维报告的整理以及相关文档的编写；任职要求：1、3年以上linux系统运维工作经验，熟悉并使用过阿里云产品者优先；2、精通docker容器技术、熟悉k8s，熟悉ceph、kafka、spark等组件的运维。3、熟悉主流数据库，善于分析解决问题。4、具有良好的产品学习能力；5、具有独立分析解决问题的能力、团队合作意识及良好的文档记录习惯。,人工智能,2000人以上,spark,北京
数据仓库,https://www.lagou.com/jobs/5720218.html,朝阳区,15k-30k,北京瓴岳信息技术有限公司,1-3年,本科,六险一金；十四薪；午餐晚餐；扁平化管理,岗位描述： 1、负责公司级的数据仓库平台相关产品的设计研发，服务于公司各个业务线； 2、负责大数据服务平台接口的迭代开发，构建离线&实时的数据仓库平台3、基于hadoop、spark、hive、hbase、flink等开源技术构建解决方案满足业务方需求4、构建设计良好的数据仓库、调度系统、查询引擎，数据服务、分析系统等，保证系统稳定高效运行，以实现数据的最大价值。 我们期望： 1、熟悉多项大数据处理分析相关的工具框架，e.g. Hadoop Mapreduce Hive flink Spark kylin kafka hbase canal etc；2、强悍的编码能力，生产环境快速 troubleshooting能力，对新技术有强烈的学习热情；3、优秀的理解沟通能力，能快速理解业务背景，对数据敏感，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值，有web应用开发能力者优先。4、熟练使用java语言，有大数据平台系统研发经验，熟悉Java\python开发经验优先。,"移动互联网,金融",150-500人,spark,北京
大数据工程师,https://www.lagou.com/jobs/7133010.html,丰台区,10k-20k,中汽知识产权投资运营中心（北京）有限公司,3-5年,本科,发展前景,岗位职责：1.负责大数据平台架构的规划、设计与实施；参与建设、维护、优化数据平台，为业务提供易用的数据工具和平台；2.负责基于大数据平台的数据、分析、加工、清理程序的开发；3.通过大数据平台和工具，支撑海量数据分析、数据挖掘、机器学习工作。任职条件：1.熟练使用hadoop生态系统内常见项目的使用（hdfs、hive、impala、hbase、spark、yarn、zookeeper等），能够进行数据集群搭建及维护，具有丰富MapReduce、Spark开发经验；2.具有丰富JAVA及Scala语言使用经验，具有数据处理系统开发经验；3.具有在线及离线数据处理及统计分析经验，能够独立承担数据ETL及统计分析工作。4.熟练使用MySQL数据库及SQL语言。,"企业服务,软件开发",50-150人,spark,北京
java开发工程师,https://www.lagou.com/jobs/6961417.html,海淀区,18k-25k,北京华夏乐游科技股份有限公司,3-5年,本科,薪资待遇 发展前景,"1.3年以上Java互联网开发经验；2.精通java,对Spring Boot、SpringCloud、MyBatis了解其原理和实现机制，具有微服务相关框架开发经验优先；3.精通SQL，熟练使用MySQL数据库，并具有一定的SQL优化能力；4.熟悉Memcached、Redis、MongoDB等常用NoSQL解决方案；5.熟悉Hadoop，Spark，Hive，Kafka，zookeeper等大数据生态相关组件，有相应的应用经验者优先；6.熟悉Linux操作系统常用命令；",游戏,150-500人,spark,北京
推荐算法工程师,https://www.lagou.com/jobs/6682948.html,海淀区,20k-40k,深思考人工智能机器人科技（北京）有限公司,3-5年,硕士,"AI行业,专业性,平台",岗位职责：1、负责内容推荐，用户画像等业务，开发机器学习算法原型系统，开展线上算法实验；2、针对海量人机交互行为数据，搭建公司个性化推荐引擎，并和个性化交互系统进行整合。 职位要求：1、硕士及以上学历，2年以上相关方向工作经验，研究方向可为自然语言处理、深度学习、推荐算法；2、熟悉Linux，熟练掌握Python、Java等编程语言，能够独立完成模块开发和上线；3、熟悉特征工程的构建，以及推荐相关的推荐算法（lightgbm、xgboost、LR、FM、deepFM等）；4、在深度学习领域有较强的理论研究与实践经验，熟悉tensorflow、pytorch、keras一种或多种开发框架；5、具有实际推荐项目经验或参加过相关竞赛并取得优异成绩者或相关领域学术会议发表过论文者优先；6、熟悉使用Hadoop，Storm，Spark，HBase等大数据技术平台，有大规模数据日志处理经验者优先；6、优秀的数据分析问题能力和解决问题能力，抗压能力强，对解决具有挑战性问题充满激情。,"移动互联网,企业服务",50-150人,spark,北京
java高级开发工程师,https://www.lagou.com/jobs/7214900.html,朝阳区,20k-35k,北京睿帆科技有限公司,5-10年,本科,发展空间大,"岗位职责:1、负责产品需求对接，理解用户需求，整体负责产品架构设计；2、负责产品需求的技术分析，和产品经理一起制订产品技术解决方案;3、完成产品相关概要设计、详细设计、产品实现，以及相关设计文档编写；4、制定产品设计、实现标准规范，指导团队进行相关设计、实现及部署工作等；5、制定开发计划，推进产品研发、督促研发及开发人员按计划完成研发任务；6、负责系统核心部分代码编写及疑难问题的解决任职要求：1、计算机或相关专业本科毕业, 5年以上Java开发经验，3年以上大中型系统架构经验；2、JAVA基础知识抓实，精通集合、I/O、多线程等，了解JVM工作原理；3、熟悉设计模式、常见数据结构与算法；4、熟练掌握Spring Framework、Spring Boot、Spring Cloud、Dubbo、Mybatis、Hibernate, Maven等开发框架5、熟悉缓存（如Redis）、消息队列（如KAFKA）、配置中心（如ZK）等中间件，掌握工作原理；6、熟悉MySQL、Oracle、SQL Server等数据库，精通数据库表结构设计与相关优化；7、熟悉微服务、搜索、分布式缓存、消息中间件、负载均衡、容灾、安全防护等，有高并发、高性能、高可用系统架构设计成功实践；8、对Spark、Kafka、Flink有丰富的经验者优先；9、有强烈的责任心，优秀的学习、思考能力以及良好的团队沟通协作能力，具备一定的项目管理能力，能规划中长期架构方向者优先","企业服务,数据服务",15-50人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6388423.html,朝阳区,10k-20k,摩邑盟诚（北京）科技有限公司,1-3年,本科,五险一金 团队Nice 出国旅游,职位诱惑：五险一金 团队Nice 出国旅游职位描述：职位描述：1.设计公司数据流架构，2.开发维护数据流平台3.挖掘数据商业价值-搭建公司整体数据流体系-搭建公司实时、离线报表-搭建流量变现数据模型职位要求：1.本科及以上学历，计算机相关专业。2.拥有良好的代码习惯，代码结构清晰，命名规范，逻辑性强。3. 熟练掌握Hadoop、Spark、Java语言；4.Python、PHP至少掌握一种语言；5.搭建过广告变现的离线流、实时流6.具有较强的学习能力和积极主动性，有责任心，良好的团队合作精神。,广告营销,50-150人,spark,北京
产品经理 （BI方向）,https://www.lagou.com/jobs/6546208.html,朝阳区,15k-30k,北京区块节点科技有限公司,3-5年,本科,五险一金、带薪年假、节假日福利,工作职责：1.负责数据平台规划及设计，完成流程设计、产品原型、PRD文档等，推动产品方案落地实施2.负责与开发、测试等相关部门紧密协作，推进产品开发、测试及交付上线全流程管理，把控产品质量3.负责产品发布后的用户反馈和跟踪优化工作，规划产品迭代版本，管理产品生命周期。任职资格：1、统招本科及以上，计算机相关专业，3年以上产品经验，大数据平台产品开发方面工作经验优先2、具有优秀的表达、沟通与协调能力、团队合作精神3、熟悉大数据行业工具及系列产品，熟悉BI工具、ETL工具、数据管理工具等4、善于思考，逻辑严谨扎实，有程序化思维，具有不断发现并解决问题的能力5、有tableau、永洪BI、FineBI、powerbi使用或设计经验的优先6、使用Axure、Xmind、Viso等交互设计工具制作可交互的产品需求原型和业务流程图 7、了解Hadoop，Spark，K8S等分布式大数据技术、能与技术人员良好沟通的优先。,移动互联网,50-150人,spark,北京
EI数据中心java开发工程师,https://www.lagou.com/jobs/6766429.html,朝阳区,15k-30k,北京区块节点科技有限公司,3-5年,本科,上市企业平台，接受应届生、实习生,岗位职责（接受应届生、实习生）1、基于产品、项目需求，完成模块开发、单元测试工作2、协助工程实施人员做好项目的后期维护工作任职要求1、统招本科以上学历，计算机、数学相关专业，1-3年实际Java开发经验；2、JAVA基础扎实，对JVM原理有一定的了解；3、掌握常用的数据结构和基本算法，面向对象的思想和设计模式；4、熟练使用SpringBoot、SpringMVC、MyBatis、JPA等开源框架，了解原理和机制；5、熟悉mysql/Oracle 数据库，并有一定的SQL优化经验；6、有hadoop、spark使用经验；8、工作习惯良好，自驱动，擅于合作，代码清晰整洁,移动互联网,50-150人,spark,北京
广告系统开发工程师,https://www.lagou.com/jobs/6186208.html,朝阳区,30k-60k,行吟信息科技（上海）有限公司,3-5年,本科,良好的发展前景,工作职责：负责推进广告预估模型和策略的算法工程化。1）和广告算法策略配合，搭建高效率，高通量的模型训练框架，2）打通数据与线上服务，推进特征工程和算法模型的快速迭代。经验要求1、熟悉Hadoop、Hive、Spark等离线数据框架，并有实际pipeline开发调优经验。2、熟悉在线服务中间件（如RPC框架），分布式存储技术（如redis，hbase等）。3、熟悉并使用过在线数据流计算框架（如spark streaming，flink）等优先。4、有一定的数据分析和统计经验，熟悉并使用过流行训练框架（如tensor flow）等优先。5、理解业务需求，学习能力强，具有良好的沟通能力和团队合作能力，,消费生活,500-2000人,spark,北京
商业化-数据开发Leader,https://www.lagou.com/jobs/5763319.html,朝阳区,30k-60k,行吟信息科技（上海）有限公司,3-5年,本科,良好的发展前景,工作职责：1、负责广告产品核心业务模块数据仓库的构建；2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；任职要求：1、计算机、数学相关专业，本科及以上学历，三年以上大数据开发工作经验，数据挖掘和BI分析领域优先；2、熟练掌握Hive/SQL，熟悉Spark/Map-Reduce/MPI分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；3、有产品sense，主动思考基于业务场景下的数据体系建设，而不单单只会做执行；4、工作认真，负责，良好的团队合作精神和解决问题分析能力，钻研技术克服困难，勇于挑战；5、有数据分析经验优先。,消费生活,500-2000人,spark,北京
ETL工程师(J10262),https://www.lagou.com/jobs/7085728.html,朝阳区,15k-25k,包头市包银消费金融股份有限公司,3-5年,本科,六险一金；年终奖；节日福利,,金融,150-500人,spark,北京
高级Java开发工程师(J10242),https://www.lagou.com/jobs/6789733.html,朝阳区,20k-35k,包头市包银消费金融股份有限公司,5-10年,本科,六险一金；节日福利；年终奖,工作职责:1、开发和维护公司核心业务系统；2、重点项目需求分析、方案设计、编制设计文档；3、制定项目计划，组织设计评审；4、指导Java开发工程师工作以及代码复核；5、解决项目中的技术难题。任职资格:1、全日制统招本科及以上学历，计算机相关专业；2、5年以上java开发工作经验，3年以上分布式项目开发经验；3、精通Java EE相关技术，精通Spring、iBatis/ Mybatis等开源框架；4、精通mysql、oracle数据库的使用及优化；5、精通常用分布式框架，精通Dubbo、SpringCloud、Zookeeper等技术，熟悉分布式事务处理；6、精通Linux操作；7、熟悉大数据相关技术，hadoop、hbase、hive、spark；8、具备高度责任感，具备良好的团队合作能力，良好的沟通表达能力、学习领悟能力；9、有银行信贷、征信相关工作的优先。,金融,150-500人,spark,北京
高级java开发工程师,https://www.lagou.com/jobs/7171960.html,海淀区,18k-21k,南通东华软件有限公司,5-10年,本科,发展平台好。,"1.本科或以上学历，计算机，软件工程等相关专业，6年以上工作经验；2.熟悉主流云平台的技术结构特性或运营框架模式；3.掌握虚拟化、容器等技术，掌握公有云IAAS服务的定制开发，并具有云服务架构及组件的开发、测试和运维的实践经验；4.精通java语言，java基础扎实，精通io、多线程、集合等基础框架，精通分布式、缓存、消息、搜索等机制；5.了解性能压测、持续集成、持续交付系统和工具开发，了解UI/UE前端开发。6.精通Spring、Springboot、Mybatis 等框架开发。7.熟悉Mysql、Oracle；熟悉MongoDB、Redis、elasticsearch、Filebeat、Nxlog、kafka等。8.熟悉Linux下的常用命令，熟悉Spark、SparkStreaming，有一定的hql/sql性能调优经验。9.熟悉CEP、Flink优先。10.有较好的沟通交流能力,善于主动思考和行动,乐于解决具有挑战性的问题","信息安全,数据服务",150-500人,spark,北京
大数据运维工程师(J10921),https://www.lagou.com/jobs/6935647.html,朝阳区,15k-25k,北京仁科互动网络技术有限公司,3-5年,本科,技术大牛、团队氛围好、地铁周边,工作职责:1、负责公司大数据集群的运维工作（Kafka/Hadoop/HBase/Spark/Flink/Clickhouse等）；2、负责集群性能优化，扩容3、负责hadoop集群的监控、数据备份、数据监控、报警、故障处理；研究运维相关技术，根据系统需求制定运维技术方案，开发自动化运维工具和运维辅助系统；4、深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技及发展方向；任职要求：1、有2年以上大数据集群运维经验；2、有实际部署经验，并能够独立排查及解决问题。熟悉hadoop在运行环境，任务调度，参数配置等方面的调优；3、精通Python、Shell、Java中任一语言，熟悉linux开发环境以及相应的配置、管理及优化；4、熟悉Hadoop生态圈，包含但不限于Hbase/Hadoop/Zookeeper/Spark/Kafka等，能够独立部署并上线运行；5、有流数据处理运维经验，ETL pipeline处理经验者优先考虑；有Flink/Clickhouse运维经验的候选人优先；6、有一定开发经验，能协助大数据环境下的性能问题定位和优化的候选人优先；7、有在线实时获取、传输、计算、反馈相关系统部署经验；有创新精神和团队意识，可以将想法转化成行动。熟悉Docker；8、计算机及相关专业本科及以上学历，三年以上相关工作经验；优先条件：熟悉云计算相关技术，有2年腾讯云、阿里云或AWS使用经验，有AWS认证为佳；有Java开发背景最佳；,"移动互联网,数据服务",500-2000人,spark,北京
广告算法工程师,https://www.lagou.com/jobs/6828404.html,朝阳区,20k-40k,北京热云科技有限公司,3-5年,本科,六险一金，午休两小时,"岗位职责:1.设计、实施并持续改进实时竞价广告系统的CTR、CVR预测算法；2.设计、实施 lookalike算法；3.多维度数据分析；4.广告机制的研究，广告转化和变现效果优化。  任职资格:1. 计算机、数学、统计或相关专业，本科及以上学历，至少3年以上广告领域算法经验；2.掌握java/python/scala其中一种或者几种语言，掌握linux常规命令；3.具备程序化广告、dsp等竞价系统点击率预测和建模项目经验， 熟练opcx实施落地；4.具备广告、电商等场景下的推荐算法建模经验；5.熟练fm、ffm、deepfm、xgboost模型框架并有过实际项目经验；6.熟悉常规的机器学习算法原理,对聚类算法有较丰富的使用经验；7. 熟悉 tensorflow/sklearn/spark MLlib等常见机器学习框架；8.熟悉用户画像方法、DMP系统等可加分。","数据服务,移动互联网",150-500人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6846945.html,朝阳区,15k-30k,北京热云科技有限公司,3-5年,本科,17薪，午休两小时,"岗位职责:1、参与ADI大数据的开发，实现数据驱动业务；2、根据业务需求进行数据模型的调研、设计、开发及验证工作，并持续进行模型的优化；3、负责数据模型架构的构建，建立数据抽取、清洗、校验等数据加工流程规范及OLAP多维数据分析模型；4、持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。岗位要求：1、统招本科或以上学历，计算机、数据挖掘等相关专业，工作至少3年以上；2、熟悉Java开发，有脚本语言（shell,python)开发经验者优先；3、至少熟悉一种大数据处理技术，如Hadoop、Spark；4、掌握HBase、Redis、Elastic Search等开源大数据存储技术，并能结合不同的业务场景深入使用；5、熟悉常用Java Web开发框架，如：Spring Cloud等；6、熟悉多线程编程，并对Java自带线程池有一定研究；7、对解决具有挑战性的问题充满激情，具有良好的分析问题和解决问题的能力，能够医治各种系统的疑难杂症；8、有营销背景优先考虑。","数据服务,移动互联网",150-500人,spark,北京
中高级大数据开发工程师,https://www.lagou.com/jobs/7217699.html,海淀区,15k-25k,神州数码（中国）有限公司,5-10年,本科,发展空间大 七险一金,工作职责负责构建信创生态的核心软件能力，研发面向信创领域的创新应用软件产品的大数据方向软件开发任职要求1、本科以上学历2、5年以上开发经验，3年以上大数据软件开发经验，熟练掌握java或python等大数据产品开发语言中的一种，熟悉hadoop、spark、storm、elasticSearch等框架组件3. 有大数据领域的应用规划，设计和开发经历者优先考虑4. 有良好的沟通能力，有较强的独立工作能力和解决问题的能力，工作认真负责，积极主动，能够承担工作压力,"硬件,数据服务",2000人以上,spark,北京
研究开发所-大数据研发岗,https://www.lagou.com/jobs/6102352.html,海淀区,13k-26k,中国移动通信集团设计院有限公司黑龙江分公司,不限,硕士,服务待遇完善,学历要求：硕士及以上毕业院校要求 ： 211学校专业要求(含研究方向)：计算机、通信工程或相关专业其他需求条件：1、掌握 Java、Hadoop、Hive、HBase、Zookeeper、Spark、Storm 的安装配置，具有 MapReduce 开发经验，有实际大数据项目经验者优先选择。2、掌握 hadoop 生态系统内常见项目（hdfs、hive、hbase、spark、zookeeper、yarn），有系统架构、核心算法与开发测试者优先选择。3、掌握Linux/Unix 系统环境下的操作；4、掌握Tomcat 等应用服务器的配置和优化。5、掌握Oracle、MySql 等主流数据库。6、具有较强的学习能力，具有一定的英语阅读能力，能积极主动跟踪与研究业界主流技术和热点问题；7、具有良好的沟通和团队协作能力及解决问题的能力，良好的职业道德及敬业精神，具有责任心，踏实稳重，吃苦耐劳；,通讯电子,2000人以上,spark,北京
数据研发工程师-数据挖掘(J10287),https://www.lagou.com/jobs/6785321.html,海淀区,20k-40k,北京读我科技有限公司,1年以下,本科,业务发展清晰、车补房补、地铁周边、年终奖,,移动互联网,500-2000人,spark,北京
数据开发工程师(J10363),https://www.lagou.com/jobs/6785316.html,海淀区,20k-40k,北京读我科技有限公司,3-5年,本科,业务发展清晰、车补房补、地铁周边、年终奖,,移动互联网,500-2000人,spark,北京
java高级开发工程师,https://www.lagou.com/jobs/7191532.html,海淀区,18k-30k,北京博安智联科技有限公司,5-10年,本科,一年多次调薪,岗位职责：1、参与基础开发平台、业务平台、云生态、大数据的架构设计及落地，并负责技术方案的规划、可行性分析；2、参与项目需求分析、系统框架搭建、架构设计，负责项目的模块设计，承担核心功能或组件的代码编写；3、参与重点项目核心算法的研发和优化，提升产品核心组件性能；4、负责项目/产品的高性能、高可用的技术路线设计与执行计划，交付具备稳定性、高并发、高效率的等特性的软件产品；5、负责接口开发，与第三方系统或平台的接口对接集成，整合通用框架模式的接口开发体系；6、负责主导技术难题攻关，持续提升核心系统在高并发、海量请求下的处理性能，协助技术组长解决高并发、高可靠性等各种技术问题；7、参与对软件开发团队的技术指导、设计规范、软件产品改进工作，并能结合公司实际业务系统进行框架设计，撰写相关技术文档；8、负责接口文档、开发文档、设计文档等相关技术文档的编写与交付；9、参与技术团队管理，负责日常工作任务分配、技术指导、系统故障定位与排除；10、负责按时完成领导分配的其他任务并及时反馈。岗位要求：1、公办全日制统招本科以上学历，计算机相关专业，至少5年以上Java开发经验、3年以上中大型项目架构设计参与经验；2、扎实的Java开发功底，有丰富的分布式、IO、并发编程以及数据库使用经验，熟悉Linux操作系统；3、熟悉分布式、SOA、缓存技术、并发控制、 Linux/ Nginx环境，有负载均衡、双机热备等系统部署经验，并具有1个以上的大型应用和多系统组网集成的经验，精通Tomcat、Nginx等中间件的应用配置与性能调优；4、精通oracle、mysql等常用关系型数据库，熟悉数据库建模，并具有很强数据库设计、管理、性能优化等经验和优秀的SQL功底；5、熟悉Hadoop生态圈的相关组件，深度了解HDFS、HBase、Hive、Spark、YARN、MR等组件，并具备3年以上Spark（或Hadoop）代码级的调优经验；6、熟悉NoSQL类数据库，精通Redis的使用、集成开发与持久化等；7、积极主动，具备良好的自我驱动能力和责任心，具备良好的团队合作精神和承受压力的能力。,"人工智能,软件开发",15-50人,spark,北京
大数据高级开发工程师,https://www.lagou.com/jobs/7013578.html,朝阳区,25k-50k,北京孔网时代科技有限公司,5-10年,本科,团队靠谱 餐饮免费、人性化工作、水果,职位描述：1、负责大数据平台的开发，完成关键数据报告；2、基于产品与业务需求，在产品端设计埋点方案、推动技术开发上线；3、理解产品业务逻辑，利用数据分析手段，发现产品体验问题并推动改进；4、负责建立用户画像及用户分层的数据。任职资格：1、计算机、数学、统计等专业，5年以上大数据相关工作经验；2、良好的Java基础，熟悉JVM原理，熟悉java主流框架，如：Spring，Spring mvc，mybatis等；3、熟悉并使用过各种大数据相关技术，如elk、Hadoop、Spark、Hive等；4、熟悉并使用过mysql等关系型数据库进行数据开发；5、熟悉埋点、插码、数据采集等工作；6、有从0到1的构建数据平台经验者优先；7、有互联网电商领域数据工作经验，熟悉电商业务者优先。,电商,50-150人,spark,北京
大数据研发高级工程师,https://www.lagou.com/jobs/3254204.html,大兴区,18k-30k,广州摩翼信息科技有限公司,3-5年,本科,"队伍年轻,年终奖金,大牛过招,环境耐撕",工作职责：1.1 完成大数据系统工程建设。包括离线和实时架构和业务。1.2 完成业务需求，包括数据采集、存储、计算、展示 等流程建设。1.3 保证数据质量，包括数据校验、异常监控、报警处理。1.4 研究学习新技术，引入新思路，解决业务问题，保持技术领先性。任职要求：1.1 计算机、软件、数学 等相关专业或具有相应能力。1.2 熟悉实时数据流计算，包括spark streaming、flink 、kafka。1.3 熟悉hadoop体系。包括hdfs、hbase、hive、YARN。1.4 熟悉计算引擎和即席查询。包括MR/hive、Tez、spark sql、Impala、Presto。1.5 熟悉展示图形系统。包括Zeppelin、Superset、Kylin  。1.6 熟悉常用数据建模。,"移动互联网,教育",500-2000人,spark,北京
风控数据挖掘工程师,https://www.lagou.com/jobs/7152139.html,朝阳区,15k-30k,北京蓝莓时节科技有限公司,1-3年,本科,"六险一金，上市公司旗下,14薪",职位描述1、对数据与模型进行分析，提出可行性方案和结果；2、参与风控画像风险体系建设，基于业务数据，算法模型库进行风险标签探索；3、对业务风险点、线上策略执行进行监控分析，完成分析报告、报表，通过数据分析不断改进风控策略和规则。职位要求1、有1～3年数据分析经验，对指标在模型中的评估机制有系统化的认知；2、熟悉数据挖掘，数据探索，异常数据监测的方法，并有在大数据集上落地经验；3、熟悉Hive、Spark等大数据平台；4、熟悉 python 语言，掌握常见的数据分析工具 numpy/scipy/pandas，掌握常见的可视化分析方法matplotlib/seaborn 等；5、有风控数据分析挖掘工作经验者优先，有风控画像工作经验者优先。,"移动互联网,社交",50-150人,spark,北京
数据分析工程师,https://www.lagou.com/jobs/5245795.html,朝阳区,20k-30k,北京方研矩行科技有限公司,1-3年,本科,"五险一金,带薪年假,补充医疗，发展空间",工作地：北京需求人数：3人岗位职责：各业务平台数据的收集、分析、存储、查询；根据不同的业务平台制定相应的数据分析模型以及相关的数据挖掘；监控数据分析平台的各项任务的执行状态、分析平台的运行指标、存储指标等。岗位要求：熟悉Java/Scala编程技术，编程能力强；熟悉大数据处理技术，善于学习应用业界领先数据架构和技术；对大数据开源组件有使用经验，对hadoop/spark/flink其中一项精通；熟悉数据挖掘算法和机器学习算法；善于学习，思维活跃，善于发现并解决问题；有算法研发经验者优先，对行业有自己思考的优先。,"企业服务,硬件",15-50人,spark,北京
数据中台leader,https://www.lagou.com/jobs/6914328.html,西城区,50k-80k,苏州精正信息科技有限公司,不限,本科,薪资可谈,岗位职责组建和带领数据中台产品线的产品、技术、数据建模和分析、售前和运营服务团队，打造有市场竞争力的面向政务市场的数据中台产品线。对产品营收和利润负责，根据公司年度预算目标定义产品发展方向，产品目标，团队预算、通过有效的团队管理驱动目标达成。对产品规划和落地负责，根据市场需求、结合公司生存和发展的实际情况，规划行业方向、产品策略、产品迭代路径，带领团队完成产品从立项、开发、运营、服务的商业全生命周期链条。对产品可售卖、可交付、可服务运维负责，协同公司其他部门，保障产品商业转化和用户服务质量，与商务团队合作促成项目成单，与交付团队合作确保验收回款，与服务团队合作保障客户数据运营的连续性和业务价值。岗位需求对Hadoop、Hive、Hbase、Spark、NiFi、Oozie、HUE等开源大数据软件有深入了解和实操（使用、系统开发、系统优化等，下同）经验。对数据仓库建设和使用有深入了解和实操经验，对于数据采集和导入、数据清洗和治理、数据建模与分析、数据质量检测、血缘分析等数仓建设关键操作的方法论、流程和依赖工具有深入了解和实操经验。对数据标准制定、数据资产管理、数据运营服务流程定义和优化、数据安全标准制定有深入了解和实操经验。熟悉上层数据应用对于数据中台的需求，有能力将数据应用需求转化为数据中台产品迭代路径。对于数据中台理论有深入理解和实操经验。5~8年以上开发经验，5年以上技术管理经验。有政务信息化项目相关经验者优先，有项目交付经验者优先，在一二线互联网公司、一二线政务信息化公司有数据中台、数据产品相关经验者优先。,"企业服务,金融",少于15人,spark,北京
后端工程师,https://www.lagou.com/jobs/7184034.html,朝阳区,15k-30k,况客科技(北京)有限公司,1-3年,本科,五险一金、绩效奖金、节日福利、午餐茶点,岗位要求：1. 计算机基础知识扎实，包括不限定于操作系统、计算机网络、数据结构和算法2. 熟练使用 Node.js或 Python 任意一门编程语言3. 熟悉 MongoDB、Mysql、Oracle、Redis 等数据库4. 熟悉 Web 开发，熟悉 Linux5. 具有良好的沟通能力，自我驱动能力加分项1. 有 Docker、Kubernetes 使用经验2. 有 React.js 等前端框架使用经验3. 有大规模数据运算处理经验4. 有 Spark，Kafka 使用经验,金融,15-50人,spark,北京
Node.js 开发工程师,https://www.lagou.com/jobs/7215172.html,朝阳区,15k-30k,况客科技(北京)有限公司,1-3年,本科,五险一金、绩效奖金、节日福利、午餐茶点,岗位要求：1. 计算机基础知识扎实，包括不限定于操作系统、计算机网络、数据结构和算法2. 熟练使用 Node.js 或 Python 任意一门编程语言3. 熟悉 MongoDB、Mysql、Oracle、Redis 等数据库4. 熟悉 Web 开发，熟悉 Linux5. 具有良好的沟通能力，自我驱动能力加分项1. 有 Docker、Kubernetes 使用经验2. 有 React.js 等前端框架使用经验3. 有大规模数据运算处理经验4. 有 Spark，Kafka 使用经验,金融,15-50人,spark,北京
大数据开发,https://www.lagou.com/jobs/7143637.html,朝阳区,1k-2k,北京云畅游戏科技股份有限公司,3-5年,大专,"年终奖金,五险一金,弹性打卡,房补饭补",岗位职责：1.负责基于spark、sparkSQL、hadoop开发BI分析报表；2.负责参与数据处理、调优等；3.负责数据分析平台功能完善扩展。任职要求：1.本科以上学历，计算机专业优先；2.3年以上JAVA开发经验，熟悉linux环境；3.熟悉hadoop、sparkSQL等，SQL分析能力强者优先；4. 精通java、了解python优先；5. 独立的思维能力，乐于沟通、协作，具备高度的自我约束,"游戏,移动互联网",150-500人,spark,北京
高级数据库内核研发工程师,https://www.lagou.com/jobs/6585425.html,海淀区,25k-50k,北京聚云位智信息科技有限公司,5-10年,本科,不打卡、团队大牛多、带薪年假、扁平化管理,岗位职责：1. 负责分布式数据库内核架构设计和开发;2. 负责分布式数据库SQL层的设计，开发和性能优化;3. 负责分布式数据库引擎的稳定性以及性能优化;4. 负责分布式数据库内核核心技术调研;任职要求：1. 五年以上开发经验，三年以上数据库领域开发经验，扎实的编程能力，精通Java语言；2. 对分布式数据库执行引擎有比较深入的了解；3. 熟悉Spark/Flink/Hive等分布式计算框架的SQL处理机制中的一种或多种；4. 熟悉任意一种数据库系统的执行引擎/存储引擎/优化引擎的架构和实现原理；5. 优秀的发现和解决问题能力，良好的沟通能力，具备团队管理能力；加分项：1.对前沿技术有浓厚的热情和探索欲望，有开源项目经历；2.熟悉 Spark/Flink 内核，并阅读过其中的源码；3.熟悉 MySQL/PostgreSQL/Greenplum 的内核，并阅读过其中的源码。,数据服务,50-150人,spark,北京
数据库产品经理,https://www.lagou.com/jobs/6843868.html,海淀区,25k-50k,北京聚云位智信息科技有限公司,3-5年,本科,"股权激励,扁平化管理,不打卡,五险一金",岗位职责：1、参与数据仓库、大数据平台相关的行业分析、竞品调研      2、参与数据库与大数据平台的产品策划以及相关产品材料（产品需求文档、白皮书、解决方案）的撰写3、参与数据库产品的市场推广、品牌运营、客户运营等相关工作4、协调组织各个团队和各类资源达成产品相应目标 任职要求：1、本科及以上学历，计算机相关专业，3年以上相关工作经验2、对常见数据库如Mysql，SQLServer，Oracle，PostgreSQL，或Teradata等有使用或运维经验，对数据库架构有较深入的理解3、对分布式数据库有使用或运维经验，针对系统架构有较深入的理解4、熟悉产品经理基本工作流程5、参与过产品立项、设计、研发、推广应用及维护改进的整个过程6、强烈的市场导向和创新意识7、具备良好的文案能力，文笔通畅，逻辑思维较强8、具备良好的沟通和协调能力，能迅速理解问题关键点和用户痛点，并能简明扼要的传达产品的价值点9、熟悉Hadoop、Spark、数据集成、数据治理、商业智能分析BI等技术原理，具有实践经验者优先10、有研发经验者优先，通过Oracle、Teradata、SQLServer技术认证或同等资格认证的优先,数据服务,50-150人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6859839.html,朝阳区,12k-18k,广州海鹚网络科技有限公司,1-3年,本科,六险一金 双休 13薪 年终奖,岗位职责：1、参与数据产品后端开发；2、参与底层数据清洗及开发工作。岗位要求:1、本科及以上学历、计算机相关背景 ；2、 2-3年以上数据开发经验 ；3、熟练掌握java或者scala语言 ；4、熟悉Hadoop/hive/spark/kafka等大数据技术优先; 5、有数据仓库项目经验者优先 ；6、有医疗相关数据开发经验者优先。,移动互联网,150-500人,spark,北京
数据处理工程师,https://www.lagou.com/jobs/7172249.html,东城区,20k-30k,北京酷云互动科技有限公司,3-5年,本科,周末双休 六险一金 地铁口,"岗位职责：1.对海量业务的数据进行处理和分析。2.构建业务数据分析体系，帮助确定及处理各项业务数据指标。3.支撑其它业务部门的数据处理需求。4.通过数据分析支持产品改进及新模式的探索。 任职资格：1.计算机、数学专业，重点本科或硕士以上学历，3年以上数据处理相关工作经验2.精通java、python语言或者scala语言等主流编程语言。3.精通spark编程。4.熟悉HDFS、Zookeeper、Kafka、Elasticsearch、Flume、Redis等，有Flink经验者更佳。5.善于发现和解决问题，良好的数据分析能力，逻辑思维能力。6.具有良好的沟通能力,工作态度积极主动，有较强的抗压能力，良好的团队合作意识。7.有互联网大数据处理分析工作经验者优先。","数据服务,广告营销",150-500人,spark,北京
大数据高级开发工程师,https://www.lagou.com/jobs/6785774.html,东城区,20k-30k,北京酷云互动科技有限公司,5-10年,本科,福利好 领导棒 周末双休 六险一金,工作职责：                        1. 根据业务项目需求，参与大数据项目的设计开发工作2. 开发维护数据仓库，保证数据的准确性、可靠性3. 保证大数据相关服务的稳定性、高可用性，不断优化服务性能                                                         任职资格的具体描述：                                                1、5年以上工作经验，3年以上大数据相关经验，参与过多个大数据项目的开发，熟练掌握java、scala编程语言。                        2、熟练使用Spark、Hadoop、Hbase、Hive，具有数据仓库相关经验者优先。 3、熟悉Zookeeper、Redis、Kafka、elasticsearch、Flink等大数据组件，有相关的使用经验。   4、熟悉Spring开发，有SpringBoot使用经验者优先。             5、熟练使用Linux系统，熟悉python语言者优先。                        6、具有较强的沟通能力，工作协作能力，学习能力，执行力，组织能力。                                         7、工作态度积极主动、细致、有全局观，有一定的抗压能力，善于与他人合作，良好的团队合作意识。,"数据服务,广告营销",150-500人,spark,北京
网络安全开发工程师,https://www.lagou.com/jobs/7159735.html,海淀区,15k-25k,神州数码（中国）有限公司,3-5年,本科,发展空间大 七险一金,岗位职责：负责构建生态的核心软件能力，研发面向大数据、网络安全及AI方向创新应用软件产品岗位要求：1. 三年以上软件开发经验，熟练使用C/C++/Java/Python/Go中至少两种编程语言2. 熟悉大数据处理平台Hadoop/Spark，或者主流深度学习工具TensorFlow/Caffe/Theano等3. 有大数据和深度学习领域的应用规划，设计和开发经历者优先考虑4. 有良好的沟通能力，有较强的独立工作能力和解决问题的能力，工作认真负责，积极主动，能够承担工作压力,"硬件,数据服务",2000人以上,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7092105.html,海淀区,25k-35k,北京灵图软件技术有限公司,3-5年,本科,餐补，年度体检,岗位职责：1、海量GIS领域（geomase等）大数据的分析/处理，包括海量数据的存储、计算和检索；2、基于分布式平台（MR/storm/Spark/flink）的业务数据分析和逻辑job的开发；3、开发数据统计系统、数据可视化系统等。任职要求：1、计算机、数学或统计学相关专业本科以上学历；3年以上数据的开发相关经验，特别是(1) 离线领域hadoop的ETL开发经验 或者 (2)实时计算领域包括storm、spark、flink等的开发经验 其中之一经验者；2.、有很好的海量数据开发经验，理解元数据管理。具有一定数据模型和数据架构基础；交通领域大数据工作者更佳；3、 熟悉unix或者linux，具备优秀的编程能力，熟练掌握java或者scala开发，有MR、storm、spark、flink等等语言中的一种或几种经验者优先；4. 对数据敏感、对技术敏感，有研究的意识和直觉者更佳；5. 有良好的团队合作意识，沟通表达能力和综合协调能力,移动互联网,150-500人,spark,北京
语音识别算法工程师,https://www.lagou.com/jobs/6933058.html,西城区,30k-60k,上海任意门科技有限公司,3-5年,本科,"高薪资,上升空间,扁平管理,期权股权","岗位职责：1，负责soul语音识别业务线产品的研发与落地；2，负责海量社交音频数据的分析理解工作，包括但不限于语音分类、音频信号处理、声学模型、语言模型等核心模块的实现和优化；3，跟踪前沿语音算法，主动使用新技术、新算法、新思路、新观念；包括但不限于协同运营打压站内低俗、低质音频内容，社交音频质量评估，协助推荐团队提升排序召回质量。职位要求：1，计算机、数学或统计学等相关专业本科及以上学历，3年以上相关工作经验。2，熟练掌握机器学习、深度学习的基础理论和方法，熟练使用一种或几种深度学习框架（如tensorflow、caffe、mxnet、pytorch等）；3，熟悉语音识别基本算法(HMM, GMM, CTC等)与框架(HTK, Kaldi等)，熟悉深度学习算法，熟悉RNN、CNN等神经网络；4，熟悉Java、Scala、Python、C++、Shell等常用编程语言中至少一种,熟悉linux开发环境，有良好的编程基础和数据结构算法基础；5，较强的分析问题和解决问题的能力，对解决具有挑战性问题充满激情，熟练阅读相关英文论文资料，能自觉跟踪发展现状，理解算法原理，并进行落地实现。加分项：参与或主导过语音项目（语音分类，唤醒，语言模型的训练与优化，声纹识别）；熟悉Hadoop、Spark、Hive 等大数据处理技术；有完整产品落地/上线者优先。","社交,文娱丨内容",150-500人,spark,北京
研发工程师-机器学习平台,https://www.lagou.com/jobs/7089207.html,西城区,20k-40k,上海任意门科技有限公司,3-5年,不限,"高薪资,上升空间,扁平管理,期权股权",岗位职责：1.基于第三方公有云计算平台之上，搭建机器学习平台，满足soul推荐及匹配等算法场景的架构设计和研发工作；2.理解soul各个业务场景算法研发场景需求，能将需求转化为产品架构设计，将实现过程沉淀为产品方案；岗位要求：1、熟练掌握Java，C++等常用的编程语言以及Python等脚本语言，有大规模分布式计算框架开发经验，有基于TF、Caffe等深度学习算法开发经验或者相关研究背景的优先；2、熟悉大规模数据处理平台Hadoop/Spark/Flink/Redis等；3、对常用的机器学习推荐算法原理非常清楚；乐于研究工业界前沿推荐算法，同时能够根据业务需求进行改进；4、具备优秀的逻辑思维能力，善于发现和推理不同事物之间的关系和影响，在复杂业务场景下能够分解和抽象问题，提供优秀、完整、可行的解决方案；5.具有娴熟的沟通技巧，执行力强，具有优秀的团队合作精神、敬业精神；优先：1、参与过机器学习平台的研发；2、具备1年以上搜索引擎，广告，推荐系统经验者优先；,"社交,文娱丨内容",150-500人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6735211.html,朝阳区,12k-20k,弘康人寿保险股份有限公司,1-3年,本科,"五险一金,节日福利",职责描述： 1、负责基于Hadoop、Spark平台的海量数据处理、数据计算、数据开发。2、负责高并发、高可用性、高可扩展性的线上数据系统开发。3、负责数据挖掘应用服务开发和数据挖掘算法研究和应用。4、负责数据产品和数据项目的相关开发支持。5、负责垂直领域的数据探索，价值数据提取。任职要求： 1、计算机及相关专业本科及以上学历；2、精通java和scala开发技术，熟练掌握多进程/多线程开发，熟悉常用设计模式；3、熟练掌握ElasticSearch、Hadoop、Spark、Sqoop、Kafka、HBase、Impala、Kudu等大数据开发技术，进行过大数据项目实践；4、有机器学习、数据挖掘、推荐系统经验者优先；5、具有分布式计算/搜索引擎/广告引擎等后台开发经验者优先；6、对技术有激情、有追求；富于技术创新精神，勇于解决技术难题,金融,150-500人,spark,北京
大数据架构师,https://www.lagou.com/jobs/6873200.html,昌平区,30k-50k,北京传智播客教育科技有限公司,5-10年,本科,五险一金,岗位职责： 1.根据业务需求进行数据模型的调研、设计、开发及验证工作，并持续进行模型的优化。 2.对基础数据进行整理清洗、建模和统计分析。 3.从埋点方案制定、数据处理、分析挖掘到可视化展示，提供相应数据支持。 4.参与大数据基础架构和技术体系的规划建设、开发和维护。  任职要求： 1.大学本科以上学历，计算机、数学相关专业，3年以上大数据开发经验。 2.掌握主流大数据处理技术，如：Hadoop、Hbase、Hive、Spark、Flink等。 3.精通Java或者Scala，并熟练使用其对应的常用框架Spring、Mybatis等。 4.具备使用Spark Streaming、Flink实时引擎进行数据流开发和调优的经验。 5.熟悉Linux系统环境，使用过Shell/Python/Perl等至少一种脚本语言。 6.熟悉数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验,教育,500-2000人,spark,北京
java开发工程师,https://www.lagou.com/jobs/7139995.html,海淀区,15k-20k,南通东华软件有限公司,5-10年,本科,七险一金 双休,"职位职责1.本科或以上学历，计算机，软件工程等相关专业，6年以上工作经验；2.熟悉主流云平台的技术结构特性或运营框架模式，至少有一个私有云\公有云项目的开发和实施经验。3.掌握虚拟化、容器等技术，掌握公有云IAAS服务的定制开发，并具有云服务架构及组件的开发、测试和运维的实践经验；4.精通java语言，java基础扎实，精通io、多线程、集合等基础框架，精通分布式、缓存、消息、搜索等机制；5.了解性能压测、持续集成、持续交付系统和工具开发，了解UI/UE前端开发。6.精通Spring、Springboot、Mybatis 等框架开发。7.熟悉Mysql、Oracle；熟悉MongoDB、Redis、elasticsearch、Filebeat、Nxlog、kafka等。8.熟悉Linux下的常用命令，熟悉Spark、SparkStreaming，有一定的hql/sql性能调优经验。9.熟悉CEP、Flink优先。10.有较好的沟通交流能力,善于主动思考和行动,乐于解决具有挑战性的问题；","信息安全,数据服务",150-500人,spark,北京
数据开发实习生,https://www.lagou.com/jobs/6978586.html,朝阳区,4k-8k,北京思维造物信息科技有限公司,应届毕业生,本科,"弹性工作,氛围轻松,学习机会多",职位职责：1.参与得到大数据平台建设，参与海量数据的离线和实时计算工程开发；2.支撑数据产品研发，提升数据产品性能和稳定性。职位要求：1.具备大数据思想，希望在大数据领域深入发展；2.了解业界主流的大数据生态组件和解决方案，至少熟悉三个以上技术点，如 HDFS，MapReduce，Spark，ES，Flink等；3.具有扎实的Java基础，掌握J2EE体系结构；4.熟练使用SpringBoot，对设计模式有深入理解为加分项；5.热爱技术，思维清晰，性格open，自我驱动；6.本科及以上学历，计算机相关专业，可确保每周最低4天到岗，2021年毕业生优先。,"移动互联网,文娱丨内容",150-500人,spark,北京
算法工程师,https://www.lagou.com/jobs/6435968.html,朝阳区,20k-35k,清枫（北京）科技有限公司,1-3年,本科,"北大博士,腾讯大牛,电竞大数据,期权激励",【有以下装备者欢迎投递】 ---你需要参与---1.现有个性化推荐系统的研发和优化，优化推荐排序；2.挖掘和分析用户行为数据对用户进行建模，建立精准的用户画像；3.使用统计学习方法和自然语言技术对内容数据进行建模，建立精准的内容画像。 ---我们对你的要求---1.熟练掌握机器学习基础知识，有推荐算法开发或自然语言处理、用户画像等方面的相关工作经验；2.有较强的工程架构和开发能力，能够实现支撑百万级用户、TB级用户行为数据的推荐系统或者算法；3.熟练使用至少一门编程语言：Scala/Java/Python/C++等，熟练使用Spark平台。4.熟悉SQL和NoSQL数据库，如Mysql／MongoDB／HBase等；5.具有用C端产品广告算法、推荐系统、反作弊系统等相关经验者优先；6.热爱电竞游戏者优先。---我们为你提供---1.年底双薪+无上限年终奖+7天带薪年假+定期体检；2.舒适电竞椅办公+周末双休拒绝996，身体才是革命的本钱；3.周三尖叫之夜，大家一起开黑、桌游、switch.. 4.每周各部门分享沙龙，培养T型人才；5.零食下午茶、无限量饮料必不可少；6.小黑屋电竞馆尽享员工优惠，同事也是最强队友..,游戏,50-150人,spark,北京
后端开发工程师-瞳门科技,https://www.lagou.com/jobs/7198502.html,海淀区,20k-30k,北京格灵深瞳信息技术有限公司,3-5年,本科,"扁平化管理,不定期团建,领导好","后端开发工程师职位描述：1）负责智慧商业，智慧金融等项目的系统后端建设2）开发和维护产品平台，参与基础架构设计等核心工作3）参与平台的方案制定，技术选型，落地实施等工作职位要求：1）计算机相关专业，本科及以上学历2）三年以上全职工作经验3）精通Java/Python/Golang等至少一种语言，微服务架构，具备扎实的编程基础和良好的变成习惯4）有良好的面向对象编程能力，掌握常用设计模式5)  掌握ElasticSearch6）掌握MySQL，Redis，Kafka，docker，kubernetes等7)  有hive, hbase, Hadoop, Spark经验者优先","企业服务,数据服务",150-500人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6997551.html,丰台区,12k-14k,北京先进数通信息技术股份公司成都分公司,3-5年,本科,五险一金；餐补；带薪年假；免费体检；,岗位职责：负责大数据开放式集群的搭建、管理、监控、优化以及相关应用的开发等工作。要求：1.计算机、金融、理工及相关专业本科毕业；2.熟悉HADOOP生态圈，熟悉关系型数据库3.熟练使用SQL、HIVEsql编写4.能够独立搭建HADOOP集群，熟悉HDFS、HIVE、HBASE、SPARK、MAPREDUCE、ZOOKEEPER、KAFKA5.熟悉Linux，能够编写SHELL、PYTHON脚本6.熟悉数据库性能及SQL优化,"软件开发,其他",500-2000人,spark,北京
高级数据仓库工程师,https://www.lagou.com/jobs/4860449.html,朝阳区,15k-30k,马上消费金融股份有限公司,3-5年,大专,"年底双薪,扁平化管理,技术大牛",职责描述：1. 构建面向全公司的数据产品及数据解决方案；2. 深入理解业务逻辑，基于海量数据完成数据仓库、集市的模型设计及开发工作；3. 通过技术手段为业务方提供快速、准确、灵活的数据服务化； 任职要求：1.学历要求：本科及以上学历，计算机相关专业；2.经验要求：5年以上数据仓库/大数据开发经验； 3.技能要求：（1）精通sql并能在hadoop环境下进行性能调优；（2）有丰富的Hadoop生态群系统开发经验，如hive/spark/kylin/kafka/hbase；(3)熟练使用一种以上编程语言，如python、java、scala；（4）深入理解数据仓库建模理论，有大型数据仓库实施经验；4.通用能力：（1）思路清晰，具备良好的沟通能力和快速解决问题的能力；（2）具备良好的学习能力与抗压能力；,"金融,移动互联网",2000人以上,spark,北京
资深大数据运维/运维架构师,https://www.lagou.com/jobs/7062598.html,海淀区,30k-40k,马上消费金融股份有限公司,5-10年,本科,算法大牛导师制、年底双薪,职责描述：1、 负责hadoop、hbase、storm、spark，flume，kafka等大数据平台的规划、部署、监控、系统优化等工作;2、处理各类异常和故障，确保系统平台的稳定运行;3、深入理解系统平台，为其持续优化提供建设性意见任职要求：1、学历要求:统招本科及以上学历，计算机以及相关专业，2、经验要求: 5年以上大数据运维经验3、技能要求:（1）精通Hadoop Mapreduce 运维；了解Hadoop、HDFS原理、shell/Python语言熟练（2）熟悉Hbase redis等nosql系统，了解Hbase实现原理 ，熟悉HIVE、zookeeper安装部署、spark安装维护调优、Kafka 安装维护、Scala安装维护、tomcat 的维护；（3）对分布式开源项目有技术兴趣，能跟踪Hadoop开源社区的发展方向，不断改进和优化集群（4）熟悉python\java语言的优先考虑、熟悉linux操作系统、优化操作4、通用要求：（1）性格坚韧，乐观向上，有抗压能力（2）能自我驱动，通过学习解决技术问题；善于沟通，勤于创新,"金融,移动互联网",2000人以上,spark,北京
智能营销算法专家/高级专家,https://www.lagou.com/jobs/6811907.html,朝阳区,28k-56k,支付宝（杭州）信息技术有限公司,3-5年,本科,互联网金融 大平台,蚂蚁金服数金数字化运营团队正在寻找充满激情和创业精神的人工智能专家，用科技的力量赋能财富、保险、借贷、信用的管理，链接人和服务、包括余额宝、相互宝、花呗、借呗、定期、基金和股票、健康险、寿险、财险等。蚂蚁金服作为金融科技的领导者，开创了互联网金融时代，正在使用数据和AI的力量，从资产销售平台到智能服务平台的转型，为普通用户提供普惠的服务，让百姓的人生更自由。你可以接触到最前沿的金融科技和人工智能技术，在百亿规模的数据，用科技的力量赋能金融，给世界带来更多微小而美好的改变。职位描述1、 计算机、软件工程、电子信息、自动化、数学、信息安全等相关专业背景，本科及以上学历；2、 对搜索、推荐、广告、金融工程、智能营销、智能助理、智能客服、大数据风控、生物核身、无人驾驶等；3、 务有三年以上实际工作经验，对NLP、CV、机器学习、深度学习、强化学习、最优化等领域有深入研究，曾在领域内**会议上发表论文；4、 熟悉常见的NLP、ML、DL开源软件，如Tensorflow、Caffe、Parameter Server等，能够快速实现最前沿的AI研究和想法；5、 扎实的技术基础，熟练掌握编程语言（C/C++、Java、Python等）、操作系统、数据结构、编译系统、数据库等。有大数据平台的处理经验，熟悉Hadoop、Spark等分布式计算和存储平台；6、 热衷于技术创新和突破，能够改变已有框架，运用各种资源解决具体问题、拿到业务结果，对于使用分布式、大数据和人工智能技术应用到财富管理领域、产生商业价值具有强烈的热情。,"金融,移动互联网",2000人以上,spark,北京
中级大数据开发工程师,https://www.lagou.com/jobs/6850958.html,朝阳区,17k-22k,北京亿和博嘉教育科技有限公司,3-5年,本科,互联网医疗行业 节日福利 有挑战,岗位职责：1、参与大数据平台的通用功能设计和开发、单元测试、文档编写等工作；2、负责大数据平台的数据整合、数据挖掘、画像推荐等方面的技术研究工作；3、使用SparkML、TensorFlow等常用机器学习库，实现并调优常用的机器学习算法；任职要求：1、精通Java或scala语言；2、本科以上学历，计算机、应用数学、统计学相关专业;3、熟悉大数据技术包括Hadoop、Spark、Flink、Kafka、Hive、ElasticSearch、HBase、kylin、Zookeeper等，并具备2年以上实际的大数据开发经验，对分布式数据处理和数据存储设计有很强的理解和优化能力，具备实时流数据处理的项目经验；4. 熟悉常用机器学习算法，包括但不限于决策树，线性回归，聚类，支持向量机，关联规则，线性规划等；5. 熟悉深度学习领域的基础理论，熟悉TensorFlow常用的神经网络模型如：DNN、CNN、LSTM等；6、熟悉Linux操作系统，熟练使用Shell或Python完成相关工作；7、优秀的分析问题和解决问题的能力，对解决具有挑战性的问题充满激情，良好的沟通能力和团队合作能力；,"教育,医疗丨健康",50-150人,spark,北京
大数据项目经理,https://www.lagou.com/jobs/5166237.html,海淀区,15k-30k,北京芯盾时代科技有限公司,3-5年,本科,"五险一金,健康体检,绩效奖金,发展空间",岗位职责：1、参与及负责大数据项目的实施落地。2、负责大数据产品相关文档编写及培训等工作。3、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长。4、协助客户参与各种环境业务系统的投产及技术支持。5、协调项目资源，对于项目实施进度的规划、控制、监督和管理。6、负责与公司内相关部门沟通协调，制定整体方案，推进项目执行。7、负责定期汇报项目状态，跟进项目问题风险。 任职要求：1、熟悉Linux操作系统常用命令。2、熟悉Tomcat、Weblogic基本操作及调优。3、熟悉MySQL、Oracle安装及相关配置，熟悉SQL基本操作。4、熟悉Hadoop、Redis、ElasticSearch、HBase、Spark、Storm、Kafka等大数据组件，对离线计算、内存计算和流式计算均有较为深刻理解。5、有一定的Java开发能力者优先。6、熟练掌握Power point、Excel、Project、Visio等工具。7、熟悉软件项目管理过程，具有较强的项目管理能力和沟通协调能力。8、具有较强的大局观，能够统筹跨团队项目，具有丰富的项目组织及人员管理经验，能够有效管理项目团队。9、具备较强的语言表达能力，能与客户顺畅沟通或产品介绍。10、具备较强的学习与动手能力，能够适应出差。,"移动互联网,信息安全",150-500人,spark,北京
机器学习算法工程师,https://www.lagou.com/jobs/7034832.html,海淀区,15k-25k,北京芯盾时代科技有限公司,3-5年,本科,五险一金、晋升空间、年终奖,1. 与客户沟通，了解业务逻辑与需求，分解出可优化的问题；2. 针对客户需要优化的核心问题，结合业务数据情况，使用符合场景的机器学习和数据挖掘技术，提出合理的解决方案；3. 应用场景包括但不限于：交易反欺诈，信贷反欺诈，营销反欺诈，金融产品推荐。岗位要求：1. 计算机、自动化控制、运筹学、统计等相关专业背景，硕士及以上学历；2. 熟悉Linux开发环境，具有扎实的编程基础（熟练使用C++/Python/Shell/Scala等），有大数据处理经验者优先（熟悉Hadoop或者Spark等分布式处理平台）；3. 扎实的数学、机器学习和数据挖掘基础，及三年以上的工作项目经历；4. 熟悉一个或多个常见的 ML/DL/NLP 开源工具库，如SparkML、Caffe、Tensorflow、Pytorch、Sklearn等，能够快速实现新的想法；5. 积极主动，优秀的分析问题和解决问题能力；6. 具有良好的沟通表达能力，具备较强的团队合作意识。加分项：1. 参与过与客户打交道的项目；2. 参加过机器学习与数据挖掘相关竞赛（KDD Cup，Kaggle等）；3. 有数据可视化项目经验，熟悉常用的可视化方法；4 在国内外**期刊或者会议上发表过人工智能相关领域研究成果；5 以**发明人身份申报国内或国际人工智能相关专利。,"移动互联网,信息安全",150-500人,spark,北京
Java开发工程师,https://www.lagou.com/jobs/6355463.html,石景山区,18k-30k,上海道勤软件有限公司,5-10年,本科,新技术、牛团队、自由多、空间大。,"岗位职责：1. 参与公司JMIS系统的产品及架构设计工作。2. 参与产品模块设计开发，业务逻辑开发等工作。3. 解决开发中遇到的技术问题。4. 参与制定和实施技术决策和技术方案，升级优化，性能优化，线上问题解决；任职要求：1、大专及以上学历，计算机、软件工程、物理或数学专业；2、5年以上互联网公司Java开发工作经验，代码编写规范，编程基础扎实，逻辑思维能力强；3、 精通Java语言，了解C、C++、PHP、Python、Golang等常见语言；4、对整个 J2EE 解决方案有深刻的理解及熟练的应用，精通Spring家族、SpringBoot，SpringCloud、Dubbo，Hibernate、Mybatis等开源框架；5、熟悉Hadoop，Hdfs,Spark，Storm，Flume，Sqoop,Kafka,kettle 等大数据处理平台使用经验;6、熟悉MySQL、SQLServer、Oracle等主流数据库中的一种；7、熟悉常见的数据结构、设计模式和算法；8、 有Data Warehouse，数据平台搭建经验优先考虑;9、熟练使用Git版本管理工具之一，具有良好的团队协作开发意识；10、具备良好的编码习惯、文档习惯、清晰的结构与注释；11、具有严谨的逻辑思维分析能力，惯于最优化的编程思想；12、熟悉Linux常用命令及开发环境，能直接在Linux环境下配置、开发。",企业服务,50-150人,spark,北京
高级大数据开发工程师,https://www.lagou.com/jobs/5933871.html,朝阳区,25k-50k,北京闲徕互娱网络科技有限公司,3-5年,本科,发展前景,"职位描述：1、负责公司数据平台的架构设计及实施；2、负责数据仓库的设计与实施；3、负责符合业务的数据工具的抽像及研发；4、负责大数据开发团队小组的工作协调和管理。任职条件1、熟练掌握大数据常用框架，如spark,hive,hbase等；2、熟练开发spark streaming流式分析作业及离线分析作业，熟练应用spark 2.x新特性，掌握flink开发；3、掌握scala开发语言，对底层实现有一定研究，熟练使用Python语言；4、有丰富的数据仓库设计及开发经验，从数据采集到数据报表的整个全链路有比较深刻的理解；5、具有良好的沟通能力和团队合作精神。",移动互联网,150-500人,spark,北京
java开发工程师,https://www.lagou.com/jobs/7217341.html,海淀区,7k-14k,北大医疗信息技术有限公司,1-3年,本科,"六险一金,餐补,通讯补助,年终奖",工作职责：        1、负责医疗数据集成和数据应用的需求设计、研发、维护工作        2、根据方案设计、产品设计进行产品模块化的开发工作        3、根据需要完成需求、设计、技术文档编写        4、配合团队完成文档、审计评审、代码走查互查、代码评审工作。5. 配合项目人员完成集成测试、系统测试和系统上线工作 任职要求：1. 本科及以上学历，计算机相关专业，2年以上Java项目开发经验2．熟练掌握Spring Boot、 SpringMVC等框架设计思想及使用3．熟练掌握HTML、XML、JSON、AJAX、JavaScript等前端技术，有ReactJS、vue经验优先；4．熟练掌握SVN、Git等版本管理工具5．熟练掌握SQL语言及至少一种主流关系数据库(Oracle、MySQL等)的使用及调优技术6．熟悉HTTP协议、Servlet规范，熟悉Tomcat、Jetty或Undertow等Java应用服务器的使用及相关配置7．了解Linux系统常用操作命令8．有医疗软件开发(HIS、LIS、PACS、集成平台、CDR等)背景者优先9.  有Kafka、HBase、Spark开发经验者优先；10. 有ElasticSearch或Solr开发经验者优先；11. 具有良好的沟通、团队协作能力，具备比较强的逻辑思维能力，良好的编码习惯和技术文档能力,医疗丨健康,500-2000人,spark,北京
高级爬虫研发工程师,https://www.lagou.com/jobs/7105612.html,海淀区,20k-40k,北京熵简科技有限公司,1-3年,本科,五险一金、包含一日三餐、团队年轻、团建,岗位职责：1) 探索并实践前沿爬虫技术；2) 负责分布式爬虫系统的维护、优化；3) 稳定、高效的解决高难度互联网数据采集；4) 挑战反爬虫，如果你不甘心被BAN的话；任职资格：我希望你是爬虫领域里的强者，而非平庸之辈。下面的条件有点多，全都会可能有点强人所难，但希望你能满足至少一半的条件。或者如果你对爬虫有激情，并且相信自己未来可以成为强者，那么这里有很多小伙伴跟你一起成长。别担心，薪资不是问题，快来加入我们吧。1) 热爱技术、对解决难题富有激情、学习能力强、求知欲望强，这样你才能赶上并超越对手；2) 具备强悍的编码能力，敏捷的思维能力，内功扎实；3) 精通python，而不仅仅是熟悉；4) 精通常见的、不常见的爬虫或反爬虫策略，解决过一个或多个具有高难度反爬虫的网站，如果没有，那么希望你能继续努力；5) 熟悉Windows、Linux、Mac等环境下的开发、运维，环境不应该影响你的发挥；6) 希望你开发过属于自己的爬虫框架，不要只用别人的，适合自己的才是最好的；7) 希望你曾经采集过千万量级以上的数据，这样你就能帮助我们优化数据库的使用；8) 希望你搞定过App逆向，免得面对加密参数时一筹莫展；9) 熟练使用Pyppeteer、破解过浏览器指纹、使用过各种自动化控制工具，解放自己双手；10) 使用过OpenCV、PIL、搞定过验证码最好了；11) 如果再用过Docker、K8S、Spark那就更好了；,"金融,数据服务",50-150人,spark,北京
Data engineer,https://www.lagou.com/jobs/7070443.html,朝阳区,30k-60k,北京神州祥龙投资管理有限公司,不限,本科,work life balance,"Do you want to be in the forefront of engineering big data solutions that takes Transportation models to the next generation? Do you have a solid analytical thinking, metrics driven decision making and want to solve problems with solutions that will meet the growing worldwide need? We are looking for top notch Data Engineers to be part of our world class Transportation Business Intelligence team. We are building real time analytical platforms using big data tools and AWS technologies like Hadoop, Spark, EMR, SNS, SQS, Lambda, Kinesis Firehose, DynamoDB Streams.The ideal candidate relishes working with large volumes of data, enjoys the challenge of highly complex technical contexts, and, above all else, is passionate about data and analytics. He/she is an expert with data modeling, ETL design and business intelligence tools and passionately partners with the business to identify strategic opportunities where improvements in data infrastructure creates out-sized business impact. He/she is a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoys working in a fast-paced and global team. It's a big ask, and we're excited to talk to those up to the challenge!     Good Engilish skill and can work with global team    0-7 years of experience performing quantitative analysis, preferably for an Internet with large, complex data sources.     Hands-on experience on Big data technologies and frameworks. Hive, Spark, Hadoop, SQL on Big Data, Redshift     Experience in near real time analytics     Experience with scripting languages i.e. Python, Perl, etc.     Experience with ETL, Data Modeling, and working with large-scale datasets. Extremely proficient in writing performant SQL working with large data volumes     Ability to manage competing priorities simultaneously and drive projects to completion.     Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering).     Experience with large scale data processing, data structure optimization and scalability of algorithms a plus","移动互联网,电商",2000人以上,spark,北京
c++服务端,https://www.lagou.com/jobs/7127550.html,朝阳区,30k-50k,高德软件有限公司,3-5年,本科,"阿里平台,年底双薪, 海量数据",1. 负责建立实时和离线大数据处理流程，结合算法模型进行处理流程整合2. 参与实时数据平台的开发建设，与实时数据引擎一起协同研发，满足业务方对于实时数据的业务需求3. 深入发掘和分析业务需求，进行业务模型抽象，通过技术、平台减低数据生产成本职位描述1. 计算机及计算机相关专业，三年以上服务端开发经验2. 熟悉linux平台，精通c++，熟悉python，具有良好的编程习惯和算法基础3. 熟悉一种或者多种大数据生态技术（Flume/Kafka/Hbase/Spark/Storm/Hadoop/Flink等），有大规模分布式系统开发等经验者优先4. 具备优秀的逻辑思维能力，对解决挑战性问题充满热情，善于解决问题和分析问题5. 有强烈的上进心和求知欲，善于学习新事物，有良好的团队合作精神，较强的沟通能力和学习能力,工具,2000人以上,spark,北京
Java高级软件工程师/专家/架构师,https://www.lagou.com/jobs/7181211.html,海淀区,20k-40k,浪淘金（北京）科技有限责任公司,5-10年,本科,六险一金 餐补交补 丰厚年终奖,岗位职责：1、分析及参与业务需求的迭代开发，提供系统架构设计方案并进行落地。2、负责对业务增长中遇到的技术瓶颈进行攻关，确保系统稳定性及业务高速增长。3、负责对现存及未来系统进行宏观的思考，规划完善形成统一的框架、平台、体系或组件。4、负责推荐系统及大数据分析系统的规划与演进。任职要求：1、精通相关语言的技术栈：Java、Go、Python，并主导设计过通用架构框架。2、扎实的编程技术基础，精通微服务、消息中间件、容器化等相关技术有相关系统设计经验。3、对数据结构、算法设计、系统架构设计等有较为深刻的理解，有大数据相关系统开经验如Hadoop、Spark、Flink等。4、有大型分布式、高并发、高负载、高可用性系统设计开发经验。5、具有较强的项目规划和决策能力，善于捕捉业务需求、架构设计中存在的问题并给出有效的解决措施和方法。,"移动互联网,社交",50-150人,spark,北京
大数据运维工程师,https://www.lagou.com/jobs/7178424.html,朝阳区,18k-23k,上海华钦信息科技股份有限公司,3-5年,本科,13薪 六险一金,"4年以上大数据运维项目经验，英语读写熟练，口语能简单的交流4年以上it运维经验，熟悉大数据运维，专门做大数据平台搭建运维熟悉ETL，informatica，airflow，kafka，这几个技术点都ok airflow，hadoop(hdfs hbase)，ETL informatic，spark，kafka。三年以上大数据平台运维经验，熟悉Ubuntu Centos Redhat等Linux操作系统熟悉Hadoop生态系统核心组件，HDFS/ Hbase, Spark, Hive, Presto 熟悉Kafka集群的搭建以及优化熟悉informatic工具的使用熟悉airflow的搭建英文可以作为工作语言ETL运维技能要求：岗位要求：1.计算机或者相关专业本科以上学历;2.具有4-8年以上it项目运维经验，思路清晰，有BI项目运维经验者优先;3.熟练操作ETL及数据库软件(oracle、sqlserver等)、熟练掌握SQL语句, 熟悉Linux系统;4.具有良好的沟通能力，能够承受工作压力;5.熟悉etl工具或者BI界面开发软件者优先， ；6. 熟悉informatics的使用，有生产环境接入经验","数据服务,金融",500-2000人,spark,北京
NLP算法工程师,https://www.lagou.com/jobs/6462282.html,朝阳区,20k-40k,上海淇毓信息科技有限公司,不限,本科,上市公司，包三餐，3-9个月年终奖,职位描述1、针对360金融所有核心业务，研究和开发以深度学习和自然语言处理（NLP）为核心的算法模型，设计和推动建设整个算法体系。2、负责智能催收、智能客服、智能质检等项目；研究开发各种对话机器人算法，包括语义理解、多轮对话、知识库挖掘等。3、研究开发金融舆情算法，从互联网海量数据中发现有价值的信息。包括事件抽取、事件发现与追踪、情感分析、实体识别等，应用于风险控制和量化投资等场景。4，沉淀算法平台，开发客服、舆情等人工智能产品，参与基础数据收集整理及特征工程建设。职位要求1、计算机，数学，统计学等相关专业硕士以上学历，3年以上NLP工作经验；在以下一个或多个领域经验：机器学习、深度学习、自然语言处理、对话机器人、舆情分析。2、优秀的算法和编程能力，熟悉搜索、排序、图等通用算法，精通C++或Python等。熟悉大规模数据处理平台Hadoop/Spark/ODPS等。熟悉主流深度学习工具TensorFlow/Caffe/MXNet/Theano等。3、具有很好的表达能力，很好的抗压能力和团队合作能力。4、热衷于技术创新，善于突破既有框架做出改变，善于运用有限资源针对具体问题拿到结果。对于把大数据和人工智能技术能够应用到实际业务场景产生商业价值具有强烈的热情。等项目经验者优先。,金融,500-2000人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6347339.html,朝阳区,30k-40k,上海淇毓信息科技有限公司,5-10年,本科,上市公司，免费三餐，0-9个月年终奖,职责描述：1.根据360金融业务和集团的海量数据，为风控、BI提供数据支持；2.对数据处理的需求场景进行抽象，形成自动化工具，提升工作效率；3.基于日常的需求场景，构建安全、高效、稳定的大数据平台，为业务提供更有效的数据支撑。任职要求：1.属性Linux操作系统，熟悉Shell编程语言；2.大数据处理经验丰富，熟悉hadoopmap/reduce编程；有Hbase、Spark、Storm的应用开发经验；3.熟悉其它分布式存储相关技术，包括HDFS，Hive、Redis、mongodb、Flume、Kafaka、Sqoop、Zookeeper、ElasticSearch等。具有以下经验者优先考虑：1.具有海量数据调优、数据倾斜调优经验者优先考虑；2.有大数据平台开发经验者优先考虑；3.具有SQL优化经验优先考虑；4.熟悉REDIS使用的优先考虑。,金融,500-2000人,spark,北京
大数据运维,https://www.lagou.com/jobs/7151858.html,朝阳区,16k-20k,天津卓朗科技发展有限公司,不限,本科,大数据产品，提升空间大,1、负责大数据平台部署、维护、管理、优化、规划等，包括但不限于Hadoop、Hdfs、HBase、Hive、Spark、Storm、Kafka等系统；2、保障大数据平台稳定性和可靠性；3、开发监控报警平台；4、建设自动化部署及运维工具；5、给业务提供技术支持及优化；任职要求：1、四年全日制统招本科学历，计算机相关专业，3年以上大数据运维经验；2、熟悉/精通linux操作系统；3、熟悉Hadoop、HBase、Kafka、Hive、Spark等组件的工作原理；4、熟悉hadoop/hbase/hive/spark/kafka/storm等大数据开源系统部署、升级、扩容、优化等5、熟练掌握java/python/shell/perl/php等至少一种开发语言；6、有CDH安装部署及运维经验；7、有相关运维管理平台或自动化部署系统开发经验；,"移动互联网,数据服务",500-2000人,spark,北京
零售行业大数据技术经理,https://www.lagou.com/jobs/6651545.html,海淀区,15k-30k,上海诺悦智能科技有限公司,5-10年,本科,五险一金 奖金 餐补 通讯补助等,"岗位职责：1.  负责零售行业大数据SAAS平台系统架构设计、搭建，应用域及微服务拆分；2.   负责各应用域开发技术选型、落实。3.  带领研发团队进行零售行业大数据产品的设计及开发；4、  负责开发工作细WBS拆分、排班、跟进以及开发质量管理。5.  配合产品经理、业务顾问、运营顾问完成需求分析、技术落地，对产品进行持续的优化和改进。 任职要求：1.   本科及以上学历， 5年以上大数据相关工作经验；2.   对大数据生态的Hadoop，SparkStreaming，Kafka，Flume，Flink等相关组件有深如理解；3.   深入了解分布式系统、大数据平台、消息队列等高可用高弹性架构;4.   对HDFS/Yarn/HBase/Hive/Spark相关组件的性能优化和补丁跟踪等有实际经验5.   精通Scala、java语言，有Scala实际编程经验，精通Linux 操作系统，6.   精通Spring Cloud 框架，有微服务设计、开发经验。7.   对阿里云、腾讯云等第三方大数据平台有过研究及使用者优先；8.   有零售行业大数据开发经验者优先； 9.   对技术有热情,有不错的数据思维和敏感度,对深度学习,机器学习有一定的了解优先；",数据服务,50-150人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6647090.html,海淀区,12k-24k,上海诺悦智能科技有限公司,1-3年,本科,五险一金 奖金 餐补 通讯补助等,任职要求：1.   精通Scala、java语言，有Scala实际编程经验2.   深入了解分布式系统、大数据平台、消息队列等高可用高弹性架构;3.   对HDFS/Yarn/HBase/Hive/Spark相关组件的性能优化和补丁跟踪等有实际经验4.   在Hadoop、Spark、Storm、Flink等开源社区有过贡献最佳5.   熟悉银行业务，有过银行数据处理、分析经验者优先6.   良好的英语读写能力7.   本科及以上学历，2年以上相关工作经验；,数据服务,50-150人,spark,北京
"Sr Software Eng, Data",https://www.lagou.com/jobs/6574445.html,朝阳区,32k-43k,北京万戈尔科技有限公司,5-10年,本科,美资外企，国际化团队，福利待遇优,"We are building a world-class engineering team with diversified skills and backgrounds. As the leader in in-app video advertising, we are taking on a challenge that has never been solved: how to fundamentally change the mobile advertising industry so that ads make sense for users, application developers, and advertisers.Responsibilities:As a Data Engineer, you should have a passion for developing a robust, real-time data pipeline. You love building next-generation software solutions and implementing large scale data stores that maximize performance and reliability for our use cases. In addition, you thrive in an environment where you're given the freedom to either build or hack open source tools to help other engineers access your data more efficiently.Requirements:
 8+ years of software engineering experience
 Third degree black belt in OO programming paradigm and implementation using Scala, Java, Python or similar language
 In-depth understanding of the inner workings of one or more of the big data technologies such as Hadoop, Kafka, Spark etc.
 Experience with NoSQL databases such as HBase, Cassandra, MongoDB, etc.
 Experience with distributed data warehouse Redshift, GreenPlum or others
 Experience building streaming or batch processing data pipeline
 Knowledge of various ETL techniques and frameworks, experience integrating data from multiple data sources
 Solid understanding of distributed system concept
 Possess an excellent understanding of scheduling and workflow frameworks and principles
 Robust development abilities and a strong predilection for automation
 Bachelor’s degree or above in Computer Science / related field of study
 Experience building hybrid infrastructure is a plus
 Experience with Golang is a plus
 Ability to read and write English fluently","移动互联网,广告营销",15-50人,spark,北京
高级研发工程师,https://www.lagou.com/jobs/7216857.html,朝阳区,15k-25k,广州欢网科技有限责任公司,5-10年,本科,弹性工作 餐补 五险一金 双休 年终奖,"岗位职责：1.技术选型及架构设计；2.系统设计和主要代码的编写；3.负责技术攻坚及疑难问题解决；4.对外技术沟通和培训；5.技术文档编写。岗位要求： 1.计算机相关专业本科学历；2.具有5年以上工作经验；3.良好的Java技术功底，精通设计模式及常用算法；4.熟悉mysql、MongoDB等常用数据库并具有较强的数据库设计能力；5.精通springBoot、springMvc等主流开发框架；6.掌握springCloud微服务架构；7.掌握容器相关技术,了解k8s和rancher；8.熟悉大数据相关知识：hadoop,hive,spark,clickhouse,kafka，ELK；9.有应用商店、CMS系统、广告系统开发经验优先；10.具备良好的沟通和协调能力。",硬件,150-500人,spark,北京
PHP开发工程师,https://www.lagou.com/jobs/6929884.html,朝阳区,15k-30k,北京世相科技文化有限公司,3-5年,本科,成长空间、成就感、不错的收入,岗位职责：1、参与公司在线教育产品核心研发工作；2、参与技术方案和系统设计评审，把握复杂系统的设计，确保系统的架构质量；3、基于产品和业务需求，构建各类用户标签的算法策略，支持产品智能化业务。任职要求：1、计算机或相关专业本科以上学历 （硕士加分）；2、具备至少1-3年的PHP项目开发经验（具备Python开发经验加分），能独立研发，参与过较大型WEB系统设计；3、具备较强的数据库分析和设计能力，熟悉MySQL、Redis、Mongodb、Hbase，使用过消息队列；4、熟悉常用算法，有较强的抽象设计能力，熟练掌握应用各类设计模式；5、良好的代码习惯，思维敏捷，能够分析出问题的本质和关键点，从长远发展上给出最优解；6、良好的沟通能力与学习能力，对工作热情、认真、负责心强，及时响应线上问题；7、熟悉yaf、swoole框架；8、加分项，了解Hadoop/Hive/HBase/Spark/Storm等相关技术栈。,文娱丨内容,150-500人,spark,北京
高级推荐算法工程师,https://www.lagou.com/jobs/7206507.html,海淀区,25k-45k,北京金山办公软件股份有限公司,3-5年,本科,"互联网,发展空间大,薪资待遇优","工作职责：1.负责用户推荐架构、算法和基础服务的研发和优化2.搭建大规模推荐系统和机器学习模型，提供高效可靠的线上服务；4.参与特征工程、排序学习等模型和算法的持续优化和研究，持续提升产品体验和商业价值。      职位要求：    1. 具备很强的工程及编码能力，能独立实现和调优算法，熟悉Linux开发环境，熟练掌握Python, JAVA2. 两年以上数据挖掘与机器学习应用经验，在推荐/广告/搜索之一的领域有比较丰富的实战经验    3. 对常用机器学习算法有较好的理解及实践经验，有深度学习经验优先4. 熟悉Hadoop、Spark等大数据处理技术优先；  5. 沟通能力强，具有优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激情，有较强的抗压能力",移动互联网,2000人以上,spark,北京
机器学习高级工程师,https://www.lagou.com/jobs/7084657.html,海淀区,20k-40k,北京深维智信科技有限公司,3-5年,硕士,**投资机构投资，全球**科学家跟投,"工作职责：1. 研究机器学习领域的前沿技术,并用于实际问题的解决和优化2. 负责机器学习的算法和模型的开发，尤其是深度学习领域3. 研发NLP、机器学习、深度学习等算法，应用于公司2B的业务场景岗位要求：1. 计算机、自动化、统计学、数学等相关专业本科及以上学历, 3年以上工作经验2. 熟悉常用机器学习算法，尤其是深度学习相关领域，对NLP、模式识别，概率统计等算法原理及应用，有扎实的基础，深入的理解和浓厚的兴趣，在相关期刊和会议上发表过论文的优先考虑3. 精通C/C++、Java、Python、Golang等至少一门编程语言，有较强动手能力，精通常用的算法和数据结构4. 了解目前常见的机器学习或者深度学习框架中的一个或者多个：Spark，XGBoost，Pytorch，Tensorflow等5. 乐于动手，有良好的逻辑思维能力和数据敏感度，能够熟练阅读英文论文并且予以实践和改进，具有优秀的新技术研究和实现能力",企业服务,15-50人,spark,北京
运维工程师,https://www.lagou.com/jobs/7066921.html,朝阳区,15k-30k,深圳迪巨智能科技有限公司,不限,不限,福利待遇、职业拓展、新技术机遇,职位描述：1. 提供公有云、私有云及混合云解决方案、系统部署、运维；2. 负责网络及服务器的网络设置、维护和优化、系统的安全监控、数据备份、系统性能管理和优化、网络性能管理和优化；3. 负责公司内部kubernete集群的管理和维护；4. 负责公司内部mysql、mongodb、neo4j、redis、kafka等数据服务的管理和维护；5. 参与自动化运维系统建设，包括常见组件的运维效率提升、流程优化等；6. 负责公司产品的运维工作，相关系统部署，协助开发团队故障处理等；7. 探索、研究新的运维技术方向。任职要求：1. 计算机本科及以上学历，三年以上运维工作经验；2. 熟悉主流windows、linux系统管理、网络管理及相关应用的跨平台部署；3. 熟悉主流云平台部署、运维，熟悉nginx、jenkins、apache、tomcat等web应用的使用与优化；4. 熟悉docker镜像构建、kubernete集群的管理运维操作，可熟练编写shell或python等脚本5. 熟悉mysql、mongodb、neo4j、redis数据服务的运维和优化，有大数据相关工具栈如spark、flink等的部署、运维和优化者优先；6. 熟练掌握自动化部署和运维工具，对智能化运营方向有自己的见解；7. 有较好的学习、沟通表达能力和一定的抗压能力，有良好的团队合作能力。关于我们：目前，以知识图谱为代表的大数据知识工程已然成为实现各行业智能升级的重要基础。行业知识图谱的自动化构建与支撑应用探索充满挑战与机遇，我们旨在通过研发“人机交互式知识图谱构建系统”把数据标注任务纳入行业知识应用场景中，在辅助用户进行行业资讯查阅、知识管理、知识问答等场景中实现灵活高效的知识输入与输出，进而完成“机器模型知识初步抽取-人工应用场景知识标注-机器自学习模型提升”的行业知识图谱构建闭环，在降低人工构建知识图谱高成本的同时，又可为用户提供行业知识服务。团队初期成员来自中科院自动化所，有着丰富的网络舆情、行业知识情报采集与挖掘、文本数据处理等项目经验，围绕知识图谱技术栈的关键环节如知识建模、数据采集、知识获取、知识融合、知识存储与知识应用等开展了积极探索与研究，积累了一定的技术基础与实战经验。期待有共同志向者加入团队，研发行业知识图谱构建与应用关键技术，推动知识图谱技术落地，助力行业智能升级。,"硬件,人工智能",15-50人,spark,北京
大数据运维工程师,https://www.lagou.com/jobs/6957673.html,朝阳区,20k-35k,北京快看世界信息技术有限公司,3-5年,本科,零食水果 免费晚餐 发展空间大,岗位职责1. 负责快看大数据基础平台和组件的运维和优化工作2. 保障线上服务的高可用，在此基础上进行服务的架构优化、业务优化3. 深入业务场景，解决业务层的存储、计算和分析需求4. 跟进大数据新技术的发展，持续提升大数据服务的效率任职要求 1. 熟练掌握Python、Shell、Golang等主流开发语言中的一种，熟悉Java开发优先2. 对大数据生态圈技术栈比较了解，包括但不限于如：Hadoop、HBase、Spark、Flink、ZooKeeper和Kafka等3. 熟悉Linux系统，计算机基础扎实，包括但不限于操作系统/网络/数据结构/算法4. 良好的自我驱动和学习能力,文娱丨内容,500-2000人,spark,北京
推荐算法工程师,https://www.lagou.com/jobs/5279056.html,朝阳区,25k-50k,北京快看世界信息技术有限公司,3-5年,本科,"双休,七险一金,免费晚餐,重点业务",工作职责： 1.负责平台亿级用户推荐召回算法的调研、开发和应用； 2.负责平台亿级用户画像、作品（帖子）画像涉及到的机器学习算法的调研、开发和应用； 任职要求：1.本科及以上学历，计算机或相关专业，计算机专业知识扎实，熟悉常用数据结构和算法，深入理解常用机器学习算法；2.熟练使用Java/Python语言，有过3年及以上的推荐算法开发经验；3.熟练使用大数据开发平台进行离线ETL数据处理；4.熟练使用Spark ML、Python机器学习库；5.工作态度积极，热爱团队合作。,文娱丨内容,500-2000人,spark,北京
数据仓库工程师,https://www.lagou.com/jobs/6611895.html,丰台区,15k-30k,北京高灵智腾信息科技有限公司,3-5年,本科,集团化运作、年终奖金、大牛带队、专家坐镇,岗位职责：1、负责公司大数据方向的整体架构设计，结合公司实际业务情况进行技术选型2、参与数据能力中心的设计、架构及关键模块的开发3、负责架构优化及系统关键模块的设计开发4、负责公司数据产品研发任职要求：1、具有扎实的大数据和数据仓库功底，2、对Hadoop大数据体系有深入认识，对Hadoop、Hive、HBase、Spark、Storm、 Kafka、ES等有实际应用研发经验3、掌握常规ETL采集方法，熟练使用KETTLE 等开源ETL产品4、对医疗领域有项目经验者优先考虑,"医疗丨健康,移动互联网",50-150人,spark,北京
算法工程师（风控）,https://www.lagou.com/jobs/7112657.html,朝阳区,20k-35k,无线生活（北京）信息技术有限公司,3-5年,本科,竞争力薪资，完善福利，靠谱儿团队,【工作职责】1、负责微店风控核心算法模型开发、迭代；2、利用最前沿的机器学习、数据挖掘、深度学习、图挖掘算法对海量用户行为数据以及商品等文本、图片数据进行分析与挖掘，提升系统风险感知能力；3、负责建立算法体系架构、利用大数据实时计算引擎进行毫秒级风险对抗。【职位要求】1、具备强悍的编程能力，精通Java/C++/Python/Scala语言中至少一种，对常见数据结构和算法原理有较为深入的理解；2、熟练掌握数据挖掘、机器学习、深度学习基础理论与方法，有一定相关研究或项目经验；3、有风险挖掘相关经验，如电商风控、内容风险、反作弊等方向模型优化或在线对抗经验者优先；4、熟悉Linux平台编程环境，具备Hadoop/Spark/Flink/Hive/HBase等实际工作经验；5、有良好的逻辑思维能力和分析问题能力，对数据敏感，能够发现关键数据，抓住核心问题，对解决具有挑战性的问题充满激情；6、注重团队协作，有优秀的沟通能力和极强的责任心。,电商,500-2000人,spark,北京
Java开发工程师,https://www.lagou.com/jobs/7079470.html,海淀区,12k-20k,北京启明星辰信息安全技术有限公司,3-5年,不限,七险一金 上市公司 网络安全领航者,"岗位职责：1、负责部门后台核心业务研发，对流量日志和安全设备日志进行处理分析，并能够在高流量下保持系统稳定性，对系统性能持续优化；2、负责数据处理结果后端展示接口开发；3、负责产品概要设计文档、详细设计文档的编写。岗位技能：1、本科及以上学历，计算机、通信等相关专业；2、能流利阅读英文文档；3、有扎实的Java基础知识(熟悉io、多线程、集合等基础框架，熟悉分布式、缓存、消息队列，熟悉JVM内存模型），熟悉Python、Go、Scala并有相关实践开发经验优先；4、熟悉计算机网络知识、http/tcp协议，了解网络安全相关知识，熟悉安全漏洞、网络攻击方式优先；5、熟悉 Linux 平台常用操作命令及服务器相关知识, 有编写脚本能力，能在Linux系统上熟练的操作和部署软件；6、熟练运用Hdfs、Kafka、Zookeeper、spark等开源大数据组件，并了解其原理，熟练使用docker；7、熟练掌握mysql、Redis存储技术，了解其原理，并能够对其查询、存储进行调优；8、熟练使用 Spring boot等Web框架, 了解其原理，熟悉微服务架构；9、有敏捷开发经验优先职位。",信息安全,500-2000人,spark,北京
数据开发专家（实时计算方向）,https://www.lagou.com/jobs/7190880.html,东城区,30k-45k,北京轻松筹网络科技有限公司,5-10年,本科,福利待遇 发展前景,岗位职责：1.   负责流计算平台的开发与优化工作2.   负责流式计算平台开发结合业务的应用、处理实时数据、实时应用场景的开发3.   负责实时计算系统的运维，保证系统的高可用性和稳定性4.   负责设计，开发，优化数据接入、数据存储、数据计算服务框架5.   负责对业务的数据接口开发6.   负责优化分布式框架，解决大并发下的各种问题 任职要求： 1.   5年以上相关工作经验，本科或以上学历；2.   具备扎实的Java语言基础;3.   熟悉并行计算或者分布式计算原理，熟悉高并发、高稳定性、可线性扩展、海量数据的系统特点和技术方案；4.   有Spark/Storm等数据平台的开发和使用经验；5.   对性能调优，算法效率和分布式计算的资源管理策略有较深的理解；6.   熟悉Spring、Spring MVC、ibatis等使用框架，深入原理者优先；7.   熟悉ZooKeeper/kafka/Hadoop/HBase/Flume/Redis等平台者优先；8.   具备良好的沟通能力和自我学习能力。,"移动互联网,金融",500-2000人,spark,北京
售前工程师,https://www.lagou.com/jobs/6878622.html,朝阳区,15k-30k,北京宝兰德软件股份有限公司,5-10年,大专,发展空间大 上市公司 六险一金 带薪年假,"工作内容：1.提供公司相关产品和技术的售前技术咨询；2.为客户和合作伙伴介绍、宣讲、演示产品和技术解决方案;3.在客户端进行产品的POC测试；4.与销售配合，推广公司产品和方案。配合销售完成产品、解决方案投标工作；资格要求：1.统招学历，3年以上售前经验;2.良好的沟通能力和责任心；3.有技术背景优先；技能要求：1.具备良好的售前能力，有与用户进行技术交流、技术方案宣讲、应用系统演示等经验；2.熟悉常见技术方案编写、标书的准备、讲解及用户答疑等工作；3.具备良好的沟通技巧；4.熟悉云计算、大数据和应用性能管理等常见技术，对云计算环境下的智能运维有较深的理解； 有下述技能优先：1.有大型系统的运维管理经验；2.熟悉JavaEE常见框架和架构，Unix基本管理和操作，java常见问题分析和优化；3.对云计算的产品和技术有比较深入的理解，例如OpenStack, VMware, CloudFoundry, docker,, Mesos, APM等。4.对大数据产品和技术有一定了解，如数据交换、数据集成、大数据hadoop、cdh、spark等、BI、数据可视化；5.熟悉某种中间件产品或技术，例如Apache, Tomcat, JBOSS, Weblogic, Websphere, VisiBroker, Tuxedo, CICS 等。",企业服务,150-500人,spark,北京
BI工程师,https://www.lagou.com/jobs/6202384.html,朝阳区,15k-25k,北京兰亭高创科技有限公司,1-3年,本科,带薪年假、周末双休、免费班车、上市公司,岗位职责：1. 技术大数据平台完成各类统计和开发任务2. 完成日常数据分析查询需求3. 数据仓库的设计、开发、维护任职要求：Must have1. 大学本科及以上学历，硕士优先，计算机、软件工程相关专业优先；2. 1-3年BI相关项目经验3. 熟悉java语言开发，熟悉spring开发框架，熟悉MR执行流程，能够编写MapReduce程序4. 熟悉Hadoop、Hive相关大数据技术5. 熟练使用SQL，熟悉数据库原理，有日志处理经验的优先考虑6. 熟悉Linux操作系统，熟练使用shell脚本Prefer to have1.有日志处理经验者优先；2.有大数据处理经验者优先，熟悉spark技术者优先；综合类要求：1、具有良好的沟通能力和协调能力，团队合作能力 2、具有较强的执行力、学习能力,"电商,消费生活",500-2000人,spark,北京
投放算法,https://www.lagou.com/jobs/6369976.html,朝阳区,30k-50k,北京兰亭高创科技有限公司,5-10年,本科,美股上市、带薪年假、团队nice,岗位职责：1、负责Google Adwords/Facebook等平台广告投放相关算法，优化账户结构以及出价，提升广告效果；2、基于海量数据，进行大规模机器学习相关算法的架构设计和优化改进，以持续提升核心业务指标；3、负责机器学习前沿技术的研究和开发；4、 参与团队技术决策，技术人员培养，技术氛围建设等工作；5、上级交办的其他事项。 任职要求：1、计算机或相关专业硕士以上学历；5年以上机器学习研究或开发经验；2、熟练使用java/C++/Python等中的一门语言，熟练使用数据结构常用算法，有较强的算法设计和实现能力；3、有分布式平台海量数据处理经验，熟悉Hadoop、Hive、Spark等数据处理平台;4、较强的技术攻关能力，能够跟进领域内最新技术研究成果并结合应用场景快速实验和调优；5、对数据敏感，有优秀的分析及解决问题的能力，责任心强有良好的技术落地能力；6、优秀的分析和解决问题的能力，对挑战性问题充满激情；良好的团队合作精神，较强的沟通能力；,"电商,消费生活",500-2000人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6976796.html,海淀区,13k-20k,北京世纪高通科技有限公司,1-3年,硕士,一年多薪 免费班车 公司出游,岗位职责：1.负责位置大数据应用系统的开发；2.负责海量位置数据的接入、清洗、处理和发布；3.负责位置数据处理逻辑与处理性能的优化；4.负责现有位置大数据工程的维护和迭代；岗位要求：1.有较强的英语或德语写作和沟通能力；2.有丰富的Scala和/或Java实践开发经验；3.有批处理（如Apache Spark）和流处理（如Apache Flink、Kafka）实战经验；4.能够熟练使用IntelliJ/Eclipse、Maven、Jenkins、Git、Jira、Confluence或类似工具的经验；5.了解AWS批/流处理以及监控组件；6.了解敏捷方法，如SCRUM、LESS等；7.善于团队合作并有较强的解决问题和决策能力；8.有地理空间分析以及空间数据使用经验者优先,"移动互联网,其他",150-500人,spark,北京
高级数据分析建模工程师,https://www.lagou.com/jobs/7143695.html,西城区,20k-40k,联洋国融（北京）科技有限公司,5-10年,硕士,**数据分析团队，权威机构数据来源,岗位职责：1. 运用Python、R、SQL等工具，根据产品需求进行大数据模型设计与开发；2. 基于模型部署、测试、实施及模型应用效果监控工作，进行模型调优与维护；3. 撰写大数据建模项目可行性方案、建模分析报告；4. 根据实际的建模业务，负责提出并反馈流程、策略、人员等问题。任职要求：1、应用数学、统计、计算机及相关专业国内外知名院校硕士以上学历；2、具有数学建模或大数据建模实际项目经验，熟悉数学建模与优化算法设计，掌握逻辑回归、决策树、神经网络等机器学习算法；3、熟练运用Python、R、Matlab等常用数学建模与分析工具；4、熟悉数据库结构，熟练运用SQL等数据库语言，熟悉数据清洗、预处理与特征工程，熟悉Hadoop生态、Spark结构，Java语言；5、具有扎实的统计分析功底，快速精准的分析能力，能够处理大量数据进行建模；6、具有良好的业务问题分析，模型抽象能力和创新能力；7、具备较强的执行力和责任心，具备优秀的学习能力、沟通协调能力、逻辑思维能力和解决问题能力，有团队合作精神。,数据服务,50-150人,spark,北京
大数据开发-实习生,https://www.lagou.com/jobs/5827709.html,西城区,3k-5k,联洋国融（北京）科技有限公司,1年以下,本科,前沿行业，最新技术，团队活跃,"岗位描述1)  参与大数据基础平台的研发工作；2)  对现有系统的进行架构深入分析及系统优化,进一步提升系统的性能及数据处理能力；3)  硕士及以上在读,能保证每周5天出勤,至少6个月的实习期；4)  计算机相关专业,基础扎实,编码能力强,对新技术有学习热情5)  熟练掌握Java,熟悉数据结构和算法；6)  有大数据相关工具/框架经验者优先, Hadoop、Hve, Storm、Spark、kafka、hb； 待遇1）  日薪200-300元,按照实际出勤天数计算工资；2）  对于优秀的硕士研究生,可以推荐合作单位攻读博士或留任工作;",数据服务,50-150人,spark,北京
技术-架构师,https://www.lagou.com/jobs/7192552.html,海淀区,30k-40k,北京慧赢国际教育科技发展有限公司,5-10年,本科,双休 五险一金、车补、房补、法定假日,岗位职责1、负责互联网系统整体架构的规划设计，完成功能分析、整体架构，使系统体系化并具有技术前瞻性；2、负责相关开发方法和标准的建立和优化工作（不公布），主导重大项目的架构设计和核心模块设计；3、深入理解业务架构和需求，解决各类潜在系统技术风险；4、解决项目中的系统架构问题和技术难题，负责关键技术难点的攻关和预研，对基础架构团队进行技术指导和培训；5、与产品负责人持续优化完善业务架构和技术架构；6、协助推进前沿技术的应用，制定可行的、富有成效的、前沿的架构方案，并落地实现；7、引导开发团队，使用架构设计和系统规划，提升研发人员的技术视野和架构设计能力。任职资格1、本科及以上学历，计算机相关专业毕业者优先；2、8年以上开发工作经验，3年以上知名互联网公司架构师经验，对互联网、大数据应用有技术前瞻性，具有丰富的技术架构设计经验；3、熟练掌握系统优化，性能优化；4、精通MySQL、Oracle等数据库设计、开发优化，熟悉大并发系统架构与软件架构；5、对系统性能、安全性、可靠性有充分认识和实际经验，精通常见的脚本漏洞及避免方法；6、熟悉如何提高系统程序的运行效率，保证程序的安全和稳定运行，并能及时预防及应对各种安全事件；7、熟悉Hadoop、Spark等大数据技术，了解常用数据挖掘与数据分析算法。,教育,50-150人,spark,北京
互联网运维工程师,https://www.lagou.com/jobs/6573321.html,海淀区,15k-25k,北京慧赢国际教育科技发展有限公司,3-5年,本科,底薪高于同行业20%~30%,"岗位职责1、遵守公司及部门的业务流程、制度与规范，参与改进与优化业务流程、制度与规范；2、负责根据公司和部门工作内容和时间要求，制定工作计划，上级审核通过后遵照执行；3、记录相关工作会议的会议纪要，使用问题表跟踪并解决问题，根据工作输出和检查结果完成工作绩效表格；4、负责公司业务系统环境和办公环境的服务器及网络环境的部署、维护、更新、优化、数据和系统备份，以及故障处理，确保服务器高效、稳定的运行；5、负责支持高并发（1000+QPS）和百亿条PB级数据的服务器和网络系统部署方案，完成硬件网络和软件系统选型(测试)、评审、部署、上线及优化工作；6、负责制定应用系统部署方案及上线/更新计划，评审通过后执行，完成后提交上线报告；7、负责搭建、使用并根据需要定制自动化运维和管理工具，建立数据备份、系统/应用/数据层监控、应急响应和安全控制等流程规范与制度；8、负责搭建测试系统并完成系统级测试、系统参数配置工作；9、配合系统架构师、软件工程师，参与压力测试、功能调试并协助解决应用系统Bug和性能问题； 10、参与系统架构设计，负责优化运维基础架构，完善运维流程；11、参与IDC、服务器供应商及云平台服务商对接，负责服务器及网络测试、评估、部署(配置)、运维，以及第三方云平台功能配置与维护；12、参与运维工程师招聘、业务培训和技能培训，公司和部门的企业文化建设与培训；13、完成公司与部门交办的其他任务。任职资格1、5年以上运维经验，熟悉Linux系统及常见服务的安装配置，熟悉常见的负载均衡实现方案并有实施经验；2、熟悉Linux系统centos、熟练使用Nginx，Apache，Tomcat，Memcached，Mysql，Redis，DNS，LVS等技术常用服务的安装、配置、维护和优化；3、熟悉Hadoop、HBase、Storm、Spark系统的安装、配置与维护，熟悉华为或思科网络交换机的配置和使用；4、精通和灵活运用shell/perl/php/python/go中的1种以上的脚本语言，能够熟练排查运维过程中出现的服务故障、系统故障、网络故障，具备自动化运维的经验，熟练使用各类开源监控系统(nagios,cacti,zabbix,puppet)；5、了解数据安全、网络安全、系统安全，及相关预防措施，了解docker等容器配置、部署维护，熟悉IDC机房，华为或阿里等云服务商提供的相关服务项目经验，大型并发系统运维经验优先；6、大数据采集、处理系统Hadoop、MongoDB、Storm、Spark等实际运行系统运维经验优先，具有大数据、人工智能、知识图谱、自然语言经验者优先。",教育,50-150人,spark,北京
大数据测试工程师,https://www.lagou.com/jobs/7070743.html,朝阳区,10k-14k,上海微创软件股份有限公司,3-5年,本科,六险一金，一对一带教，车联网,"项目介绍：亿咖通公司专注于汽车智能化与网联化技术,提供智能数字座舱、智能驾驶系统以及智能联网生态平台，旨在围绕汽车与生活在互联网与物联网领域打造最安全智能的移动产品。Responsibilities:1、负责大数据平台数据采集，数据加工，ETL，数据质量等测试工作，独立设计和执行测试用例，进行缺陷跟踪、测试报告分析等； 2、独立搭建测试环境、包含但不限于常用容器部署(Tomcat、jetty)、数据库搭建(Mysql、Oracle、Hive)、异常日志及缺陷日志跟踪的脚本开发等工作；Requirements:1. 本科及以上学历，至少1年以上大数据项目测试经验，熟知大数据类型项目常用的质量控制手段；熟练掌握软件测试基本理论和工程方法，能够独立开展单个业务的测试验证2. 熟悉数据仓库，数据建模，数据分析的相关技术；有sql，Java， python等语言能力3. 熟悉常用的分布式大数据计算平台，如Spark, Hadoop等4. 熟悉性能测试的基本方法，灵活运用常用的性能测试工具，如LoadRunner、JMeter等；5. 具备较强的分析能力和定位问题的能力，快速学习能力强，具有良好的沟通能力，细心负责，有团队精神； 6. 大数据分析师，大数据开发有意向往大数据测试发展的亦可。","企业服务,移动互联网",2000人以上,spark,北京
Django讲师,https://www.lagou.com/jobs/7034200.html,海淀区,15k-25k,北京八维研修学院,3-5年,不限,"稳定,成长,成就感,领导nic",岗位职责：1.了解行业最新技术及行业市场，在线课程体系及时的迭代、优化，保持竞争力；2.在线课程的分析研究，配套教学资源开发、视频录制、直播等；3.项目案例的设计，开发、录制系列实用、热门的项目课程；4.课程的教师培训，团队管理；5.研发更新相应的切片/VIP课程；6.参与公开课的直播等工作，配合课程的推广。任职要求：1.三年以上Python一线软件开发工作经验；2.计算机及软件工程相关专业本科或以上毕业；3.精通Python全栈开发，精通Django等Web框架；4.熟悉Python Linux运维开发；5.有Python网络爬虫相关开发经验优先；6.有Python数据分析、机器学习，Spark ML、TensorFlow相关经验的优先。,教育,2000人以上,spark,北京
人工智能项目经理,https://www.lagou.com/jobs/4854901.html,海淀区,25k-40k,北京八维研修学院,3-5年,不限,"五险一金,稳定平台,技术提升",职责描述：1、实施人工智能（机器学习算法、深度学习算法）专业课程授课；  2、参与课程研发，课程体系完善；  3、参与人工智能相关软件的开发；  4、负责学生授课、答疑、辅导以及试卷批改工作。5、通过相关技术和项目经验指导，提升毕业生的技术水平和项目经验，达到就业目的。 任职要求：1、本科及以上学历，计算机、数学、统计学等相关专业；2、5年以上人工智能、大数据相关工作经验，拥有大中型实际项目经验者优先；3、要求熟练掌握python、java、scala任意一种编程语言；4、熟悉主流的数据挖掘算法，如逻辑回归、决策树、神经网络、随机森林等机器学习算法5、了解Hadoop生态圈、Spark生态圈相关大数据技术；,教育,2000人以上,spark,北京
高级推荐算法工程师,https://www.lagou.com/jobs/6753334.html,海淀区,15k-30k,北京金山办公软件股份有限公司,3-5年,本科,带薪年假，各种团建，六险一金,"工作职责：1.负责稻壳，会员增值功能等推荐产品算法设计工作.岗位要求:1.计算机或相关专业本科以上学历，三年以上互联网工作经验；2.熟悉机器学习，数据挖掘常用方法及流程，并有相关项目经验；  3.精通推荐算法或深度学习优先，包括：用户画像，离线召回，点击预估，Deep learning。  4.有海量数据处理和并行计算开发经验,熟悉Hadoop、Storm、Spark等技术者优先；  具备良好的团队合作和沟通能力。",移动互联网,2000人以上,spark,北京
高级测试开发工程师,https://www.lagou.com/jobs/7207641.html,朝阳区,20k-40k,北京沃东天骏信息技术有限公司,3-5年,硕士,京东大数据平台，技术发展前景好,职责描述：1.负责数据产品相关测试工作，包括web端测试、APP端测试、后端测试、数据测试以及性能测试等，并且能够在发现问题的同时帮助研发快速定位问题；2.结合公司内部业务需求开发自动化测试工具，构建持续集成环境、提高测试效率；任职要求：1.本科以上学历，2年以上相关互联网测试开发经验，精通测试用例设计，熟练掌握不同的测试方法；2.熟悉Linux操作系统，熟练编写shell脚本，数量掌握python、Java、scala等语言，可以通过Code Review发现潜在的代码问题；3.有大数据开发或测试经验（Hadoop/Storm/Spark/Flink/Hive等），可熟练编写SQL语句；4.有较强的沟通和问题定位能力，协调各角色进行解决工作中遇到的问题,"移动互联网,区块链",2000人以上,spark,北京
高级测试开发工程师,https://www.lagou.com/jobs/7197840.html,朝阳区,25k-50k,北京沃东天骏信息技术有限公司,5-10年,本科,京东大数据平台，技术发展前景好,职责描述：1.负责数据产品相关测试工作，包括web端测试、APP端测试、后端测试、数据测试以及性能测试等，并且能够在发现问题的同时帮助研发快速定位问题；2.结合公司内部业务需求开发自动化测试工具，构建持续集成环境、提高测试效率；任职要求：1.本科以上学历，2年以上相关互联网测试开发经验，精通测试用例设计，熟练掌握不同的测试方法；2.熟悉Linux操作系统，熟练编写shell脚本，数量掌握python、Java、scala等语言，可以通过Code Review发现潜在的代码问题；3.有大数据开发或测试经验（Hadoop/Storm/Spark/Flink/Hive等），可熟练编写SQL语句；4.有较强的沟通和问题定位能力，协调各角色进行解决工作中遇到的问题,"移动互联网,区块链",2000人以上,spark,北京
大数据业务负责人,https://www.lagou.com/jobs/7056831.html,朝阳区,40k-65k,北京妙医佳健康科技集团有限公司,5-10年,本科,福利健全，准上市公司，平台发展前景好,职责描述：1、 建立和完善基于Hadoop 生态的大数据平台，构建完善的数据存储、加工、分析、挖掘及数据产品开发的基础数据系统；2、建立业务部门需求沟通机制，发现与改进公司产品及业务流程中的问题，为公司的商业决策提供依据；3、推动大数据商业应用的内部咨询服务，根据业务部门需求，指导下属将数据分析结果转化为商业洞察和启示；4、领导开发有关的数据产品，例如用户画像系统、用户行为分析系统、可视化报表系统以及其他数据挖掘产品等；5、负责数据治理体系的规划和建设，制定统一的指标口径，提升数据质量，加速分析效率；6、组建团队，包括数据架构、数据分析、算法研究、策略实施等，对团队人员进行指导和考核。7、具有前瞻性思考，能够从公司的长远发展的要求出发，提出创新性的数据规划，扩展数据来源，探索创新性的分析挖掘方向，用数据驱动决策任职要求：1、本科及以上学历，计算机相关专业；2、5年以上大数据经验，具备丰富数据服务平台体系建设经验，对业务指标体系的建设也有较好的成功经验，并对数据保持足够的敏感和关注；3、具有非常良好的技术沟通能力和商业沟通能力，能够与研发人员、产品设计人员、业务运营人员、市场人员、第三方合作伙伴、用户等多方进行有效沟通和合作。4、熟练掌握数据仓库架构设计，数据建模方法，对数据质量治理有一定的经验或者自己的思考；5、对数据敏感，在元数据管理，数据安全和数据质量监控有实际应用经验；6、有搭建完善数据应用体系经验，包括数据产品构建、数据分析需求响应、数据集市；7、熟悉主流分布式存储及计算技术体系，如Hadoop，Spark生态的各种开发工具,移动互联网,150-500人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7141734.html,朝阳区,18k-25k,北京妙医佳健康科技集团有限公司,3-5年,本科,福利健全，准上市公司，平台发展前景好,岗位职责：1.大数据平台建设和维护；2.数据仓库建模和开发；3.实时数据仓库开发；4.研究大数据前沿技术，提升系统效率。任职要求：1. 计算机相关专业，3年以上大数据开发经验； 2. 熟悉Hadoop/Hive/Sqoop/Spark/Storm/Flink/Elasticsearch等当前主流的开源大数据组件并具有相关开发经验；3. 参与过数据仓库（实时、离线）设计和搭建，有数据治理相关经验；4. 熟悉superset/tableau等报表工具；5. 有良好的逻辑思维能力、做事积极主动、有较强的执行能力和较好的沟通能力；6. 2年以上java开发经验，熟悉微架构Dubbo、Spring Boot。,移动互联网,150-500人,spark,北京
分布式平台大数据研发工程师,https://www.lagou.com/jobs/7063935.html,海淀区,10k-20k,中国科学院自动化研究所,不限,本科,一流的科研平台，优秀的科研团队和环境,"岗位职责：1.负责资源/作业调度相关功能设计，收集满足客户需求，完善系统。2.负责功能的开发和实现，并完成测试。3深入理解分布式调度，打造系统稳定性和提高性能。任职要求：1. 本科及以上学历，具备扎实的计算机理论基础,对数据结构及算法有较强的功底；2. 精通Java或者c++语言编程，具备优秀的系统Debug/Profiling能力和经验；3. 有Hadoop、Spark、HBase、Kafka等大数据开发经验以及在海量数据场景下的平台性能优化经验；4. 熟悉Redis/Zookeeper等一种以上组件；5. 具备实际的大数据业务开发经验，具备大规模集群管理经验者优先；6. 具备良好的软件工程研发素质，具备极限编程或者敏捷开发经验者优先。",数据服务,2000人以上,spark,北京
nlp算法工程师,https://www.lagou.com/jobs/7204613.html,海淀区,17k-34k,北京下厨房科技有限公司,1-3年,本科,免费午餐 弹性上班,岗位职责：  1、下厨房搜索、推荐等场景策略持续优化2、使用机器学习技术改进下厨房的搜索、推荐产品的用户体验3、深度学习等算法在搜索、推荐场景的实验和落地应用任职要求：1、一年以上相关工作经验，对机器学习和数据挖掘技术有比较深入的了解，并进行过相关的实践；2、 在以下至少一个领域：自然语言处理、推荐和搜索、广告、深度学习等方面有一定的实际工作经验； 3、有深厚的编程功底，至少熟练掌握C /C++/Java/Go 当中的一种编程语言，理解常用的编程模式 使用过 Hadoop Spark、MPI 等并行计算平台中的一种或几种加分项： 有丰富的 TensorFlow、Caffe 等流行的深度学习框架使用经验的优先；参加过有影响力的竞赛例如KDD-CUPACM-ICPCMCMICMKAGGLE并取得较好成绩者优先工作地址,移动互联网,150-500人,spark,北京
算法工程师,https://www.lagou.com/jobs/7204672.html,海淀区,17k-34k,北京下厨房科技有限公司,1-3年,本科,免费午餐 弹性上班,岗位职责：  1、下厨房搜索、推荐等场景策略持续优化2、使用机器学习技术改进下厨房的搜索、推荐产品的用户体验3、深度学习等算法在搜索、推荐场景的实验和落地应用任职要求：1、一年以上相关工作经验，对机器学习和数据挖掘技术有比较深入的了解，并进行过相关的实践；2、 在以下至少一个领域：自然语言处理、推荐和搜索、广告、深度学习等方面有一定的实际工作经验； 3、有深厚的编程功底，至少熟练掌握C /C++/Java/Go 当中的一种编程语言，理解常用的编程模式 使用过 Hadoop Spark、MPI 等并行计算平台中的一种或几种加分项： 有丰富的 TensorFlow、Caffe 等流行的深度学习框架使用经验的优先；参加过有影响力的竞赛例如KDD-CUPACM-ICPCMCMICMKAGGLE并取得较好成绩者优先工作地址,移动互联网,150-500人,spark,北京
java开发工程师 （应届生）,https://www.lagou.com/jobs/7215650.html,朝阳区,15k-20k,北京嘟嘟一下科技有限公司,应届毕业生,本科,高速成长；租房补助；股票期权,岗位描述：1、后台相关业务的系统设计开发；2、项目的需求分析、概要设计、详细设计，技术文档的编写；3、开发框架的搭建、改进；4、系统用户的快速增长，提高系统的并发能力，保证高可用，参与小打卡系统服务化，系统分拆减少系统之前的耦合；5、参与支持相关项目(首页feed，搜索，后端服务)的开发，系统建设。岗位要求：1、扎实的计算机专业基础，包括算法和数据结构，操作系统，计算机网络，计算机体系结构，数据库等；2、扎实的 Java 或相关编程语言基础（我们以 Java 为主），良好的编程素养，对代码有美感和**的追求；3、理解实时流计算（ Spark/Storm/Flink ）或海量数据处理（ Hadoop/HBase/Hive ）相关经验优先考虑；4、掌握机器学习、数据挖掘或深度学习的原理和相关算法优先考虑；5、强烈的技术热情和工作责任感，热衷于创新和分享，逻辑清晰并具备批判性思维能力和习惯；6、计算机软件或相关专业毕业，本科以上学历。,"移动互联网,数据服务",50-150人,spark,北京
高级大数据研发工程师（北京）,https://www.lagou.com/jobs/5182064.html,朝阳区,20k-30k,天津市国瑞数码安全系统股份有限公司,5-10年,本科,"五险一金,股票期权,员工旅游,带薪年假",岗位职责：1、根据产品需求、项目需求，进行软件架构设计，制定项目计划、技术方案、技术架构；2、根据产品需求、项目需求进行产品和项目的开发；3、负责团队技术架构的设计与规划，对团队成员进行技术指导，提升团队整体技术能力；4、负责大数据相关基础数据的技术规划，编制相关规范文档；5、负责大数据相关技术发展方向的预研；6、参与业务需求调研，根据需求及行业特点设计大数据解决方案并跟进具体实施项目；7、参与制定大数据平台汇总数据质量、业务质量监控及管理方案。 职位要求： 1、全日制本科及以上学历（非民办类），计算机、软件、数学等相关专业背景，5年以上大数据开发工作经验；2、熟悉并掌握大数据相关算法（机器学习算法、深度学习算法、神经网络算法相关）；3、具有Hadoop、Storm、Spark、ES等大数据技术的开发经验；4、具有Oracle、HBase、Hive、Redis等主流数据库的相关开发和调优实战经验；5、精通Java、Scala、Python中的一种或多种语言，熟悉Linux环境下编程，熟悉常用的shell命令工具；6、有R、Python、SAS、SPSS等数据分析和挖掘经验者优先；7、深刻理解大数据处理、流计算、分布式计算、分布式文件系统、分布式存储等相关技术和实现方法，有架构和设计实践经验优先；8、具有优秀的表达、沟通与协调能力、团队合作精神、保密意识。,信息安全,150-500人,spark,北京
数据分析师,https://www.lagou.com/jobs/7159714.html,朝阳区,15k-25k,上海冰鉴信息科技有限公司,1-3年,本科,"金融高科技,新兴领域,发展空间大",职位描述：1. 负责金融风险管理相关的数据分析，对风险预警异常情况进行深入分析，对业务风险指标进行跟踪分析及优化；2. 负责机器学习模型的构建、维护、和评估；3. 参与公司征信评分模型和征信系统的研发，包括但不局限于反欺诈模型、申请评分、行为评分、催收评分等模型设计开发；4. 对于部门内产品、需求提供数据支持，对于风险规则策略提供建议；5. 配合项目计划，负责建模驻场项目，完成客户需求的任务。任职要求：1. 统计、数学、计算机等理工科相关专业本科及以上学历，至少1年金融业相关工作经验（做过个人征信和企业征信者最佳）；2. 熟悉常用数据挖掘算法与模型，熟悉逻辑回归、神经网络、决策树、聚类等建模方法；3. 熟练使用python、R等数据处理工具，熟悉SQL、hive、spark，Hadoop，了解MapReduce分布式计算，具备扎实的数据分析功底；4. 对数据敏感且对处理大量数据有强烈兴趣，喜欢探索钻研，有独立思考的能力；5. 思维活跃，有创新思考能力，具有良好的逻辑分析能力，能够快速学习新方法，责任心强；6. 注重团队协作，有独立承担项目的经验和能力，具有优秀的职业素养和抗压能力；7. 具有良好的编码能力，具备产品思维，可适应短期出差者优先考虑。,"信息安全,数据服务",150-500人,spark,北京
高级数据仓库开发工程师,https://www.lagou.com/jobs/5708856.html,海淀区,20k-40k,厦门美图之家科技有限公司,3-5年,不限,"大数据平台,千万级用户,福利待遇好",1、负责美图系各产品线核心业务模块数据仓库的构建；2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；3、负责全产品线数据字典维护，提升数据资产质量。职位要求：1、计算机、数学相关专业本科及以上学历，三年以上大数据开发工作经验；2、 深入理解常用的数据建模理论，可独立把控数据仓库的各层级设计；有数据挖掘，机器学习，推荐相关经验优先；有熟悉java或php语言、后台服务开发经验优先3、熟练掌握Hive/SQL，熟悉Spark/Map-Reduce/MPI分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；4、有数据和产品意识，主动思考基于业务场景下的数据体系建设5、工作认真，负责，良好的团队合作精神和解决问题分析能力，钻研技术克服困难，勇于挑战。,硬件,2000人以上,spark,北京
java开发工程师,https://www.lagou.com/jobs/7206592.html,海淀区,15k-24k,亚信科技（中国）有限公司,1-3年,硕士,五险一金；免费班车；年终奖金；弹性工作；,岗位职责：1、负责智能安防一体机产品开发及技术攻关；2、负责产品核心功能优化；3、负责技术方案编写；4、安排的其他重要工作。岗位要求：1、熟练掌握主流Java开发技术如：spring/springboot、mybatis/hibernate等；2、熟悉js/jquery/vue等前端框架者优先；3、熟练掌握mysql、oracle 等关系型数据库；4. 对hadoop、spark、redis、kafka 有深度使用经验的优先；5、有分布式系统分析、设计、开发、优化经验者优先。,"企业服务,移动互联网",2000人以上,spark,北京
算法工程师,https://www.lagou.com/jobs/7086378.html,朝阳区,30k-50k,智锐创想（北京）科技有限公司,5-10年,本科,"领导好,团队和谐,五险一金",岗位描述：1、 在分布式系统上进行数据计算、挖掘、和实现算法 2、 数据仓库模型设计和建立 3、 数据梳理流程的实现和维护 4、 物流场景下的地址文本、空间属性研究和分析岗位要求：1、本科以上学历，有扎实的统计学，数据挖掘，机器学习，自然语言识别理论基础，一种或几种以上的实际使用经验。  2、熟悉聚类、分类、回归等机器学习算法和实现，对常见的核心算法和数据挖掘方法有透彻的理解和实际经验  3、深入理解Map-Reduce模型，对Hadoop、Hive、Spark、Storm等大规模数据存储于运算平台有实践经验  4、有扎实的计算机理论基础，至少熟悉一种编程语言，Java优先  5、有三年以上互联网公司或者海量数据处理工作经验，大数据挖掘、分析、建模经验,消费生活,50-150人,spark,北京
用户增长负责人,https://www.lagou.com/jobs/7127684.html,朝阳区,25k-45k,抱抱（北京）信息技术有限公司,3-5年,本科,弹性工作、福利丰厚、百度背景、技术大咖,岗位职责：1，通过用户研究、数据挖掘，洞察用户需求，推动体验优化，提升长期留存；2，关注用户触达、下载、激活、使用、留存的全链路转化优化，提升获客效率；3，与产品/商务/运营/数据/技术等团队深入协作，落地增长策略，支持业务决策。岗位要求：1，用户研究能力，能通过用户调研、行业对标、行为分析等，深入洞察用户需求；2，数据分析能力，能使用Hive/Spark/Hadoop等大数据平台进行深度数据挖掘；3，业务理解能力，能快速抓住业务关键点，并基于用户研究及数据分析提升关键路径转化率；4，团队协作能力，能有效推动产品/运营/技术/采量/变现等相关团队落地增长策略；5，有growth/用户研究/用户增长相关经验。,移动互联网,50-150人,spark,北京
前端开发工程师,https://www.lagou.com/jobs/6707161.html,朝阳区,11k-18k,北京博乐科技有限公司,不限,本科,13薪+项目奖金+出国游+周末双休,"岗位职责：1 主要负责业务部门的数据平台开发工作；2 开发和完善数据产品的前端系统, 优化数据图表和可视化页面及性能优化；3. 负责数据采集，清洗，存储监控等工作；招聘要求：1 熟练掌握响应式Web开发框架（AngularJS、Vue或React等)2 掌握 JavaScript 基本原理，熟悉 ES5/ES6 特性，理解函数式与面向对象特点；3 熟悉数据可视化库，如ECharts/D3.js/HighCharts,并有过相关开发经验；4 有node.js 项目开发经验， 熟悉一种或者多种常见的服务框架 ( koa、expressjs等等 ) ；5、熟练Msql、MongoDB，对事物、锁、性能有一定认知 者优先；加分项：1 对 nodejs 提供的 cluster、stream、buffer、events、v8、net 等等包有着一定的理解2 熟悉大数据处理和查询产品，掌握Spark、Flink、Presto、Impala中的一种，有实际的大数据处理经验3 了解AWS、GCP、阿里云等云计算平台，特别是云上大数据产品；",移动互联网,150-500人,spark,北京
node.js开发工程师,https://www.lagou.com/jobs/7112613.html,朝阳区,15k-25k,北京博乐科技有限公司,1-3年,本科,13薪+项目奖金+出游+周末双休,"职位诱惑：优秀技术团队、有竞争力的薪资福利职位描述：岗位职责：1 主要负责业务部门的数据平台开发工作；2 开发和完善数据产品的前端系统, 优化数据图表和可视化页面及性能优化；3. 负责数据采集，清洗，存储监控等工作； 招聘要求：1 熟练掌握响应式Web开发框架（AngularJS、Vue或React等)2  掌握 JavaScript 基本原理，熟悉 ES5/ES6 特性，理解函数式与面向对象特点；3  熟悉数据可视化库，如ECharts/D3.js/HighCharts,并有过相关开发经验；4  有node.js 项目开发经验， 熟悉一种或者多种常见的服务框架 ( koa、expressjs等等 ) ；5 对 nodejs 提供的 cluster、stream、buffer、events、v8、net 等等有着一定的理解；6、熟练Msql、MongoDB，对事物、锁、性能有一定认知 者优先；  加分项：1  熟悉大数据处理和查询产品，掌握Spark、Flink、Presto、Impala中的一种，有实际的大数据处理经验；2 了解AWS、GCP、阿里云等云计算平台，特别是云上大数据产品。工作地址北京 - 朝阳区 - 奥运村 - 北苑路甲13号院北辰新纪元大厦23层2305",移动互联网,150-500人,spark,北京
算法工程师,https://www.lagou.com/jobs/7019164.html,东城区,20k-40k,北京云动九天科技有限公司,3-5年,硕士,扁平管理、成长空间、技能提升,职位描述：1、研究电商搜索引擎的策略算法工作，包括 query 理解、用户意图分析、召回策略、相关性模型、排序模型等算法；2、设计与搭建搜索系统，提升系统转化率;3、建立搜索离线效果评估和线上效果验证的方案;4、应用数据挖掘、机器学习、自然语言处理等技术，提升搜索效果。岗位要求：1、计算机或者数学相关本科及以上学历，在推荐、搜索、广告、数据挖掘等方向有 2 年以上的项目经验；2、熟悉solr/elasticsearch/lucene 开源检索系统3、具备机器学习、自然语言处理、数据挖掘等研究背景或项目背景；4、熟练掌握海量数据处理技术，有使用 Hadoop / Hive / Spark / Storm 分析海量数据的能力和经验；5、具备 Linux 环境开发经验，熟练掌握至少一种主流编程语言（ C++ / Java / Python 等）。,"移动互联网,电商",150-500人,spark,北京
后端开发工程师,https://www.lagou.com/jobs/6436400.html,海淀区,15k-30k,医渡云（北京）技术有限公司,3-5年,本科,14薪、1日3餐免费、下午茶、健身房免费,"1 医疗大数据相关产品，按时高质量的完成需求开发    2 完成合理的架构设计，高质量的实现以及测试     3 技术文档完善         4  与PM和QA进行需求和问题沟通，及时响应  1 必须：计算机相关专业，本科及以上学历。       2 必须：至少熟悉Python, Java, C++在内的一种以上的编程语言，有后端服务开发经验。       3 必须：具备扎实的算法、数据结构、程序设计基础知识， 掌握这里列出领域的基本原理和基础知识：面向对象的程序设计、多线程模型、分布式架构、数据库操作。     4 必须：熟悉软件开发流程，代码质量、开发文档等符合要求。     ""5 加分项：a)         Github/stackoverflow/知乎/CSDN 等社区的代码项目或发表的文章  b)         在Linux shell环境工作  c)         docker使用经验  d)         使用spark, hadoop开发应用的能力  e)         有ES、MONGO使用经验  f)         了解软件设计常用设计模式  ""","消费生活,医疗丨健康",150-500人,spark,北京
python后端研发工程师,https://www.lagou.com/jobs/7062628.html,海淀区,20k-35k,医渡云（北京）技术有限公司,5-10年,不限,高薪,"1 医疗大数据相关产品，按时高质量的完成需求开发 2 完成合理的架构设计，高质量的实现以及测试 3 技术文档完善 4  与PM和QA进行需求和问题沟通，及时响应 1 必须：计算机相关专业，本科及以上学历。  2 必须：熟悉Python编程语言，有后端服务开发经验。  3 必须：具备扎实的算法、数据结构、程序设计基础知识， 掌握这里列出领域的基本原理和基础知识：面向对象的程序设计、多线程模型、分布式架构、数据库操作。 4 必须：熟悉软件开发流程，代码质量、开发文档等符合要求。 ""5 加分项：a)         Github/stackoverflow/知乎/CSDN 等社区的代码项目或发表的文章  b)         在Linux shell环境工作  c)         docker使用经验  d)         使用spark, hadoop开发应用的能力  e)         有ES、MONGO使用经验  f)         了解软件设计常用设计模式  ""","消费生活,医疗丨健康",150-500人,spark,北京
数据挖掘工程师,https://www.lagou.com/jobs/6895835.html,朝阳区,20k-40k,北京嘟嘟一下科技有限公司,1-3年,本科,租房补助,岗位描述： 1、研究数据挖掘或统计学习领域的前沿技术，针对海量用户行为和内容信息，挖掘信息；2、负责构建用户画像，用户兴趣模型，地理位置挖掘、圈子画像等数据挖掘工作；3、分析用户行为数据，建立数据分析模型，并参与推荐系统与搜索系统的改进。岗位要求： 1、本科以上学历，1-3年大数据开发相关工作经验； 2、熟练掌握大型数据库开发技术，如Hive SQL、Mysql等等掌握至少一种，灵活运用SQL实现海量数据ETL加工处理与查询性能调优； 3、掌握数据仓库模型设计方法论以及基本数据结构和算法，并有实际模型设计及ETL开发经验 ；4、熟悉Hadoop / Spark / Hive / Hbase 等， 有相关源码有研究更佳5、熟悉常用的数据挖掘、分析的工具和方法，有数据挖掘工作经验；熟悉linux平台，精通shell/python等脚本语言的一种或多种，编码基本功扎实 ； 6、具备快速学习能力、沟通协调能力及团队精神，有较强的责任心和抗压性。,"移动互联网,数据服务",50-150人,spark,北京
Java开发工程师,https://www.lagou.com/jobs/6858487.html,海淀区,15k-25k,北京天融信网络安全技术有限公司,3-5年,本科,餐补交补、八险一金、带薪年假,"工作职责:1.参与和部分负责架构设计，需求分析、功能设计、开发实现、测试验证、发布版本等活动。2.现场工行项目维护和支持工作，高效率、高质量、按计划的完成每月版本投产。3.可以指导3-4名初中级开发人员进行工作；任职资格:1.教育程度：大学本科及以上学历, 计算机相关专业；2.精通java编程/数据结构/软件工程基础，理解OO思想（面向对象、设计模式、STL使用等技术）；3.至少三年以上java开发经验，有实际的开发实践经验，熟悉Linux编程环境和调试环境；4.熟悉springboot\flume\kafka\es\hadoop\hive\spark\flink\hbase等，至少对其中一项以上精通实现原理；5.对信息安全技术（如：网络攻防、IDS、远程扫描等技术）有一定了解者优先；6.具备团队合作精神，积极的工作态度和较强的责任心，良好的沟通和学习能力。",信息安全,2000人以上,spark,北京
算法工程师,https://www.lagou.com/jobs/7121504.html,海淀区,25k-50k,北京聪明核桃教育科技有限公司,3-5年,本科,互联网教育公司，少儿编程赛道****,岗位描述1.参与用户画像、召回等核心系统的策略优化，持续提升推荐效果2.独立完成数据分析任务，从用户行为等数据中挖掘出有价值的信息，探索深度学习等算法在业务上的应用3.利用数据挖掘方法解决业务实际问题，包括构建用户数据模型，挖掘用户群体属性等职位要求1.计算机科学、机器学习、人工智能等专业本科及以上学历，扎实的算法和编程能力；2.3年以上业务相关经验，熟悉常用的机器学习算法；3.有大规模海量数据机器学习、数据挖掘、计算广告、搜索引擎相关经验者优先；4.熟悉Hadoop、HBase、Spark、Kafka等计算平台和工具；,教育,500-2000人,spark,北京
推荐系统工程师,https://www.lagou.com/jobs/7129761.html,朝阳区,25k-35k,北京奇艺世纪科技有限公司,5-10年,本科,大平台 学习机会多,岗位职责：1、负责文学个性化推荐相关基础服务的业务需求迭代、架构升级、性能优化和线上维护；2、能够支持推荐算法的快速开发、实验、效果分析、快速迭代，提升迭代效率；3、负责与需求方沟通需求，独立完成对需求的分析和设计开发工作。任职要求：1、大学本科以上学历，5年以上推荐系统相关工作经验；2、熟练掌握JAVA、Scala至少一种编程语言，熟悉io、网络、多线程等编程，有良好的编程习惯；熟练使用Java各种开源项目（Spring / Guava /Apache Commons等）；3、熟悉Hadoop，Spark，Storm，Kafka等大数据框架；熟悉常用算法和数据结构，有一定的系统架构设计经验；4、有推荐系统相关经验、了解推荐相关算法及开源项目；5、有较强的沟通能力和良好的团队合作精神。温馨提醒：如果 7 天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可。,文娱丨内容,2000人以上,spark,北京
效能产品架构工程师,https://www.lagou.com/jobs/7173869.html,朝阳区,20k-40k,北京新氧科技有限公司,3-5年,本科,发展前景,职位描述:1、参与公司效能产品的设计与需求沟通，负责效能产品的研发与开发； 2、参与公司效能产品的应用架构或技术架构设计，负责详细设计和计划；3、写系统相关接口的实现文档； 4、关注新技术，优化现有的服务系统 ；任职要求： 1、统招本科及以上学历，计算机软件工程等相关专业，>5年工作经验2、扎实的 Java 编程基础，熟悉php后端技术，掌握 Spring Cloud3、能够熟练使用linux系统；了解前端常用技术知识，熟悉分布式应用系统的相关框架及技术，如rpc框架、配置中心、消息队列、缓存；有较好的面向对象设计和编程理念，有较好的设计功底。4、熟悉Docker/Kubernetes生态开源项目代码; 熟悉DevOps流程，有贡献容器相关开源项目者优先5、熟练使用常用的关系型数据库，熟悉常用NoSQL技术 如Redis\MongoDB；熟悉大数据领域的技术栈，如Spark/Flink/Hadoop/Hive等7、全栈工程师者优先；,"移动互联网,消费生活",500-2000人,spark,北京
数据安全工程师,https://www.lagou.com/jobs/6994192.html,海淀区,20k-40k,北京长亭未来科技有限公司,不限,本科,"带薪年假,工作餐,年底多薪,五险一金",岗位职责：1、负责对各类安全日志进行挖掘分析，对网络入侵、恶意程序感染、异常流量等安全事件建模分析；2、负责洞察并构建安全数据应用场景，梳理业务流程，推动算法应用落地。岗位要求：1）计算机或信息类、数学统计类相关专业本科及以上学历2）至少1年以上大数据分析经验3）熟练掌握将特定的安全业务需求转化为数学模型能力3）具有类SQL工具，具备数据建模、机器学习等工具经验4）具有hive，hbase，hdfs，mapreduce、Spark等使用经验5）充分理解态势感知、威胁建模，分析监控等安全数据需求模型6）有态势感知产品研发经验者优先7）熟悉DGA、隐匿信道技术者优先,"企业服务,信息安全",150-500人,spark,北京
机器学习工程师,https://www.lagou.com/jobs/6835068.html,海淀区,20k-40k,北京长亭未来科技有限公司,1-3年,本科,"带薪年假,工作餐,年底多薪,五险一金","岗位职责：1、基于机器学习技术对网络安全事件进行分析；2、研究数据挖掘、统计学习、深度学习领域的前沿技术，针对海量数据建模，进行行为分析；岗位要求：1、3年以上经验，具有计算机科学、图像处理、模式识别、机器学习、人工智能、数学等相关专相关专业本科以上学历。2、熟悉常见的机器学习算法，熟悉sk-learn,xgboost等库，能够深入算法细节。对某一领域有深入的经验尤佳，如用户画像、关系网络、精准营销、个性化产品推荐、IoT分析等。3、熟悉分布式机器学习框架比如Spark MLLib, SparkSQL,GraphX4、扎实的工程实现能力，熟练使用Python，PySpark等大数据分析工具，熟悉Hive,SQL,Linux等5、热爱AI，能自我驱动持续学习，对新技术有强烈求知欲和探索能力，对业界新成果有高敏感度。6、有网络安全从业背景者优先；","企业服务,信息安全",150-500人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6992911.html,海淀区,20k-40k,混沌时代（北京）教育科技有限公司,3-5年,本科,"弹性工作,六险一金,年度体检,学习氛围",职位描述：1. 负责大数据系统的数据清洗、建模、监控及治理2. 负责相关开源组件的性能、稳定性、可靠性等方面的深度研究和优化3. 解决生产环境的各种实际问题，保障大数据系统的平稳运行任职要求：1. 计算机相关专业本科及以上学历， 3 年以上工作经验2. 熟悉Python/Java，熟悉常见的数据结构和算法3. 对大数据生态体系中的一项或多项有深入了解，如 HDFS、MapReduce、HBase、Hive、Spark、Kafka等；4. 熟悉整个大数据平台的处理流程和大规模分布式集群的环境搭建5. 有Python web开发经验并熟悉主流开发框架者优先6. 良好的团队协作及沟通能力,"移动互联网,教育",150-500人,spark,北京
大数据开发高级工程师,https://www.lagou.com/jobs/7116794.html,朝阳区,18k-24k,玄吉（上海）信息技术有限公司,3-5年,本科,优秀的研发团队，良好的工作环境,岗位职责：1. 参与大数据平台架构建设2. 参与数据仓库的搭建和分层设计3. 负责大数据在线、离线分析，数据挖掘模型的建立、应用、监控和优化任职要求：1. 本科3年以上相关工作经验2. 熟悉Hadoop/Spark生态圈及环境搭建3. 熟悉ETL开发及流程4. 熟悉数据仓库的建设和大数据分析5. 熟悉Hive-SQL，Spark-SQL，Spark-Streaming，Scala语言6. 熟悉Hbase和Elasticsearch优先7. 能够独立产出数据报告，熟悉数据采集到报表展示的全流程,移动互联网,15-50人,spark,北京
金融数据算法工程师,https://www.lagou.com/jobs/6549790.html,朝阳区,25k-50k,颐月信息技术（北京）有限公司,1-3年,本科,午餐补助、带薪休假,"职责描述：1. 围绕金融交易数据进行数据挖掘、分析。比如用户画像，交易行为等等；2. 进行量化投研基本面分析、风险分析、量化策略研究、量化因子体系、智能交易风控、智能投研等模型算法研发；3. 负责模型算法系统设计架构、调优；4. 和金融相关业务人员沟通模型和算法，落地更多金融AI场景；5. 将机器学习算法应用到金融数据中并开发相应的策略； 任职要求：1. 985工程高校毕业，本科及以上学历，理工科专业（数学、统计、金融工程，计算机），有复合学历背景者优先； 2. 熟悉大数据架构的相关技术，包含但是不限于hadoop, spark，Sklearn、Tensorflo等；3. 具有熟练的编程能力 ( Matlab / Python / R /java 等优先)，在机器学习、深度学习、数值模型研究方面有兴趣并有相关经验；4. 熟悉机器学习或自然语言处理技术（分词、词性标注、命名实体识别、文本分类、意图识别等），深度学习例如CNN、RNN、Lstm等，了解最新的模型例如DenseNet、Bert、GNN等，对数据预处理、特征工程等有丰富的经验； 5. 有金融数据分析及量化分析经验优先考虑；6. 在主流基金、 金融科技公司相关经验优先考虑；7. 有数字货币行业研究经验优先考虑；8. 有数据使用经验，比如Sql，HiveSQl，SparkSql优先考虑；9. 有论文、开源项目、算法竞赛经验者优先考虑；10. 良好的创新意识，逻辑思维能力、数据分析能力、沟通协调能力、抗压能力、团队合作能力和快速学习能力，勤奋踏实好学，能承受一定的工作强度。","金融,数据服务",50-150人,spark,北京
高级研发工程师（Java） (MJ000140),https://www.lagou.com/jobs/7082167.html,朝阳区,18k-28k,百融云创科技股份有限公司,3-5年,本科,"年底双薪,年度旅游,带薪年假,绩效奖励",岗位职责：1、负责项目需求分析，并结合部门内技术栈，进行技术选型和架构设计；2、完成软件系统代码的实现，编写代码注释和开发文档；3、根据设计文档或需求说明完成代码编写，调试，测试和维护；4、与测试组及运维组协作实现产品上线，并监控产品服务，及时处理线上异常。任职要求：1、本科及以上学历，专业基础扎实，计算机及相关专业优先2、为人踏实，协作能力强，能接受一定的工作压力。3、具有较强的自我驱动能力和自学能力，沟通能力强。4、java web开发2年以上经验，熟悉面向对象开发模式，了解常用的设计模式。5、精通Java面向对象开发模式，了解常用的设计模式、熟练使用j2ee开源框架如Spring/Springboot/mybatis/Maven等，并了解其架构和实现原理。6、精通java集合包和并发包。或者精通guava等第三方集合包。7、熟悉mysql数据库，能独立完成mysql的数据库设计、性能调优等。8、熟悉kafka、rabbitmq、redis、mongodb、hbase等常用mq和非关系型数据库9、有支付、账务系统、BI及数据可视化行业工作经验或者有大数据使用经验，熟悉hadoop、hive、spark等优先。,金融,500-2000人,spark,北京
数据平台经理/算法专家 (MJ000131),https://www.lagou.com/jobs/6813454.html,朝阳区,35k-60k,百融云创科技股份有限公司,5-10年,硕士,"年底双薪,年度旅游,带薪年假,绩效奖励",职位数据平台负责人（数据工程与算法方向）工作职责1.新兴金融科技平台，千万实名用户，百万月活，百款产品，业务增速快，数据丰富，应用场景多2.结合业务需求，负责规划和实现公司数据系统和运营分析；负责核心产品算法系统和模型的研发和优化3.负责对业务提供数据能力输出，建设各类赋能业务分析的数据产品及应用，包括用户画像，产品推荐，营销反作弊支持等4.负责通用大数据平台工具的架构和开发，包括开发平台，多维分析平台，可视化系统以及 ABTest 实验平台，数据采集规范，数仓建设等5.负责数据平台团队的人才结构建设和内外协作管理，提升团队的技术实力和服务能力任职资格：1.五年以上数据架构或者数据平台工作经验，有大数据处理实战经验2.深刻理解 Hadoop、Spark、Hive、Kafka 和 Flink 等技术体系，代码开发能力强悍3.熟悉机器学习原理与算法，能熟练运用分类、回归、排序等模型解决有挑战性的问题4.具备强烈的理解业务、服务业务和驱动业务的意识5.具备出色的逻辑思维能力、组织协调能力、沟通交流能力,金融,500-2000人,spark,北京
基础架构研发工程师,https://www.lagou.com/jobs/6800074.html,海淀区,25k-45k,度小满科技（北京）有限公司,1-3年,本科,发展前景广,任职要求：1、本科及以上学历，计算机、通信等相关专业； 2、熟练掌握Linux环境下的Java/Go/C/C++/Python等1至2种以上语言； 3、具有linux服务器端软件开发经验；4、熟悉Hadoop生态、Spark生态优先；5、善于沟通及主动思考总结、倡导创新与持续优化、思路周密、代码严谨、对待技术有强烈兴趣；6、有良好的团队合作及抗压能力、有强烈的主人翁意识推进事务进展；7、 具备一定架构能力、有大容量、高性能、分布式系统的设计开发经验优先。8、有社区贡献者优先岗位职责：1、为百度金融研发基础架构服务组件，包括分布式存储、计算引擎2、调研新技术，推动适合的技术落地满足业务需求,金融,2000人以上,spark,北京
数据工程师,https://www.lagou.com/jobs/5471343.html,海淀区,20k-40k,竹间智能科技（上海）有限公司,3-5年,硕士,待遇好，空间大，提升快，老板酷,"【职位描述】根据业务场景，建立数据模型，开发数据指标；建立数据集规范，数据采集/数据服务API规范；负责数据仓库设计，开发；根据业务场景，建立领域数据模型；研究算法，开发数据指标。【职位要求】三年以上具有数据开发、数据建模相关经验，能熟练使用python,java；熟悉主流数据库，熟练运用SQL，并熟练运用Python进行ETL开发；了解数据仓库OLAP，熟悉多维分析优先，及了解数据分析、数据挖掘常用算法；熟悉Hadoop生态体系，熟练使用Hadoop、Spark、Kafka、HBase等大数据体系相关系统；参与过大数据平台搭建，开发或运维实践经验优先；如有，加分项1、对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先；2、有Low latency（包括Spark-streaming、Flink、Storm、Kafka等）大数据处理经验者优先；3、有存储系统（包括Hbase、Cassandra、Redis、Mongodb等）经验者优先；4、有大数据查询系统（包括ClickHouse、Phoenix、Presto、Impala、Druid、Kylin、Greenplum等）经验者优先；5、有海量数据下图计算、关系挖掘、推荐预测实践经验者优先。","移动互联网,其他",150-500人,spark,北京
高级交付开发工程师,https://www.lagou.com/jobs/5847331.html,海淀区,20k-40k,竹间智能科技（上海）有限公司,5-10年,本科,"福利全,空间大,平台好,牛人多",职位描述：1.负责项目的定制化开发，系统接口连调，产品交付等工作，并能够解决关键技术问题。2.能够与用户进行需求交流和工作确认，根据现有产品提供应用解决方案；3.快速掌握公司现有平台的应用开发技术；4.作为公司在客户现场与客户沟通交流的代表和接口，与客户保持积极良好的沟通和交互。5.能够带领和培养研发团队，制定技术规范，建立良好的工作文化，并与产品团队协作沟通，将项目交付中的用户需求提炼成产品需求。任职资格：1.学历要求：-统招本科及以上学历，理工科相关专业背景。2.工作经验：-5年以上java开发经验，深刻理解面向对象思想，熟悉常用项目构建工具，具备大规模高并发访问的Web应用开发经验。-掌握Linux操作系统，熟练使用python、shell等脚本语言进行数据处理工作。-3年及以上软件项目交付的经验。-熟悉网络架构，熟悉Java中间件（Tomcat、WAS、Weblogic）以及数据库（MySql、Oracle、DB2）任意一种者优先。-敏捷沟通、思维逻辑能力强，学习能力强。有大型互联网公司高并发分布式开发、测试、运维、应用工作经验者优先。3.能力要求：-具备良好的沟通能力，能与用户进行沟通交流；-具备团队合作意识，能够主动总结和分享自己的工作经验。4.优先考虑：-具有人工智能的实际工作经验者优先，有带团队经验优先。-熟悉Spark等大数据平台，docker/k8s等容器编排和企业云架构者优先。,"移动互联网,其他",150-500人,spark,北京
NLP课程教研,https://www.lagou.com/jobs/7117675.html,海淀区,20k-25k,北京开课吧科技有限公司,3-5年,本科,五险一金,岗位职责：1. 负责人工智能课程NLP、机器学习架构的搭建；2. 负责与智囊团及外部讲师对接，主导共建课程大纲等内容；3.和任课老师交流，对竞品、市场和用户进行前期调研及后续跟进，从课程内容、课程思想、课程体验建立课程核心竞争力。任职资格：1.985/211 计算机、数学、物理、统计等相关专业本科及以上学历；2.三年及以上数据挖掘、机器学习、自然语言处理等算法相关项目经验，计算机科学的相关发展趋势有一定认识；3.熟练掌握Python编程语言，有数据抓取、处理、分析及数据可视化相关项目经验；4.有Hdoop、Spark分布式数据处理经验者优先；5.熟练掌握基础的数学、统计相关知识，对微积分，概率论等基础知识清楚。有较强的算法设计和实现能力，在Kaggle、天池、ACM等国内外竞赛中获奖者优先；6.热爱技术交流和分享，有内训经验、参加公开技术大会的优先。加分项：1. 表达能力强；2. 曾经发表过大数据或者AI相关论文优先；3. GitHub提交超过150次；4. 有自己的个人主页或博客，并持续更新；5. 敲代码速度快（60字/分钟以上）,"移动互联网,教育",500-2000人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/6690555.html,朝阳区,15k-30k,中商惠民（北京）电子商务有限公司,3-5年,本科,"五险一金,餐补,生日福利,员工旅游","技能要求：java岗位职责：1、负责大数据平台的架构和开发；2、负责海量数据处理分布式平台以及数据分析系统；3、参与数据工具、ETL程序开发工作；4、参与大数据处理，算法实施等工作；5、参与数据分析平台的数据开发和调优工作。职位要求：1、此岗位必须具备flink实际项目工作经验，熟悉主流的云计算、大数据产品（hadoop、spark、flume等）和数据分析技术（机器学习)并具有相关项目经验2、四年以上数据仓库设计和ETL开发经验，熟悉数据仓库建模设计，元数据管理，数据质量监控等3、四年以上的离线，实时，OLAP数据分析处理项目经验4、三年年以上MapReduce开发经验5、精通Java，Hive SQL，Linux shell；具备较丰富的Scala，Kafka 开发经验；6、有较强的性能优化及问题排查，解决能力；对开源技术非常感兴趣并具有一定的研究能力,有良好的沟通协调能力。7、有数据挖掘、机器学习、推荐算法、人工智能、数学建模项目经验者优先。任职地点：北京集团总部",电商,2000人以上,spark,北京
AI研发总监,https://www.lagou.com/jobs/7070634.html,海淀区,50k-80k,北京力拓飞远科技有限公司,5-10年,硕士,五险一金，补贴,岗位职责：1、负责公司AI业务的推进和落地；2、负责公司整体数据平台的建设；3、负责基于统计学方法的A/B实验平台建设；4、对海量数据进行分析挖掘，改进推荐技术，优化推荐算法，提升用户体验和业务价值；5、组织技术攻关，并对技术选型和具体技术问题进行指导。岗位要求:1、计算机、数学、统计学、模式识别等相关专业，211、985院校研究生及以上学历；2、熟悉常见的数据挖掘、机器学习、深度学习相关算法，有推荐系统、机器学习及深度学习相关商业项目经验；有大型推荐系统架构经验优先；3、有五年及以上面向产品的算法熟悉Hadoop、Spark、Flink等大数据开源框架；4、有良好的表达沟通能力，在技术和产品上均有热情，愿意跳出纯技术范畴考虑问题；5、具有项目管理、团队管理经验，能推动公司AI项目落地上线。,"移动互联网,消费生活",50-150人,spark,北京
AI研发总监,https://www.lagou.com/jobs/7070634.html,海淀区,50k-80k,北京力拓飞远科技有限公司,5-10年,硕士,五险一金，补贴,岗位职责：1、负责公司AI业务的推进和落地；2、负责公司整体数据平台的建设；3、负责基于统计学方法的A/B实验平台建设；4、对海量数据进行分析挖掘，改进推荐技术，优化推荐算法，提升用户体验和业务价值；5、组织技术攻关，并对技术选型和具体技术问题进行指导。岗位要求:1、计算机、数学、统计学、模式识别等相关专业，211、985院校研究生及以上学历；2、熟悉常见的数据挖掘、机器学习、深度学习相关算法，有推荐系统、机器学习及深度学习相关商业项目经验；有大型推荐系统架构经验优先；3、有五年及以上面向产品的算法熟悉Hadoop、Spark、Flink等大数据开源框架；4、有良好的表达沟通能力，在技术和产品上均有热情，愿意跳出纯技术范畴考虑问题；5、具有项目管理、团队管理经验，能推动公司AI项目落地上线。,"移动互联网,消费生活",50-150人,spark,北京
大数据架构师,https://www.lagou.com/jobs/6968128.html,朝阳区,25k-30k,北京友友天宇系统技术有限公司,5-10年,本科,补贴，晋级，13-15薪,任职资格1、 学历要求：本科以上 2、 专业要求： 计算机或相关专业 3、 英语要求： 无 4、 工作经验要求： 8年以上技术管理经验1、8年以上java/scala/python开发经验，有6人以上技术团队管理经验，工作习惯良好，善沟通、擅合作； 2、熟悉常用算法的实现，熟悉多线程原理； 3、熟悉springboot、springcloud、dubbo等微服务开发框架； 4、熟悉linux平台，会用shell脚本； 5、数据hadoop生态，对hive/hbase/spark/flink/kudu/kafka/ogg等一个或多个组件有应用开发经验； 6、有SQL使用和开发经验；加分项：有SQL优化经验；加分项： 1、 有automation、airflow或其他ETL任务调度工具的产品、设计、开发经验； 2、 有TD/GP应用、运维、开发实施经验； 3、有元数据管理、数据治理、数据目录、数据地图、数据资产管理相关产品的设计、开发、使用经验； 4、有数据服务、API自动生成、服务自动发布相关产品的设计、开发、使用经验；岗位职责： 1、参与大数据应用开发平台、准实时应用开发平台、数据湖等项目之一的开发、技术管理、技术交流总结等工作；2、参与项目开发过程中与行方的需求沟通、讨论，输出需求或需求分析等相关文档； 3、参与和指导开发过程：能在需求讨论、方案设计、代码评审、测试验证等开发环节，指导团队成员； 4、在hadoop(hive/hbase/spark/kafka/ogg)等组件基础上，参与大数据应用开发平台、准实时数据平台、数据中台、数据资产管理等相关产品之一的设计、开发、优化； 5、加分项：有金融行业工作经验、产品经理或参与设计过大数据相关产品的工作经历；,数据服务,150-500人,spark,北京
大数据工程师,https://www.lagou.com/jobs/6775033.html,朝阳区,15k-20k,北京本来工坊科技有限公司,3-5年,本科,前景好,岗位职责：1. 负责业务相关数据内容规划和设计，实现数据互通共享体系，解决海量数据面临的挑战；2. 负责大数据存储和计算框架的设计、开发和优化，构建离线、实时数据的计算能力；3. 负责GP和PG集群的管理和优化，打造高性能、高可用性的数据存储、计算系统；4. 根据业务需求进行上游数据平台设计开发，打造高可用的数据平台。5.构建稳定的GP集群、数据集市和数据查询引擎；任职要求：1. 本科及以上学历，3年及以上数据研发经验，具备良好的沟通能力和表达能力；2. 熟悉Linux系统，具备Java/Scala/Python/PHP等一种或几种语言的开发能力；3. 熟悉Hadoop/Spark/Kafka/Hive/HBase/Flume/Storm/GP等大数据相关技术，对源码有研究或者有调优经验者优先；4. 熟悉并行计算或者分布式计算原理，熟悉高并发、高稳定性、可线性扩展、海量数据的系统特点和技术方案；5. 有大数据系统平台项目经验，掌握实时数据、离线数据处理系统搭建和开发；6. 学习能力强，热衷开源技术，有团队观念，具备独立解决问题的能力。有GP、自动化报表和查询工具经验者优先,消费生活,2000人以上,spark,北京
Java开发工程师,https://www.lagou.com/jobs/7174094.html,海淀区,5k-8k,华控清交信息科技（北京）有限公司,应届毕业生,本科,午餐晚餐，弹性工作制，在校同学非应届,岗位描述1.参与明密文计算，联邦学习等计算框架的开发2.参与调度框架的研发岗位要求：1、熟练掌握 Linux环境下的C/C++/Go/ Python/Java等1至2种以上语言；2、熟悉至少一种计算框架（ Spark/Ray/ Tensorflow/Pytorch），做过源代码级别的修改3、有强烈的工作责任心，较好的学习能力、沟通能力；4、一周至少可以实习3天以上，实习期3个学以上。,数据服务,50-150人,spark,北京
数据开发,https://www.lagou.com/jobs/6854370.html,朝阳区,20k-40k,北京数美时代科技有限公司,1-3年,本科,"大佬领投,五险一金,补充医疗,免费下午茶",你将要负责1、负责构建大数据分析平台以及数据分析和挖掘工作2、负责数据的离线和实时流分析3、参与支撑业务的数据模型建设及数据指标的计算和分析4、参与海量数据的存储、查询和运营数据分析体系搭建5、运用Hadoop、Spark、ES等分布式计算和存储平台希望你1、计算机相关专业应届毕业生2、对Spark及Hadoop技术有深入了解3、熟悉Python/Java/Scala/Php等编程语言，熟练使用SQL，有良好的编码习惯，对分布式有深刻理解4、了解Windows、Unix、Linux等主流操作系统原理，熟练运用系统层支持应用开发5、技术视野开阔，有强烈的上进心和求知欲，善于学习和运用新知识，勇于解决难题 6、善于沟通和逻辑表达，拥有优秀的分析问题和解决问题的能力，良好的团队合作精神和积极主动的沟通意识 7、有激情，具有自我驱动力，追求卓越 【关于数美】www.ishumei.com 数美科技成立于2015年6月，致力于为全球客户提供专业的AI业务风控服务，由国内知名VC机构腾讯、襄禾资本、顺为资本、清流资本、BV百度风投联合投资，为互联网、互联网+、以及产业互联网客户提供全栈式、可信赖的业务风控解决方案。团队核心成员均来自百度、阿里、腾讯、360、小米等知名互联网企业，拥有10余年搜索、安全、语音等互联网在线产品研发经验。4年探索深耕，数美科技基于先进的人工智能技术，构建了全场景、全流程、全维度业务风控产品矩阵与秒级迭代全球SaaS AI风控服务网络，承载海量风险识别请求，以业务、模型、数据驱动的产品实现快速进化。数美科技结合多年黑产对抗经验打造全栈式实时智能风控引擎-天网，旨在为客户解决营销欺诈、支付风控、数据盗爬、欺诈广告等风险问题；同时，结合人工智能技术打造全栈式智能内容识别引擎-天净，为客户提供一站式的智能内容安全解决方案，帮助客户识别文本、图片、音频、视频、网页中出现的涉黄、涉政、低俗、色情、导流广告等问题，规避业务风险，提升运营效率。数美科技的业务风控服务已成功覆盖游戏、直播、新零售、地产、电商、视频、金融、媒体、旅游、出行、教育等行业。截至目前，数美科技已服务华润置地、苏宁、云闪付、酷狗、爱奇艺、映客、探探、vipkid、B站、汽车之家、游族、小红书、keep等上千家知名企业。…………………………………………………………………………了解更多：www.ishumei.com,"企业服务,数据服务",150-500人,spark,北京
大数据研发工程师,https://www.lagou.com/jobs/3516764.html,朝阳区,20k-40k,北京数美时代科技有限公司,1-3年,本科,"扁平管理,班车饭补,待遇给力,股票期权",你将要负责1、负责构建大数据分析平台以及数据分析和挖掘工作2、负责数据的离线和实时流分析3、参与支撑业务的数据模型建设及数据指标的计算和分析4、参与海量数据的存储、查询和运营数据分析体系搭建5、运用Hadoop、Spark、ES等分布式计算和存储平台希望你1、计算机相关专业应届毕业生2、对Spark及Hadoop技术有深入了解3、熟悉Python/Java/Scala/Php等编程语言，熟练使用SQL，有良好的编码习惯，对分布式有深刻理解4、了解Windows、Unix、Linux等主流操作系统原理，熟练运用系统层支持应用开发5、技术视野开阔，有强烈的上进心和求知欲，善于学习和运用新知识，勇于解决难题 6、善于沟通和逻辑表达，拥有优秀的分析问题和解决问题的能力，良好的团队合作精神和积极主动的沟通意识 7、有激情，具有自我驱动力，追求卓越 公司福利待遇：有竞争力的薪酬期权奖励五险一金+商业保险午餐+晚餐补助交通+通讯+电脑补贴结婚+生育+丧葬+住院礼金伯乐奖金年假8天起+带薪病假年度体检、零食畅享、团队建设、生日会、弹性办公【关于数美】www.ishumei.com数美科技成立于2015年6月，致力于为全球客户提供专业的AI业务风控服务，由国内知名VC机构腾讯、襄禾资本、顺为资本、清流资本、BV百度风投联合投资，为互联网、互联网+、以及产业互联网客户提供全栈式、可信赖的业务风控解决方案。团队核心成员均来自百度、阿里、腾讯、360、小米等知名互联网企业，拥有10余年搜索、安全、语音等互联网在线产品研发经验。4年探索深耕，数美科技基于先进的人工智能技术，构建了全场景、全流程、全维度业务风控产品矩阵与秒级迭代全球SaaS AI风控服务网络，承载海量风险识别请求，以业务、模型、数据驱动的产品实现快速进化。数美科技结合多年黑产对抗经验打造全栈式实时智能风控引擎-天网，旨在为客户解决营销欺诈、支付风控、数据盗爬、欺诈广告等风险问题；同时，结合人工智能技术打造全栈式智能内容识别引擎-天净，为客户提供一站式的智能内容安全解决方案，帮助客户识别文本、图片、音频、视频、网页中出现的涉黄、涉政、低俗、色情、导流广告等问题，规避业务风险，提升运营效率。数美科技的业务风控服务已成功覆盖游戏、直播、新零售、地产、电商、视频、金融、媒体、旅游、出行、教育等行业。截至目前，数美科技已服务华润置地、苏宁、云闪付、酷狗、爱奇艺、映客、探探、vipkid、B站、汽车之家、游族、小红书、keep等上千家知名企业。…………………………………………………………………………了解更多：www.ishumei.com,"企业服务,数据服务",150-500人,spark,北京
推荐系统开发工程师（Java）,https://www.lagou.com/jobs/6976151.html,朝阳区,18k-35k,北京展心展力信息科技有限公司,不限,本科,职位空间大、发展好、福利佳,岗位描述： 1. 负责平台产品的设计和开发，确保项目质量和进度 ；2. 能深入理解产品和业务，推动技术不断升级，解决客户和平台问题。岗位要求： 1. 编程基本功扎实，熟悉常用数据结构和算法，擅长Java编程语言，熟悉JVM机制，熟悉shell、python等脚本语言；2. 学习能力较强，有较好的逻辑思维能力，较强的抽象、概括和总结能力，有较好的沟通交流能力，善于主动思考，对技术有强烈激情；3. 熟悉分布式系统，例如hadoop、spark、flink，或者熟悉ElasticSearch/Lucene开源系统者优先 ；4. 有内容、电商、新闻、短视频等行业推荐系统开发经验者优先；5. 有云计算相关开发经验者优先 ；6. 具有敏捷开发经验者优先，具有完整产品生命周期开发者优先。,"移动互联网,游戏",150-500人,spark,北京
模型算法工程师(J10266),https://www.lagou.com/jobs/5746694.html,东城区,25k-50k,北京腾云天下科技有限公司,3-5年,本科,早餐水果生日年节福利 老板nice,工作职责:1. 理解业务部门建模目标和建模需求 2. 数据源检查和分析，以及建模数据准备工作 3. 对数据进行分析，明确建模方向 4. 使用建模工具进行模型开发，包括数据准备、特征工程，建模及数据分析、模型的选取与圈定、模型验证工作 5. 面向业务部门进行模型解读 6. 对业务部门提出模型应用建议 7. 管理数据分析与建模类的项目，辅导初级建模人员任职资格:1. 具有计算机、数理统计及相关专业大学本科及以上学历； 2. 5年以上数据分析和挖掘经验，3年以上数据建模工作经验； 3. 熟悉至少一种常用建模工具，Python常用工具或spark语言工具包者优先； 4. 熟悉至少一种常用数据库，例如mysql，oracle等数据库、熟悉hadoop-spark分布式并行计算环境者优先考虑 ；5. 具有阿里巴巴、百度、腾讯、京东等大型互联网公司工作经验优先，或为此类企业提供过数据分析与建摸服务者优先,移动互联网,500-2000人,spark,北京
搜索算法高级工程师,https://www.lagou.com/jobs/7175325.html,朝阳区,30k-50k,互动峰科技（北京）有限公司,3-5年,不限,医疗独角兽 业务广 成长空间大 挑战性,职位描述：1.负责好大夫搜索技术研究，包括查询理解、语义相关性、召回索引、转化率预估等核心技术；2.探索个性化搜索中深度学习、强化学习技术，并落地应用；3. 探索前沿人工智能技术，并落地个性化搜索业务。职位要求：1. 对NLP、图嵌入、语义技术、排序模型有深入的理解和应用经验，有搜索算法经验。2. 熟练掌握机器学习、深度学习等方向理论和应用，动手能力强，有主动探索和思考。3. 熟练应用算法平台，如TensorFlow、PyTorch等，熟悉Spark、Hive等大数据处理框架优先。,医疗丨健康,500-2000人,spark,北京
ETL数据工程师,https://www.lagou.com/jobs/5266420.html,朝阳区,10k-20k,北京千橡网景科技发展有限公司,3-5年,本科,上市公司 六险一金 弹性工作制,岗位描述1.根据业务产品特性，针对数据仓库进行设计和开发工作；2.负责海量数据的处理、分析和挖掘工作；3.负责多业务数据仓库的设计、构建和ETL工作；4.优化已有离线分析平台5. 深入了解业务流程，理解需求，制定技术解决方案 。岗位要求1.熟练掌握数据仓库设计，开发工作，大数据开发经验3年以上（要求完全的大数据开发经验3年以上，java转过来的，转之前的经验不算）2.对数据模型有自己深刻的认识，能够对业务数据进行抽象，分类。3.极强的sql编写和优化能力。5.逻辑思维能力强，对数据敏感，具备海量数据分析能力。6.了解Hive，Hbase，Spark，Storm等一种以上大数据处理工具和技术；7.具备较强的沟通能力和文字表达能力，有较强的团队管理能力；8.有互联网、银行行业背景,"社交,金融",2000人以上,spark,北京
策略分析与算法工程师,https://www.lagou.com/jobs/6785394.html,海淀区,30k-55k,北京火币天下网络技术有限公司,5-10年,本科,五险一金、补充医疗、节日福利、免费健身,工作职责：1. 负责业务产品全流程风险策略的设计；2. 与产品、技术等合作部门沟通协作，推动风险政策与策略在具体业务层面进行落实；3. 了解前端部门的需求和变化，在合理控制风险前提下推动业务发展；4. 监测和分析风险政策与策略的执行情况和效果，持续优化与完善，根据业务需求，监控业务日常的各项风险指标，提出风险预警；5. 通过数据挖掘和其他手段，发现和了解风险变化趋势，提出建模构想；6. 根据业务需求，监控业务日常的各项风险指标，提出风险预警。任职要求：1. 大学本科以上学历，所学专业为统计学、数学、计量经济学、金融工程、计算机等相关专业优先；2. 有数据分析、数据挖掘的工作经验，对数据敏感，能从海量数据中提炼出核心结果，有同行经验者优先；3. 熟悉数理统计、数据分析、数据挖掘；4. 会熟练使用SQL语言，会使用python、spark、SAS、R语言其中的一种；5. 会独立建模，了解逻辑回归、随机森林等常用建模方法。,金融,2000人以上,spark,北京
资深数据开发工程师,https://www.lagou.com/jobs/7035125.html,海淀区,25k-50k,北京火币天下网络技术有限公司,5-10年,本科,五险一金、补充医疗、节日福利、免费健身,"岗位职责：1. 负责数据的信息抽象，数据仓库建设；2. 主持和参与实时架构设计并实现；3. 基于开源系统大数据系统进行二次开发；4. 基于金融风控的模型训练的机器学习。任职资格：1. 本科及以上学历，计算机相关专业，5年以上数据平台开发经验；2. 熟悉Java/Python，熟练掌握SQL，对大数据平台有深入的了解；例如 Hadoop生态系统，MongoDB, Elastic Search， Spark,Flink和图数据库，能够按照业务需求选择底层技术；3. 熟练使用Javaweb，Spring-boot， Redis 等web开发；4. 有大型数据仓库实施经验,应对复杂业务数据建模,经过大型应用场景的考验；5. 有金融风控系统，征信系统经验，金融衍生品知识的优先；6. 有用户画像，消费行为分析经验的优先；7. 有团队管理经验者优先。8. 有监督学习，非监督学习的线上工作经验。9. 向往区块链行业。",金融,2000人以上,spark,北京
数据中台工程师,https://www.lagou.com/jobs/6787932.html,大兴区,20k-30k,北京对啊网教育科技有限公司,3-5年,大专,公司环境好，晋升空间大，团队有活力,3、协助业务系统分析，设计及解决数据方面问题，如：数据量大，高并发，提供源数据支持等。,移动互联网,500-2000人,spark,北京
产品经理（数据中台）(J10706),https://www.lagou.com/jobs/7198512.html,昌平区,20k-30k,树根互联技术有限公司,5-10年,本科,工业大数据分析,,"移动互联网,企业服务",150-500人,spark,北京
Software Engineer-BigData,https://www.lagou.com/jobs/6975663.html,海淀区,30k-60k,微软（中国）有限公司,不限,本科,国际化团队；云服务；大数据,"Responsibilities
 As an engineer, you have the opportunity to work on the latest technology in big data area:
 Design and develop world-class experience for new big data cloud offering
 Design and develop platform-specific APIs and tools as building blocks for a world-class user experience
 Operationalize open source analytics to run at scale, for example, Spark, Hadoop, Yarn, etc.
 Work with various open source technologies and make contributions to these technologies
Basic Qualifications:
 Bachelor’s degree in Computer Science or Engineering or Mathematics or 1+ years of industry software engineering experience
 2+ years of programming experience in Java or JavaScript or object-oriented programming
 Preferred Qualifications:
 Passion and experience for building great developer experience and user experience of modern analytics systems
 Experience with open source components like Spark and Hadoop ecosystem as a plus
 Experience with leveraging ML and AI for analytics as a plus
 Great curiosity and willingness to question
 High enthusiasm, integrity, ingenuity, results-orientation, self-motivation, and resourcefulness in a fast-paced competitive environment
 Love the next problem, the next experiment, the next partner
 Have a deep desire to work collaboratively, solve problems with teams across the world, find win/win solutions and celebrate successes
 Get excited by the challenge of hard technical problems
 Solve problems by always leading with deep passion and empathy for customers","移动互联网,数据服务",2000人以上,spark,北京
大数据分析工程师(J11108),https://www.lagou.com/jobs/6841602.html,朝阳区,8k-13k,朗新科技股份有限公司,应届毕业生,本科,节日福利五险一金交通补助带薪年假弹性工作,,"移动互联网,企业服务",2000人以上,spark,北京
大数据开发工程师(J11109),https://www.lagou.com/jobs/6841596.html,朝阳区,8k-12k,朗新科技股份有限公司,应届毕业生,本科,节日福利五险一金交通补助带薪年假弹性工作,,"移动互联网,企业服务",2000人以上,spark,北京
算法工程师（非北京地区候选人可远程办公）,https://www.lagou.com/jobs/7132029.html,海淀区,20k-40k,北京吧咔科技有限公司,1-3年,本科,五险一金 不打卡 午餐补贴 零食供应,1.对海量文本内容提取非结构化文本的特征提取，建立、测试、调优分析模型，进行语义识别、文本聚类、情感分析等相关文本挖掘算法的研究与开发；2.结合多源多结构数据，进行用户画像构建，支持文章推荐，用户分组等业务场景；3.对UGC等复杂文本内容进行语义挖掘，情感分析，行为规范梳理，评定内容价值，支持线上作业、自动化培训等业务优化。 工作要求：1.本科及以上学历；2.优秀的算法基础和编码能力，熟悉linux环境，spark大数据框架，精通python/Java、shell等脚本语言；3.在如下专业领域有丰富经验：分词、词性标注、新词发现、词义消歧、命名实体识别、句法分析、情感分析、主题模型、话题分析、事件发现、舆情分析、知识图谱，独立实现过复杂NLP系统；4.有1年以上开发落地经验；5.有很强的分析和解决问题的能力，思路清晰，学习能力强，善于归纳、总结、推理；6.心里素质佳，有优秀的团队合作意识，良好的沟通能力以及团队协调能力。PS：该岗位其他省份候选人可以投递，非北京地区的可以远程办公,移动互联网,50-150人,spark,北京
架构师,https://www.lagou.com/jobs/7100276.html,海淀区,25k-35k,北京励立长平教育科技有限公司,5-10年,本科,六险一金、节假日福利、生日礼品等,一、岗位职责：1、从事互联网广告应用系统的需求分析、架构设计、项目推进、技术研发，负责线上系统的维护和管理，保障系统稳定运行；2、从事广告应用平台的架构建设，结合业务项目，创新突破技术难点，提升研发运维效率，提升组织效能；3、对所负责系统进行规划，并结合项目不断优化和升级，提高性能、稳定性、扩展性；4、结合业务发展，与产品运营配合进行业务分析、项目预研，推进业务创新发展。二、岗位要求：1、5年以上JAVA开发经验，3年以上主导业务抽象与建模、业务架构的设计与开发；2、深入了解spring，ibatis，cache，mq，rpc，jvm等领域的框架或产品的机制与代码；3、熟悉redis、MySQL数据库应用，熟悉数据数据层高可用、性能优化；4、有很强的分析问题和解决问题的能力，有强烈的责任心。对新技术有发自内心的兴趣，学习能力强，抗压能力强；5、设计并实现过高并发，高可用，低延迟的后端分布式服务系统；6、全面的软件知识结构：操作系统、软件工程、设计模式、数据结构、数据存储、网络安全；7、对Java/JVM基础、面向对象设计有着深厚的功底，可以根据业务场景灵活运用相关设计模式；8、追求规范代码，实际解决过复杂的线上问题；9、高效使用Maven、Git、Junit、Eclipse、IntelliJ等工具；10、设计处理过大流量高并发的系统， 有互联网公司工作经验，有Spring Cloud使用经验，熟悉Hadoop、Spark等大数据平台，并有相关开发经验，有基础服务平台架构经验，比如账号、消息、搜索等经验者优先。三、工作时间：因公司所处教育行业，该岗位的工作时间稍特殊，为周三-周日10:00-19:00，周一、周二休息。,教育,500-2000人,spark,北京
微服务,https://www.lagou.com/jobs/7175981.html,海淀区,15k-20k,亚信科技（中国）有限公司,3-5年,本科,发展前景好,职位描述1、负责微服务平台前沿技术研和方案实施落地；2、负责微服务项目关键难点模块开发；3、参与业务需求分析、微服务规划、拆分、设计、开发工作；4、根据开发规范与流程独立完成核心模块的设计和编码；5、提升应用系统的稳定性、性能、质量。 任职要求1、3年以上相关工作经验，本科及以上学历；2、精通java编程，Java 基础扎实，精通常用GC算法、JVM内存结构和参数调优，具备良好的面向对象设计能力和编程习惯；3、了解微服务、SOA，ESB。具备丰富的高并发，分布式实战经验，精通系统性能调优，精通Spring-Cloud和Spring-Boot；4、熟悉redis、kafka、MariaDB、mongodb、hadoop、spark、ElasticSearch等大数据技术；5、熟悉docker、kubernetes、mesos、rancher等容器技术并有实际使用经验。,"企业服务,移动互联网",2000人以上,spark,北京
数据集成平台项目经理,https://www.lagou.com/jobs/7148996.html,东城区,20k-30k,宝石花医疗信息技术有限公司,5-10年,本科,医疗集团、国企控股、平台规模大、项目稳定,"岗位职责:1.负责集团数据集成平台项目管理、架构设计和软件技术选型 2.参与集团数据集成平台技术发展路线的制定和实践，以及大数据相关标准制定等工作3.负责平台相关组件功能和性能优化设计和实施落地工作4.参与团队技术人才培养，指导产品研发团队建设5.研究大数据技术发展动态，研究新型计算框架，并能够提出优化解决方案  任职要求:1. 计算机相关专业本科及以上学历，具备2年以上医疗行业数据集成、管理、分析相关工作经验2. 熟悉目前市场主流医院信息系统及其数据结构3. 熟悉Java语言开发，熟悉Python、Scala或者Go语言之一,熟练掌握Linux操作系统4. 精通主流数据（如Oracle、MySQL、PostgreSQL或GP其中一种）5. 熟悉主流的ETL工具，如DataPipeline，Kettle，Talend或 Datax等。6. 熟悉Hadoop生态圈的相关组件，了解HDFS、HBase、Hive、Spark、YARN、MR等组件。7. 具备较强的学习能力和自我管理能力，性格积极乐观，能够在压力环境下工作。","医疗丨健康,人工智能",50-150人,spark,北京
高级推荐算法工程师,https://www.lagou.com/jobs/6673030.html,海淀区,40k-60k,光辉齐晟（北京）信息技术有限公司,3-5年,本科,周末双休，节日福利，高于同行业的薪酬。,岗位职责1、理解业务特点，参与探索内容分发、社区构建的算法落地路径2、参与构建推荐系统，包括内容/用户标签体系的构建，召回、排序模型的构建，以及推荐系统的效果分析及提升3、指导初高级工程师岗位要求1、扎实的计算机及机器学习基础知识，熟悉Java、Python开发。2、有4年以上的相关领域的推荐算法经验3、熟悉常用的推荐算法，包括但不限于协同过滤、FM、GBDT4、熟悉常用的深度学习算法，包括但不限于CNN、LSTM、DeepFM5、了解不同模型在不同场景下的适应性，对推荐的一些难点如用户的冷启动等问题有较深刻的理解6、熟悉Tensorflow，并有使用Tensorflow上线推荐深度学习模型的经验7、熟悉Spark/Flink、HBase、Kafka是加分项,"移动互联网,金融",15-50人,spark,北京
AI算法工程师,https://www.lagou.com/jobs/7071426.html,海淀区,3k-5k,联通云数据有限公司,应届毕业生,硕士,央企、高薪酬、高福利,岗位职责：1、协助进行云平台智能运维研发，涉及故障预测、智能告警管理，故障根因定位方向；2、协助进行云平台运维数据分析处理、AI模型训练、数据挖掘工作；3、协助AI平台建设和运维工作。任职要求：1、至少熟悉Java、Python、Scala中一种；2、熟悉Tensorflow框架，具备机器学习、深度学习、自然语言处理等相关经验；3、熟悉常见算法，如SVM、CNN、RNN、神经网络、随机森林等；4、熟悉Hadoop、Spark等大数据框架者优先。,硬件,500-2000人,spark,北京
大数据基础架构工程师（python）,https://www.lagou.com/jobs/6518563.html,海淀区,20k-40k,爱笔（北京）智能科技有限公司,3-5年,本科,六险一金，班车，餐补,职位描述：1. 负责AIBee数据中台的大数据架构与组件（包括但不限于工作流系统、任务调度系统、监控与保障系统等）的开发与维护2. 从业务中不断抽象并提取出基础数据架构，并开发相应的基础数据组件职位要求：1. 熟悉大数据基础组件的基本工作原理，如yarn、hadoop、spark、airflow、kafka、hive等2. 有优秀的代码开发能力，熟悉Python，了解Java、C++、Go加分3. 对分布式系统设计有一定的经验4. 对创业有热情，上进肯吃苦5. 善于沟通，有团队合作精神，有强烈的责任心,"移动互联网,企业服务",150-500人,spark,北京
java高级开发工程师,https://www.lagou.com/jobs/7188461.html,海淀区,25k-35k,中科星图股份有限公司,5-10年,本科,国有控股企业，业务发展迅速，升职机会大,"负责信息系统的技术选型和架构搭建要求：1.精通Java语言，5年以上工作经验；      2.熟悉多种数据库类型，熟悉多种消息中间件；       3.熟练掌握各类常见服务架构，掌握负载均衡、数据库调优、容器化等技术；      4.本科或硕士学历，本科毕业院校211/985；      5.加分项：PG/Postgis,Hadoop/MapReduce,Spark,ES。","信息安全,数据服务",500-2000人,spark,北京
c#开发工程师,https://www.lagou.com/jobs/7152421.html,朝阳区,11k-20k,西窗科技（苏州）有限公司,1-3年,本科,福利多 六险一金 补贴 年假长 弹性工作,后端研发工程师：    工作职责：1.    支持西窗平台和应用的开发、维护和技术支持；2.    参与项目需求的分析讨论，并协助设计相应的技术解决方案；3.    积极参与主要项目的架构设计和项目评审；4.    严格遵循公司的开发流程，做好每个阶段的过程管理；5.    主动并及时发现和解决产品运营过程中的问题。岗位要求：1.    统招本科以上学历，计算机相关专业毕业，1年以上后端开发经验。热爱软件开发并对前沿的软件开发有很高的兴趣；2.    熟悉Java或者.NET Core平台中的一种，良好的算法基础，精通各种搜索和排序算法；3.    精通多线程处理、并行处理、流式处理和异步处理；4.    熟悉分布式和大数据编程，熟悉Postgreql等开源数据库，有一定的数据库优化，有Spark、Flink、Hadoop，ElasticSearch，Kafka，Redis，Zookeeper中的一个及以上使用和优化经验优先；5.    优秀的沟通和配合能力，能够和PM顺畅进行业务沟通，能够和其它技术团队成员进行良好的技术沟通，可以独立完成项目的设计和开发。 西窗科技是一家脱胎于微软MSN的新兴科技公司，专注于为中国用户出海创造更有效的广告账户优化服务。广告优化研发组，由Microsoft工程院富有经验的工程开发师，国内外高校毕业的博士生带队，致力于用先进的机器学习算法提高现有平台的效率。选择西窗：1、技术领先：基于分布式和容器的微服务架构，支持数以百计的服务自动部署并拓展到海量节点，拥有全自动、高弹性的开发、测试和运维架构；2、紧跟行业发展趋势：扎根于大数据研究，公司拥有海量数据，日常处理需要和数十T、数以百亿计的数据交互，是数据工程师、算法工程师和AI工程师的理想学习环境；3、良好的团队氛围：团队鼓励多沟通和主动学习，经常有讨论和分享会议。Manager曾经获得过微软广告与在线服务事业部大中华区总裁奖，主持了数以千万计的流量门户架构设计。公司为外企氛围，轻松愉快，鼓励创新，重视研究核心技术。,"移动互联网,广告营销",150-500人,spark,北京
后端研发工程师,https://www.lagou.com/jobs/7088830.html,朝阳区,11k-20k,西窗科技（苏州）有限公司,1-3年,本科,福利多 六险一金 补贴 年假长 弹性工作,后端研发工程师：    工作职责：1.    支持西窗平台和应用的开发、维护和技术支持；2.    参与项目需求的分析讨论，并协助设计相应的技术解决方案；3.    积极参与主要项目的架构设计和项目评审；4.    严格遵循公司的开发流程，做好每个阶段的过程管理；5.    主动并及时发现和解决产品运营过程中的问题。岗位要求：1.    统招本科以上学历，计算机相关专业毕业，1年以上后端开发经验。热爱软件开发并对前沿的软件开发有很高的兴趣；2.    熟悉Java或者.NET Core平台中的一种，良好的算法基础，精通各种搜索和排序算法；3.    精通多线程处理、并行处理、流式处理和异步处理；4.    熟悉分布式和大数据编程，熟悉Postgreql等开源数据库，有一定的数据库优化，有Spark、Flink、Hadoop，ElasticSearch，Kafka，Redis，Zookeeper中的一个及以上使用和优化经验优先；5.    优秀的沟通和配合能力，能够和PM顺畅进行业务沟通，能够和其它技术团队成员进行良好的技术沟通，可以独立完成项目的设计和开发。 西窗科技是一家脱胎于微软MSN的新兴科技公司，专注于为中国用户出海创造更有效的广告账户优化服务。广告优化研发组，由Microsoft工程院富有经验的工程开发师，国内外高校毕业的博士生带队，致力于用先进的机器学习算法提高现有平台的效率。选择西窗：1、技术领先：基于分布式和容器的微服务架构，支持数以百计的服务自动部署并拓展到海量节点，拥有全自动、高弹性的开发、测试和运维架构；2、紧跟行业发展趋势：扎根于大数据研究，公司拥有海量数据，日常处理需要和数十T、数以百亿计的数据交互，是数据工程师、算法工程师和AI工程师的理想学习环境；3、良好的团队氛围：团队鼓励多沟通和主动学习，经常有讨论和分享会议。Manager曾经获得过微软广告与在线服务事业部大中华区总裁奖，主持了数以千万计的流量门户架构设计。公司为外企氛围，轻松愉快，鼓励创新，重视研究核心技术。,"移动互联网,广告营销",150-500人,spark,北京
Java开发工程师,https://www.lagou.com/jobs/7133419.html,海淀区,20k-35k,广州依万达电子科技有限公司,1-3年,本科,福利待遇,"工作职责：负责业务后台架构设计、开发及维护。任职资格：1. 2年以上Java相关开发经验；2. 精通Java语言，精通多线程编程、网络编程，有性能优化经验者优先；3. 具备独立设计并实现高并发、高可用的大型应用的能力优先；4. 熟练应用成熟的分布式缓存、分布式存储技术方案；5. 熟悉TCP/IP、HTTP等协议, 了解分布式应用的各种协议，Thrift/Protocol Buffer等；6. 熟练使用Spring，MyBatis等常见开发框架；7. 熟悉 Hadoop、Spark、等大数据处理框架和平台以及有推荐系统设计经验的优先。8. 熟悉移动互联网服务及应用开发者优先。薪酬范围：20-35k","金融,数据服务",15-50人,spark,北京
大数据开发工程师(J10019),https://www.lagou.com/jobs/7177029.html,东城区,25k-30k,塞纳德（北京）信息技术有限公司,5-10年,不限,六险一金 带薪病假 年假 工作氛围好,,"移动互联网,社交",500-2000人,spark,北京
研发工程师 （Golang方向）(J17208),https://www.lagou.com/jobs/6565780.html,海淀区,15k-25k,鑫车投资（上海）有限公司,3-5年,本科,上市集团 股东背景强 福利待遇丰厚,,移动互联网,2000人以上,spark,北京
大数据研发工程师,https://www.lagou.com/jobs/6597093.html,大兴区,9k-15k,广州摩翼信息科技有限公司,应届毕业生,本科,专业导师、队友奈斯、周末双休、五险一金,工作职责：1.1 完成大数据系统工程建设。包括离线和实时架构和业务。1.2 完成业务需求，包括数据采集、存储、计算、展示 等流程建设。1.3 保证数据质量，包括数据校验、异常监控、报警处理。1.4 研究学习新技术，引入新思路，解决业务问题，保持技术领先性。任职要求：1.1 计算机、软件、数学 等相关专业或具有相应能力。1.2 熟悉实时数据流计算，包括spark streaming、flink 、kafka。1.3 熟悉hadoop体系。包括hdfs、hbase、hive、YARN。1.4 熟悉计算引擎和即席查询。包括MR/hive、Tez、spark sql、Impala、Presto。1.5 熟悉展示图形系统。包括Zeppelin、Superset、Kylin  。1.6 熟悉常用数据建模,"移动互联网,教育",500-2000人,spark,北京
数据仓库工程师,https://www.lagou.com/jobs/6243715.html,朝阳区,25k-40k,北京怡合春天科技有限公司,5-10年,本科,发展前景好,"1.负责数据仓库设计、数据治理，数据标准建设及维护工作;2.负责梳理用户数据模型，提供数据设计文档3.数据仓库模型的ETL实施，ETL性能优化以及相关技术问题的解决4.负责业务相关数据指标的计算挖掘5.负责数据建模以及数据仓库应用产品的设计和开发6.负责数据仓库ETL流程的优化及解决ETL相关技术问题7.满足业务方的数据需求，提供面向业务报表、数据提取等数据服务； 岗位要求:1.本科及以上学历，统计学、计算机相关专业2.5年以上企业级数据仓库开发经验，熟悉数据仓库理论，具备复杂业务需求梳理能力3.熟练数据仓库的ETL的开发和数据建模4.熟练SQL开发，精通Mysq|等关系型数据库中的一种或几种5.熟练掌握Hadoop应用开发，熟练掌握HBase、Hive、 Storm、 spark等大数据开发工具中一种或几种6.熟悉Linux系统,具备shell、python等 脚本开发能力者优先7.学习能力强，喜欢研究开源新技术，有团队观念，具备独立解决问题的能力8.性格积极乐观，良好沟通合作，善于思考总结，可承担较大的工作压力9、有从0搭建数据仓库经验者优先;","移动互联网,消费生活",50-150人,spark,北京
大数据平台工程师,https://www.lagou.com/jobs/5564889.html,海淀区,25k-50k,脸球（北京）科技有限公司,1-3年,本科,"大牛多,福利多,氛围轻松,**VC","职位描述：1、负责数据分布式存储、计算系统；2、高水平团队，有 Ownership 的推动数据系统迭代；3、从架构到业务，支持公司快速发展；4、支撑用户行为分析, 用户画像等相关的业务。职位要求:1、掌握分布式系统原理，对存储、离线计算、实时计算中的一项或多项有深入的理解和认识；2、很强的系统设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；3、思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原因；4、熟悉Hadoop, Spark, Druid, Flink, OLAP等技术；5、对 HDFS, RocksDB, LevelDB, Memcache, Redis, MySQL, HBase, Kafka 的一项或多项有开发;6、了解 Kafka、 MQ 等消息系统,有过用户行为分析, 用户画像相关的经验优先;7、 拥抱新技术，有很强的学习能力。","移动互联网,社交",15-50人,spark,北京
高级大数据开发工程师,https://www.lagou.com/jobs/6508784.html,海淀区,25k-50k,脸球（北京）科技有限公司,5-10年,本科,"大牛多,福利多,氛围轻松,**VC","岗位描述：1、负责大数据的日常开发,包括架构和日常的业务；2、与业务方沟通日常的需求,梳理需求文档,产出技术方案;3、支撑用户行为分析,用户画像,智能推荐系统的开发和建设。技能要求: 1. 能够熟练运用java语言和scala语言实现编程; 2. 深刻理解HDFS分布式文件系统存储结构和高可用原理; 3. 能运用scala进行spark RDD，spark streaming编程; 4. 熟练掌握hadoop mapreduce计算框架编程，对yarn的资源调度，作业监控了解; 5. 深刻了解Spark运行机制,掌握spark streaming编程，对定时批量任务处理; 6. 熟悉flume，kafka等日志收集以及kafkaconnect实时多系统导入导出工具等分发框架的使用，能够将他们和storm、spark进行整合,进行数据的实时处理; 7. 能够熟练运用hive数据仓库工具，对日志数据进行查询，统计等数据操作，并且有一定的数据优化经验; 8. 能将hive和spark sql进行整合，进行数据查询等相关操作; 9. 熟悉hbase数据库的使用及其编程; 10. 熟悉redis内存数据库，能搭建redis高可用集群及其编程; 11. 熟悉ELK技术栈，了解ElasticSearch，Logstash的整合使用; 12. 掌握Sqoop数据迁移工具的使用，能熟练的将数据从不同的存储介质进行迁移; 13. 了解linux系统，熟悉常用的linux的shell命令，能在linux系统下搭建开发环境; 14. 熟练掌握JavaSE，深刻理解面向对象设计思想，熟练使用IO流操作、集合框架、网络编程等JavaSE主流技术及ssm框架的使用; 16. 能熟练使用Oracle，MySql主流数据库技术，擅长SQL语句的编写 17. 熟悉大数据环境的搭建,集成,运维工作,擅长调优最好加分项:   有过从0-1搭建大数据的环境,产出大数据上线项目的,优先考虑   有过社交领域用户行为分析,用户画像,智能推荐系统经验的优先考虑","移动互联网,社交",15-50人,spark,北京
后端开发工程师,https://www.lagou.com/jobs/6509141.html,朝阳区,30k-60k,北京九贤网络科技有限公司,不限,本科,优厚的福利待遇,岗位要求：1.良好的设计和编码能力，熟练掌握golang，python2.熟悉掌握常用的机器学习算法如LR，GBDT，UserCf等等，对推荐系统，搜索引擎等相关技术至少熟悉一种3.熟悉Hadoop，Spark，Hive等大数据处理工具4.有信息流相关工作经验岗位职责1.负责信息流的推荐核心技术算法研究、实现和优化2.在NLP、用户画像、召回、排序、冷启动某个方向依据需求将各种前沿技术落地3.运用机器学习、数据挖掘技术处理海量数据，分析与挖掘潜在规律和关联,"文娱丨内容,软件开发",50-150人,spark,北京
大数据ETL工程师（主攻数据集市）,https://www.lagou.com/jobs/7092604.html,海淀区,10k-11k,北京宏达盛丰科技有限公司,3-5年,本科,五险一金，周末双休,任职条件：1､有传统数据仓库、数据集市开发经验，熟悉数据平台的开发流程和方法论；2､熟悉hive，spark等大数据组件；3､有3年及以上工作经验，计算机相关专业毕业；4､能快速接受新知识，学习能力强，有银行、金融行业经验优先。,"电商,软件开发",50-150人,spark,北京
【2020校招】算法工程师,https://www.lagou.com/jobs/6435978.html,朝阳区,7k-14k,清枫（北京）科技有限公司,应届毕业生,本科,"北大博士,腾讯大牛,电竞大数据,提前转正",【有以下装备者欢迎投递】 ---你需要参与---1.参与现有个性化推荐系统的研发和优化，优化推荐排序；2.挖掘和分析用户行为数据对用户进行建模，建立精准的用户画像；3.使用统计学习方法和自然语言技术对内容数据进行建模，建立精准的内容画像。---我们对你的要求---1.本科以上计算机相关专业在校生，毕业前可实习3个月以上，每周至少3天实习时间；2.熟练掌握机器学习基础知识，有推荐算法开发或自然语言处理、用户画像等方面的相关实习经验者优先；3.有较强的工程架构和开发能力，能够实现支撑百万级用户、TB级用户行为数据的推荐系统或者算法；4.熟练使用至少一门编程语言：Scala/Java/Python/C++等，熟练使用Spark平台。5.了解SQL和NoSQL数据库，如Mysql／MongoDB／HBase等；6.热爱电竞游戏者优先。---我们为你提供---1.加入优秀的互联网研发团队，给足挑战与空间，获得加速成长；2.新生培训计划+一对一导师制+远超出行业平均水平的实习薪资；3.转正后年底双薪+无上限年终奖+10天带薪年假；4.电竞椅办公又酷又舒适+定期体检+周末双休拒绝996，身体才是革命的本钱；5.周三尖叫之夜，大家一起开黑、桌游、switch.. 6.每周各部门分享沙龙，培养T型人才，零食下午茶、无限量饮料必不可少；7.小黑屋电竞馆尽享员工优惠，同事也是你的最强队友..,游戏,50-150人,spark,北京
高级算法工程师【北京】,https://www.lagou.com/jobs/6770466.html,朝阳区,15k-30k,杭州数澜科技有限公司,3-5年,本科,技术大牛多，公司氛围好，晋升机会多,岗位职责：1、从事前沿机器学习技术研发，设计改进算法框架，深度分析数据特征，挖掘数据价值；2、至少涉及以下一种职责，包括机器学习，计算机视觉、自然语言处理等的算法研发和数据建模；3、面向应用的推荐系统、风控系统、图像处理、综合文本挖掘系统研发，通用算法组件、算法平台的构建。岗位要求：1、视野开阔，创造性思维，具有良好的沟通能力和团队精神，有推进大数据、人工智能的理想和使命感；2、熟悉主流的大数据技术，比如Spark、Hadoop、Storm、Flink、NoSQL等；3、精通或熟悉Tensorflow、Torch、MxNEt、Caffe等神经网络计算框架一种或者几种更佳；4、对机器学习（深度学习）的理论有深刻的理解，并在以下至少一个领域有较深入的研究：在计算机视觉方向（如图像分类、目标检测、人脸识别、图像内容理解等）有一定的研究经历；对自然语言处理(如文本分类、情感分析、文本翻译、信息检索、知识图谱等)有一定认知；对通用的算法组件、算法平台有项目实施经验。5、满足以下某一项条件优先考虑:有过海量数据系统开发经验者；在相关领域的知名国际会议或期刊上发表过论文者；在国内外主流算法竞赛中获取过一定名次者,"企业服务,数据服务",150-500人,spark,北京
高级数据工程师【北京】,https://www.lagou.com/jobs/6770460.html,朝阳区,15k-30k,杭州数澜科技有限公司,3-5年,不限,技术大牛多，公司氛围好，晋升机会多,岗位职责：1、 负责数据产品需求分析、数据建模，主导完成相关设计及编码；2、 完善现有数据产品，优化现有产品数据体系；3、 深入理解业务需求，能从数据角度推动业务发展，开发相应数据产品及工具。岗位要求1. 计算机、数据等相关专业本科以上学历，2-3年工作经验；2. 熟悉数据仓库和数据集市的框架结构，具备数据仓库与数据集市的架构设计能力；3. 熟悉SQL，熟悉Oracle、MySQL等关系型数据库；4. 熟悉HiveSQL/MapReduce/Spark等数据开发技术；5. 有一定的Java/python开发能力，熟悉linux/Shell；6. 在数据统计、机器学习上有一定基础的优先；7. 沟通与交流能力强，业务理解能力强，具有一定的业务建模能力。,"企业服务,数据服务",150-500人,spark,北京
ETL建模工程师,https://www.lagou.com/jobs/7179260.html,大兴区,15k-25k,深圳大地云坞科技有限公司,3-5年,本科,福利待遇好 发展前景大,一、岗位职责：1、负责数据etl开发，熟悉数据仓库常用模型2、etl开发中有数据治理经验，保证数据链路的质量监控3、保证etl开发中数据的准确，稳定，时效易用性4、精通SQL，由丰富的sql性能调优经验，能够通过sql统计完成复杂的业务需求5、负责BI报表数据的日常维护、开发及测试二、任职要求：1、3年及以上ETL数据处理开发经验，能独立完成数据处理开发工作2、熟悉至少两种以上ETL开发工具，例如DataPipeline，Kettle，Talend，Informatica ，Oracle Goldengate，Datastage， MS SSIS等3、熟悉Oracle 、DB2 、MySql等主流数据库的一种或多种，熟练上述数据库的开发4、熟悉数据范式、多维数据模型的设计理论和开发技能 5、熟悉hadoop，spark，hive，Datax大数据技术者优先考虑6、有数据建模经验、熟悉维度建模、范式建模等优先7、良好的团队合作、协调、问题处理能力,"数据服务,软件开发",150-500人,spark,北京
大数据研发工程师,https://www.lagou.com/jobs/7179474.html,大兴区,15k-25k,深圳大地云坞科技有限公司,3-5年,本科,福利待遇好 发展前景大,一、岗位职责：1、主要负责用户画像、运营平台、智能推荐等相关数据应用的研发工作2、跟进相关业务的数据梳理，进行各项据指标的计算和分析3、参与海量数据的存储、查询和运营数据分析体系搭建4、负责平台数据治理相关工作，负责数据质量、数据一致性及稳定性保障等建设二、任职要求：1、计算机相关专业本科及以上学历，3年以上的企业级大数据一线开发工作经验2、有大规模离线计算，实时计算，OLAP数据仓库和海量数据存储经验者优先3、有数据挖掘、数据分析、数据仓库、推荐算法等开发经验者优先4、对Hadoop/Storm/Spark/Hive/HBase其中之一有较深的研究和实战经验者优先5、掌握大型数据库开发技术，如Oracle、Teradata、DB2、Mysql等等掌握至少一种，灵活运用SQL实现海量数据ETL加工处理与查询性能调优6、熟练至少一种流计算框架，如Spark、Flink等7、善于沟通，良好的表达能力，乐于技术分享8、具备快速学习能力、沟通协调能力及团队精神，有较强的责任心和学习积极性,"数据服务,软件开发",150-500人,spark,北京
ETL高级开发工程师,https://www.lagou.com/jobs/5483655.html,海淀区,25k-35k,北京快快网络技术有限公司,5-10年,本科,"六险一金,有餐补,团队氛围好，成长空间大","数据工程师岗位职责:1. 负责金融大数据平台建设研发，架构的升级和优化，不断提升系统的稳定性和效率；2. 负责数据仓库ETL流程的优化及解决ETL相关技术问题；3. 负责数据可视化、数据展现工具、创新数据业务等技术的研发4. 设计实现对机器学习、数据挖掘的系统性支持；岗位要求：1. 统招本科及以上学历，计算机相关专业，四年以上数据开发经验；2. 具备良好的编程习惯，熟悉常用的数据结构和算法；3. 熟练掌握PHP/Python/java任一语言；4. 具备良好的数据库理论基础知识，较强的sql书写能力，熟练使用MySQL/postgres等数据库；5. 有数据处理，ETL流程优化实战经验,熟悉sqoop/kettle/informatica等抽取工具；6. 有使用 kafka，storm，spark streaming 实时数据处理系统建设经验优先。",金融,500-2000人,spark,北京
大数据研发经理,https://www.lagou.com/jobs/6256868.html,海淀区,30k-50k,北京快快网络技术有限公司,不限,本科,班车 打不卡 BAT技术团队,"岗位职责:1． 参与金融大数据研发；2． 参与数据仓库ETL流程的优化及解决ETL相关技术问题；3． 负责数据基础架构的升级和优化，不断提升系统的稳定性和效率；4． 设计并实现对机器学习、数据挖掘的系统性支持；岗位要求：1． 计算机相关专业，统招本科及以上学历；2． 具备良好的编程习惯，熟悉常用的数据结构和算法；3． 熟练掌握PHP/Python/java任一语言；4． 具备良好的数据库理论基础知识，较强的sql书写能力，熟练使用MySQL/postgres等数据库；5． 有数据处理，ETL流程优化实战经验,熟悉kettle/informatica等抽取工具；6. 有使用 kafka，storm，spark streaming 实时数据处理系统建设经验优先。",金融,500-2000人,spark,北京
资深数据研发工程师,https://www.lagou.com/jobs/7024531.html,海淀区,18k-25k,广州小鹏汽车科技有限公司,3-5年,本科,机会多、前景好,工作职责:1.数据统计分析：小鹏汽车业务用户行为数据统计与分析，产品效果评估与分析，为产品策略优化迭代提供强有力的数据支持2.数据挖掘：从海量日志数据中发掘有价值的信息，建立多个维度上的模型，用于指导产品优化职位要求:1.数学、统计、金融、计算机或者相关专业本科以上学历2.熟悉Java/Python，熟练掌握SQL，具有2年以上开发或者统计分析经验3.了解HADOOP大数据平台架构，熟悉HDFS/HBase/Hive/MapReduce/Spark，熟练掌握HiveSQL、Mapreduce程序开发4.对数据仓库系统架构具有良好的认知，熟悉数据仓库相关技术，如 ETL、报表开发，具备数据分析技术并具有相关项目经验5.掌握常用的数据分析工具、数据挖掘、机器学习算法是加分项,汽车丨出行,2000人以上,spark,北京
推荐算法工程师,https://www.lagou.com/jobs/7034179.html,朝阳区,15k-25k,加和（北京）信息科技有限公司,3-5年,本科,领导nice 福利丰富 团队年轻,职责描述：1.深入理解业务数据，扩充有效的特征，挖掘用户兴趣，建立用户画像；2.不断优化召回和排序模型，并提供稳定的线上服务；3.跟踪业界最前沿的机器学习算法，并尝试将其应用于实际的生产环境。任职资格：任职要求：1.扎实的机器学习功底，熟悉常见算法如协同过滤、GBDT、SVD、LDA、LearningToRank、word2vec、深度学习等，并有丰富实战经验；2.熟练掌握Python、C、C++等其中的一种或几种，参与过大型互联网项目，具备良好的编码习惯和算法基础；3.三年以上推荐/广告/搜索系统核心算法研发经验，对个性化推荐系统有深刻理解；4.熟悉hadoop、Spark等分布式计算系统，了解hbase、storm、kafka工具者优先；5.有深度学习等机器学习前沿方向的研究经历者优先。,"移动互联网,数据服务",50-150人,spark,北京
NLP算法专家(J14705),https://www.lagou.com/jobs/6992229.html,东城区,30k-50k,北京云杉世界信息技术有限公司,不限,不限,公司发展好，行业独角兽。,,电商,2000人以上,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7215079.html,海淀区,40k-55k,青岛德谦智行企业管理有限公司,5-10年,本科,独栋办公，独角兽,工作职责：1、负责海量数据的采集，离线和实时计算平台的设计，开发，维护与优化；2、参与计算平台的架构设计，开发，运维等相关工作，并能够进行自动化平台建设；任职资格：必要条件：1、3年以上工作经验;2、掌握hadoop、spark、storm、flink等大数据相关组件，理解底层运行原理，并运用开发3、精通数据采集，离线计算、实时计算4、3年以上的Java或scala开发经验(熟练使用java、scala、python等开发语言);5、了解数据结构及算法（基本算法即可）加分项1、有过参与大数据计算平台的系统规划，并落地的经验优先2、熟悉Kubernetes者优先,企业服务,少于15人,spark,北京
Java工程师（大数据方向）,https://www.lagou.com/jobs/7008208.html,朝阳区,15k-30k,北京代码乾坤科技有限公司,1-3年,本科,六险一金、年底双薪、工作有趣、同事友好,任职资格：1. 本科以上学历，计算机相关专业毕业2. 精通Java，2年以上Java应用开发经验；了解JVM原理；熟悉多线程和高并发技术，熟悉运用数据库、缓存、消息队列3. 精通Web开发，熟练Springboot、MyBatis等常用框架，有RESTFul微服务开发经验4. 熟悉大数据相关技术开发（Hadoop/Spark、Hbase、Hive、Zookeeper等）5. 熟练Linux环境和常用shell脚本，掌握linux环境下进程管理和问题排查6. 喜欢钻研，具有快速学习能力；注重代码质量，有良好的软件工程知识和编码规范意识7. 对数据仓库和机器学习有一定了解，有实际机器学习开发经验或者海量数据平台开发经验更佳8. 良好的团队合作，较强的沟通能力，对解决挑战型问题充满激情岗位职责：1. 负责数据平台中实时部分核心业务流程的研发2. 负责大数据和AI相关组件的服务封装，API实现,游戏,150-500人,spark,北京
数据开发实习生,https://www.lagou.com/jobs/7145151.html,朝阳区,5k-6k,上海蔚来汽车有限公司,应届毕业生,硕士,成熟平台 福利好 上升期,岗位职责：1、参与蔚来汽车电池相关数据的处理，在分布式计算平台基础上建立高效、实时的数据 pipeline；2、参与检索系统/推荐系统的数据分析，发现模式与规律，为实验解释、系统改进提供数据支持；3、参与Hadoop，Spark 等大数据基础设施和平台的改进，解决大规模生产环境集群可用性和性能化问题；岗位描述：1、本科及以上学历，计算机相关专业，每周可实习4天以上，持续3个月以上；2、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具；3、对数据敏感，掌握量化分析方法，善于从数据中发现问题，提出假设并使用数据进行验证；4、对至少一项分布式计算平台有使用经验，例如 Hadoop，Spark，Hive，Storm，Kafka 等；5、有参与开源项目对社区有贡献的经历，有互联网公司实习经历，有大数据处理或用户行为数据分析经验者优先；6、有机器学习算法经验者优先。,"移动互联网,硬件",2000人以上,spark,北京
大数据架构师,https://www.lagou.com/jobs/7152283.html,海淀区,40k-80k,北京利君鑫达管理咨询有限公司,10年以上,本科,上市公司，核心职位，重点人才,"岗位职责：1、负责基于Hadoop/Spark等生态系统的大数据平台的架构设计、技术选型、搭建、开发、管理、监控和性能调优，保证集群高效稳定运行，对数据应用提供数据存储、查询引擎、实时计算、元数据管理的架构设计；2、系统核心部分代码编写、指导和培训工程师、不断进行系统优化；3、跨团队/部门协作，系统分析并解决各类大数据平台相关的运行或数据问题；4、打造有行业竞争力的系统，能够支撑快速发展的数据业务。岗位要求：1、本科及以上学历，5年以上的大数据从业经验。2、有大型分布式系统设计经验，负责过海量数据平台上高可用、高性能分式系统的架构设计。3、精通任意一门编程语言，对大数据基础架构和平台底层原理有深度理解和丰富开发经验, 对复杂系统的性能优化和稳定性提升有一线实战经验，具备相关产品（Hadoop、Hive、HBase、Kafka、MapReduce、Spark等）项目应用研发经验；对开源社区有贡献者优先；4、熟悉Greenplum、TiDB数据库技术有实际生产项目应用经验者优先； 5、具有一定的项目规划和决策能力，善于捕捉业务需求、架构设计存在的问题，并给出有效的解决措施和方法；",企业服务,15-50人,spark,北京
NLP算法实习生,https://www.lagou.com/jobs/7130415.html,海淀区,5k-7k,北京深维智信科技有限公司,应届毕业生,本科,**投资机构投资，全球**科学家跟投,"工作职责：1. 研究机器学习领域的前沿技术,并用于实际问题的解决和优化2. 负责机器学习的算法和模型的开发，尤其是深度学习领域3. 研发NLP、机器学习、深度学习等算法，应用于2B的业务场景岗位要求：1. 计算机、自动化、统计学、数学等相关专业硕博在读研究生2. 熟悉常用机器学习算法，尤其是深度学习相关领域，对NLP、模式识别、概率统计等算法原理及应用，有扎实的基础，深入的理解和浓厚的兴趣，在相关期刊和会议上发表过论文的优先考虑3. 了解目前常见的机器学习或者深度学习框架中的一个或者多个：Spark，XGBoost，Pytorch，Tensorflow等4. 乐于动手，有良好的逻辑思维能力和数据敏感度，能够熟练阅读英文论文并且予以实践和改进，具有优秀的新技术研究和实现能力",企业服务,15-50人,spark,北京
大数据开发工程师-天津,https://www.lagou.com/jobs/7111229.html,朝阳区,15k-30k,捷信消费金融有限公司,5-10年,本科,六险一金，带薪年假,"工作内容：1. 负责大型数据平台的离线和实时计算编码及代码优化。2. 基于Spark技术参与海量数据的处理，分析，统计和挖掘。3. 参与Kafka的开发与优化。4. 负责构建或维护搜寻器系统，并为Web数据开发自动搜寻器脚本。5. 最新社区技术的实时跟进，可应用于实际生产。6. 具有金融行业大数据平台离线实时场景登陆经验者优先。任职资格：1.  3年以上Spark 或 Spark Streaming开发经验，有良好的编程基础2.  熟悉Hadoop架构，熟练掌握Spark框架和Scala语言 3.  熟悉Linux/Unix操作系统，使用过Kafka、Redis、ES、Hbase等组件中的一种以上（或类似组件）4.  熟悉Spark Streaming, Structured streaming和Spark SQL, RDD、DataFrame编程 5.  具备良好的沟通能力和表达能力，有较强的数据敏感度，能承受一定的工作压力6.  对新技术感兴趣，较强的学习能力，有优良的Trouble Shooting能力",金融,2000人以上,spark,北京
高级大数据工程师,https://www.lagou.com/jobs/6891153.html,朝阳区,20k-30k,开易（北京）科技有限公司,5-10年,本科,弹性工作、技术大咖、丰厚奖金,岗位职责：1、负责大数据离线、实时分析处理，为业务提供数据服务及支持工作；2、整合公司各业务线数据，主要工作内容包括数据接入、存储、实时数据开发等；3、面向业务目标，从数据模型、数据分布、数据传输、数据存储等方面进行大数据系统的开发；4、对现有系统的不足进行分析，找到目前系统的瓶颈，能够通过不断迭代提升数据的准确性与系统性能。任职要求：1、计算机相关专业本科以上学历，5年以上大型互联网数据平台大数据处理经验；2、熟悉Python或java，有一定的后端开发能力，熟悉linux；3、具备基于Hadoop大数据平台开发经验，熟悉SQL、ETL工具，有一定大数据处理经验，能够独立进行服务部署以及大数据查询服务引擎开发；4、熟悉Hadoop、Kafka、Hive、Spark、Mongodb、Redis能够进行常用的ETL开发工作及服务维护；5、具备清晰缜密的逻辑思维能力，有较强的数据分析能力；6、具备优秀的沟通能力、学习能力、执行能力、团队协作能力；7、责任心强，能承受一定的工作压力。,"数据服务,其他",150-500人,spark,北京
搜索推荐算法专家,https://www.lagou.com/jobs/7109705.html,海淀区,20k-40k,上海壹佰米网络科技有限公司,3-5年,本科,互联网电商/五险一金/补充医疗/下午茶,"职位描述：1. 负责开发叮咚买菜产品的智能售卖, 骑手调度管理, 定价和收益管理, 智能营销等ai系统;2. 不断优化cvr, ctr预估系统, 通过数据收集, 特征挖掘, 模型调优不断优化用户体验和转化效果;3. 不断优化商品销量的预测准确性降低缺货和损耗, 提升公司收益;4. 深入理解公司业务, 基于业务场景能搭建数据分析体系, 制定策略算法方向并落地实施; 任职要求：1. 计算机、数学等相关专业, 本科及以上学历;2. 熟悉Linux开发环境和平台，精通C++/Python/go/java, 扎实的编程能力, 有大型线上服务的工程经验优先考虑；3, 有实际ctr/cvr预估模型训练调优和大规模在线预测经验优先; 信息流, 推荐4. 熟练使用Hadoop、Spark、Hive等大数据平台做数据处理；5. 精通LR, GBDT, Xgboost, dnn, wide&deep等相关算法理论, 并对技术发展趋势有深度认识； 6. 优秀的分析和解决问题的能力，很强的逻辑能力;7. base北京 ;",消费生活,2000人以上,spark,北京
高级java开发工程师,https://www.lagou.com/jobs/6791293.html,海淀区,20k-30k,北京商越网络科技有限公司,3-5年,本科,公司大牛多，企业氛围好，福利好,"岗位要求:1、本科以上学历，计算机专业背景，扎实的数据结构、操作系统、编译原理等2、负责Elasticsearch管理平台的架构设计与开发,负责基于ES数据检索产品的架构的设计与开发3、至少3年JAVA以上及3年以上ElasticSearch开发经验，熟悉ES部署、监控及性能调优4、熟悉盘古、ICTCLAS、IK等常用词库，对分词算法有深入的研究，能设计垂直行业的分词算法和规则、熟悉搜索引擎原理，熟悉Spark和ES、Hadoop者优先5、善于分析总结问题,热衷技术,精益求精,喜欢研究开源代码,有高并发、大数据处理实际项目产品经验者优先 6、负责Elasticsearch管理平台的架构设计与开发,负责基于ES数据检索产品的架构的设计与开发7、具有一定的系统设计和架构能力，能够独立完成系统的设计和实现8、具有ES/Solr/Lucene等相关开发经验者优先具有搜索、推荐系统开发经验者优先。9、学习并参与体系化的核心搜索系统建设，包括分布式检索引擎、实时数据引擎、在线特征计算与模型预估框架等，研发高可用、高稳定、高吞吐、低延迟的搜索系统；","移动互联网,企业服务",50-150人,spark,北京
GIS开发工程师,https://www.lagou.com/jobs/7197070.html,海淀区,12k-20k,神州数码信息服务股份有限公司,3-5年,本科,八险一金 带薪年假 年终奖,岗位职责：1.研究空间大数据前沿技术，参与空间大数据管理系统的设计和开发。2.负责空间大数据管理系统在项目中的实施。3.参与大数据GIS平台的总体设计和模块开发。任职资格：1、计算机、地理信息系统、遥感等相关专业背景，本科及以上学历，3年以上工作经验。2、对OGC规范有深刻理解，熟悉空间数据库引擎。3、扎实的编程基础，能够熟练运用Java\Scala语言；4、了解和使用过Geoserver、Geotools、Openlayers等主流开源GIS平台。5、熟悉GIS领域主流数据分布式存储方案，有空间数据存储、管理、检索经验；有GeoMesa、GeoWave、GeoTrellis等软件实践经验者优先。6、熟悉大数据管理系统，如HBase、Cassandra、Accumulo、Solr、MongoD等。7、对分布式计算框架有所了解，如MapReduce、Spark、Storm等。8、熟悉NIFI、Sqoop等主流的ETL数据处理工具9、具备良好的沟通能力，敬业、有上进心，有良好的团队合作精神。注：桌面端gis(Arcengine)、gis(supermap)目前都有需求,"移动互联网,企业服务",2000人以上,spark,北京
c++架构师,https://www.lagou.com/jobs/5949479.html,海淀区,25k-40k,虎特信息科技（上海）有限公司,5-10年,本科,七险一金 弹性工时 交通补助 双休 零食,"工作职责：开发企业安全解决方案后端引擎，本引擎接收来自于端点探针（PC/服务器）安全相关的信息。引擎对这些数据做分析包括大数据分析发现复杂威胁并且做关联。技能要求：- 熟练掌握Linux下C++开发。 同时掌握python等脚本语言。- 较强的系统架构能力，主要集中在后端服务器的分级、平行延展以及和第三方系统/数据来源的对接等方面。- 对来自于几千、几万个数据源的实时数据处理有相关经验,每个数据源的数据量不是很大，但数据源的量会比较大。- 有大数据分析开发经验的优先，熟练使用redis、ES等，了解Hadoop软件栈以及Spark等。- 有安全解决方案开发经验的优先- 良好的团队合作精神，愿意在有需要的时候帮助其它团队成员解决不是自己负责的模块的问题","信息安全,移动互联网",15-50人,spark,北京
大数据工程师,https://www.lagou.com/jobs/6349669.html,海淀区,20k-40k,小船出海教育科技（北京）有限公司,5-10年,本科,七险一金、免费三餐、打车报销,1.负责业务需求数据开发；2.提供面相业务的数据服务，完成数据指标统计、多维分析和展现；3.搭建数据治理、数据质量和元数据等规范体系。职位要求：（本职位不接受只会写SQL）1.熟练掌握JAVA、scala、Python其中一种或多种语言2.精通Hive、Hadoop、Spark、Flink中的一种或多种框架，且有阅读源码的经验3.熟悉数据仓库模型设计方法论，并有独自负责主题从0到1的建设经验4.加分项：有实时数仓、Flink实际经验者优先考虑,工具,2000人以上,spark,北京
高级开发工程师,https://www.lagou.com/jobs/5824322.html,西城区,15k-30k,中钞信用卡产业发展有限公司,5-10年,本科,战略发展项目，央企品牌雇主,"岗位职责：1、制定编写软件详细设计和数据库的实施方案；2、根据能设计文档，开发核心软件，并负责系统集成执行；3、代码排查，找出其他成员代码中存在的隐患；4、负责数据库的创建和表结构建立及安全机制建立；5、线上系统产生非异常情况，给予及时处理；5、至少精通一个技术方向，了解另外两个技术方向。技术方向清单如下：JAVA微服务开发技术（Spring Boot、Spring Cloud等）、大数据应用技术（Hadoop、Flink、Spark、Storm等）和人工智能应用开发技术（Tensorflow、Caffe、CNTK等）。任职要求：1、计算机或相关专业本科以上学历；2、5年以上的软件开发工作经验，至少参与过2个成功项目的开发；3、有数据库设计开发工作经验者优先考虑；4、熟练掌握软件研发的OO方法；5、精通java、熟练使用ajax、struts/struts2、spring、ibatis等主流开源框架；6、熟练使用Eclipse等主流Java集成开发环境；7、熟悉Oracle、MySql等数据库管理系统软件,以及DML操作；8、具有较好的沟通能力和文档组织能力。","移动互联网,金融",150-500人,spark,北京
【校招】后端开发工程师,https://www.lagou.com/jobs/6141659.html,海淀区,15k-30k,爱笔（北京）智能科技有限公司,应届毕业生,本科,成长空间/六险一金/免费午晚餐/技术大牛,"岗位职责：1. 后端基础架构和开发；2. 提供高并发语音、图像、视频、自然语言处理和大数据分析请求的处理能力；3. 海量数据存储平台搭建。任职要求：1. 本科及以上学历，计算机相关专业；2. 至少精通一种后端开发语言，如C++、Java、PHP、Go、NodeJS、Python；3. 熟悉网络协议栈；4. 掌握主流后端开发技术栈，如Nginx、Redis、MemCache、MySQL、MongoDB；5. 熟悉分布式系统，如Hadoop、Spark，并且有实践经验者优先；6. 熟悉Docker等虚拟化技术者优先；7. 熟悉TensorFlow、Caffe等深度学习框架者优先；8. 有较强的学习能力和解决问题的能力。Responsibilities:1. Back-end infrastructure architect and development;2. Process highly concurrent requests, including voice, image, video, NLP, big data analysis;3. Build up mass data storage platform；Qualifications:1. Bachelor‘s degree or above in Computer Science, Electronic Engineering, Automation, Mathematics, Physics, etc.;2. Proficiency in at least one of the back-end development language, such as C++, Java, PHP, Go, NodeJS, Python;3. Familiar with the network protocol stack;4. A strong command of the mainstream back-end development technology stack, such as Nginx, Redis, MemCache, MySQL, MongoDB;5. Candidates familiar with distributed systems, such as Hadoop, Spark, and have practical experience are preferred;6. Candidates familiar with virtualization technology such as Docker are preferred;7. Candidates familiar with deep learning framework such as TensorFlow and Caffe are preferred；8. Excellent communication, learning, execution and teamwork skills.","移动互联网,企业服务",150-500人,spark,北京
大数据开发,https://www.lagou.com/jobs/6831306.html,朝阳区,15k-30k,北京多氪信息科技有限公司,3-5年,本科,上市公司 公司业务稳定,岗位职责：1.负责大数据产品代码开发和架构设计2.负责数据清洗、处理、转换3.数据赋能业务，提升数据价值发现的能力和效率任职要求：1.3年及以上大数据开发经验，丰富的实时或离线数据体系建设经验2.熟悉Hadoop、HBase、Spark、Storm、Flume、ES等大数据生态技术栈3.熟悉Java、Python等开发语言中的一种或几种4.拥有良好的学习能力、团队协作能力和沟通能力。,"移动互联网,电商",500-2000人,spark,北京
高级python研发工程师,https://www.lagou.com/jobs/6814780.html,朝阳区,20k-35k,北京云杉智达科技有限公司,3-5年,本科,五险一金、午餐等福利、晋升空间、绩效奖金,【工作内容】1、负责项目技术方案把控与研发；2、参与项目需求分析、业务逻辑流程设计、文档编写；3、领导项目组完成各项业务需求；4、负责项目实施、部署、维护；5、培养团队新人【岗位要求】1、有扎实的编程能力，优秀的设计和代码品位 ；2、熟悉Mysql 、Memcache、Redis、消息队列，nginx等常用WEB组件，有能力优化其使用 ；3、有在线/离线 数据服务设计和实现经验优先，有使用 Hadoop、spark、hdfs 等数据处理工具组件，并有能力优化其使用；4、了解 Css/JavaScript/Ajax/ 等前端技术5、深入了解python / java / golang / PHP 等语言中的一门；6、有较好的沟通能力,"移动互联网,企业服务",15-50人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7172740.html,海淀区,15k-25k,北京一览群智数据科技有限责任公司,3-5年,本科,前景广阔，团队不错,1. 负责大数据平台规划、部署、优化和维护，保证平台稳定可靠高效运行、熟练掌握并使用cdh、hdp、华为云等大数据管理平台2. 熟练掌握hadoop、hive、hbase、spark、kafka、es、oozie、azkaban、flink等分布式组件的工作原理及应用场景，能够独立应用相关组件独立开发项目3. 深入理解大数据平台架构以及适用场景，有较强的自主分析解决问题的能力4. 熟练使用java、python、scala、shell等开发语言5. 深入理解mysql、oracle任一数据库存储原理、有较强的sql能力6. 熟悉linux环境，有过服务器运维经验者优先7. 从事过spark mlib、spark graphx、neo4j、tigergraph、kudu、impala、Phoenix、tez相关项目开发者优先8.  有过真实日增TB级数据量项目开发经验者优先9.  有过两年以上后端开发经验者优先,移动互联网,150-500人,spark,北京
高级java开发工程师,https://www.lagou.com/jobs/7207027.html,朝阳区,18k-30k,北京优势财富科技有限公司,5-10年,本科,大数据技术打造最尖端的金融市场服务平台,工作职责：1. 负责公司To B产品的研发迭代2. 使用大数据分析技术及机器学习，服务二级市场资管业务3. 新技术的调研及落地4. 与团队内外人员的沟通协作任职资格1. 计算机、数学或相关专业本科及以上学历，3年以上工作经验2. 熟练掌握Java编程语言，精通数据结构和算法3. 熟悉Spark，有大数据项目开发经验4. 熟悉主流Web框架如Spring等5. 扎实的数学功底和统计学知识，热爱技术6. 良好的沟通表达能力和团队协作能力7. 熟悉金融二级市场知识优先8. 有Python-Pandas大数据开发经验优先,金融,50-150人,spark,北京
数仓开发（大数据）,https://www.lagou.com/jobs/7177583.html,石景山区,13k-25k,深圳索信达数据技术有限公司,3-5年,本科,七险一金，不加班；晋升快速，涨知识；,经验要求及优先条件：1.计算机及相关专业本科及以上学历;2.有数据仓库项目开发工作经验、熟练运用automation等主流ETL工具专业技能及其它要求：1.熟悉linux平台，熟练掌握shell操作及编程。2.掌握实时流计算技术，有sparkstreaming、flink、storm等开发经验者优先3.熟悉hadoop，熟练掌握基于hive、hbase和spark等组件的ETL开发。4.精通SQL，有较强的SQL优化及编写能力5.精通linux操作系统，熟练掌握shell操作及编程；6.熟悉perl或python等脚本语言7.熟悉数据质量管理、元数据管理及数据标准管理，理解数据管控的意义,人工智能,150-500人,spark,北京
高级后端开发工程师（可线上面试）,https://www.lagou.com/jobs/6995776.html,朝阳区,35k-60k,探探科技（北京）有限公司,5-10年,本科,奖金期权，弹性工作，免费三餐，晋升空间,"工作职责：1. 负责一整套，包括分流、埋点、数据追踪以及效果分析对比的AB测试体系的整体规划与落地2. 负责规划探探智能实验平台未来技术方向，进行全局性和前瞻性的架构设计，以及核心技术细节的实现3. 探索新的实验方法和统计分析技术，推动建立数据驱动机制，提供持续的创新和优化能力，帮助业务实现智能化职位要求:基本要求:1. 四年以上软件开发经验，有较强的编程能力和编程经验，至少熟悉Java/C++/Golang/Python其中一种编程语言，至少会一种脚本语言2. 熟悉高并发、高性能的分布式系统的设计及应用、调优熟悉io、多线程、网络通信，熟悉分布式、缓存、消息等机制3. 了解搜索、推荐、广告等系统4. 了解大数据相关的处理技术，如hadoop,spark,storm等5. 了解统计分析等方法和工具6. 有较好的数据sense，有丰富的数据驱动产品创新的意识加分项：有ABTest相关经验以及统计分析相关背景者优先","移动互联网,社交",150-500人,spark,北京
大数据研发架构师,https://www.lagou.com/jobs/6849120.html,海淀区,25k-45k,江西牛客科技有限责任公司,3-5年,本科,一线互联网知名公司 体制内 薪酬福利好,"工作职责：1、负责云平台软件基础设施中大数据相关产品；2、负责云平台大数据软件基础设施的设计、研发工作；3、负责基于大数据软件基础设施的场景化解决方案。任职要求：1、计算机或相关专业本科（或以上）学历；2、熟悉Linux 平台，分布式系统原理，对存储、计算、网络中的一项或多项有深入的理解和认识；3、熟悉多项大数据处理/分析相关的工具/框架，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kafka ；4、有Hadoop, Mapreduce, Hive, Storm, Spark, kafka 使用经验者优先；5、做事认真负责，沟通能力良好，自学能力较强。","移动互联网,电商",少于15人,spark,北京
大数据架构师,https://www.lagou.com/jobs/7197497.html,朝阳区,40k-80k,秦皇岛旺钧电子商务有限公司,不限,本科,大型互联网平台,"岗位职责：1、负责基于Hadoop/Spark等生态系统的大数据平台的架构设计、技术选型、搭建、开发、管理、监控和性能调优，保证集群高效稳定运行，对数据应用提供数据存储、查询引擎、实时计算、元数据管理的架构设计；2、系统核心部分代码编写、指导和培训工程师、不断进行系统优化；3、跨团队/部门协作，系统分析并解决各类大数据平台相关的运行或数据问题；4、打造有行业竞争力的系统，能够支撑快速发展的数据业务。岗位要求：1、本科及以上学历，5年以上的大数据从业经验。2、有大型分布式系统设计经验，负责过海量数据平台上高可用、高性能分式系统的架构设计。3、精通任意一门编程语言，对大数据基础架构和平台底层原理有深度理解和丰富开发经验, 对复杂系统的性能优化和稳定性提升有一线实战经验，具备相关产品（Hadoop、Hive、HBase、Kafka、MapReduce、Spark等）项目应用研发经验；对开源社区有贡献者优先；4、熟悉Greenplum、TiDB数据库技术有实际生产项目应用经验者优先； 5、具有一定的项目规划和决策能力，善于捕捉业务需求、架构设计存在的问题，并给出有效的解决措施和方法；",通讯电子,50-150人,spark,北京
大数据研发架构师,https://www.lagou.com/jobs/6607616.html,海淀区,15k-30k,北京易捷思达科技发展有限公司,3-5年,本科,远程工作，大牛多，扁平化，氛围好,"【职位描述】：1、负责云平台软件基础设施中大数据相关产品；2、负责云平台大数据软件基础设施的设计、研发工作；3、负责基于大数据软件基础设施的场景化解决方案；【任职资格】：1、计算机或相关专业本科（或以上）学历；2、熟悉Linux 平台，分布式系统原理，对存储、计算、网络中的一项或多项有深入的理解和认识；3、熟悉多项大数据处理/分析相关的工具/框架，e.g. Hadoop, Mapreduce, Hive, Storm, Spark, kafka ；4、有Hadoop, Mapreduce, Hive, Storm, Spark, kafka 使用经验者优先；5、做事认真负责，沟通能力良好，自学能力较强。",数据服务,150-500人,spark,北京
行业解决方案云架构师-北京、广州/深圳,https://www.lagou.com/jobs/6682888.html,海淀区,25k-35k,北京易捷思达科技发展有限公司,5-10年,本科,公司发展快、氛围好,"工作职责：1、  支持公司业务拓展，为客户定制云化解决方案，带领产品和服务团队进行技术，业务验证，及项目招投标技术工作；2、  为客户提供业务和技术层面的架构咨询服务，理解合作伙伴及客户的业务和功能性、性能以及可靠性需求，针对客户的业务需求提供架构设计方案，支持客户或合作伙伴构建上层应用系统和服务；3、  与产品研发团队合作，传递市场需求，共同研发或完善满足特定行业和应用场景的产品；4、  基于金融、政府、能源、交通、制造行业企业等特点，通过云计算、大数据、人工智能等技术孵化行业性创新性解决方案。任职要求:1、  精通基于云计算的应用架构设计方法、应用迁移方法、过程及工具；2、  在某个行业有丰富的售前解决方案咨询，设计落地经验和案例；3、  结构化思维习惯，至少熟悉一种架构方法论及框架，如TOGAF, ITSA, DODAF等；4、  具备良好的文档能力，善于总结沟通，清晰表达技术观点和架构意图，能熟练的编写技术文档；5、  深入了解云计算技术体系、OpenStack及Docker技术框架和企业级应用架构，虚拟化技术（如KVM, Vmware, Hyper-V, Xen等），熟悉云计算相关领域技术，如分布式存储（Ceph）、SDN、容器集群技术Kubernetes、DevOps&CICD、大数据相关技术Hadoop、Spark等；6、  具有Java/Python/PHP/C/C++开发经验，熟悉软件开发过程和设计模式。Spring，Struts, Hibernate 开发框架以及微服务开发应用经验，Tomcat 或WebLogic 等中间件技术/产品使用经验优先。",数据服务,150-500人,spark,北京
计算平台leader,https://www.lagou.com/jobs/7212934.html,海淀区,40k-60k,青岛德谦智行企业管理有限公司,5-10年,本科,独栋办公，独角兽,工作职责：1、负责海量数据的采集，离线和实时计算平台的设计，开发，维护与优化；2、参与计算平台的架构设计，开发，运维等相关工作，并能够进行自动化平台建设；任职资格：必要条件：1、3年以上工作经验;2、掌握hadoop、spark、storm、flink等大数据相关组件，理解底层运行原理，并运用开发3、精通数据采集，离线计算、实时计算4、3年以上的Java或scala开发经验(熟练使用java、scala、python等开发语言);5、了解数据结构及算法（基本算法即可）加分项1、有过参与大数据计算平台的系统规划，并落地的经验优先2、熟悉Kubernetes者优先,企业服务,少于15人,spark,北京
资深数据抓取工程师,https://www.lagou.com/jobs/5253197.html,海淀区,20k-40k,北京金堤科技有限公司,1-3年,本科,"诱人的平台,超牛的技术,超棒的领导",友情提示：我想让你更了解我（天眼查）是谁，投递简历前可以先下载【天眼查】app或者浏览网页端进行产品体验。我们需要你1.负责分布式网络爬虫系统的架构设计与开发；2.负责海量数据的爬取、清洗、解析、入库；3.负责破解各类反爬机制；4.不断提升数据抓取系统的自动化水平。我们希望你1.计算机等相关专业本科及以上学位；2.熟练使用Python或Java；3.熟悉Scrapy或Webmagic等抓取框架的机制和实现；4.了解常见的反爬手段，了解前端知识；5.有大规模爬虫系统实现的经验。【加分项】熟悉Hadoop、Spark、Hive等大数据处理工具不可错过的福利待遇1、国家高新科技企业，优秀员工有机会申请《北京市工作居住证》；2、可为明星员工、硕士以上学历留学生解决北京市户口；3、全年13+N薪，完善的五险一金；4、一年两次涨薪机会；5、大小周休息制，享有加班加时薪资补偿；6、加班福利：提供多种口味免费晚餐，并享有额外饭补，9点以后打车全额报销，保障你的安全；7、高标准的年度体检福利；8、5A级别办公区，地铁出站口即是；9、行业内领先的技术团队，千万量级用户产品，给你更优质的发展平台；10、不定期团建活动，加入我们，让你不再孤单！,数据服务,500-2000人,spark,北京
数据抓取工程师,https://www.lagou.com/jobs/5253176.html,海淀区,10k-20k,北京金堤科技有限公司,不限,本科,"诱人的平台,超牛的技术,超棒的领导",友情提示：如果想了解我（天眼查）是谁，投递简历前可以先下载【天眼查】app或者浏览网页端进行产品体验。我们需要你1.负责分布式网络爬虫系统的架构设计与开发；2.负责海量数据的爬取、清洗、解析、入库；3.负责破解各类反爬机制。我们希望你1.计算机等相关专业本科及以上学位；2.熟练使用Python或Java；3.熟悉Scrapy或Webmagic等抓取框架的机制和实现；4.了解常见的反爬手段，了解前端知识；5.有大规模爬虫系统实现的经验。【加分项】熟悉Hadoop、Spark、Hive等大数据处理工具。不可错过的福利待遇1、国家高新科技企业，优秀员工有机会申请《北京市工作居住证》；2、可为明星员工、硕士以上学历留学生解决北京市户口；3、全年13+N薪，完善的五险一金；4、一年两次涨薪机会；5、大小周休息制，享有加班加时薪资补偿；6、加班福利：提供多种口味免费晚餐，并享有额外饭补，9点以后打车全额报销，保障你的安全；7、高标准的年度体检福利；8、5A级别办公区，地铁出站口即是；9、行业内领先的技术团队，千万量级用户产品，给你更优质的发展平台；10、不定期团建活动，加入我们，让你不再孤单！,数据服务,500-2000人,spark,北京
测试工程师（大数据方向）,https://www.lagou.com/jobs/6991578.html,朝阳区,15k-30k,北京万维之道信息技术有限公司,3-5年,本科,六险一金 话补、饭补、地铁周边、培训,"岗位职责：针对平台大数据相关业务进行相关测试。职位要求：1、2年以上Hadoop及大数据生态圈产品实践经验，如Kafka/HBase/Presto/YARN/Spark等2、有一定的测试开发能力，至少会python、PL/SQL、java、shell中的至少一种语言进行自动化脚本开发3、逻辑能力强，思维敏捷4、对数据敏感,有过数据测试相关经验,熟练编写mysql,mssql,hbase,hive的sql语句的能力5、可以快速熟悉整个生产线业务逻辑，数据库表之间数据关系6、可以验证数据在处理过程中的数据业务逻辑的正确性和数据准确性7、对大型分布式数据库、数据仓库或后台大型集群系统有丰富的测试经验、大数据开发经验者优先8、可单独完成大数据侧的测试工作9、具有较好的文档编写能力、沟通能力、跨团队协作能力","移动互联网,文娱丨内容",150-500人,spark,北京
AI开发工程师,https://www.lagou.com/jobs/7111755.html,朝阳区,15k-25k,深圳市华云中盛科技股份有限公司,3-5年,本科,福利待遇好、团队氛围好、年终奖,,"数据服务,移动互联网",500-2000人,spark,北京
数据仓库开发工程师,https://www.lagou.com/jobs/7055244.html,朝阳区,20k-25k,深圳市华云中盛科技股份有限公司,3-5年,本科,福利待遇好、团队氛围好、年终奖,,"数据服务,移动互联网",500-2000人,spark,北京
java,https://www.lagou.com/jobs/6060882.html,海淀区,10k-20k,北京马赫谷科技有限公司,1-3年,本科,竞争力薪酬，前景好，氛围佳,任职资格：1、Java基础扎实，理解JVM原理，熟悉Collection、Commons、Guava等工具库的使用，有多线程编程经验、网络通信系统/大数据系统开发经验的优先。2、熟悉MySQL等关系数据库，以及相应的SQL优化；具有Redis、Mongo、Hbase、Elasticsearch等NoSQL数据库使用开发经验的优先。熟练使用主流开源框架，如：Springframework、Spring MVC、Spring Security；熟悉Spring Boot、Netty、Lucene等开源框架的优先。3、有hadoop、spark、storm、flink、druid、kafka、zookeeper等大数据分析技术实战经验的优先。4、良好的学习能力、团队协作能力和沟通能力；善于思考，能独立分析和解决问题；对大数据分析、机器学习有浓厚兴趣的优先。,"信息安全,数据服务",15-50人,spark,北京
大数据开发,https://www.lagou.com/jobs/7174025.html,海淀区,15k-30k,北京鼎普科技股份有限公司,3-5年,本科,七险一金、餐补交通补贴、周末双休等,岗位职责：1、负责数据应用产品的研发及架构相关工作。2、和产品经理一起推进项目需求落地，将业务和产品需求转变成为技术实现方案。3、深入理解产品的需求、场景、后续发展方向，参与核心模块代码开发。4、作为关键技术攻坚人员，解决重大项目的技术疑难问题。任职要求：1. 统招一本（或者二本且英语6级）及以上学历，5年以上大数据相关开发设计经验；2. 编程能力扎实，熟悉JAVA/PYTHON/SCALA中至少一种，具有良好的数据结构、算法、操作系统、计算机网络等基本知识；3. 对大数据主流技术如Hadoop、HBase、Phoenix、Kafka、Flink、Spark、Elasticsearch等有深入理解和丰富的使用经验，有平台建设经验优先；4. 有网络安全、数据安全相关产品开发经验优先；5. 学习能力强，善于独立思考，思维活跃，对技术有强烈渴望；6. 较好的沟通和团队配合能力，以及对工作的强烈责任。,"移动互联网,信息安全",150-500人,spark,北京
数据建模工程师,https://www.lagou.com/jobs/6837892.html,东城区,20k-40k,高济（天津）投资有限公司,5-10年,本科,"BAT大拿,资金雄厚,弹性工作","1.深入挖掘和分析业务部门建模需求，利用数据能力去建模，基于多维度数据、结合数据特征分析，在会员、营销、选品、供应链等相关业务场景进行定制化建模； 2.研究机器学习算法在不同场景下的应用，能够针对新零售的不同营销阶段进行特征构建、变量筛选，并选择匹配算法进行模型训练； 3.在其它团队协助下对于模型进行上线部署、监控调用状况以及持续优化。 任职资格: 1.本科及以上学历，数学、统计、计算机等相关专业； 2.熟悉常用机器学习算法理论,对于常用的预测模型比如回归模型和树模型有过实践经历； 3.熟练使用R、Python等数据处理工具，熟悉Spark，Hadoop优先； 4.能够独立完成机器学习等模型建模，包括变量特征衍生，处理，特征筛选，转换，建模，评估工作； 5.能够较好理解各种预测模型的优劣，并且能在不同的业务场景下采取相应的模型； 6.3-5年数据分析挖掘或者统计分析建模经验，零售、电商、供应链行业经验者优先。","医疗丨健康,数据服务",150-500人,spark,北京
推荐算法工程师,https://www.lagou.com/jobs/6989581.html,朝阳区,30k-50k,简阳联盟凯睿企业管理有限公司,3-5年,本科,公司固定12薪+3-6个月年终奖；,1、负责推荐产品的推荐架构搭建，优化模型与推荐策略，达成业务目标；2.、通过机器学习方法，用先进的召回和排序手段，优化产品推荐效果和数据效果计算机或者相关专业，扎实的C/C++/Python/Java开发功底熟悉hadoop、spark等常用的大数据处理平台熟悉常用的推荐算法，并具备独立将算法应用于实际生产系统的成功经验和能力有大规模海量数据机器学习/数据挖掘/搜索引擎相关经验,"企业服务,人工智能",150-500人,spark,北京
资深C++开发工程师（推荐方向）,https://www.lagou.com/jobs/7151967.html,海淀区,25k-40k,网易（杭州）网络有限公司,5-10年,本科,三餐免费,岗位职责：1. 负责网易新闻推荐系统在线预估服务的设计与开发工作，支持多种深度学习模型的在线服务2. 负责在线特征抽取、模型管理、深度学习模型与线性模型对接等工作，支撑高可用预估系统的开发3. 基于Tensorflow Serving设计与开发深度学习线上预估系统，对性能问题进行定位分析与解决，实现高性能、稳定、可扩展职位要求：1. 熟练使用c++在linux平台进行项目开发，了解c++11、c++14等规范，有较强的动手实践能力与问题分析能力2. 具备架构设计能力，了解常用设计模式，具备高并发、分布式项目的设计与开发经验，了解容器化、服务管理、负载均衡等相关技术与组件3. 对性能调优、多线程编程、数据结构和算法设计具有深刻的理解与实践经验4. 熟悉tensorflow、tensorflow serving以及性能优化方案5. 有推荐系统、广告预估、搜索等相关项目的实际开发经验最优6. 具有Spark、Hadoop、Storm 等大规模分布式计算平台的使用经验7. 了解常用推荐算法原理(LR/DNN/FM/GDBT等)8. 善于学习了解前沿知识与技术，自驱能力较强，有较强的技术选型及规划能力、较好的沟通能力，积极主动，愿意接受挑战，抗压能力强,电商,2000人以上,spark,北京
高级/资深Java开发工程师,https://www.lagou.com/jobs/7110996.html,海淀区,20k-35k,广州华多网络科技有限公司,3-5年,本科,大平台；快速发展；团队氛围；福利保障,"工作职责：负责YY教育线业务后台架构设计、开发及维护。任职资格：1. 3年以上Java相关开发经验；2. 精通Java语言，精通多线程编程、网络编程，有性能优化经验者优先；3. 具备独立设计并实现高并发、高可用的大型应用的能力优先；4. 熟练应用成熟的分布式缓存、分布式存储技术方案；5. 熟悉TCP/IP、HTTP等协议, 了解分布式应用的各种协议，Thrift/Protocol Buffer等；6. 熟练使用Spring，MyBatis等常见开发框架；7. 熟悉 Hadoop、Spark、等大数据处理框架和平台以及有推荐系统设计经验的优先。",文娱丨内容,2000人以上,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7204348.html,海淀区,10k-20k,杭州安恒信息技术股份有限公司,3-5年,本科,上市公司 五险一金,岗位职责：1、负责各项目海量日志信息收集、分析/查询、分布式存储、的代码实现；2、协助建立并完善数据的分析挖掘流程及体系。任职资格：1. 精通多线程，精通微服务开发，有较强的源码研究理解能力；2、熟练使用Spring Boot、Spring Cloud、MyBatis等常用框架;3、具备一定的数据仓库ETL设计及开发经验，精通数据仓库逻辑架构、元数据管理、数据质量监控等数据仓库主要环节，有BI经验者优先4. 精通Spark、Flink、Hive、Hbase、Storm等大数据平台和开源软件的设计和使用；5、熟练使用HiveQL、SparkSQL6、能够熟练应用一种或多种主流数据库（如：Teradata、Greenplum、Oracle、MySQL等）7、熟练使用一种或多种大数据产品CDH，HDP，以及cloudmanager，ambari；8、有k8s设置及管理开发经验者优先。,"信息安全,数据服务",500-2000人,spark,北京
高级数据开发工程师,https://www.lagou.com/jobs/7084682.html,海淀区,20k-30k,启迪公交（北京）科技股份有限公司,3-5年,本科,补充医疗,"工作职责：1.        负责公司业务系统的服务端数据和应用的开发2.        负责搭建业务系统微服务平台，解决数据对接和开发过程中的各种问题，进行系统优化；3.        深入理解业务需求，负责数据产品需求分析，根据数据建模完成相关设计及编码；4.        配合产品团队，完成对外包项目的技术管控。 任职要求：1.        计算机相关专业本科及以上学历，2年以上工作经验，有数据挖掘/BI开发经验；2.        熟悉HIVE开发，熟练使用HQL，有阿里云MaxCompute使用经验优先,至少熟悉一种关系型数据库如MySQL、Oracle等；3.        熟悉Hadoop、MapReduce、Spark、Flink等分布式计算框架，进行海量数据模型设计、数据ETL开发；4.        有Java开发经验，有一定的分布式开发经验，对消息服务、负载均衡、高可用等机制经验；5.        思维灵活,逻辑缜密,能快速理解业务；6.        具备数仓或BI模型设计能力优先；7.        具备良好的编码习惯和技术文档编写能力，具有很强的沟通和协调能力，能够承受较强的工作压力和强度，有工作责任心。","移动互联网,消费生活",15-50人,spark,北京
大数据开发工程师,https://www.lagou.com/jobs/7147035.html,朝阳区,15k-25k,北京睿至大数据科技有限公司,5-10年,本科,五险一金，弹性工作，带薪年假，节日福利,"岗位职责:1、管理、优化并维护集群,解决各种线上问题;2、参与ETL开发，数仓设计与搭建，平台工具开发、数据治理;3、为海量数据及其上的大规模数据挖掘、数据分析、机器学习业务系统提供可靠、高效的支持；4、研究业界最新的大数据技术，提供有通用性的大数据解决方案；5、乐于挑战技术难点，快速理解业务场景，从具体问题中抽象出通用的解决方案。任职资格:1、计算机或相关专业本科以上，5年以上工作经验，不少于4年大数据开发经验；2、具备扎实的Scala语言编程基础，具备良好的编程习惯，较强独立解决问题的能力；3、精通Spark架构，对社区有贡献者加分;4、熟练掌握hadoop生态的大数据开发工具，包括Flink，Kafka，Hbase，Hive,ES等，拥有海量数据处理经验者优先；5、参与过大型复杂分布式系统的设计、数仓架构者优先；6、熟悉多线程编程和JVM性能调优，有高并发、高吞吐量服务开发经验者优先；7、做事严谨踏实，责任心强，具有良好的沟通能力和团队意识；8、有华为大数据服务平台开发经验者优先；9、思维活跃、理解能力强，具有良好的沟通协作能力者优先；","数据服务,信息安全",150-500人,spark,北京
高级服务器开发,https://www.lagou.com/jobs/6861932.html,海淀区,25k-45k,阿里云计算有限公司,应届毕业生,本科,五险一金 带薪年假,"1、本科以上学历，计算机专业相关专业；2、熟悉 Python 语言以及常用的类库，3 年左右 python 或者 Golang 开发经验；3、扎实的面向对象编程思想，具备模块化编程的思维与经验，熟悉 Git；4、了解 python Web 开发框架如 Flask/Django 等优先；5、对代码和设计质量有严格要求，重视 Code Review，知道良好的编程习惯的标准；6、有基于 Python Web 的高并发设计和实现经验者加分；7、有推荐系统 lambda 架构经验者加分；8、有 hadoop/spark 等大数据处理经验者加分；9、有机器学习经验者加分。任职要求：1、全年日制本科以上学历；2、5 年以上实际服务器项目开发实施工作经验；3、熟悉 JAVA，php，ruby， python，C#语言中的一种，愿意深入学习 python；4、熟悉 MySQL, redis，MongoDB 等数据库；5、掌握面向对象的编程和建模方法；6、了解前端 HTML，javascript 技术；7、善于学习新技术、新语言，具有良好的分析和解决问题的能力；8、对代码和设计质量有严格要求，重视 Code Review，知道良好的编程习惯的标准；9、有良好的沟通能力者、优秀的解决问题能力者优先。","电商,企业服务",2000人以上,spark,北京
JAVA开发工程师,https://www.lagou.com/jobs/7198809.html,西城区,40k-80k,优师传道（大连）教育科技有限公司,应届毕业生,本科,央企-不加班-待遇很好,多个JAVA职位，央企-不加班-待遇很好【岗位职责】     岗位职责     1、负责公司监控、流式计算、告警平台技术选型和底层架构设计的战略规划，带领团队完成有质变的技术解决方案和技术特性。     2、负责开展监控、告警平台整体评估、架构和关键模块的开发。     3、对实时流式计算平台建设有很深的理解，突破现有技术难题。     4、负责新技术的调研，并能在团队进行推广应用。     5、能进行组内外的合作协调。          任职资格     1、全日制本科及以上学历，计算机或相关专业，5年以上工作经验；      2、具有扎实的Java、大数据或python编程能力，精通数据结构和算法；     3、熟悉分布式系统的监控、告警，高可用原理和设计理念；     4、技术栈比较全面，精通流式计算spark streaming，包含flink，storm，kafka等，需要有对开源软件有二次开发经验；     5、熟练掌握基本的Linux操作系统和某种脚本语言编程（如Shell等）；     6、有丰富的团队管理经验；     7、热爱技术专研探索，精读某些开源软件源码者优先；     8、具有监控、告警、流式计算平台建设经验优先；,其他,500-2000人,spark,北京
数据算法工程师,https://www.lagou.com/jobs/7198281.html,海淀区,15k-30k,北京寄云鼎城科技有限公司,3-5年,本科,五险一金，带薪年假，弹性工作，年度体检,岗位职责：1. DA组件开发 （包含组件发布成分析任务）；2. DA分析工程系统后台维护。任职要求：1. 精通spark，spark streaming编程；2. 精通一种面向对象语言（包括python，java，C++）；3. 有实际的大数据分析经验；4. 熟悉机器学习算法；5. 能读英文文献。优先条件：有文章发表者优先,"移动互联网,数据服务",50-150人,spark,北京
大数据架构研发实习生,https://www.lagou.com/jobs/6018078.html,海淀区,4k-6k,北京达佳互联信息技术有限公司,不限,本科,"带薪年假,年度体检,免费午餐,弹性工作",工作内容1、Hadoop生态子系统的研发、测试与优化改进工作，解决实际业务需求与性能问题。子系统包括但不限于HDFS，HBASE，YARN，SPARK，KAFKA、FLINK、DRUID等。2、承担数千台规模Hadoop集群的管理工作，解决超大规模Hadoop集群在应用与运行过程中的出现各种问题，保证集群的高效稳定运行。3、和开源社区保持交流，从社区引入对公司业务场景有帮助的特性与系统，或将内部研发的功能贡献到社区。任职要求：1、计算机或相关专业，本科及以上学历，每周至少4天，连续实习3个月以上。2、扎实的基础知识，如操作系统、计算机网络、计算机体系结构，熟悉数据结构与算法。3、熟悉java或C++等至少一种面向对象语言，工程质量自我要求高，比较强的程序设计与实现能力。4、思维活跃，熟悉Hadoop生态子系统尤佳。5、强烈的责任心，对工作有激情，良好的沟通能力。,文娱丨内容,2000人以上,spark,北京
数据挖掘算法工程师/专家,https://www.lagou.com/jobs/7122651.html,海淀区,20k-40k,北京达佳互联信息技术有限公司,不限,本科,六险一金，下午茶,"1、负责快手推荐相关业务的数据挖掘与分析；2、建立用户数据分析模型，提供核心算法和基础特征，为推荐系统的搭建提供支持；3、分析站内外海量数据，探索平台新的业务增长点。任职要求：1、良好的编码与代码控制能力, 有扎实的数据结构和算法功底； 2、优秀的分析问题和解决问题的能力，能够从海量数据中发现关键特征； 3、熟悉Linux开发环境，熟悉Python语言，熟悉Hadoop相关开源组件如：Hive/Spark/Storm等；  4、具有大规模数据挖掘、机器学习经验者优先。",文娱丨内容,2000人以上,spark,北京
