job_name,job_url,job_location,job_salary,job_company,job_experience,job_class,job_given,job_detail,company_type,company_person,search_key,city
Spark 数据工程师,https://www.lagou.com/jobs/6069628.html,普陀区,30k-60k,上海游盾网络科技有限公司,3-5年,本科,同事Nice 发展空间大,岗位职责：1、负责构建 Spark/Hadoop 大数据处理系统2、使用 Spark/Hadoop 进行数据处理、查询和统计等工作3、负责基于 Scikit-Learn 和 Spark ML 进行机器自动学习的设计和编程岗位要求：1、本科以上学历，熟悉 Spark 相关技术，至少有一年的 Spark 开发经验2、熟悉 Spark SQL 和 Hadoop 生态圈3、熟练使用常用机器学习的框架和工具，有实际机器学习项目经验者优先4、精通 Python 或 Scala,移动互联网,15-50人,spark,上海
Java+Spark资深开发工程师,https://www.lagou.com/jobs/6934185.html,浦东新区,21k-42k,上海华钦信息科技股份有限公司,3-5年,本科,金融、银行、外企,"Java,J2EEMinimum 7 years experiences as a full stack developer and minimum 2 year in a team lead roleComputer science or related engineering degree is requiredJava server side technologies for enterprise development such as Spring framework and messaging frameworks such as JMSAn enterprise RDMS database such as Oracle or SybaseBig data:At least 8 years of experience in information technology and software development, with 5+ years of financial service experiences.5+ years of experience working with Java, J2EE, Oracle, SQL, PL/SQL is required 3+ years of experience with development of user interface using Angular-JS is requiredExperience in using Open Source technology is required.","数据服务,金融",500-2000人,spark,上海
运维主管 (MJ000190),https://www.lagou.com/jobs/5997315.html,浦东新区,20k-40k,上海剑圣网络科技有限公司,5-10年,大专,跨国项目；团队氛围佳,"岗位职责：1.负责公司大数据基础平台的规划、部署、管理理和优化，保障平台稳定可靠高效运⾏；2.负责Hadoop、HBase、Hive、Spark、Kafka等集群的维护、优化工作；3.负责故障追踪定位，分析和解决问题，并制定后续的改进和规避⽅方案；4.负责系统的架构优化、容灾优化、性能优化等；5.深⼊理解公司大数据平台架构，发现并解决性能瓶颈，⽀支撑业务和数据量量的快速增长；6.了解产品业务，加⼊产品从原型设计到正式上线的整个过程，基于对产品的理理解，从技术架构的⻆角度给予持续的优化意见；7.开发大数据自动化运维、监控、故障处理理⼯工具，监控所有基础设施组件、应⽤用程序，提供紧急应急措施；8.跟进推动复杂技术方案，保证项目的成功完成，优化运维体系并带领和提升运维团队，实现可靠和可扩展的运维环境。任职要求：1.有3年以上Hadoop生态系统维护经验, 3年以上运维团队管理经验；2.熟悉Hadoop、HBase、Kafka、Hive、Spark等组件的工作原理理，搭建、调优并维护过spark、Hive、Storm、Kafka、Redis等服务；3.熟悉Linux开发环境，熟练掌握Java/scala/python等任一编程语言，算法基础扎实，编码能⼒力力优秀4.熟悉分布式系统设计范型，有大规模系统设计和工程实现者优先；5.熟悉Linux操作系统，熟练使用Perl、Python、SHELL等至少一种语言；6.深入理解TCP/IP的通讯原理，掌握各种路由协议的技术原理及部署方式，熟悉VPN、防火墙、NAT等网络技术和应用；7.熟悉开源监控管理理软件的基本原理理和部署方式；8.熟练Mysql、Nginx等常见服务的安装部署、日常运维和优化。","移动互联网,游戏",150-500人,spark,上海
大数据运维工程师 (MJ000167),https://www.lagou.com/jobs/5653206.html,浦东新区,15k-30k,上海剑圣网络科技有限公司,3-5年,不限,数据量巨大 跨国项目 项目前景好,岗位职责：1、管理公司大数据集群，提供高可用、高性能大数据集群系统，并保障系统稳定运行；2、负责大数据集群各服务自动化运维与监控工具，日常监控、数据备份、数据监控、数据报警及故障处理；3、负责大数据平台集群的权限管理、故障处理、日常错误情况处理等；4、根据业务需要优化hadoop环境，包含MR作业、计算框架、提升集群吞吐并降低成本。职位要求：1、全日制本科及以上学历，计算机或相关专业，3年及以上相关工作经验，理解并实施大数据产品的部署场景；2、熟悉Hadoop生态圈，对HBase、Hive、Spark、Impala、Kafka、Redis、azakaban、zookeeper、yarn等主流分布式开发套件有一定认识， 有相关安装部署及调优经验者优先；3、对Cloudera 有使用及运维经验，熟悉日志采集工具，如filebeat、logstash、flume等；4. 熟悉Linux类操作系统的基础命令操作，能够编写脚本开展日常运维工作；5. 熟悉Linux开发环境，会使用Shell/Java/Python中的一门脚本语言；6. 熟悉常见开源工具如Nginx、Zabbix、Grafana等的安装配置和使用。,"移动互联网,游戏",150-500人,spark,上海
Java数据开发,https://www.lagou.com/jobs/7194454.html,徐汇区,20k-32k,深圳苹果树数据科技有限公司,3-5年,本科,腾讯团队,任职资格：    1、本科及以上学历，计算机相关专业；    2、3年以上JAVA开发经验，基础扎实，掌握常用的微服务开发框架，理解JVM原理，理解io、多线程、集合等基础框架，掌握面向对象设计开发;     3、精通MySQL等数据库原理及性能优化；    4、具有大数据开发经验，熟悉Python、R等语言，熟悉Spark开发，熟悉常用的大数据开发工具；    5、熟悉Unix/Linux操作系统原理、常用工具；    6、全面并且扎实的软件知识结构（操作系统、软件工程、设计模式、数据结构、数据库系统、网络安全）；    7、具备良好的分析解决问题能力，能独立承担任务和有系统进度把控能力；    8、好学、责任心强、思维缜密敏捷、良好的对外沟通和团队协作能力；    9、有海量数据和高并发开发经验者优先。,"金融,数据服务",150-500人,spark,上海
解决方案架构师--上海,https://www.lagou.com/jobs/7030602.html,徐汇区,20k-30k,杭州观远数据有限公司,5-10年,本科,牛人团队 成长空间 期权激励 独当一面,岗位职责：1.配合销售、顾问团队工作，在需求沟通、方案讲解、产品POC、招投标等环节提供支持；2.作为解决方案架构师，能够为客户提供技术咨询服务，结合产品能力，针对性的给出项目技术方案设计；3.负责技术材料、用户案例、产品解决方案、市场营销材料的总结与编写。岗位要求：1.本科及以上学历，计算机相关专业优先；2.5年以上工作经验，至少1年售前或咨询经验，参与过数据平台、数据分析类项目，熟悉相关领域的产品、解决方案和系统建设方法；3.熟悉常见的技术栈，包括传统架构、主流大数据架构（如Hadoop，Spark等），能够理解并阐明各类技术原理；4.优秀的文档编写能力、演讲能力，资源协调和关系管理能力；5.熟悉主流BI产品优先。,"企业服务,数据服务",150-500人,spark,上海
数据BP-点评APP数据仓库开发,https://www.lagou.com/jobs/6786138.html,长宁区,25k-40k,北京三快在线科技有限公司,3-5年,本科,上市公司 核心部门 大牛云集,,消费生活,2000人以上,spark,上海
java开发工程师,https://www.lagou.com/jobs/6220537.html,浦东新区,14k-24k,奥解思信息科技（上海）有限公司,1-3年,本科,福利好，弹性工作制，培训机会多,1、2年以上Java开发经验，良好的基于Java系统设计和开发相关经验。2、本科及本科以上计算机相关专业3、熟悉JAVA(核心JAVA、多线程、Spring、Restful服务)4、熟悉Maven、GIT、Hudson、JUnit等类似技术。5、数据库- Oracle或具有SQL、PL/SQL编程经验。6、unix /Linux脚本编写技巧(Korn shell)7、具有Mongo DB经验，会Spark优先考虑8、有消息服务(JMS、Tibco EMS)和Websphere application server方面经验优先。9、英语优秀优先考虑。,金融,500-2000人,spark,上海
ETL工程师,https://www.lagou.com/jobs/5184192.html,浦东新区,15k-25k,上海商涌网络科技有限公司,1-3年,本科,学习成长快 团队氛围好发展空间大新兴行业,"职责描述： 1、负责项目中数据处理工作，分析原始数据并采用合适的算法，对数据清洗、转换、入库与分析；2、负责数据仓库ETL流程的优化、表结构与表关系设计及解决ETL相关技术问题；3、整体考虑ETL的架构、性能、存储、调度等问题 ；4、钻研业务，能够更为深层次地理解业务数据需求。任职要求：1、 计算机或统计、数学相关专业本科及以上学历，两年以上ETL相关的工作经验；2、 参与并承担过数据统计，数据挖掘等相关数据处理开发工作；3、 熟悉hive,sparksql熟悉其基本理论。有hive，sparksql调优、解决SQL性能问题经验； 4、 熟悉关系型数据库理论，熟悉掌握主流数据库系统中的一种或多种，例如Oracle、DB2、MYSQL、SQL Server； 5、 熟悉SQL语句，对SQL查询优化有丰富的经验，熟悉PL/SQL，熟悉存储过程、函数、包、触发器等的开发； 6、 了解ETL架构，有一定的ETL开发经验，了解日常作业的部署和调度； 7、 至少熟悉一种ETL开发工具，如DataX,Flume,Sqoop,Kettle等； 8、 掌握Shell脚本编写，至少掌握一种编程语言如Python,Java,Scala等； 9、 具有基本的数据敏感性加分项:1、 熟悉Hadoop,Spark,Hive,HBase,Docker；2、 有过保险/金融/医疗行业从业经验；3、 善于沟通","数据服务,人工智能",50-150人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6626474.html,浦东新区,11k-22k,上海商涌网络科技有限公司,3-5年,本科,学习成长快 团队氛围好发展空间大新兴行业,"职责描述： 1、参与大数据平台环境搭建，架构设计及优化，源码二次开发；2、参与基于HBase分布式数据高并发查询架构设计及优化，程序开发；3、参与基于Flink实时平台，实现数据采集，清洗和集成开发任务，并及时跟进解决问题；4、钻研最新大数据技术，能够更为深层次地理解数据技术架构。任职要求：1、计算机相关专业本科及以上学历，两年以上大数据开发工作经验；2、熟悉Linux、Unix系统及掌握基本命令；3、熟悉Hadoop，HBase，Flink，Spark及其基本理论。有过HBase实时高并发查询开发经验和Spark开发经验；4、熟悉使用SQL语句，对SQL查询优化有丰富的经验，熟悉MySQL，熟悉存储过程、函数、包、触发器等；   5、掌握Shell脚本编写，至少掌握两种及以上编程语言如Python,Java,Scala等； 6、了解高并发实时访问开发及其架构构建，具备实施调优经验；7、对Spark，Hadoop等开源的源码有过研究，对于新技术有研究热情，较强的学习能力和团队协作意识；8、有过保险/金融/医疗行业从业经验者优先。","数据服务,人工智能",50-150人,spark,上海
应用运维工程师-上海,https://www.lagou.com/jobs/5876944.html,徐汇区,20k-40k,腾讯科技（深圳）有限公司,5-10年,本科,知名互联网企业工作经历,"工作职责：负责IT系统整体运维平台的设计与开发工作；负责跟进IT项目的运维需求收集、建设、优化；负责新兴运维技术探索与应用，持续提升系统运维能力。任职资格：计算机相关专业本科及以上学历，至少5年以上应用运维实战经验或运维自动化平台研发经验，熟悉软件开发和系统架构;精通python/java/django等开发语言与技术,熟悉分布式框架和微服务架构;熟悉运维相关系统工具与流程，熟悉DEVOPS/CI/CD等，具备相应的二次开发能力，如：变更系统、监控系统等;熟悉各种开源组件的使用，包括jenkins、redis、rabbitmq、saltstack、docker、zabbix等;熟悉主流数据库Oracle/Mysql/SQL SERVER等，熟悉SQL/SHELL等的开发;熟悉大数据体系，如hadoop、spark、storm、kafka等的优先;高度的责任心、良好的沟通技巧和团队合作精神，热爱运维开发工作",社交,2000人以上,spark,上海
AI基础-高级后台开发工程师,https://www.lagou.com/jobs/6177858.html,徐汇区,20k-40k,腾讯科技（深圳）有限公司,不限,本科,"前沿技术,发展平台,专业深度,AI",岗位职责：1. 负责机器学习，深度学习算法的工程化和服务化，研发高可用的线上服务系统。2. 负责AI平台的搭建，包括分布式计算框架和数据平台的研发。岗位要求：1.    扎实的数据结构，算法和编程功底，有良好的编程习惯和风格; 2.    熟悉 Linux 开发环境，精通 Go/Python/Scala/Java等一种或者几种编程语言，熟悉C/C++； 3.    熟悉深度学习算法（CNN/RNN等），掌握深度学习框架（Caffe/Tensorflow/PyTorch等）者优先; 4.    有海量数据处理和并行计算开发经验者优先，如 Hadoop/Spark/ES等; 熟悉K8S和Docker等容器技术优先； 5.    精通Spring MVC、ORM框架（ibatis或hibernate）、模板引擎（velocity）、关系型数据库设计及SQL; 6.    优秀的分析问题、解决问题能力和团队合作意识、有良好的责任心、善于沟通、工作上能自主驱动、用于接受挑战、富有创新精神;,社交,2000人以上,spark,上海
算法专家（风控安全）(J11334),https://www.lagou.com/jobs/6775949.html,闵行区,25k-40k,上海钧正网络科技有限公司,3-5年,硕士,年底绩效奖金 五险一金 餐补夜宵,,"移动互联网,硬件",2000人以上,spark,上海
TS-数据开发工程师,https://www.lagou.com/jobs/6727378.html,虹口区,20k-40k,顺丰科技有限公司,3-5年,本科,职位发展前景大，福利高,职责描述：1.负责设计落地数据ETL、收集、关联和计算；2.负责整合数据，挖掘需要的数据信息；3.负责系统的营运指标报表开发、营运日常数据获取；任职要求：1.计算机相关专业，本科及以上学历，3年以上相关工作经验，具有互联网、大数据开发经验；2.熟悉hadoop、hbase、hive等其中一个或者多个技术；3.熟悉大数据领域的解决方案形态，数据仓库建模和设计，ETL设计思路，海量分布式数据处理架构；4.熟悉常见主流数据库系统；5.阅读并改写过hadoop/spark源码优先；6.语言方面熟悉python、php者优先；7.良好的沟通能力，有团队合作精神和责任感。加分项：1.参与过BI系统设计与开发；2.熟悉git等开发管理工具，熟悉Unix/linux系统；3.有较好的SQL性能调优经验。,"软件开发,数据服务",2000人以上,spark,上海
高级大数据平台架构师,https://www.lagou.com/jobs/6480677.html,虹口区,30k-50k,奇虎360科技有限公司,5-10年,本科,牛人多、空间大、环境佳,"职位描述：1、参与商业化广告数据平台相关系统的规划设计、开发与运维，包括但不限于离线Hadoop平台、实时流计算平台、OLAP平台、调度系统等；2、支撑商业化业务目前日均100TB/100亿流量下的数据仓库、实时报表等关键业务，并有能力推进底层数据架构的中台化和进行合理的数据治理。 任职要求：1、掌握Spring      Boot, Spring Cloud, Angular或者VUE等，有大数据平台开发经验；2、熟悉HDFS/YARN/MapReduce/Spark/Flink/Druid/Presto等中的至少一种大数据生态技术的原理，有深度使用经验，能够深入阅读与理解源码，有源码贡献经验者优先；3、熟悉Java/Scala/Python/Shell等开发语言，了解JVM原理，有一定的JVM优化经验；4、理解数据仓库分层模型，有数据治理经验优先；5、具有良好的团队合作意识和良好的沟通能力，思维敏捷、有主动发现问题与解决问题的能力。",信息安全,2000人以上,spark,上海
算法工程师,https://www.lagou.com/jobs/5376839.html,虹口区,25k-50k,奇虎360科技有限公司,3-5年,硕士,牛人多、空间大、环境佳,职位描述：1、设计和实现各种策略，提升广告平台的变现效率和用户体验；2、维护和优化CTR、CVR、Prerank、流量控制、Pacing等广告竞价相关策略和模型；3、创意模板生成、配图优化、文案生成等创意优化策略。任职要求：1、优秀的代码能力，数据结构和算法基础扎实；2、熟悉机器学习、数据挖掘的基本理论和常用算法，有相关工作经验；3、有较强的分析和解决问题的能力，有持续学习新知识的能力和意愿；4、沟通能力强，有优秀的团队合作意识。加分项：1、熟悉Hadoop/Spark/Storm等大规模分布式计算系统；熟悉Linux、Python等开发环境；2、了解计算广告学的相关知识，有实际广告投放系统工作经验。,信息安全,2000人以上,spark,上海
高级算法工程师（广告方向）,https://www.lagou.com/jobs/6800328.html,杨浦区,25k-35k,达疆网络科技（上海）有限公司,3-5年,本科,商业化 互联网 新零售,工作职责：1. 参与设计、搭建京东到家个性化广告系统算法模块；2. 研究O2O广告、CTR/CVR预估等算法模型；3. 优化机制策略，不断改善用户体验、广告效果；岗位要求：1. 熟练掌握数据挖掘、机器学习、深度学习的基础理论和方法；2. 熟悉常用的推荐算法，如关联规则挖掘、协同过滤等；3. 有一年以上广告、推荐、搜索算法开发经验；4. 有Hadoop/Spark等大数据工具使用经验；5. 对技术有热情，动手能力强，参加过各类竞赛并取得较好成绩。,消费生活,2000人以上,spark,上海
1121SD-资深开发工程师,https://www.lagou.com/jobs/6496381.html,浦东新区,15k-30k,平安科技（深圳）有限公司,3-5年,本科,"五险一金,带薪年假,节日福利,绩效奖金",,金融,2000人以上,spark,上海
1121T1-Java架构师,https://www.lagou.com/jobs/6523024.html,浦东新区,20k-40k,平安科技（深圳）有限公司,5-10年,本科,"五险一金,带薪年假,节日福利,绩效奖金",,金融,2000人以上,spark,上海
公共数据-数据开发工程师,https://www.lagou.com/jobs/5878337.html,长宁区,25k-45k,北京三快在线科技有限公司,3-5年,本科,上市公司 核心部门 大牛云集,,消费生活,2000人以上,spark,上海
大数据架构师,https://www.lagou.com/jobs/6499991.html,徐汇区,25k-50k,上海驰骛信息科技有限公司,5-10年,本科,体检 员工餐 不打卡 地铁周边,"工作职责：1. 根据项目需求，分析、设计、并实现可扩展的系统架构方案。2. 负责海量数据采集、处理及存储、应用方案的技术选型及架构实现。3. 负责开发海量数据分析/查询、分布式存储、流式/实时计算等应用层架构搭建及核心代码实现。4. 追踪大数据和云计算的最新产品和技术，并协调团队应用于数据产品研发。5. 参与代码的实现，并编写技术文档，对通用技术实现复用。任职要求：1. 本科及以上学历，5年以上大数据设计和研发经验。2. 熟悉Hadoop底层文件系统，熟悉Hadoop分布式计算框架（HDFS、Hbase、Hive、Mapreduce、Spark、Storm、Flink等。3. 精通Java, Scala, Python 至少两种编程语言，有较强的分布式计算基础和软件工程能力。4. 熟悉业界有影响力数据仓库和大数据领域的产品、解决方案形态和技术，熟悉OLAP、OLTP引擎和DB，熟悉主流数据整合、治理技术和工具。5. 熟悉大数据和数仓领域的系统架构设计方法，有海量数据系统的安装部署维护经验，对大规模数据并行计算／传输／处理等有丰富的经验者优先。6. 熟悉掌握通用大数据数据合并、建模、抽取、分析挖掘机、展示等挖掘算法，具有在实际项目中结合业务场景开发大数据算法的经验者优先。7. 具备DMP、CDP、数据中台设计和实施经验者优先。8. 具备Amazon AWS、Microsoft Azure、Alibaba Cloud等云厂商产品和技术使用经验者优先。","数据服务,移动互联网",50-150人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6888789.html,徐汇区,10k-20k,上海驰骛信息科技有限公司,1-3年,本科,团建活动、 带薪年假、定期体检、零食水果,"岗位职责：1. 参与大数据产品的设计和开发，包括数据的采集，清洗，预处理，存储，建模，分析挖掘等2. 根据业务用户需要分析数据，提供数据支持3. 参与公司大数据产品的运维和监控，保障数据质量和服务稳定性任职要求： 1. 具备本科以上学历, 计算机, 软件以及相关专业, 3年以上大数据开发经验2. 具备3年以上数据仓库建模和开发经验者优先3. 熟练掌握Java, 对Hadoop相关的技术和组件(HDFS, MR, Hbase, Hive, Spark, Storm, Kafka等）有全面深入了解4. 熟练掌握Shell或者Python中的一种5. 具备2年以上Spark调优经验者优先6. 具备实时计算(Kafka+Storm/Spark Streaming. 经验者优先7. 具备数据分析和数据挖掘方面经验者优先","数据服务,移动互联网",50-150人,spark,上海
0231G9-资深大数据开发工程师-上海,https://www.lagou.com/jobs/6973773.html,浦东新区,11k-20k,中国平安人寿保险股份有限公司,3-5年,本科,"五险一金,年终分红,节日福利,员工旅游",,金融,2000人以上,spark,上海
搜索推荐算法专家,https://www.lagou.com/jobs/7162326.html,杨浦区,40k-70k,上海识装信息科技有限公司,5-10年,本科,独角兽、业务前景佳、技术氛围好,岗位职责： 1.负责信息流推荐系统研发，效果优化，保障相关场景持续的指标提升； 2.深入产品和业务，能从数据中发现机制和算法的不足，提出改进方案并推动实现； 3.研究前沿算法技术，结合业务特点做算法改进和技术创新用于实际业务。 任职要求 1.5年以上互联网工作经验，有推荐系统实践经验； 2.对机器学习系统有一定了解；熟悉最优化的基础理论，能够将业务问题转化成相关的优化问题并求解，深刻理解并独立实现过相关算法（回归、决策树、分类问题、深度神经网络、图模型，概率统计，最优化方法等）； 3.熟悉大规模数据处理的常用方法，熟悉Hadoop/spark/strom等至少一种分布式系统； 4.熟悉常用数据结构，具备扎实的算法基本功，热爱编程，熟悉Java、Python、go或其他主流编程语言；5.良好的业务理解能力和逻辑思维能力，能够从海量数据中发现关键特征，出色的问题分析及解决能力。,"移动互联网,电商",500-2000人,spark,上海
数仓工程师,https://www.lagou.com/jobs/7162030.html,杨浦区,20k-35k,上海识装信息科技有限公司,3-5年,本科,独角兽、业务前景佳、技术氛围好,"岗位职责： 1 参与公司数据仓库的设计与搭建 2 与分析和开发团队协作进行数据建模工作,推动业务部门的数据化运营 3 参与公司数据应用项目开发建设 岗位要求:  1 从事数据仓库领域至少4年以上,熟悉数据仓库模型设计与ETL开发经验,掌握维度建模设计方法,具备海量数据加工处理（ETL）相关经验 2 熟悉数据仓库领域知识体系和技能，对数据采集、数据融合、数据质量、数据应用链路有深入理解 3 具有一定数据模型和数据架构基础，熟悉大数据生态，包括但不限于 Hadoop/hive/hbase/spark/kafka/flink/presto/kylin等;  4 精通SQL，有一定的SQL性能调优经验，熟悉hive sql的开发 5 精通java/python/shell/Scala其中至少一门语言 6 具有电商行业经验或者互联网相关经验，有业务sense，能够通过梳理设计业务模型发现业务问题，并驱动业务目标实现； 7 性格积极乐观，诚信，积极分享成果，有较强的语言表达能力；具备强烈的进取心、求知欲及团队合作精神。 加分项: 1 有用户行为分析和画像构建等成功数据应用项目经验的优先 2 对数据质量管理、元数据管理、数据权限管理、数据应用等有独到见解的优先 3 熟悉storm/spark streaming/flink中一种或多种计算框架的优先 4 对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先","移动互联网,电商",500-2000人,spark,上海
大数据测试,https://www.lagou.com/jobs/7194139.html,浦东新区,13k-16k,上海碧驼信息科技有限公司,1-3年,本科,大数据测试 甲方国企 有机会转正,岗位职责： 1. 负责数据平台数据质量保证工作，负责质量测试方法的探索和效率提升；2. 根据业务需求进行数据测试工作，并持续进行数据质量的优化验证；3. 保障数据生命周期数据的正确性以及合理性。岗位要求：1. 本科或以上学历，2年及以上测试经验，1年以上数据测试相关经验；2. 熟悉软件工程，掌握软件测试基本理论，熟悉软件测试流程，熟悉至少一种流程管理软件；3. 能独立搭建测试环境，熟悉至少一种自动化、性能测试工具；4. 掌握SQL语言，熟悉常用UNIX命令，了解Hadoop/Spark等大数据技术的优先；5. 数据敏感，有一定的数据分析技能和经验，能基于业务理解推动数据测试的落地工作；6. 工作细致负责，具有良好的沟通能力和协作能力。,软件开发,50-150人,spark,上海
游戏业务中台数据分析师,https://www.lagou.com/jobs/7036832.html,闵行区,18k-36k,北京字节跳动科技有限公司,3-5年,本科,"六险一金,股票期权,弹性工作,免费三餐",,文娱丨内容,2000人以上,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6428613.html,浦东新区,14k-18k,上海海万信息科技股份有限公司,3-5年,大专,做五休二，交通便利，大牛团队,岗位职责：    1、 负责数据统计与分析的研发和维护；    2、 根据产品经理和运营团队等的统计需求，进行开发实现；    3、 负责对用户行为数据的深度挖掘，以数据指导产品改善。    岗位要求：    1、 全日制专科及以上，3年以上工作经验；    2、 Java基础扎实，熟悉主流开源框架，懂JVM调优更佳；    3、 熟悉HBase、Spark、HIVE等数据框架；    4、 熟悉Kafka、ES、Redis等数据中间件；有实时计算经验更佳    5、 良好的SQL语句功底，熟悉MySQL、PostgreSQL、Oracle数据库中的一种；    6、 逻辑清楚、快速的学习能力及良好的沟通能力。,"移动互联网,金融",500-2000人,spark,上海
高级数据挖掘工程师,https://www.lagou.com/jobs/7050502.html,浦东新区,30k-50k,上海基分文化传播有限公司,3-5年,本科,六险一金、带薪年假、绩效奖金、餐补等,职位描述：1.运用数据挖掘/统计学习的理论和方法，深入挖掘和分析萌推用户行为、供应商及商家数据2.在海量数据及用户商品分析数据的基础上，构建场景个性化的用户和商品画像体系，为平台个性化智能推荐提供数据支撑3.通过采集的业务信息以及应用相关的海量数据，分析挖掘用户价值，构建用户偏好模型和商品流量预测模型，为平台更好的实现人货匹配提供数据支持任职要求：1.计算机、数学、统计相关专业，本科及以上学历；2.熟悉数据库查询语言如SQL，MySQL等，熟悉python语言，有spark开发经验；3.具备数据敏感性和探知欲、分析、解决问题的能力，能够承受工作中的压力，专注数据的价值发现和变现转化；4.工作主动、认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧。5.有电商数据分析或数据挖掘工作经历优先；,文娱丨内容,500-2000人,spark,上海
高级广告算法工程师,https://www.lagou.com/jobs/7144060.html,浦东新区,30k-50k,上海基分文化传播有限公司,3-5年,本科,六险一金、带薪年假、绩效奖金、餐补等,"工作职责趣头条广告模型组招聘，负责千万日活产品的商业变现能力优化，工作地点 北京/上海。团队内骨干来自于海内外大厂，自建有一套完整的深度学习工作流（数据、训练与线上服务），并基于此开展 点击率/转化率 等预估模型的迭代，也包括 CV、NLP 的相关应用。任职要求我们希望你 ：
 有工作热情，有独立负责某项具体业务迭代优化 的责任心与自驱力；
 有技术追求，掌握良好的自学方法论，愿意钻研前沿技术并快速应用于生产实践；
 有大数据上的 特征工程 或 模型开发（LR/FM/GBDT/DNN 不限） 经验，在一项长期业务中有过持续迭代优化经验更佳；
 能够熟练使用 Spark 或 Hive SQL 进行数据处理，熟练使用 Python / Java / C++（中的一项或多项）做开发，Tensorflow 等深度学习框架的了解掌握是加分项；
 具备一定的机器学习基础，有较强的业务理解能力，能够对算法系统进行 效果分析与问题排查。",文娱丨内容,500-2000人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/5057134.html,静安区,10k-20k,上海海万信息科技股份有限公司,3-5年,大专,"带薪休假,节日礼金,体检旅游,年底奖金","岗位职责：1、参与公司大数据平台的研发2、负责大数据平台基础架构环境搭建，数据仓库建模，及相关运维工作3、处理日常ETL工作4、参与维护大数据平台，并能快速高效解决遇到的问题, 保障平台正常稳定运行任职要求：1、熟悉Hadoop、HBase、Hive、Spark、Flume、Kylin等开源项目的部署、性能调优；2、对Hadoop/Spark有深入理解；3、熟悉Linux系统管理工作；熟悉Shell编程，能够编写脚本解决日常问题，包括自动化的工作流设计","移动互联网,金融",500-2000人,spark,上海
高级算法工程师-消息营销平台方向(T0228),https://www.lagou.com/jobs/6691693.html,长宁区,35k-65k,上海寻梦信息技术有限公司,3-5年,本科,核心业务团队,"岗位职责：1.负责营销消息个性化推荐算法设计。2.负责营销平台用户画像数据挖掘和用户特征库建设，优化完善营销系统DMP。3.负责满足业务营销需求的人群聚类和挖掘的算法设计，设计和构建Lookalike算法系统。岗位要求：1.熟悉机器学习原理与算法，能熟练运用分类、回归、排序等模型解决相关问题。2.精通Python语言编程，熟悉C++/JAVA/SCALA其中任一门以上语言，熟悉linux平台。3.对常用机器学习模型如LR/GBDT/FM以及深度学习有较好的设计经验,有大规模机器学习模型应用经验者优先。4.具备基于大数据的分析解决问题的能力，熟悉Spark/Hadoop等大数据处理优先。5.具备良好的分析问题和解决问题的能力；有较强的自我驱动力和沟通协调能力；愿意接受挑战，抗压能力好 。6.计算机相关专业硕士以上学历加分项1.有大型推荐系统实践经验优先。2.熟悉spark、tensorflow、scikit-learn等机器学习框架者优先。工作年限可适当放宽，不局限，都可以看","电商,移动互联网",2000人以上,spark,上海
搜索广告算法工程师(T0187),https://www.lagou.com/jobs/6691026.html,长宁区,30k-60k,上海寻梦信息技术有限公司,1-3年,本科,"平台大,大牛多,氛围好",岗位职责：1、负责搜索广告，算法和策略优化，提高广告场景的变现效率和用户体验；2、深入产品和业务，能从数据中发现机制和算法的不足，提出改进方案并推动实现；3、跟进业务前沿技术，结合业务特点，探索前沿算法并应用于实际业务。任职要求：1、本科及以上学历，计算机或软件工程相关专业；2、熟悉Linux系统，熟练使用Java/C++/Python其中任一编程语言，有Hadoop/Spark/Storm等大数据计算平台经验者优先；3、具备机器学习或者深度学习理论基础和实践经验者优先，在广告、搜索、推荐某一领域有工作经验者优先；4、有较好的数理基础和逻辑思维能力，热爱算法，热爱思考，较好的主动性和沟通协作能力。,"电商,移动互联网",2000人以上,spark,上海
大数据负责人G00078,https://www.lagou.com/jobs/6874905.html,闸北区,30k-60k,易玩（上海）网络科技有限公司,3-5年,本科,氛围轻松 知名团队 福利好,"工作职责:1、理解业务分析的本质需求，设计和开发对应的数据仓库/数据集市，负责ETL开发和优化工作，完成结构层次合理、灵活、可扩展的数据仓库；2、负责数据仓库模型设计、报表开发和资料品质管理与维护；3、深刻理解业务模型，数据模型，系统模型，提升系统生产效率、监控与调优；4、配合算法端,业务端的数据提供、数据分析并解决分析数据异常相关的技术问题；任职资格:1、计算机、数学或统计学相关专业本科以上学历；熟悉互联网行业，3年以上DW/ETL/BI工作经验；熟练掌握至少一种主流ETL/BI解决方案；2、精通数据仓库架构及原理，具备大型数据仓库架构设计、模型设计和处理性能调优等相关经验；精通SQL/Hive，有较好的SQL性能调优经验，有Java开发经验者优先；3、能够熟练应用一种或多种主流数据库（如： MySQL等），有数据库设计经验者优先；4、有大数据分布式计算平台开发经验,熟悉Hadoop, Spark，Flume，Kafka原理及应用；5、工作认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧。·","游戏,社交",50-150人,spark,上海
ACG智慧政务事业部-大数据系统研发工程师,https://www.lagou.com/jobs/7053258.html,浦东新区,22k-40k,百度在线网络技术（北京）有限公司,5-10年,本科,发展前景,工作职责:-负责核心业务海量数据的存储、计算、查询等架构开发和系统体系搭建，及面向政府、企业级应用的产品建设和项目交付。-负责大规模数据场景下数据分析、应用相关平台研发工作-负责工程架构相关新技术方向研究、开发和应用职责要求:-计算机或相关专业本科及以上学历-熟悉linxu平台，熟悉Java/Shell/python等编程语言-有过大数据领域开发经验，对Hadoop、Spark、Flink、Hive等大数据技术栈有一定了解-有大型私有化项目开发部署实施、大型分布式系统架构设计研发等相关经验者优先-具备优秀的逻辑思维能力，对解决挑战性问题充满热情，善于解决问题和分析问题-良好的团队合作精神，较强的沟通能力,工具,2000人以上,spark,上海
AI开发平台部_Python/C++研发工程师,https://www.lagou.com/jobs/7137494.html,浦东新区,18k-36k,百度在线网络技术（北京）有限公司,不限,本科,发展空间大,"工作职责:-负责研发可信存储与深度学习数据的融合-负责EasyData数据质量评估算法开发-建设灵活易用的机器学习/深度学习组件，支持业务打造定制化AI应用/平台-建设丰富灵活的异构/混合云算力资源调度及工作流任务调度能力职位要求:- 本科或以上学历，计算机相关专业优先- 3年以上Python研发经验 或1年以上的C++研发经验，具有良好的编程习惯，熟悉多线程编程，内存管理，设计模式和Linux/Unix开发环境- 熟悉Hadoop/HIVE/MPI/Spark等分布式计算框架，了解常见深度学习框架引擎，熟悉Docker技术及Kubernetes容器调度系统- 对AI技术发展有强烈兴趣，有良好的学习能力，热爱钻研与分享- 良好的沟通与表达和团队协作能力，较强的动手能力与逻辑分析能力工作地点：上海市,北京市,深圳市",工具,2000人以上,spark,上海
java开发工程师（海外研发中心）,https://www.lagou.com/jobs/6978560.html,徐汇区,25k-40k,北京市商汤科技开发有限公司,5-10年,本科,AI独角兽；弹性工作；餐补；扁平管理；,岗位职责： 1、 负责业务系统核心服务的需求分析、技术调研、设计、开发、单元测试工作2、 负责相关技术文档编写工作 3、 解决系统中的关键问题和技术难题任职要求：1、5年以上java开发设计经验2、Java编程基础扎实，熟练使用SpringMVC\Spring Boot\Spring Cloud3、有SaaS系统的实际开发经验，熟悉多租户系统OAuth鉴权，数据隔离，个性化服务路由4、具有一定的基于数据库、缓存、分布式存储开发高性能、高可用数据应用的实践经验；5、熟悉PostgreSQL/MySQL/Redis/MongoDB6、有ElasticSearch，kafka，RocketMQ开发经验者优先7、有 Hadoop/HBase/Spark/Flink/Storm经验者优先8、熟悉Docker与K8S者优先9、可将英语作为工作语言,人工智能,2000人以上,spark,上海
C++开发工程师,https://www.lagou.com/jobs/6978690.html,徐汇区,25k-35k,北京市商汤科技开发有限公司,3-5年,本科,AI独角兽；弹性工作；餐补；扁平管理；,"工作内容：1.与ＡＩ研究员和算法工程师深入合作，推动ＡＩ算法与原型系统在大规模分布式平台落地，打造万路高性能、高可用的分布式智能视频分析平台2. 独立开发基于Kubernetes与Docker的微服务功能模块并进行系统集成、持续集成测试 3. 快速相应项目需求，进行快速项目功能迭代与更新、与基础架构组同事协同打造云原生分布式智能视频分析平台系统岗位职责：1. 大学本科以上学历，本科两年相关大数据平台开发工作经验，研究生一年相关大数据平台开发工作经验，有大厂经验优先2. 熟练掌握常用数据结构以及设计模式3. 熟练掌握并使用以下语言之一：Golang, C++, Python, Java4. 熟练掌握并使用以下容器编排框架之一：Kubernetes/Mesos/Openshift/Docker Swarm5. 对大数据处理框架以及中间件有使用经验者优先：Hadoop/Spark/Kafaka/Zookeeper/Cassandra6. 了解相关微服务开发框架优先：Spring Cloud/Dubbo/SOA7. 良好的沟通能力、有团队协作意识优先""",人工智能,2000人以上,spark,上海
高级Python后端研发工程师,https://www.lagou.com/jobs/2688021.html,浦东新区,10k-15k,上海斗象信息科技有限公司,1-3年,本科,互联网公司，弹性上班，带薪年假，期权激励,"岗位职责：1. 负责斗象科技企业级安全产品相关平台及后端引擎设计与研发工作；2. 对现有系统的不足进行分析，找到系统瓶颈，持续改进系统架构，提高系统性能。任职要求：1. 计算机相关专业，本科以及以上学历 ，1年以上工作经验，对技术研发有极大的热情；2. 熟悉Linux及计算机网络，熟悉Python或Java等至少一种后端开发语言，有后端产品研发经验；3. 熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息等机制；4. 有较强的逻辑思维能力，对技术有强烈的兴趣，具有良好的学习能力；5. 有良好的沟通能力和代码编写规范习惯；6. 具有良好的团队合作能力。加分项：有Spark，Hadoop相关开发经验的优先考虑。来点儿福利：双休、三餐补助、五险一金、年终奖、健康体检、带薪年假、福利病假、员工活动经费、半年一次国内旅游、员工生日会、季度优秀员工奖、过年过节礼品、日常工作中提供零食、咖啡、冷饮免费供应等相关福利。
 具有竞争力的薪水；           
  GeekPlace、硅谷范儿又不失小清新的工作环境；
 让你出其不意又精彩纷呈的节假日活动；
 优秀员工期权激励计划等。
当然，以上都不重要！重要的是，斗象科技给你带来的成长：
 朝阳行业，学习更多最新前沿知识，结识更多**人物和事物；
 了解国内安全动态及其背后的故事，让你拥有更敏锐的趋势判断，前提如果你够努力；
 兼具面向企业与面向用户的业务，职场成长经验多倍加成！",信息安全,150-500人,spark,上海
测试经理,https://www.lagou.com/jobs/7167208.html,浦东新区,15k-20k,上海斗象信息科技有限公司,3-5年,本科,扁平管理 期权激励 人脉积累 多元福利,1、负责测试分析和报告，推动测试中发现问题及时合理地解决，保障和提升产品质量；2、负责核心产品功能、性能、接口及自动化测试，保证产品满足质量标准 ；3、熟练运用bug管理系统提交和跟踪bug，对bug进行正确的判断和回归，善于发现问题、分析问题；4、团队管理及测试项目管理。任职要求：1、计算机或相关专业，8年及以上产品测试工作经验，3年及以上测试团队管理经验，熟悉B/S架构产品；2、精通各种软件测试理论、技术、方法；3、熟悉主流测试工具和框架，具有多个大型项目的测试实施经验；4、熟悉Hadoop、Spark、Hive、flink、ELK等大数据相关技术；5、掌握至少一种编程语言，如Python等；6、具备独立性能和自动化测试能力；7、有较强的逻辑分析能力和学习能力，工作责任心强，细致有耐心；优先条件：1、具有相关安全产品测试者优先来点儿福利：双休、三餐补助、五险一金、年终奖、健康体检、带薪年假、福利病假、员工活动经费、半年一次国内旅游、员工生日会、季度优秀员工奖、过年过节礼品、日常工作中提供零食、咖啡、冷饮免费供应等相关福利。具有竞争力的薪水；GeekPlace、硅谷范儿又不失小清新的工作环境；让你出其不意又精彩纷呈的节假日活动；优秀员工期权激励计划等。当然，以上都不重要！重要的是，斗象科技给你带来的成长：朝阳行业，学习更多最新前沿知识，结识更多**人物和事物；了解国内安全动态及其背后的故事，让你拥有更敏锐的趋势判断，前提如果你够努力；兼具面向企业与面向用户的业务，职场成长经验多倍加成!,信息安全,150-500人,spark,上海
高级数据仓库工程师,https://www.lagou.com/jobs/7162924.html,青浦区,22k-40k,上海中通吉网络技术有限公司,5-10年,本科,平台稳定,工作职责1、参与快递行业数据仓库设计和研发；2、负责从各业务系统抽取数据，做ETL处理后入库到数据仓库；3、负责公司内部数据产品的数据开发；4、参与各业务系统调研工作，熟悉快递行业业务知识；任职要求1、熟悉数据仓库建设方法论，了解快递行业更佳；2、至少熟悉一种大数据处理技术，如Hadoop、Spark；3、本科及以上学历，计算机、软件工程等相关专业，3年以上工作经验；4、对解决具有挑战性的问题充满激情，具备良好的解决问题的能力，对待工作有较强的自我驱动力,电商,2000人以上,spark,上海
BI研发负责人-广告数据平台,https://www.lagou.com/jobs/6778827.html,闵行区,30k-45k,北京字节跳动科技有限公司,不限,本科,六险一金,,文娱丨内容,2000人以上,spark,上海
数据仓库工程师,https://www.lagou.com/jobs/7056502.html,闸北区,20k-30k,易玩（上海）网络科技有限公司,3-5年,本科,周末双休 一年两次旅游 企业文化,职位描述:1.负责数据仓库的ETL开发，优化ETL过程；2.负责对数据分析师、数据报表、数据应用的数据支持；3.负责数仓的维护工作，发现故障及时诊断、定位、分析和调试，保证数据准确、稳定。职位要求：1.基础知识扎实，计算机/数学相关专业本科及以上学历，至少两年以上的数据仓库/ETL/数据开发经验；2.无论是对自己还是对项目的责任心；3.基础Linux上的开发技能掌握；4.基础知识扎实，熟悉常见的算法；5.具备MYSQL或hadoop、hive、pig、hbase、storm、spark分布式数据库等主流平台的数据开发及调优经验，有DBA经验者优先；6.有使用主流数据库技术，Python 或 Java 开发经验。熟悉 SQL 开发与复杂 SQL 优化；7.具备aws及阿里云emr构建及开发经验。,"游戏,社交",50-150人,spark,上海
Big Data Engineer,https://www.lagou.com/jobs/6701144.html,静安区,25k-35k,珐菲琦(上海)电子商务有限公司,3-5年,本科,"弹性工作,股票期权,精英团队,工作氛围好","The RoleWe are looking for a Senior Software Engineer who is motivated to build world-class data applications using top-notch technology. This position will contribute to the engineering of the next-generation data science products and interfaces that connect our machine learning technology to the vast ecosystem of internal applications.You will be working in a friendly and relaxed environment and be part of a well-motivated, talented and growing team. If you love to learn, if you are willing to share knowledge and would love to be part of the building process to reach the top, using the latest technology stack and having fun doing it, this is an opportunity you can’t miss.The ideal candidate will be comfortable in a startup environment and will bring an energetic, fun and creative approach to their work.What You'll Do:• You will collaboratively design, build, and maintain microservices in our platform.• Working closely with our Data Science and Machine Learning teams in highly impactful and complex challenges, you will help redefine how our business processes work using AI. You will help us expand our data services and products, taking them to the next level while using state-of-the-art technologies.• You will collaborate with Data Scientists, Big Data, Software Engineers, Tech Ops, and Release Engineers to deliver efficient data products.• You will design and develop scalable and performance oriented services with a strong emphasis on algorithmic design and scalability.• Finally, you will work with the Big Data team to develop and maintain large-scale Data Science services.Who You Are:• Over 4 years experience in Computer Science and/or Software Engineering roles• Expert in Python, Java or C++ backend development and microservices• Passionate about code quality and delivering high-quality software• Capable of delivering production-level code and managing the software lifecycle• DevOps mindset and experience with any of the following Docker, Terraform, Ansible, Kubernetes, Cloud Environments (Azure, Google, AWS), CI/CD• Experience in distributed data stores (Cassandra, Bigtable, HBase, MongoDB, HDFS)• Exposure to batch and streaming processing (Hadoop, Spark, Kafka, Flink, Beam, Storm, Samza)• Hands-on experience in developing big-data ETLs and orchestration (Hue, YARN, Airflow, Luigi, Zookeeper)• Strong preference for proven experience in scaling and architecting production-level machine learning systems and data products*We do appreciate all applicants, but only selected candidates will be contacted by us. And all information provided will be kept confidential.",电商,150-500人,spark,上海
资深数据开发工程师,https://www.lagou.com/jobs/7145567.html,长宁区,20k-40k,携程计算机技术（上海）有限公司,5-10年,本科,发展前景大,"职位描述: 研发高可靠、高可扩展、易用的公司统一大数据平台，包括数据中台生产工具类产品(类似阿里dataworks),大规模工作流调度、异构数据交换和同步、数据质量、数据安全、统一元数据中心, 等核心大数据平台和工具链的研发和性能优化。 任职要求 
 有Hive，Kafka，Datax，Zeus, MapReduce，Spark，Flink, Airflow, Presto等两种以上1年以上使用和优化经验
   2. 参与或主导过大型数据平台建设项目，对大数据平台有一定的整体感知和把控能力    3. 熟悉主流的Java开源框架，对Netty、Spring、Tomcat等框架有深入的了解和使用    4. 精通多线程编程，熟悉常见的缓存、消息队列等中间件，熟悉MySQL；    5. 熟悉分布式基本原理，对高可靠，高并发，高吞吐系统特性有一定理解    6. 本科及以上学历，计算机相关专业，三年以上工作经验。符合以下条件优先：    1. 研究过开源代码并有代码贡献。    2. 主导或参与过数据相关产品的后端开发，对大数据技术（比如Hadoop、Spark、Flink等）有一定的了解。   3.有前端开发经验的优先",旅游,2000人以上,spark,上海
服务端工程师,https://www.lagou.com/jobs/5470885.html,浦东新区,20k-35k,上海倾听信息技术有限公司,不限,不限,团队优秀,工作职责：1、 完成蜻蜓FM推荐系统等服务端功能的设计与开发，保障需求正常推进；2、开发和维护大数据分析脚本，评估和分析推荐系统的能力；3、负责服务的部署和运维，保证服务高质量的运行；4、分析服务数据及日志，指导产品设计和业务运营；5、参与团队code review，design review等工作；6、主动思考产品需求，并依据平台特性提出体验、功能方面的优化建议。任职要求：1、计算机相关专业本科及以上学历，有过大型计算机竞赛经验优先；2、有扎实的计算机知识、优秀的算法基础及良好的代码习惯；3、3年以上服务端开发经验，能力优秀者不限；4、处理过高负载的服务开发，了解高可用、缓存、队列等服务端设计机制；5、熟练掌握Scala/Java开发语言，熟悉Play Framework的优先，熟悉如Go等其他开发语言优先；6、熟悉Hadoop、Spark、Hive、Hbase等大数据技术栈者优先；7、有较强的团队意识，能与其他成员高效沟通协作。,移动互联网,150-500人,spark,上海
（2019校招可转正）算法工程师实习生,https://www.lagou.com/jobs/5596908.html,浦东新区,4k-6k,上海倾听信息技术有限公司,不限,硕士,扁平化管理；风口行业,工作职责：1、在算法工程师指导下完成数据、算法方面的相对独立项目；2、对蜻蜓FM上的海量用户和内容数据做挖掘，利用机器学习等方法处理数据，提取特征利用于推荐系统；3、在算法工程师指导下调研新算法、技术的应用可能和评估。任职要求：1、计算机相关专业本科及以上在读学生，硕博士优先，有过大型计算机竞赛经验优先；2、对基础计算机知识、数据结构和算法掌握熟练，能熟练按照思路和算法输出代码；3、熟悉Hadoop、Spark等大数据技术栈者优先；熟悉机器学习、数据挖掘等知识优先；4、能独立调研和探索技术领域并书写技术文档；5、需要连续实习半年以上，每周3天以上。,移动互联网,150-500人,spark,上海
大数据负责人,https://www.lagou.com/jobs/6832174.html,浦东新区,25k-50k,上海巧房信息科技有限公司,5-10年,本科,跟着大牛，学到的都是干货！,"工作职责:1、规划大数据发展方向和技术选型（实时及离线）；2、负责大数据应用设计及大数据变现方案制定，例如：数据分析平台、反作弊规则制定、用户质量评分体系建设等 ；3、指导大数据团队在算法相关技术应用，并帮助提升业务的关键指标；4、面向业务需求，基于微服务框架设计、开发、部署高稳定性和可扩展的数据处理微服务 ；5、负责大数据平台技术攻关和重要开发设计方案的评审把关；6、负责大数据部门日常管理工作：团队管理、流程制度管理等 。任职资格:1、全日制大学本科及以上学历，5年以上大数据开发工作经验，4年以上技术管理经验；2、精通Hadoop、Flink、Kafka、Spark、Redis、Hive、Zookeeper等大数据相关技术，并能结合业务场景进行架构设计和模型建设，参与或主导过大数据分析项目, 有大型互联网分析项目经验者优先；3、精通Java，多线程编程、消息系统、数据库、分布式系统，对微服务架构有较深的理解，常规框架能够了解其原理并熟练使用；4、熟悉高可用、高并发、高性能的分布式系统的设计及应用，有丰富的线上调优经验；5、喜欢尝试新技术，关注新的技术方向，能够平衡好业务的需求和技术团队成长之间的关系，并能从技术趋势和设计思路上辅助产品工作；6、良好的沟通协调能力、团队协作能力、解决问题能力。","移动互联网,企业服务",150-500人,spark,上海
高级数据产品经理,https://www.lagou.com/jobs/6835179.html,静安区,35k-40k,上海丙晟科技有限公司,5-10年,本科,大数据,岗位职责：1、负责内部公司级以及对外项目大数据产品工作，包含调度系统、元数据、等数据开发平台等产品设计与规划基于大数据平台的数据产品规划设计并推动技术团队将产品落地。2、调研了解数据产品用户需求，掌握用户痛点，逐步优化数据平台产品体验。3、负责数据生产链路上监控体系的产品建设。任职要求：1、掌握sql，需要对数据仓库有较深的理解。2、良好的逻辑思维能力、良好的沟通协调、项目推进能力。3、熟悉数据开发底层的技术、熟悉Hadoop生态，包括:hive、spark、hdfs、yarn、以及数据权限等，熟悉调度系统，元数据4、负责或参与过大数据开发平台的建设与数据治理项目5、负责或参与过SAAS数据平台项目的优先6、有数据分析工作经验、数据治理经验优先,"移动互联网,电商",150-500人,spark,上海
风控数据分析师(健康险）,https://www.lagou.com/jobs/7173774.html,黄浦区,30k-40k,众安在线财产保险股份有限公司,5-10年,不限,绩效奖金 带薪年假 车贴饭贴,主要职责：1、众安健康险业务场景中，基于大数据风控手段，为业务风险进行有效防范；2、众安体系内外的数据探查分析，发现对健康险业务风险的影响因素；3、承保前后风险筛查，并对各类风险人群进行追踪，进行全面风险防范；4、理赔阶段风险筛查，有效识别理赔欺诈和逆选择，降低理赔风险；5、已上线风控规则优化，提高数据风控效率。岗位要求：1、有5年以上数据分析、风控岗位经验，优先考虑健康险、医疗健康等行业背景；2、了解Hadoop或Spark等大数据平台，熟练使用Hive、SQL等工具开发；3、熟练掌握逻辑回归、决策树、贝叶斯、聚类等算法基础原理，并在项目中有成功经历，至少掌握R、Python、SAS等统计建模工具中的一种；4、敏锐全面的洞察力，清晰缜密的逻辑思维能力，以及独立的分析调研能力；5、良好的数据分析能力，善于总结问题并能积极推进问题的解决。,金融,2000人以上,spark,上海
风控数据分析师(健康险）,https://www.lagou.com/jobs/7173566.html,黄浦区,30k-40k,众安在线财产保险股份有限公司,5-10年,本科,绩效奖金 带薪年假 车贴饭贴,主要职责：1、众安健康险业务场景中，基于大数据风控手段，为业务风险进行有效防范；2、众安体系内外的数据探查分析，发现对健康险业务风险的影响因素；3、承保前后风险筛查，并对各类风险人群进行追踪，进行全面风险防范；4、理赔阶段风险筛查，有效识别理赔欺诈和逆选择，降低理赔风险；5、已上线风控规则优化，提高数据风控效率。岗位要求：1、有5年以上数据分析、风控岗位经验，优先考虑健康险、医疗健康等行业背景；2、了解Hadoop或Spark等大数据平台，熟练使用Hive、SQL等工具开发；3、熟练掌握逻辑回归、决策树、贝叶斯、聚类等算法基础原理，并在项目中有成功经历，至少掌握R、Python、SAS等统计建模工具中的一种；4、敏锐全面的洞察力，清晰缜密的逻辑思维能力，以及独立的分析调研能力；5、良好的数据分析能力，善于总结问题并能积极推进问题的解决。,金融,2000人以上,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/5601093.html,浦东新区,20k-40k,上海阅文信息技术有限公司,不限,本科,"Top团队,福利好,环境佳,发展快",工作职责:负责大数据BI设计和开发；负责阅文日常数据统计分析；数据仓库、数据集市的模型设计与开发；负责ETL数据准确性验证及ETL任务的优化；参与大数据平台和数据仓库的的搭建。任职资格:熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等） ；熟悉数据仓库理论与技术，对ETL及BI有概念并具有丰富的实际操作经验，熟悉ETL开发流程； 熟悉BI项目，具有数据仓库、BI系统开发经验者优先；对mysql、oracle有丰富经验，有较强的数据库脚本编程能力，有较强的存储过程编写能力； 熟练操作linux系统，熟悉shell脚本或python； 有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题； 性格积极且沉稳，勤奋严谨，强烈的进取心、求知欲和团队合作精神。,文娱丨内容,500-2000人,spark,上海
商业智能技术专家（财经领域）,https://www.lagou.com/jobs/6396967.html,浦东新区,20k-40k,上海阅文信息技术有限公司,5-10年,本科,"Top团队,福利好,环境佳,发展快",,文娱丨内容,500-2000人,spark,上海
数据挖掘工程师 (MJ000301),https://www.lagou.com/jobs/6722433.html,徐汇区,20k-40k,上海米哈游网络科技股份有限公司,3-5年,本科,"六险一金,年终多薪,技术牛人,扁平氛围",岗位职责：1、负责基于海量数据环境下进行画像、标签系统等场景的挖掘开发；2、负责数据探索、特征工程与清洗等，业务数据建模、模型的选取与优化、模型验证等工作；3、负责对运营数据进行分析与监控，基于业务需求或业务痛点进行画像开发、标签挖掘，构建对应指标体系；4、负责维护和改进已投入生产的模型。岗位要求：1、至少3年及以上数据挖掘开发经验；2、熟练使用Java、Python开发语言，并有扎实的编程基础与数据结构基础和数学基础；3、良好的SQL语句功底，熟悉MySQL和HQL/Spark SQl，并有一定的SQL优化经验；4、熟悉大数据常规解决方案，如Hadoop、Hive、Spark等分布式存储与计算；5、熟练使用常见的分类、回归等机器学习算法，如Keams、Logistic Regression、Random Forest、SVM、SVD等；6、熟练使用至少一种机器学习框架，如Spark ML、Scikit-learn等；7、熟悉数据挖掘场景下的常规开发流程，并有较强的数据敏锐能力和业务分析能力；8、了解深度学习常见的网络并熟悉一个或多个深度学习框架者优先；9、有标签系统、画像系统、舆情系统等相关项目开发经验者优先；10、有较强的学习能力与较强的力求**的工作态度，具备良好的团队合作意识。,"移动互联网,游戏",500-2000人,spark,上海
大数据架构师 (MJ000187),https://www.lagou.com/jobs/6715323.html,徐汇区,30k-60k,上海米哈游网络科技股份有限公司,5-10年,本科,"六险一金,年终多薪,技术牛人,扁平氛围",岗位职责：1、负责大数据应用系统的架构设计与功能开发；2、负责数据分析、加工、清理、处理程序的开发；3、负责数据相关平台的搭建、开发、维护、优化；4、分布式平台应用开发（Hadoop/Spark/Hive/Hbase）；5、开发数据统计系统，各类统计程序报表；6、负责用户画像体系的建设。岗位要求：1、具有5年以上的大数据研发或者架构经验，熟悉大数据组件的开发、搭建、维护以及调优；2、熟悉大数据架构体系，对Hadoop、Hive、Spark、Kafka、Flink等技术中的一个或者多个有深入理解；3、对数据有敏锐度，关注业务，有解决实际业务问题的意识和能力。,"移动互联网,游戏",500-2000人,spark,上海
资深产品经理（大数据）,https://www.lagou.com/jobs/6026883.html,虹口区,20k-35k,上海掌小门教育科技有限公司,5-10年,本科,准上市公司 个人发展 福利待遇,【职位描述】：1.负责掌门1对1平台数据产品的需求整理、原型设计以及产品的快速迭代；埋点流程规范制定、宣导、并实施和管理，基于埋点数据建立用户行为分析看板；2.深入理解业务数据，参与数据模型的设计，包括数据平台、数据产品、数据服务开发，与开发团队一起，规划和完善数据分析平台，满足业务决策和业务分析在应用数据过程中的功能述诉求；3.完成所负责数据产品线的业务规划、功能逻辑设计、竞品分析、数据验证、产品运营、效果分析，协调产品开发、测试进行迭代优化和问题评估；4.根据用户对数据的应用场景，抽象出功能模块及功能依赖关系，制定功能优先级，负责推进数据产品迭代和产品进度； 5.执行UAT验证，跟踪上线产品的数据效果、用户反馈，收集和主动挖掘改进需求，根据业务需要持续改进产品，提升产品价值。【任职资格】1.本科及以上学历，统计学、数学、计算机专业优先；2.5年以上数据产品相关经验；熟悉BI/ DW原理和实施，有埋点规划、数据报表、用户行为分析经验者优先；3、优秀的数据可视化设计能力，精通Axure RP等产品设计工具，对数据敏感，具备较强的的推动和沟通协调能力4.熟悉Hadoop(HDFS/MapReduce/Hive)、Spark、HBase、Storm、Kafka、Flume等框架技术，有大数据产品、报表平台、数据仓库规划建设经验者优先。,"移动互联网,教育",2000人以上,spark,上海
数据产品经理,https://www.lagou.com/jobs/7200773.html,虹口区,20k-35k,上海掌小门教育科技有限公司,3-5年,不限,14-18薪,【职位描述】：1.负责掌门1对1平台数据产品的需求整理、原型设计以及产品的快速迭代；埋点流程规范制定、宣导、并实施和管理，基于埋点数据建立用户行为分析看板；2.深入理解业务数据，参与数据模型的设计，包括数据平台、数据产品、数据服务开发，与开发团队一起，规划和完善数据分析平台，满足业务决策和业务分析在应用数据过程中的功能述诉求；3.完成所负责数据产品线的业务规划、功能逻辑设计、竞品分析、数据验证、产品运营、效果分析，协调产品开发、测试进行迭代优化和问题评估；4.根据用户对数据的应用场景，抽象出功能模块及功能依赖关系，制定功能优先级，负责推进数据产品迭代和产品进度； 5.执行UAT验证，跟踪上线产品的数据效果、用户反馈，收集和主动挖掘改进需求，根据业务需要持续改进产品，提升产品价值。【任职资格】1.本科及以上学历，统计学、数学、计算机专业优先；2.5年以上数据产品相关经验；熟悉BI/ DW原理和实施，有埋点规划、数据报表、用户行为分析经验者优先；3、优秀的数据可视化设计能力，精通Axure RP等产品设计工具，对数据敏感，具备较强的的推动和沟通协调能力4.熟悉Hadoop(HDFS/MapReduce/Hive)、Spark、HBase、Storm、Kafka、Flume等框架技术，有大数据产品、报表平台、数据仓库规划建设经验者优先。,"移动互联网,教育",2000人以上,spark,上海
千寻位置 - 资深风控开发专员/专家 - 信息安全,https://www.lagou.com/jobs/6851628.html,杨浦区,15k-30k,千寻位置网络有限公司,3-5年,本科,行业独角兽 高绩效激励,岗位职责:1、负责风控平台开发2、负责风控引擎开发3、负责风控规则开发任职要求:1、本科及以上学历;2、3~5年及以上使用Java语言的开发经验;3、熟悉规则引擎原理，且有项目实际落地经验;4、熟悉数据库Mysql、Linux操作系统；熟悉NoSQL如Redis;5、熟悉缓存技术和分布式系统设计知识;加分项:1、熟悉kafka/storm/spark等大数据处理框架优先;2、有大数据量、高并发系统和大型网站构建经验者优先;3、计算机数学相关专业优先;4、有多语言能力，前端开发能力优先；,移动互联网,500-2000人,spark,上海
千寻位置-大数据运维工程师/专家,https://www.lagou.com/jobs/6883576.html,杨浦区,20k-40k,千寻位置网络有限公司,5-10年,本科,阿里背景 带薪年假 餐补 补充公积金,"岗位职责：1、负责跟进项目的SQL优化，并进行分析和改进；2、跟进项目的数据库设计，使之符合规范；3、熟悉业务逻辑;4、支持日常统计分析；5、评估项目信息，并合理提出资源配置。任职条件：1、熟悉PostgreSQL或hadoop,hbase,spark，两年以上数据库管理或开发经验；2. 具有一定的脚本开发能力和较强的学习能力；3、熟悉Mysql Mongo 等数据库优先；4、具备良好的团队合作，沟通协调能力；5、熟悉PostGis优先。",移动互联网,500-2000人,spark,上海
高级大数据开发工程师,https://www.lagou.com/jobs/7062583.html,长宁区,20k-30k,飞书数字科技（上海）有限公司,5-10年,本科,互联网广告,"岗位职责：1.主导数据ETL、数仓建设；2.主导新业务和行业的数据商业化探索和数据价值挖掘;3.负责海量数据采集、处理及存储、技术选型及架构实现；4.参与代码的实现，并带领团队追踪大数据和云计算技术的最新科技成果，并应用于内部业务实践。任职要求：1.本科及以上学历，五年以上相关行业经验；2.熟悉数据仓库产品，对数据处理、维度建模、数据分析等有深刻认识和实战经验;3.有较强的编程能力和编程经验, 精通Java，熟悉Hadoop分布式计算框架（HDFS、Hbase、Hive、Mapreduce、Storm/Spark、Flink、kudu等)；4.具备较好沟通协调能力，主动建立与业务的紧密合作，推动业务升级；5.有商业变现，DMP数仓建设和维护经验的优化。","社交,广告营销",150-500人,spark,上海
网络安全工程师,https://www.lagou.com/jobs/6476798.html,松江区,12k-20k,上海明品医学数据科技有限公司,1-3年,本科,"最高6个月年终,环境好,氛围好",职责描述：1、参与自动化运维平台的开发和搭建；2、完善业务监控、报警、排错等管理平台建设；3、服务器性能调优和故障处理，保证业务 24*7 高可用。4、工作踏实认真，勤于思考，有良好的职业道德和敬业精神，抗压能力强。任职要求：1、有互联网业务相关系统维护工作经验、拥有实际的网络高并发处置经验（尤其是Apache、MySQL 优化）、网络权限控制经验等优先；2、熟练掌握 Linux 系统 ， CentOS7 优先；3、熟练配置各种互联网基础应用，包括但不限于Apache、MySQL、Tomcat、Kafka、Memcached等；4、熟练掌握 Shell 脚本；5、具有一定的网络知识，了解 TCP\IP 原理、熟悉各种架构体系设计、熟悉各种监控体系等 ；6、熟悉Linux环境中mysql/redis/kafka/hadoop/spark缓存及队列服务等工具的配置维护；6、良好的主动工作学习能力，逻辑分析学习能力、沟通能力、抗压能力、文档规划书写能力等。,"医疗丨健康,数据服务",150-500人,spark,上海
阿里云系统运维,https://www.lagou.com/jobs/7183932.html,浦东新区,15k-18k,上海微创软件股份有限公司,3-5年,本科,人工智能、企业平台运维,"高级平台运维工程师（企业人工智能解决方案后台） Introduction ElectrifAI 是全球人工智能和机器学习领域的领导者，成立于2004年，总部位于美国泽西城，业务遍及全球。业界首创围绕开源和Spark体系的计算引擎技术平台，可进行大规模的分布式数据处理和机器学习，使ElectrifAi企业解决方案可以使用任何编程语言，对数据进行编码和访问。Docker Containers和Kubernetes的结合使ElectrifAi能够在更短的周期内，构建和部署大规模的混合云企业解决方案，显著提升企业实现价值的时间。ElectrifAi企业解决方案的客户包括全球**的行业品牌企业及政府部门，如：强生集团，诺华制药，万事达卡，花旗银行，美国运通卡，美国政府，安大略省教师退休金计划和联合航空等。 微创软件 凭借强大的技术实力和高效的客户服务能力，与ElectrifAI公司将在人工智能领域等相关核心平台开发中进行深入合作，帮助ElectrifAI实现全球产品及客户价值愿景。 Responsibilities- Monitor and manage all installed systems and infrastructure- Establish, configure, test, and maintain operating systems, application software and system management tools- Monitor and test application performance for potential bottlenecks, identify possible solutions, and work with developers to implement those fixes - Write and maintain custom scripts, implement systems automation to increase system efficiency- Ensure the highest levels of systems and infrastructure availability- Participate in the design of information and operational support systems- Maintain security, backup, and redundancy strategies Requirements
 English speaking skill that be able to cooperate with foreign engineer team
 Ali Cloud experience
 Linux or UNIX based environments working experience in installing, configuring, and troubleshooting
 Solid scripting skills (e.g., shell scripts, Perl, Ruby, Python)
 Experience with automation software and monitoring systems
 Experience with virtualization and containerization (e.g., VMware, Virtual Box)
 Solid networking knowledge (OSI network layers, TCP/IP)
 Office ElectrifAI-上海研发本部
 上海市浦东新区 龙阳路2277号 永达国际大厦（邻近 地铁2号 或7号线 龙阳路站，或7号线 花木路站）","企业服务,移动互联网",2000人以上,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6829146.html,浦东新区,20k-40k,上海华钦信息科技股份有限公司,5-10年,本科,"外资,世界五百强","Qualifications:o3+ Years of application development and implementation experience.  o3+ years of experience with end-to-end design and delivery of Big Data Applications.oExpert in logical data modelling and relational database design.oExpert in maintain, improving and measuring the code quality, code coverage.oExpertise in writing technical documentation.oKnowledge of SDLCoNice to have – Knowledge of Risk domain (preferably Retail Risk)oStrong technical expertise on the followingJava/J2EE – Object oriented concepts, Core Java, Multi-Threading and collections.Hadoop Ecosystem (MR2, HDFS, Spark, Spark SQL , Scala,  Hive , Sqoop)Good understanding of Hadoop data storage formats (Avro, Parquet etc)Working with RDD, Datasets and Data frames.Relational Database knowledge and basic SQL Programming.Nice to have – Spring Batch ,Sprint Integration and any Java script frameworkExperience working with Linux Environment and shell scripts.Experience with GIT and any Git Remote repository tool, Branching and  Merging strategiesoExperience using the code coverage, code quality and profiling tools.Education:B.A/B.S in Computer Science or equivalent","数据服务,金融",500-2000人,spark,上海
架构师,https://www.lagou.com/jobs/4563804.html,浦东新区,30k-50k,云鹊医疗科技（上海）有限公司,5-10年,本科,"年底双薪,年终奖金,五险一金,补充商业险",1.分布式架构应用；2.分布式数据库应用；3.精通分布式、大流量系统的设计与开发，具有丰富的架构设计经验，熟悉java、scala、python、nodejs等开发技术；4.精通基于Spring boot、Spring Cloud的微服务架构；5.熟悉redis、kafka、MariaDB、mongodb、hadoop、spark、ElasticSearch等大数据技术；6.熟悉html5、bootstrip、jquery、vue、nodejs、fis等前端开发技术；7.熟悉docker、mesos、rancher等容器技术并有实际使用经验；8.相关工作5年以上。,"医疗丨健康,移动互联网",150-500人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6871647.html,徐汇区,15k-30k,上海思贤信息技术股份有限公司,3-5年,本科,健康体检、休闲零食、员工旅游、大牛带队,"岗位职责：
 参与基于Hadoop/Spark平台架构的设计和开发工作 ；
 负责对海量数据进行统计、分析与挖掘，不断提高系统运行效率；
 负责对数据分析及业务开发团队提供大数据技术指导和手段支撑；
 负责大数据平台的性能监控和持续优化；
 维持线上服务高效稳定，支撑业务和数据量的快速扩张;
任职资格：
 3年计算机软件行业开发经验，计算机或相关专业本科以上学历；
 具有扎实的Java或Scala开发语言基础，可以开发高效可靠的代码；
 有Hadoop和Spark实际开发经验,了解大数据组件的使用限制和应用场景，如HDFS、Yarn、HBase、Hive、Flume、Kafka、ZK、Kylin、Kudu、ES、Storm、MongoDB等;
 对分布式存储和计算原理有较深的理解；
 有实际CDH或HDP或Apache版本的Hadoop部署调优经验优先
 有参与并成功开发部署过1个日均TB级的集群项目优先","移动互联网,数据服务",50-150人,spark,上海
数据分析师,https://www.lagou.com/jobs/5897831.html,普陀区,15k-30k,上海联元智能科技有限公司,3-5年,本科,五险一金 绩效奖金 弹性工作 补充公积金,"岗位职责：1、 与市场/业务开拓人员配合，参与客户沟通，理解业务需求，理解数据环境，界定数据分析问题，并制定数据分析方案；2、 与数据开发及ETL人员配合，从数据库、服务商或用能企业方，获取数据，并进行相应的数据准备；3、 深入理解业务需求，基于业务数据进行数据探索、特征提取，选择分析方法或模型，并形成符合业务的分析结果；4、 与需求部门协作，编写分析报告及其他交付成果，并协助实现数据价值应用；5、 配合数据开发工程师，完成模型部署后的业务验证、反馈。岗位要求：1、 学习能力强、逻辑严谨简洁、工作独立负责、语言流畅（书面、口头）、能够有效阅读中英文文献；2、 熟悉数据结构，熟悉数据探索方法，熟悉数据清洗、降维等数据准备过程，能够结合业务场景和数据条件有效完成数据清洗、数据描述和数据准备；3、 熟悉回归、分类、聚类、关联规则、时间序列、神经网络、决策树及其他常用统计分析和数据挖掘技术，了解其算法原理和适用性，能够根据应用场景选择适当的方法，并通过数据分析工具实现；4、 能够准确把握数据特征，并有效地对数据和分析结果作可视化展示；5、 能够熟练使用至少一种主流关系数据库及结构化查询语言，对Hadoop, Spark, HIVE等大数据架构、环境及数据仓库有所了解；6、 熟练掌握Python、R、SAS、Matlab、tableau等数据分析工具中的至少一种；7、 有一个以上独立完整的数据分析项目经验。","移动互联网,数据服务",50-150人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7213106.html,长宁区,30k-45k,同程网络科技股份有限公司,5-10年,本科,15-19个月工资 上升空间,职位描述1. 负责大数据计算平台的架构设计，以及核心功能的开发，满足实时、离线计算的需求。2. 负责产品实时计算平台的设计和开发，为个性化推荐、实时监控、运营数据分析提供数据支持。任职要求1. 扎实的Java语言基础，对JVM底层运行机制有深入了解。2. 熟练掌握Hadoop、Spark、Flink、Elasticsearch的原理特性以及适用场景，熟悉Flink实时计算开发，并具备大规模数据集的实际开发经验。3. 有大规模数据计算平台的架构设计经验，且精通大规模数据集的存储方案设计优先。4. 具备用户问题的定位及解决能力，善于归纳总结，对数据敏感。5. 思维活跃、敢于担当、乐于沟通，具有良好的团队合作精神，积极主动，能承受一定的工作压力。6. 具备搜索、推荐类系统开发经验优先,旅游,2000人以上,spark,上海
大数据平台开发工程师,https://www.lagou.com/jobs/5529142.html,普陀区,25k-35k,叽里呱啦文化传播（上海）有限公司,3-5年,本科,"与牛人一起,团队简单,阿姨做饭",职位描述:1.负责大数据架构相关组件的开发、维护和优化2.负责搭建分布式计算平台、查询引擎、中间件；3.确定大数据架构的整体技术路线和架构走向，新技术的调研和落地岗位要求：1.熟练掌握Java/Scala，3年以上开发经验2.熟悉hadoop生态圈及hdfs、hive、kafka、spark、flink等开源产品；3.熟悉hbase、spark、ES等组件；4.精通Java有较强的编码能力，能独立解决技术,"移动互联网,教育",500-2000人,spark,上海
数据仓库工程师,https://www.lagou.com/jobs/5630273.html,普陀区,15k-30k,叽里呱啦文化传播（上海）有限公司,3-5年,本科,"与牛人一起,团队简单,阿姨做饭","工作职责1、提供快速、准确、灵活的数据仓库主题域、集市支持2、数据建模以及数据仓库应用产品的设计和开发；3、数据仓库ETL流程的优化及解决ETL相关技术问题；4、设计并实现对BI分析及报表展现、数据产品开发5、业务相关数据指标的计算挖掘；职位要求1、熟悉数据仓库方法论, 熟悉数仓架构和模型设计，精通ETL开发2、有数据建模基础，并能根据需求独立完成建模数仓架构设计、模型设计3、有基于hadoop和spark分布式平台的数仓经验4、熟悉Hadoop Hive／Spark／Storm／Kafka 等的使用和调优；5、掌握Java，Python其中一门开发语言，掌握UDF和Map-Reduce开发者优先","移动互联网,教育",500-2000人,spark,上海
数据开发,https://www.lagou.com/jobs/7112062.html,黄浦区,18k-26k,深圳市小赢科技有限责任公司,3-5年,本科,专业团队 发展潜力,岗位职责：1、负责业务整体数据仓库、数据集市的模型设计与数据架构管控、仓库建设、ETL开发等，支持上层数据分析与数据应用；2、负责数据管理与治理，确保数据一致与准确性，提升业务数据计算效率；3、负责大数据平台建设及维护，包括BI分析、数据产品开发、数据工具开发及算法开发等的系统性支持；4、参与业务数据分析体系的建设，包括但不限于数据数据统计、分析与建模等，实现数据驱动业务增长的目标；5、能够独立开展数据挖掘项目，为产品和运营提供数据决策支持。任职要求：1、3年以上数仓管理及开发的相关工作经验，有数据仓库建设、数据处理、数据建模、数据分析相关经验；2、熟练掌握hadoop、Hbase、Hive、Storm、Spark Streaming、flink等大数据开发工具中一种或几种；3、熟悉shell、python、scala、java等至少一种开发语言；4、精通sql，熟悉常用的关系型数据库和非关系型数据库；5、责任心强，具备较强的学习、表达能力，善于沟通、有团队合作精神。,金融,500-2000人,spark,上海
java开发工程师.,https://www.lagou.com/jobs/7139203.html,普陀区,12k-14k,上海汉得信息技术股份有限公司,3-5年,本科,五险一金,"1、计算机相关专业，统招本科，，本科以上学校优先；2、2-3年以上Java软件开发经验；3、精通spring,springboot；4、熟悉Spring，JavaEE，JBoss，Tomcat等；5、熟悉MySQL、Oracle等关系型数据库，及MongoDB、Cassandra等非关系型数据库；6、熟悉Redis, Kafka, RabbitMQ等中间件；7、了解Hadoop、Spark、Python等大数据和数据挖掘工具；具备Linux, Windows等操作系统知识；8、了解Subversion, Git, Maven，Jira，Confluence等工具链。","企业服务,数据服务",2000人以上,spark,上海
大数据架构师,https://www.lagou.com/jobs/6733746.html,徐汇区,30k-50k,上海漫微信息技术有限公司,5-10年,本科,工作氛围轻松 零食茶歇 节日福利,岗位职责:1、负责大数据平台整体架构和数据架构设计，根据具体业务需求和产品对数据模型进行统一分析和规划；2、负责大数据平台的各种数据产品的需求调研、（维度等）模型设计、架构及关键模块的设计和开发；3、负责数据仓库/BI需求调研和需求分析，独立主导数据仓库、数据集市的模型设计； 4、对大数据架构组件的优化和改造的工作，设计以及开发核心代码，带领并解决项目开发中的技术难点。5、承担新技术调研以及新系统的推广培训工作。6、负责大数据平台运维团队的日常系统调优及各种疑难问题排查；任职资格:1、大学本科以上学历，计算机或相关专业；如技术能力卓越，学历不作为硬性条件；2、3年以上数据仓库架构和大数据系统开发设计经验；3、熟悉大数据相关组件如：Hadoop/HBase/ZK/Spark/Hive/Kafka/Storm/Flink/ElasticSearch等的架构和内部技术细节，具有研发和定制优化能力；4、熟悉数据仓库模型的设计，分层设计原理，并结合大数据技术组建解决模型应用的问题；5、有实际大数据平台建设经验者优先；6、具有强烈的目标感、良好的服务意识、团队精神和自我驱动力；,移动互联网,150-500人,spark,上海
数据仓库专家,https://www.lagou.com/jobs/7211678.html,长宁区,35k-60k,北京圣达龙翔科技有限责任公司,5-10年,本科,大牛多，福利待遇好,"工作职责1、基于互联网行业特点构建企业级数据仓库架构,建设PB级共享数据平台 2、负责数据平台相关数据研发及管理工作，参与制定EDW相关规范并推动实施落地 3、对海量数据处理的需求进行评估及方案设计实现 4、其他数仓及风险管理数据相关工作 任职资格1、具备5年以上数据仓库开发及管理经验，3年以上互联网/电商行业经验 2、精通数据仓库建设方法论，有大型数据仓库建设项目经验（PB级以上） 3、熟悉HADOOP、HIVE、HBASE、SPARK、FLUME等工作原理，精通HiveSQL，有较丰富的HiveSQL性能调优经验 4、至少熟练使用Shell、Python、Perl等脚本语言之一 5、工作认真、负责，具备良好的团队合作、分析及沟通能力 6、有金融相关知识和机器学习模型项目经验、处理大量互联网复杂业务关系经验者优先","硬件,数据服务",150-500人,spark,上海
资深算法工程师,https://www.lagou.com/jobs/6988135.html,长宁区,35k-50k,上海绘享网络科技有限公司,3-5年,本科,团队气氛好，福利待遇好,岗位职责：1、负责推荐系统的架构和搭建，开发内容、商品相关性推荐算法；2、运用数据挖掘和机器学习技术优化搜索、推荐列表等主要的入口的排序体验； 3、结合业务需求，基于多维度数据构建商品画像和用户画像，并应用于相关业务场景；4、和工程同学合作，建设和优化相关的信息流检索系统。 任职要求：1、本科以上学历，3年以上算法工作经验； 2、扎实的机器学习算法理论基础，有搜索、推荐、广告等相关方向算法实践经验；3、对数据挖掘、机器学习排序、自然语言处理、文本相关性、用户建模等领域有一定的理解和应用经验；4、精通Java/Python，有良好的编程习惯和扎实的编程能力；5、精通部分协同过滤相关技术，如ItemCF、SVD++等；6、具备优秀的逻辑思维能力，对解决挑战性问题充满热情，对数据敏感、善于分析问题/解决问题；7、有Hive/Hadoop/Spark及日志挖掘开发经验者优先。,移动互联网,150-500人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7207802.html,徐汇区,15k-30k,大启科技（上海）有限公司,不限,不限,加班少福利好工作地点高大上氛围轻松和谐,"工作职责
 负责公司数据平台及数据产品的开发
 结合零售行业的数据场景，参与数据仓库和BI解决方案的落地
 参与数据开发团队的方案技术选型研究
任职要求
 熟练掌握HBase Kafka Spark Hive Presto  ELK 等大数据生态技术，熟悉Hadoop的底层工作机制。
 熟练 Scala/Python/Java 其中至少一项， 具备良好的编成能力。
 熟悉 BI 数据仓库 OLAP建模 ETL等 相关技术。
 熟悉Linux环境, 及Shell脚本。
 对数据敏感，具备较强的学习能力。",软件开发,15-50人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7166675.html,徐汇区,20k-40k,大启科技（上海）有限公司,5-10年,本科,薪资高加班少，世界五百强新零售，技术大牛,"岗位职责：·       大数据平台功能的技术实现，核心代码开发及日常维护·       跟据实际业务设计开发大数据应用组件或基于开源软件进行二次开发·       编写数据清洗脚本，对流入大数据平台的数据流做梳理·       编写数据抽取脚本，提供对外数据流的输出·       为BI系统、报表平台、大数据平台等提供海量数据高性能分析技术支撑职位要求：·       本科及以上学历,  计算机相关专业，5年以上相关经验·       具备基于Hadoop的大数据体系平台开发经验，精通大数据开发框架(Spark、Hive、HBase、Kafka、Sqoop等)·       熟练掌握SQL、Scala编程语言·       具备Kylin开发经验·       具备Java开发经验·       具有大数据平台性能优化经验者优先·       具有BI，数据仓库等项目实施经验者优先·       具有敏捷项目开发经验者优先·       具有领域模型驱动开发(DDD)经验者优先·       熟悉零售行业业务，具有零售行业开发经验者优先",软件开发,15-50人,spark,上海
算法专家,https://www.lagou.com/jobs/6815096.html,浦东新区,30k-60k,深圳平安综合金融服务有限公司,5-10年,本科,周末双休、职位晋升、薪资待遇,岗位职责：1、针对金融数据做一些机器学习算法的应用，优化搜索、产品推荐、营销和广告投放的效果；2、探索前沿深度学习算法，改进并提升算法效果;3、训练算法，部署算法上线并持续优化算法的效果;4、和业务需求洽谈、抽象出数据应用点，并规划项目的实施路线；5、主动创新，发现算法应用点，具有分析能力，能够撰写常规的策略运营和分析报告。技能要求：1、3年以上工作经验，最高学历要求985/211；2、互联网从业经历优先;3、有算法应用实践者优先考虑；4、有NLP经验者、风控、推荐、广告CTR预估等领域算法实践者优先；4、精通Spark，R，Python，Java等其中一个工具；5、有模型上线，封装API者，优先考虑，熟悉Redis，ELK，SparkStreaming等平台优先;6、优秀的团队合作能力和沟通能力。,金融,2000人以上,spark,上海
资深Java开发（个金会项目）,https://www.lagou.com/jobs/6893992.html,浦东新区,30k-60k,深圳平安综合金融服务有限公司,5-10年,本科,平台稳定，福利优厚,"岗位职责1、 负责大数据客户关系平台的开发2、 负责设计、开发图计算模块3、 负责线上业务的维护任职要求1、JAVA基础扎实，理解io、多线程、集合等基础框架，对JVM原理有一定的了解；2、 4年以上使用JAVA开发的经验，对于你用过的开源框架，能了解到它的原理和机制；3、 对Spring,ibatis,struts等开源框架熟悉；4、 熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息等机制；5、能对分布式常用技术进行合理应用，解决问题；6、 掌握多线程及高性能的设计与编码及性能调优；有高并发应用开发经验；7、 熟悉Hadoop、Spark等平台相关算法实现和架构设计；8、有知识图谱领域工作经验者优先；",金融,2000人以上,spark,上海
高级java开发工程师,https://www.lagou.com/jobs/7179938.html,浦东新区,15k-30k,达而观信息科技（上海）有限公司,3-5年,本科,团队氛围好、小独角兽、福利待遇好,"岗位职责：1. 负责公司知识图谱系统后端整体架构的设计、开发和性能优化工作2. 负责数据库JanusGraph、NEO4J，DGraph等的管理、维护和二次开发工作，提升图数据库性能3. 参与大数据平台hadoop、spark、hbase、ELK、Cassandra等组件的开发和管理4. 与产品经理，算法工程师等一起完成项具体场景下的知识图谱系统的设计、开发等工作5. 前沿技术的调研和推广任职要求：1. 计算机相关专业，本科及以上学历，丰富的java开发经验2. 扎实的编程功底，熟悉springboot、elasticsearch、mybatis、git等常用框架和工具，熟悉常用的数据结构和算法3. 对大数据技术有浓厚的兴趣，了解Hadoop, HBase、Spark, Kafka、JanusGraph、NEO4j、DGraph等一个或多个大数据相关系统者优先4. 具有高度的责任感，工作积极主动、学习能力强、善于钻研，代码和文档编写规范",人工智能,150-500人,spark,上海
BI工程师,https://www.lagou.com/jobs/7128496.html,杨浦区,25k-35k,北京明宇未来科技有限公司,5-10年,本科,年底奖金 双休,"工作概要：作为BI团队主要成员，通过数据分析来推动公司业务改进 工作描述：1.负责公司BI平台建设2.负责业务分析及数据建模3.负责ETL开发4.负责看板及报表开发5.负责公司BI系统性能优化 任职资格：1.统招全日制本科以上学历，计算机相关专业，5年以上相关经验2.熟悉关系数据库，精通SQL及性能优化3.精通数仓建设及多维建模方法，有DW, DM建设经验4.精通ETL开发及系统建设5.熟悉hadoop平台，精通数据可视化技术6.熟悉数据治理方法及工具使用7.拥有较强的业务分析能力8. 有完整BI平台搭建经验优先9.有impala，kudu经验优先10.有hive，spark开发经验优先",移动互联网,50-150人,spark,上海
大数据工程师,https://www.lagou.com/jobs/7214717.html,长宁区,10k-18k,上海脉多信息技术有限公司,1-3年,本科,发展前景、团队氛围、薪酬福利,1. 按照技术主管的要求，参与数据平台的系统搭建和代码编写；2. 参与研发需求分析及后续代码编写工作；3. 按照公司项目管理及开发管理流程与规范要求编制开发过程中必须的各种开发文档；任职要求：1. 本科学历，计算机或理科相关专业，2年以上数据开发相关经验；2. 精通python，scala等脚本编程，熟悉java，扎实的数据结构基础，熟悉数据算法更佳；3. 熟悉Linux环境，熟练使用hive、spark等进行数据加工；熟悉hive和spark的编写和性能调优；4. 熟悉常用开源分布式系统，如熟悉Hadoop/Hive/Spark/Storm/Flink/HBase中的一项或多项; 能够独立排查及解决数据系统的问题；5. 清晰的逻辑分析和表达能力，热爱技术，乐于分享；6. 良好的团队精神和合作意识，强烈的责任心，对工作有激情，良好的沟通能力。,"硬件,软件开发",50-150人,spark,上海
资深数据仓库工程师(J20437),https://www.lagou.com/jobs/7211316.html,长宁区,25k-35k,携程计算机技术（上海）有限公司,5-10年,本科,海量数据 业界大牛,4、参与新技术的探索和攻关,旅游,2000人以上,spark,上海
PHP开发工程师,https://www.lagou.com/jobs/5582076.html,徐汇区,14k-20k,上海竞道广告有限公司,3-5年,本科,蓝色光标、上市公司,"1.从事公司广告投放管理平台的开发;2.根据需求完成代码编写，调试，测试和维护;3.与其它部门协同,提供相关的技术支持;4.编写代码注释和开发文档;5.辅助进行系统的功能定义,程序设计。职位要求：1.计算机或相关专业毕业（条件优秀者可不要求）;2.3年以上PHP开发经验，有高并发网站建设或数据库建设经验者优先;3.有扎实的计算机基础，较强的算法能力;4.精通PHP及熟悉主流开发框架(Yii/Symfony/Laravel);5.精通MySQL数据库并有相关关系数据库设计经验，熟悉Redis/Memcached/MongoDB等;6.熟悉composer包管理器，熟练使用Git;7.熟悉Unix/Linux操作系统，熟悉Shell脚本编程及常用Unix/Linux管理命令;8.熟悉HTML5/CSS3/ES6等Web开发相关技术，熟悉Vue/React/Angular优先;9.了解Elasticsearch/zookeeper/Kafka/Spark/InfluxDB等大数据相关知识优先;10.思维严谨，具备良好的分析解决问题能力，能独立承担任务和把握进度;11.具备良好的团队合作精神，较好的沟通能力，高度的责任感;能够承受较强的工作压力。","移动互联网,广告营销",150-500人,spark,上海
算法工程师,https://www.lagou.com/jobs/7114549.html,徐汇区,15k-30k,北京源石云科技有限公司上海分公司,5-10年,大专,周末双休，员工体检，出国旅游，团队聚餐,岗位职责：1. 负责数据挖掘、AI等技术在业务场景中的落地，如推荐系统、用户画像分析等2. 设计开发算法系统架构，能够追踪算法实际效用，并推动持续优化改进岗位要求：1. 计算机、统计、数学等相关专业本科以上学历，3年以上数据挖掘相关工作经历 2. 熟练掌握机器学习常见算法LR、SVM、GBDT、RF、XGBOOST等以及深度神经网络，有机器视觉或自然语言处理项目经验3. 至少掌握一种机器学习框架，如tensorflow、mxnet、pytorch等4. 有分布式计算项目经验，熟悉spark框架，熟悉hdfs、hbase、redis等组件5. 具有较强逻辑思维能力，善于解构问题并提出可行解决方案，具有较强自我学习意识和学习能力,"移动互联网,电商",500-2000人,spark,上海
架构师-SH,https://www.lagou.com/jobs/7023607.html,徐汇区,35k-50k,北京深演智能科技股份有限公司,5-10年,本科,扁平化管理 团队氛围好,,"移动互联网,广告营销",150-500人,spark,上海
算法架构师（推荐算法方向）(J12178),https://www.lagou.com/jobs/7135169.html,浦东新区,40k-65k,上海二三四五网络科技有限公司,5-10年,硕士,团队氛围好 专业导向 提升空间大,,"数据服务,移动互联网",500-2000人,spark,上海
数据仓库架构师(J12151),https://www.lagou.com/jobs/7102501.html,浦东新区,30k-50k,上海二三四五网络科技有限公司,5-10年,本科,上市公司，六险一金，平台好发展空间大,工作职责:1、负责数据仓库实时、离线架构设计，确保架构设计合理性、扩展性、可用性。2、负责数据仓库模型设计，确保模型设计的高复用性，模型满足业务80%取数需求。3、负责数据仓库HQL性能优化与协助团队解决开发遇到的问题。4、负责数据仓库核心代码逻辑开发与推进落地。5、参与数据仓库规范制定和规范监督实施。6、负责前沿技术调研，根据业务特性适时引入前沿技术。任职资格:1、本科及以上学历，计算机相关专业优先；有较强的编程能力和编程经验，熟练使用至少Java、Python中一门编程语言； 2、5年以上数仓开发经验，熟练使用Hadoop、Hive和关系型数据库； 3、熟悉数据仓库各类模型建模理论，熟悉数据仓库数据分层架构，精通3NF和维度模型设计；4、熟悉Spark、Hbase、Kafka、Flink、缓存技术等相关技术； 5、对数据敏感，有较强的逻辑分析能力，对处理海量数据和分析有热情； 6、工作认真负责，具备主动推进业务的意识和能力，具备良好的团队协作能力。,"数据服务,移动互联网",500-2000人,spark,上海
算法专家,https://www.lagou.com/jobs/4918322.html,徐汇区,40k-60k,上海驹旗网络科技有限公司,3-5年,本科,"氛围好,大牛多",岗位描述：1. 应用NLP、机器学习、深度学习等技术，针对对用户以及用户的行为建模，结合业务设计解决方案。2. 针对大规模结构化非结构化数据，进行数据清洗，特征挖掘，统计分析，并结合应用场景实现落地。3. 构建基于用户行为的内容推荐，协同过滤和场景引擎，提升用户获取内容效率。4. 构建交易模型和推荐价格模型，提升价格合理性。 岗位要求：1. 计算机、数学或统计学等相关专业本科/硕士以上学历，熟练掌握常用数据结构和算法，有一定数学功底，能针对实际问题进行数学建模，对有挑战性的问题有足够兴趣；2. 扎实的机器学习功底，深刻理解数据平滑、特征选择、Bayes、熵、优化方法、GLM、矩阵运算等；3.熟悉协同过滤、矩阵分解、GBDT、LearningToRank、word2vec、CRF、LSTM等常见算法，并具有丰富的实战经验；4. 有分布式算法研发经验，熟悉Hadoop/Spark框架，具有海量数据处理中的算法优化经验；5. 三年以上用户模型/个性化推荐/资源模型/广告/搜索系统算法应用于生产系统经验和能力，对个性化推荐系统有深刻理解。,"移动互联网,电商",150-500人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6573099.html,徐汇区,28k-40k,上海驹旗网络科技有限公司,5-10年,本科,"大牛多,气氛好","职责描述：1、负责大数据平台搭建设计和数据开发；2、基于业务需求和应用场景，抽取呈现可用数据，帮助业务需求；3、为业务线提供数据支持和服务，降低数据使用成本，让数据赋能业务。任职要求：1、本科或以上学历，计算机专业，3年以上大数据项目开发经验；2、掌握Java/Scala其中至少一种, 熟悉Spring相关框架；3、熟悉Hadoop/Hbase/Storm/Spark等分布式计算技术，熟悉其运行机制和体系结构；4、具有独立完成从方案选型设计到原型系统开发实现的能力；5、有较强的沟通表达能力，善于学习，能迅速理解产品需求；有较强的责任心和事业心，能够自我驱动；6、熟悉docker/impala/elasticsearch/mongodb等技术的优先。","移动互联网,电商",150-500人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7179607.html,浦东新区,12k-17k,上海金亥通信设备有限公司,3-5年,大专,"五险一金,带薪休假，项目奖金",职位描述：1.负责数据产品的数仓模型设计、优化；2.负责数据模型的ETL开发及维护；3.负责面向业务的数据消费、提取、分析、报表、挖掘等系统设计和开发工作；4.负责数据全生命周期管理和数据源头回溯相关的技术开发工作；5.负责数据仓库质量控制、稽核的相关开发工作。任职资格：1、计算机专业大专及以上学历。两年以上的离线、实时、OLAP数据分析处理项目经验；2、精通SQL开发，掌握MySQl、Oracle等关系型数据库中的一种，对redis、mongoDB等数据库有一定的了解；3、具备实时处理框架的设计和开发能力，熟练掌握Storm、Spark streaming等大数据实时处理框架中的一种；4、熟悉Spark 、R、Hadoop、Hbase、Hive、Elastic Search/Solr等大数据相关技术；5、熟悉Scala、熟悉Linux开发环境，能进行shell脚本/python脚本的编写；6、两年以上数据仓库设计和ETL开发经验，熟悉数据仓库建模设计、元数据管理、数据质量监控等；7、具有较强的逻辑分析能力，高度的责任心及团队合作精神。,"企业服务,数据服务",50-150人,spark,上海
安全运维经理,https://www.lagou.com/jobs/5931401.html,杨浦区,30k-60k,即科金融信息服务（上海）有限公司,5-10年,本科,晋升空间 精英团队,【岗位职责】负责数据安全标准规范的制定和管理，包括数据安全需求识别、风险分析、数据脱敏、数据流转、泄露防护、权限管控等负责数据安全系统平台的建设工作，包括数据脱敏框架、集中流转、权限管理、风险监控等的实施建设和项目管理负责数据安全的日常维护和管理工作，包括数据开放的安全审核、数据安全事件的监控与响应、安全合规的审计与调查等跟踪分析最新安全动态，研究数据安全建模、分析等技术 【岗位要求】1、 熟悉数据安全主流技术，如行为监控、数据脱敏、权限管控等，并有相关实践经验2、 熟悉安全大数据分析，了解主流分布式计算框架（如Hadoop/HBase/Spark/Hive/Kafka等）3、 在安全风险评估、安全监控和响应等方面具备较为丰富的维护和管理经验4、 熟悉互联网业务，具备数据应用的敏感度，能判断数据的价值5、 能快速接受和掌握新技术，有较强的独立学习能力6、 本科及以上学历，五年以上相关工作经验。7、 精通系统、网络、防火墙以及应用相关的安全攻防知识；掌握系统安全配置、熟悉常见的网络攻击和预防方法；熟悉常见的企业内部安全、互联网安全防御及保障技术，熟悉各类安全工具的使用、结果分析与安全配置范围；8、 熟悉各类网络安全设备、系统，如防火墙、VPN、IPS、WAF、防毒墙、网页防篡改系统等；9、有CISA、CISSP、CISP、CCIE Security 等信息安全认证及互联网公司安全从业经历者优先,金融,150-500人,spark,上海
算法工程师,https://www.lagou.com/jobs/345201.html,杨浦区,15k-25k,即科金融信息服务（上海）有限公司,1-3年,本科,初创公司，高速成长，靠谱团队，提供午餐,"职位描述
 利用自然语言/机器学习等算法进行数据处理和挖掘、提出系统算法优化改进。
职位要求
 全日制本科(及以上)相关专业毕业计算机专业机器学习、数据挖掘处理方向；数学专业统计学、应用数学方向优先；2年及以上实际项目研究和工程经验；
 熟悉自然语言处理、对互联网数据挖掘尤其是文本挖掘有实际项目经验；有推荐、广告、搜索相关工作或项目经验者优先；
 熟悉Linux操作系统，熟练掌握Java/Python/C++/R/Clojure等编程语言之一；
 有大规模分布式计算平台Hadoop、Spark等系统的使用和并行算法开发经验的优先；
 对数据敏感，工作积极严谨，有较强的学习能力以及快速解决问题的能力；
 有良好的英文读写能力，可以熟读英文技术文档；有良好的沟通技巧及团队协作精神；
其他
 提供github或stackoverflow账号者有加分；",金融,150-500人,spark,上海
数据开发工程师,https://www.lagou.com/jobs/7092367.html,浦东新区,15k-30k,盛趣信息技术（上海）有限公司,不限,本科,五险一金、餐补、交补、商业保险、带薪年假,岗位职责1. 负责实时和离线数据平台的建设和优化，不断提高系统运行效率及稳定性； 2. 负责实时计算、运维监控等大数据平台相关子系统开发； 3. 为数据开发人员和数据分析师提供大数据技术指导，解决大数据平台应用中遇到的技术难题；任职资格1. 计算机或相关专业本科及以上学历，2年以上大数据相关工作经验； 2. 熟悉Hadoop、Spark、Kafka、Hive、Hbase、Flume、Elasticsearch等大数据相关技术和工作原理；3. 扎实的Java基础，熟悉Spring boot/Spring cloud等微服务开发框架；4. 有大数据平台相关项目的实际开发和调优经验； 5. 对大数据技术有强烈兴趣，思路开阔，喜欢钻研新技术；,"移动互联网,游戏",2000人以上,spark,上海
大数据平台架构师,https://www.lagou.com/jobs/6916694.html,浦东新区,25k-40k,盛趣信息技术（上海）有限公司,5-10年,本科,五险一金、餐补、交补、商业保险、带薪年假,岗位职责：1、负责公司大数据平台的设计、开发、性能优化、技术难点攻关； 2、负责构建高性能、稳定、灵活的实时大数据计算平台； 3、保障大数据平台架构的合理性、可扩展性及经济性；4、研究跟进大数据领域新技术及分享。 任职资格：1、计算机或相关专业本科及以上学历，3年以上大数据工作经验，有复杂数据业务全局架构设计经验； 2、熟悉主流大数据计算引擎(Hadoop、Spark、Presto等），深刻理解内部机制和原理。3、精通Flume，Kafka，Elasticsearch、Flink等实时系统组件，有至少一个以上相关项目实际开发经验； 4、Java基础扎实，有高可用高并发架构设计经验的优先； 5、熟悉数据仓库开发流程和数据仓库的各个子系统； 6、对新技术敏感，有独立分析，技术研究能力，乐于接受挑战，具有良好的团队合作精神。,"移动互联网,游戏",2000人以上,spark,上海
广告策略算法工程师,https://www.lagou.com/jobs/6937560.html,闵行区,25k-45k,上海触乐信息科技有限公司,3-5年,本科,美股上市 牛人团队 亿级日活 福利待遇佳,岗位职责：1、利用数据挖掘和机器学习方法设计和优化广告变现产品策略；2、参与用户、素材画像、商品属性等方面的海量数据清洗和特征工程，为广告精准定向提供数据支撑；3、参与各类排序、回归、分类、和优化算法的开发与迭代，以及在线serving；4、应对全球化，多数据中心的技术挑战，研发全球一体的广告系统；5、研究并解决的在线广告生态体系中涉及的各种问题，更好地服务各类型广告主；任职要求：1、具备相关3年以上从业经验，计算机、数学等相关专业本科及以上学历；2、有数理分析方面良好的素养以及数理统计基础，对数据结构和算法设计有较为深刻的理解，具备编写复杂算法的能力；3、熟练掌握数据挖掘、机器学习、优化算法的基础理论和方法，了解Embbeding等方法理念；4、丰富的海量数据处理和挖掘经验，熟练使用Hive、Hadoop、Spark等工具；5、良好的编程功底，精通至少一门面向对象编程语言（golang、python、c/c++），熟悉Linux平台；6、良好的英文文献阅读能力，有算法调研与实现经验；7、对创新和挑战的工作有激情，有良好的沟通能力和团队管理能力，具备出色的规划、执行力、团队责任感以及优秀的学习能力,"移动互联网,数据服务",500-2000人,spark,上海
广告策略算法专家,https://www.lagou.com/jobs/6937547.html,闵行区,40k-60k,上海触乐信息科技有限公司,5-10年,本科,美股上市 牛人团队 亿级日活 福利待遇佳,岗位职责：1、利用数据挖掘和机器学习方法设计和优化广告变现产品策略；2、开发和实施可并行的排序、回归、分类、和优化算法；3、提升广告CTR/CVR模型预估精度，提高在线广告的相关性、用户体验、投放效果及变现能力；4、负责流量控制、广告pacing算法、广告竞价机制的研究与实现；5、应对全球化，多数据中心的技术挑战，研发全球一体的广告系统；6、研究并解决的在线广告生态体系中涉及的各种问题，更好地服务各类型广告主；任职要求：1、具备相关5年以上从业经验，计算机、数学等相关专业本科及以上学历；2、熟悉计算广告理论，从事过广告竞价机制及预估模型优化相关工作；3、有数理分析方面良好的素养以及数理统计基础，对数据结构和算法设计有较为深刻的理解，具备编写复杂算法的能力；4、熟练掌握数据挖掘、机器学习、优化算法的基础理论和方法；5、丰富的海量数据处理和挖掘经验，熟练使用Hive、Hadoop、Spark等工具；6、良好的编程功底，精通至少一门面向对象编程语言（golang、python、c/c++），熟悉Linux平台；7、良好的英文文献阅读能力，有算法调研与实现经验；8、对创新和挑战的工作有激情，有良好的沟通能力和团队管理能力，具备出色的规划、执行力、团队责任感以及优秀的学习能力。,"移动互联网,数据服务",500-2000人,spark,上海
BI数据分析师,https://www.lagou.com/jobs/7079265.html,黄浦区,12k-18k,上海阿牛信息科技有限公司,1-3年,本科,发展空间大 扁平化管理 团队氛围自由,岗位职责1. 负责规划业务分析点，为产品和业务部门提供准确、灵活、便捷的数据分析和决策支持；2. 负责业务报表体系，输出准确的报告，提出业务改进的方向和策略；3. 帮助业务部门理解规范数据使用，支持各部门的数据需求，提高部门数据的能力；4. 参与产品用户生命周期的全过程 ，包括留存分析、漏斗分析等；5. 帮助建立用户画像，支持增长的A/B测试。任职要求1. 两年以上工作经验，有统计、计算机、数学相关专业背景；2. 具备良好的逻辑思维能力，对用户增长和业务逻辑有较深的认识；3. 熟练掌握并精通SQL，熟悉Hive SQL、python、spark等技术；4. 使用过 Tableau、GrowingIO等工具者优先。,"金融,移动互联网",150-500人,spark,上海
后端工程师,https://www.lagou.com/jobs/7164722.html,浦东新区,20k-40k,美银宝网络信息服务（上海）有限公司,不限,本科,"带薪年假,职业发展","You will closely work with the various world-class data driven e-payment related businesses by using the cutting-edge technologies and advanced data solution. E.g., risk control, customer services, privacies and etc.  You will face the complex big data challenges or problems for reg-tech industry domain, which turns the big data to more valuable business insights, like customer profiling, risk assessment/vetting and so on. You will develop the enterprise-level algorithms and solutions for huge amount of data, various types of data for more business insights. ·       Works with PayPal business units and Product Dev teams to design, develop and deliver solutions on one of the largest data platforms in the world.·       Design and develop prototypes for innovative ideas.·       Join in the design and development of applications, to support PayPal business units for compliance and risk management, fraud detection, business insights, predictive analysis, etc.·       Collaborate with other teams or groups to identify challenges and design solutions. Basic Qualifications·       Major in Computer Science or Engineering·       Solid knowledge and experience in Java development and software engineering.·       Solid knowledge and experience in basic algorithms.·       Familiar with web related frameworks.·       Good understanding of database principles and SQL beyond just data access.·       Analytical thinking and problem-solving skills.·       Excellent oral and written communication skills in English. Preferred Qualifications·       Expert in multiple programming/scripting languages, including Unix/Linux shell scripting, Perl, Python, C++, Java, Python, Ruby, Scala and etc.·       Familiar with various big data technologies, open source data processing frameworks. E.g., Spark, Hadoop, HBase, Elastic Search, Pig, Hive, and so on.·       Familiar with frontend development, e.g. html, javascript, etc.·       Knowledge on the following business domains: Risk, Payments, e-commerce","移动互联网,金融",2000人以上,spark,上海
资深数据工程师,https://www.lagou.com/jobs/7105633.html,浦东新区,25k-40k,美银宝网络信息服务（上海）有限公司,5-10年,本科,海外汇报线，英文为工作语言,"Note: 该团队成员和汇报线均在海外，英文需要作为工作语言Responsibilities: ·       Build scalable systems, lead technical discussions, participate in code reviews, guide the team in engineering best practices. Must be able to write quality code and build secure, highly available systems. 75% of the job requires production quality coding.·       Provide technical insights and contribute to the definition, development, integration, test, documentation, and support across multiple platforms ·       Highly detailed with a systematic approach, sense of responsibility and strong, positive customer focus. ·       Must be results focused and highly energetic to drive the defined team and organizational goals·       Establish a consistent, project management framework and development processes to deliver high quality software, in rapid iterations, for business partners in multiple geographies·       Manage a team that designs, develops, troubleshoots and debugs software programs for databases, applications, tools, networks etc.·       Must have demonstrably strong interpersonal and communication skills (both written and verbal), to include speaking clearly and persuasively in positive or negative situations·       Experienced in balancing production platform stability, feature delivery, and retirement of technical debt across a broad landscape of technologies Qualifications:·       5+ years of post-college working experience as a developer and architect in Engineering, or Data-Mining organization·       4+ years of Hadoop / ETL experience is required·       4+ years of strong SQL working experience is required·       4+ years of SPARK/HIVE experience is preferred·       2+ years of Linux/Unix/Python coding experience (including scripting) is required·       Strong conceptual and creative problem-solving skills; ability to work with considerable ambiguity; ability to learn new and complex concepts quickly. Relentlessly resourceful and scrappy·       Mandarin and English speaking mandatory","移动互联网,金融",2000人以上,spark,上海
高级JAVA开发,https://www.lagou.com/jobs/7172086.html,浦东新区,28k-40k,苏州精正信息科技有限公司,5-10年,本科,国企,1、全日制工科、计算机、统计或其它相关专业本科及以上学历，至少3年以上业务系统开发经验（含2年中间件开发、调优经验）；2、熟悉Java/Go/Scala/Python其中一种或多种；3、具备模块或子系统的架构设计能力，掌握常见的架构设计方法和模式，理解大型网站所需要用到的架构和技术；4、熟悉分布式缓存，消息中间件、分布式文件存储、数据分片框架、分布式事务、NoSQL、搜索、海量数据存储/处理等领域中其中2~3个的整体架构设计；5、有大型分布式系统研发经验，具备高性能、高可用、可扩展系统的体系化建设能力；6、熟悉Hadoop生态、Spark生态、Flink生态优先，具有二次开发经验优先；7、对业务产品具有独立沟通、完善业务需求，并识别方案的风险的能力；能够在负责的业务上有独立的见解，能提出合理的建议；8、具有高度的责任心，具有较强的适应能力和自学能力、良好的沟通协作、应急响应与问题处理能力，做事专心专注，能够独立分析和解决问题。,"企业服务,金融",少于15人,spark,上海
模型开发岗,https://www.lagou.com/jobs/6728624.html,浦东新区,10k-15k,拉勾猎头,1-3年,本科,大平台,﻿1、统筹模型开发、全生命周期模型管理、平台建设、新工具开发和个性化服务定制； 2、统筹推动模型开发组工作量化管理，制定工作量化统计方案，有效统计并推动各项工作进展； 3、有一定的构建大数据风控模型经验，包括但不限于反欺诈、反舞弊、信用评估、风险预测模型，并持续优化改进； 4、熟悉R、SAS、Python等分析工具，结合各类业务场景，根据风控的控制点建立模型，完善风控； 5、具有互联网金融、投资、保险行业大数据建模经验； 6、了解人工智能等新知识新技术；﻿1、教育程度：本科及以上学历，具有人工智能、数据挖掘、统计学、应用数学、金融数学、软件工程、计算机等相关专业背景； 2、相关经验：2年及以上互联网金融、大数据分析、人工智能建模经验； 3、专业能力：熟悉hadoop、oracle数据库，掌握一定的数据建模等专业技术，熟悉机器学习常用算法及建模应用（包括关联规则、神经网络、SVM、遗传算法、随机森林等），掌握R、SAS、spark等分析工具，sql、python、scala、JAVA等编程语言，熟悉系统平台搭建开发流程及关键技术，具有互联网金融、投资、保险行业大数据建模经验为佳； 4、核心能力：系统思维能力、工作组织、推动能力、沟通协调能力、风险评估与控制能力，曾从事相关行业领域人工智能开发及建模工作者优先考虑；,"移动互联网,企业服务",500-2000人,spark,上海
数据开发岗（上海）,https://www.lagou.com/jobs/7125736.html,浦东新区,13k-26k,拉勾猎头,3-5年,本科,大平台,﻿1..构建法律、风控业务数据仓库（分层建设、主题模型、元数据管理、性能和效率优化） 2.从数据采集，数据建模，到数据应用全流程参与设计与开发 3.优化数据生产链路，提高数据时效性 4.实时数仓、特征工程、用户画像等系统的设计和开发。﻿1. 本科以上学历，计算机相关专业，3年以上工作经验。 2. 熟悉网络协议栈，数据结构与算法以及数据库性能优化与操作系统原理  3. 编程功底扎实，熟练掌握Python，Hive，SQL等语言，有较强的ETL开发经验者优先 4. 掌握大数据相关技术，如Hadoop/Hbase/Spark／hive/flink引擎等技术，良好的逻辑思维能力和沟通能力； 5. 熟悉数据仓库架构及原理，能独立进行数据仓库数据建模； 6. 熟悉数据仓库建设方法论： a：了解数仓分层建设方法； b：了解主题建设方法，能抽象主题、建设模型、物理化并调整效率和性能；,"移动互联网,企业服务",500-2000人,spark,上海
大数据开发工程师(J11494),https://www.lagou.com/jobs/7077230.html,普陀区,15k-30k,秒针信息技术有限公司,3-5年,本科,更多福利可与HR详谈,,"数据服务,广告营销",2000人以上,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/5862517.html,闵行区,12k-24k,上海莉莉丝科技股份有限公司,3-5年,本科,"弹性工作,福利待遇好,工作氛围好",1） 大数据平台相关业务组件开发2) 根据业务需求更新大数据平台的数据架构3) 部署和维护机器学习算法平台以及算法模型流水线4 大数据平台运维1） 计算机相关专业，熟悉linux开发环境2） 熟悉常用bash命令，能够编写bash脚本。3） 熟悉python，ruby等脚本编程语言（任一）4） 了解Hive，Impala，Spark，HBase等Hadoop相关工具者5） 了解常用的容器技术，如docker，k8s等6） 有机器学习模型线上部署经验优先7） 热衷于钻研技术，热爱软件开发，工作踏实认真，责任心强，勇于接受挑战,"移动互联网,游戏",500-2000人,spark,上海
高级数据分析师,https://www.lagou.com/jobs/7167177.html,徐汇区,18k-28k,深圳虾皮信息科技有限公司,3-5年,本科,专业团队、零食饮料、领导nice、福利好,职责描述：1、 负责跨境电商业务相关的数据提取、数据分析、商业洞察及优化方案等工作；2、 构建多角度、多层次的业务分析指标看板和监控报表；3、与业务团队有效沟通，准确理解和把握数据分析需求；针对模糊需求，能基于经验，帮助业务团队定位问题，并对数据需求进行拆解和梳理；在沟通过程中，能起到一定的引导作用；4、从多角度分析模型构想、数据收集准备到模型实现和商业洞察，开展端到端的数据管理和分析；5、有效地向业务团队呈现分析结果和解决方案，推动业务优化。 岗位要求：1. 3 - 5年互联网领域数据分析师工作经验，电商/O2O相关领域分析师优先考虑；2. 对数据驱动业务有深入理解，对数据和商业有很强的敏感性；3. 数学、统计、计算机软件、电子商务等相关专业本科或以上学历；4. 较强的数据处理能力，精通SQL、Python、R、SPSS等一种或多种，有过Spark和海量数据分析经验优先考虑；5. 善于观察与学习，耐心且具有良好的沟通能力与团队协作意识；6. 具备英语听读写能力，CET6或以上。,电商,500-2000人,spark,上海
大数据架构师,https://www.lagou.com/jobs/7207646.html,徐汇区,25k-35k,上海悠星网络科技有限公司,5-10年,大专,绩效奖金、年底双薪、公司旅游、团建生日会,"岗位职责1、负责制定公司大数据处理框架的迭代设计工作，梳理可实现方案和技术规范；2、负责分析行业大数据应用及技术动态，研究竞争对手产品和市场策略；3、负责产品规划及产品发展方向的整体把握，全面策划及统筹产品的发展规划，设计在线、离线、流处理等大数据场景应用；4、负责业务平台数据统计分析模块的设计与规划及研发过程中的数据及存储设计；5、负责建立和维护大数据平台技术标准规范，指导开发人员编写代码。任职资格1、具有5年以上大数据架构工作经验；有过搭建千万级亿级以上数据量解析运算的大数据系统经验优先；2、熟练掌握一门或以上大数据开发相关语言（Python, Java等）；3、精通离线和实时数据处理流程，掌握离线数据处理框架，掌握实时数据处理常用技术工具等；4、熟悉Hadoop架构与生态圈（如：DFS、Hive、HBASE、Mapreduce、Spark、SparkStreaming、Kafka、ElasticSearch、Flink等）；5、强烈的工作主动性和责任心，且热爱技术、具有钻研精神；6、对公有云的大数据组件有一定了解。","游戏,移动互联网",150-500人,spark,上海
2631BQ-物联网开发工程师,https://www.lagou.com/jobs/7017163.html,浦东新区,15k-25k,平安国际融资租赁有限公司,3-5年,硕士,"五险一金,节日福利,定期体检,免费班车",,金融,500-2000人,spark,上海
0821NX-投资大数据仓库开发专家,https://www.lagou.com/jobs/6735782.html,浦东新区,25k-40k,平安养老保险股份有限公司,3-5年,本科,"五险一金,带薪年假,节日福利,绩效奖金",工作职责工作职责 :1. 负责投资大数据仓库设计2. 业务数据体系采集及处理流程的设计、业务模型设计、数据分析及数据建模3. 优化现有数据平台，提升数据处理效率及智能化运维的能力4. 参与业务需求讨论，可协助用户梳理业务规则并系统落实化5. 数据可视化开发，提升用户体验6. 按照编码规范对代码进行检视，并编写单元测试案例、集成测试案例任职要求1. 统招全日制大学本科及以上学历2. 5年以上数据库开发经验，3年以上大数据仓库建设与研发经验； 3. 根据业务需求设计数据仓库模型，熟悉离线、实时数据采集、加工方法；4. 熟悉数据仓库和数据建模相关技术细节，有编程经验，熟悉Scala/Python等语言；5. 了解Hadoop或 Spark生态相关技术，包括HDFS、Hive、Spark、Flink等；6. 有较强的学习能力，良好的团队协助精神，沟通协调能力； 7. 有证券金融相关项目背景优先考虑。,金融,2000人以上,spark,上海
BI工程师,https://www.lagou.com/jobs/6751503.html,虹口区,12k-16k,民生人寿保险股份有限公司,不限,本科,发展平台、五险一金、领导好,"工作职责：1.负责数据可视化内容的视觉设计和优化工作；2.了解公司业务，将现有Excel及BIEE报表呈现内容转换成帆软工具形式呈现；3.对图形学和数据有一定的了解，能对数据进行梳理与分析，与同事共同探讨挖掘挖掘数据图形化表达的潜力；4.能对业务提出的各类报表需求及时的进行ETL和可视化开发；任职资格：1.熟悉数据仓库的架构体系，有保险行业数据集市，数据仓库优先；2.精通各类报表的开发，有过如congnos,BO,tableau等工具的使用经验（有帆软BI经验的优先）；3.精通存储过程的开发，具备sql的调优经验，熟悉各类索引，熟悉分区；4.有大数据平台数仓的开发经验优先，熟悉hive，flink，hbase，spark，redis等技术；5.具备2年以上保险相关行业的从业经验，对保险业的基本业务知识有了解；6.耐心仔细，责任心强，具备良好的沟通和团队协作能力，团队合作意识强，能适应高强度的工作，并保持积极乐观精神；",金融,2000人以上,spark,上海
大数据平台开发工程师,https://www.lagou.com/jobs/6751525.html,虹口区,17k-24k,民生人寿保险股份有限公司,3-5年,本科,发展平台、五险一金、领导好,工作职责：1、要求能自主完成大数据平台功能模块的设计、开发、性能调优；2、负责日常数据模型的理解、技术方案设计、技术开发与测试；3、负责编制与产品或项目相关的技术文档。任职资格：1、理工科相关专业，本科以上学历，3-5年经验，计算机专业优先；2、具有保险行业工作经验，熟悉寿险业务者优先，有过监管报送系统的开发经验者优先；3、熟悉oracle、mysql等主流工具、技术，熟悉Hadoop、Spark、Flink、Kafka、Flume、HBase等大数据组件的原理，有大型项目开发经验，有系统优化和故障排错的经验和能力；4、熟悉Linux Shell开发，熟悉ClickHouse/Druid/Kudu者优先。,金融,2000人以上,spark,上海
Java/Scala大数据开发工程师,https://www.lagou.com/jobs/7148878.html,浦东新区,18k-30k,上海擎创信息技术有限公司,5-10年,本科,大数据量、复杂的业务场景,"岗位职责： 1. 负责共研及实施项目的开发工作 2. 完成开发相关文档 3.完成PM安排的开发工作，有独立开发能力和钻研精神   岗位要求： 1. 计算机以及相关专业本科及以上学历，3年以上Java或Scala开发经验； 2. 熟悉主流的开发框架，如Spring，SpringMVC, REST+JSON等开发能力 3. 熟悉Maven的使用、理解Maven的原理与使用技巧，熟练用Git进行代码版本控制 4. 熟练使用Mysql, Orale等关系型数据库，有大批量数据快速处理与优化经验 5.熟悉常用设计模式，架构模式，并有创新思维；熟练掌握面向对象开发技术，如能够对系统设计有独特的见解优先考虑 6. 具备较好的编码习惯，熟悉并能使用常见的设计模式； 7. 熟悉Zookeeper、Kafka、Elasticsearch及相关开发经验者优先 8.对Linux操作系统熟练掌握，熟悉shell等脚本编程 9.参与过分布式高性能服务的设计开发过程，有大规模分布式系统的实践经验者优先考虑 10、熟悉大数据开发有spark、flink及hadoop经验优先11.工作主动积极，责任心强，具有良好的沟通协作能力和团队合作意识，能承受较大的工作压力","企业服务,数据服务",50-150人,spark,上海
搜索Java经理,https://www.lagou.com/jobs/6750459.html,浦东新区,50k-65k,耀方信息技术（上海）有限公司,5-10年,本科,上市公司 大平台 发展空间,"职位描述：1、负责ES管理平台的架构设计与开发,负责基于ES数据检索产品的架构的设计与开发2、负责ES集群的性能调优与自动化运维,持续提升现有系统的稳定性和性能3、参与软件项目的设计与开发工作，包括需求分析、系统设计、编码和单元测试等工作。4、负责完成重要业务模块及核心框架的搭建及编码实现。5、制定技术规范和接口标准，保障平台服务在高并发环境下的性能和稳定性，6、为各业务线研发可复用的基础服务、开发框架和代码库，提升技术团队的开发效率。7、负责公司统一搜索平台系统的架构设计和开发，为业务提供灵活、稳定、高效的解决方案8、针对搜索的业务现状，探索和创新搜索技术。 岗位要求:1、编程基础扎实，熟悉JVM性能调优，能充分利用Java语言特性，以及相关的框架、程序包进行程序设计开发2、至少一年以上的ElasticSearch运维或开发经验，熟悉ES部署、监控及性能调优3、熟悉分词和搜索引擎原理，熟悉Spark和ESHadoop者优先4、善于分析总结问题,热衷技术,精益求精,喜欢研究开源代码,有高并发、大数据处理实际项目产品经验者优先5、本科以上学历，扎实的数据结构、操作系统、编译原理等6、有Java服务端开发经验，熟悉相关技术栈，熟悉网络开发，多线程开发，熟悉Linux开发环境7、具有一定的系统设计和架构能力，能够独立完成系统的设计和实现8、具有ES/Solr/Lucene等相关开发经验者优先具有搜索、推荐、广告系统开发经验者优先。9、学习并参与体系化的核心搜索系统建设，包括分布式检索引擎、实时数据引擎、在线特征计算与模型预估框架等，研发高可用、高稳定、高吞吐、低延迟的搜索系统","移动互联网,电商",500-2000人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7210262.html,浦东新区,12k-18k,奥解思信息科技（上海）有限公司,3-5年,本科,外企办公环境，弹性工作制，成长空间大,1.spark要求比较高，希望有1-2年。2. Java基础好，辨别项目中java有多久，希望1-2年3.211/985优先/省市重点本科。4.面试时候首先会面10分钟英文，如果英文不好的面技术不是特别强就会尽快结束面试。入职后会和印度人一起工作偶尔开会；英文好的人，技术偏弱会考虑。5. java很强 spark一般也可以考虑；,金融,500-2000人,spark,上海
大数据开发主管,https://www.lagou.com/jobs/7203395.html,浦东新区,35k-55k,上海银科创展投资集团有限公司,5-10年,本科,上市公司,1.      岗位职责：a)      负责大数据开发团队的管理工作。b)      负责大数据平台的架构设计和开发工作。满足实时、离线计算的需求；满足数据分析和在线应用报表的高效快速查询需求。c)      负责大数据平台的运维和性能调优，确保平台的稳定运行。d)      结合业务场景和流程，制定数据治理规范，确保数据完整性、准确性和及时性。2.      能力要求：a)      本科以上学历b)      5年以上工作经验，3年以上的大数据团队管理经验，条件特别优秀者可适当放宽。c)      3年以上大数据平台基础架构、开发、运维、调优经验。熟悉大数据领域相关生态，对Hadoop/MapReduce/Hbase/Hive/Kafka/Spark /Yarn等有较深的认识。d)      精通Java语言编程，3年以上Java/Scala开发经验。熟悉Java、Java Web、JVM原理，包括内存模型、类加载机制以及性能优化等，拥有Java Web开发经验；e)      熟练使用python或者shell等脚本语言，熟练进行Linux的运维操作；f)       熟悉虚拟化应用的部署与运维，如Docker、K8S、Swarm等技术g)      处理的数据量级在20TB级别以上h)      熟悉以下数据引擎或者框架中的一种及以上：presto【优先】、Impala、sparksql、Clickhouse、kylin、GreenPlum、MPP。,"移动互联网,金融",2000人以上,spark,上海
大数据架构师,https://www.lagou.com/jobs/7203378.html,浦东新区,35k-55k,上海银科创展投资集团有限公司,5-10年,本科,上市公司,1.     岗位职责：a)     负责大数据开发团队的管理工作。b)     负责大数据平台的架构设计和开发工作。满足实时、离线计算的需求；满足数据分析和在线应用报表的高效快速查询需求。c)     负责大数据平台的运维和性能调优，确保平台的稳定运行。d)     结合业务场景和流程，制定数据治理规范，确保数据完整性、准确性和及时性。2.     能力要求：a)     本科以上学历b)     5年以上工作经验，3年以上的大数据团队管理经验，条件特别优秀者可适当放宽。c)     3年以上大数据平台基础架构、开发、运维、调优经验。熟悉大数据领域相关生态，对Hadoop/MapReduce/Hbase/Hive/Kafka/Spark /Yarn等有较深的认识。d)     精通Java语言编程，3年以上Java/Scala开发经验。熟悉Java、Java Web、JVM原理，包括内存模型、类加载机制以及性能优化等，拥有Java Web开发经验；e)     熟练使用python或者shell等脚本语言，熟练进行Linux的运维操作；f)      熟悉虚拟化应用的部署与运维，如Docker、K8S、Swarm等技术g)     处理的数据量级在20TB级别以上h)     熟悉以下数据引擎或者框架中的一种及以上：presto【优先】、Impala、sparksql、Clickhouse、kylin、GreenPlum、MPP。,"移动互联网,金融",2000人以上,spark,上海
大数据开发工程师（上海）,https://www.lagou.com/jobs/7142977.html,长宁区,30k-60k,北京奇艺世纪科技有限公司,3-5年,本科,双休，发展前景好,岗位职责：1、负责爱奇艺海外视频业务数据仓库的构建； 2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决； 3、深入理解常用的数据建模理论，可独立把控数据仓库的各层级设计； 4、大数据的离线和实时处理，可以进行海量数据模型的设计、开发。 任职要求：1、本科及以上学历，计算机或数理统计相关专业；2、3年以上企业级数据仓库建模经验，有数据挖掘，机器学习，推荐相关经验优先；3、熟练掌握Hive/SQL，熟练掌握Hadoop及Map-Reduce应用开发，熟悉Hive、Spark、Flink等大数据开发工具中一种或几种；4、熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖掘和数据可视化；5、具有较好的逻辑思维能力和创新能力，对未知领域有浓厚的好奇心。 温馨提醒：如果 7 天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可。,文娱丨内容,2000人以上,spark,上海
ETL,https://www.lagou.com/jobs/6678196.html,闵行区,16k-21k,上海舟恩信息技术有限公司,3-5年,本科,互联网金融,1、熟悉各类关系数据库，比如MySQL、Oracle等，能够编写复杂的SQL脚本；2、精通企业级ETL工具，如Talend，Informatica，Kettle等，具备持续优化ETL过程，提升ETL性能，解决调度过程中的问题的能力；3、具有良好的沟通能力、问题分析与解决能力；4、学习能力和主动性强，具有钻研精神，充满激情，乐于接受挑战；5、思维严密、逻辑清晰，且责任心强。6、具备3年以上ETL开发经验；有大型数据仓库项目经验；7、有基于Hadoop及相关产品（Hadoop、Hive、HBase、Sqoop、Spark等）的大数据平台项目ETL开发经验。,移动互联网,150-500人,spark,上海
Java高级开发工程师（资讯平台）,https://www.lagou.com/jobs/6874973.html,徐汇区,20k-40k,东方财富信息股份有限公司,5-10年,本科,节日福利 年底双薪 五险一金,"工作职责:1、参与业务需求分析，参与确定技术方案；2、根据设计要求进行中后台应用的开发、调试与集成；3、负责中后台独立功能模块的需求分析、技术设计和开发任务；4、参与对运行系统的性能调优、BUG分析及修正等优化工作；5、完成公司交办的其他工作。任职资格:1、全日制统招本科及以上学历，计算机相关专业；2、5年以上基于java的服务器端系统开发经验，熟悉面向对象编程思想、常用设计模式；3、牢固掌握Java基础，包括集合，io流，多线程等；  4、熟练掌握Spring Cloud、Dubbo(RPC)、SOFA等开源框架，熟悉SSM整合技术；5、有丰富使用mysql，Oracle，sql server，mongoDB等数据库的经验；6、熟悉linux/UNIX等操作系统，有JVM性能调优经验者优先；7、有Hadoop, HBase, Hive, Spark, Storm等使用经验者优先；8、有信息流、实时运营、资讯加工、推荐算法等经验者优先；9、有高并发、高吞吐、强事务、高秒杀、中间件等经验者优先；10、有写过开源项目、技术框架、技术专利等项目经验者优先。",金融,2000人以上,spark,上海
大数据开发实习生,https://www.lagou.com/jobs/6731776.html,黄浦区,3k-6k,引粒网络科技（上海）有限公司,不限,本科,极佳的办公环境，发展空间前景好,工作职责:1、协助资深研发参与大数据BI系统设计和开发；2、负责大数据平台的优化维护、协助进行数据仓库平台的模型设计和开发维护；3、负责后台日常数据统计分析；任职资格:1、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等） ；2、熟悉数据仓库理论与技术，对ETL及BI有概念并具有丰富的实际操作经验，熟悉ETL开发流程； 3、熟悉BI项目，具有数据仓库、BI系统开发经验者优先； 4、熟练操作linux系统，熟悉shell脚本或python； 5、有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题；,社交,15-50人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6731653.html,黄浦区,20k-40k,引粒网络科技（上海）有限公司,3-5年,本科,极佳的办公环境，发展空间前景好,工作职责:1、负责大数据BI系统设计和开发；2、负责大数据平台的优化维护、数据仓库平台的模型设计和开发维护；3、负责后台日常数据统计分析；任职资格:1、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等） ；2、熟悉数据仓库理论与技术，对ETL及BI有概念并具有丰富的实际操作经验，熟悉ETL开发流程； 3、熟悉BI项目，具有数据仓库、BI系统开发经验者优先；4、对mysql、oracle有丰富经验，有较强的数据库脚本编程能力，有较强的存储过程编写能力； 5、熟练操作linux系统，熟悉shell脚本或python； 6、有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题；,社交,15-50人,spark,上海
高级后端开发,https://www.lagou.com/jobs/4877705.html,浦东新区,20k-40k,上海品览数据科技有限公司,3-5年,本科,"AI+,新零售+,大牛多多,成长带回报",职责描述：具备优秀的后端开发能力，完成企业级 SaaS 产品的开发和部署；具备公有云和私有云架构开发经验，开发和管理自动化运维工具；具备优秀的 python 开发能力，设计基于 Flask 框架的 web 应用和爬虫工具；具备分析技术需求，并且能够进行灵活的技术选型的能力；职位要求：熟练掌握 Python/C++ 等编程语言，熟悉常见的算法与数据结构；熟悉常见的框架，例如：Flask，Django 等；熟悉 Linux/Unix 操作系统及运维；具备大数据平台架构经验，熟悉 Hadoop、Map/Reduce，Spark、HBase、Hive、Sqoop 等开源项目；熟悉容器技术，例如 Kubernetes，Docker，Prometheus 等，掌握镜像打包和部署的方法；熟练掌握 MongoDB、Redis、Memcache、Cassandra 等数据库开发，熟悉 HTTP 协议和常见的网络等知识；有较强的责任心和良好的沟通能力，能够快速定位并解决问题，具备较强的学习能力。福利待遇：定位：元老后端定位，丰厚期权，随发展灵活涨薪；扁平化的团队管理，你的能力可以价值最大化；开放的创业团队氛围，聆听你的精彩意见；精英优秀的技术团队，秉承产品至上的专业态度；,"数据服务,人工智能",50-150人,spark,上海
后端工程师,https://www.lagou.com/jobs/6301381.html,浦东新区,15k-30k,上海品览数据科技有限公司,不限,不限,"AI+,新零售+,大牛多多,成长带回报","职位诱惑：精英团队,AI+,发展前景,曝光度职位描述：职责描述：具备优秀的后端开发能力，完成企业级 SaaS 产品的开发和部署；具备公有云和私有云架构开发经验，开发和管理自动化运维工具；具备优秀的 python 开发能力，设计基于 Flask 框架的 web 应用和爬虫工具；具备分析技术需求，并且能够进行灵活的技术选型的能力；职位要求：熟练掌握 Python/C++ 等编程语言，熟悉常见的算法与数据结构；熟悉常见的框架，例如：Flask，Django 等；熟悉 Linux/Unix 操作系统及运维；具备大数据平台架构经验，熟悉 Hadoop、Map/Reduce，Spark、HBase、Hive、Sqoop 等开源项目；熟悉容器技术，例如 Kubernetes，Docker，Prometheus 等，掌握镜像打包和部署的方法；熟练掌握 MongoDB、Redis、Memcache、Cassandra 等数据库开发，熟悉 HTTP 协议和常见的网络等知识；有较强的责任心和良好的沟通能力，能够快速定位并解决问题，具备较强的学习能力。福利待遇：定位：元老后端定位，丰厚期权，随发展灵活涨薪；扁平化的团队管理，你的能力可以价值最大化；开放的创业团队氛围，聆听你的精彩意见；精英优秀的技术团队，秉承产品至上的专业态度；","数据服务,人工智能",50-150人,spark,上海
java,https://www.lagou.com/jobs/7041370.html,闵行区,14k-18k,上海汉得信息技术股份有限公司,5-10年,本科,无,"1.计算机或相关专业，全日制本科及以上学历。2.4年Java软件开发经验。3.精通spring,springboot。4.熟悉Spring，JavaEE，JBoss，Tomcat等。5.熟悉MySQL、Oracle等关系型数据库，及MongoDB、Cassandra等非关系型数据库。6.熟悉Redis, Kafka, RabbitMQ等中间件。7.了解Hadoop、Spark、Python等大数据和数据挖掘工具。8.具备Linux, Windows等操作系统知识。9.了解Subversion, Git, Maven，Jira，Confluence等工具链。10.高度责任感和团队合作精神。","企业服务,数据服务",2000人以上,spark,上海
数据开发,https://www.lagou.com/jobs/6855053.html,长宁区,10k-20k,上海尚诚消费金融股份有限公司,3-5年,本科,薪酬福利健全 发展平台广阔,工作职责:1、主要从事大数据离线平台的设计以及开发工作，维护升级等等；2、负责离线的数据存储和加工处理，保证数据质量，负责数据监体系的建立和维护；3、负责海量数据的清洗、处理和挖掘工作，支持数据分析师和算法工程师的数据需求；4、负责日常数据仓库、监控、分析、性能调优、故障诊断与排除等工作；5、负责数据仓库ETL流程的优化及解决ETL相关技术问题；6、研究前沿技术，解决实际场景中的业务问题，优化离线/实时大数据计算任务的性能。任职资格:1、教育程度：全日制本科及以上学历，计算机或相关专业优先；2、工作经验：3年及以上工作经验，2年以上大数据开发经验，在金融领域或互联网领域有至少1年的从业经验，优秀者可适当放宽； 3、知识技能：熟悉Linux/Unix开发环境，精通数据库基本原理，熟悉SQL语言与shell编程，熟悉Hadoop原理，具备一定的hive、spark开发经验；4、精通数据仓库理论，具备数据仓库开发、维护经验；5、能力素质：良好的团队精神和合作意识，强烈的责任心，对工作有激情，良好的沟通能力，能吃苦耐劳；具备快速学习能力，思路清晰，善于思考。,"金融,移动互联网",150-500人,spark,上海
高级算法工程师（NLP）,https://www.lagou.com/jobs/5482136.html,长宁区,20k-40k,励德爱思唯尔信息技术（北京）有限公司,5-10年,硕士,15-20天年假，生日，圣诞假，节日福利,"LexisNexis – ChinaWho Are We?LexisNexis is the first stop for global legal and business information, meeting international standards as well as local market needs. Serving clients that range from law firms and Government, to business and the academic sector, our Chinese-English bilingual legal database has become an essential resource. This amazing world of information is at our clients’ fingertips. And it’s all thanks to our expert team. SR CONSULTING NLP ENGINEERThrough technology and analytics, LexisNexis is transforming the way many sectors access information. What’s more, we’re continually innovating and creating new and exciting flagship products. You’ll join us in this hub of creativity and excellence, and make your own contribution to powerful innovative solutions. JOB RESPONSIBILITIES·       Perform hands-on data analysis and modelling with huge data sets.·       Apply data mining, NLP, and machine learning/deep learning (both supervised and unsupervised) to improve relevance and personalization algorithms.·       Work side-by-side with product managers, software engineers, and designers in designing experiments and minimum viable products.·       Discover data sources, get access to them, import them, clean them up, and make them “model-ready”. You need to be willing and able to do your own ETL.·       Create and refine features from the underlying data. You’ll enjoy developing just enough subject matter expertise to have an intuition about what features might make your model perform better, and then you’ll lather, rinse and repeat.·       Run regular A/B tests, gather data, perform statistical analysis, draw conclusions on the impact of your optimizations and communicate results to peers and leaders.·       Explore new design or technology shifts to determine how they might connect with the customer benefits we wish to deliver. REQUIREMENTS·       BS, MS, or PhD in an appropriate technology field (Computer Science, Statistics, Applied Math, Operations Research, etc.).·       2+ year’s experience with data science & NLP.·       Strong programming skills with Python.·       Efficient in SQL, Hive, or Spark SQL, etc.·       Comfortable in Linux environment·       Experience in data mining algorithms and statistical modelling techniques such as clustering, classification, regression, decision trees, neural nets, support vector machines, anomaly detection, recommender systems, sequential pattern discovery, and text mining.·       Familiar with latest development in NLP & deep learning·       Solid communication skills: Demonstrated ability to explain complex technical issues to both technical and non-technical audiences.",不限,500-2000人,spark,上海
Senior Python,https://www.lagou.com/jobs/6824031.html,长宁区,20k-30k,励德爱思唯尔信息技术（北京）有限公司,5-10年,本科,福利待遇,"Senior Software Engineer (Python)  Thanks to the industries most talented and innovative technology experts, more clients can access more data than ever before. It’s a hugely exciting environment where products are continually invented – and re-invented – and where your skills can shine in an open, collaborative setting. At LexisNexis, IT professionals enjoy individualized career planning, networking opportunities and rewards for top performance in any respective throughout the organization.   JOB RESPONSIBILITIES  ➢ Join a team of driven software engineers to design, prototype, implement, deploy, and maintain features for our NLP or search related projects. ➢ Conduct experiments on large datasets to evaluate the feasibility, results, and performance of NLP technology. ➢ Make sound engineering decisions and improve software development practices with an eye for performance and reliability.  TECHNICAL SKILLS  ➢ Essential: XPath, RESTful API, Linux ➢ Database: MySQL (at least one kind of relational database), Redis ➢ Framework: flashtext, Flask/Django, Celery, Gunicorn/WSGI, Supervisord, Numpy ➢ Nice to have: AWS knowledge, Faiss(or other efficient similarity search library), Mongodb (or any kind of no-sql db), Spark, NLTK, spaCy, scikit-learn. ➢ Addition：+SQLAlchemy, boto3",不限,500-2000人,spark,上海
0921KP-大数据平台研发,https://www.lagou.com/jobs/6742759.html,徐汇区,20k-30k,平安健康保险股份有限公司,3-5年,本科,"五险一金,绩效奖金,带薪年假,节日福利",,金融,500-2000人,spark,上海
0921N1-数据总监,https://www.lagou.com/jobs/6728074.html,徐汇区,30k-50k,平安健康保险股份有限公司,10年以上,硕士,"五险一金,绩效奖金,节日福利,带薪年假",,金融,500-2000人,spark,上海
高级Java服务端开发工程师,https://www.lagou.com/jobs/7207016.html,徐汇区,30k-40k,东方财富信息股份有限公司,5-10年,本科,公司规模 福利待遇 发展前景,,金融,2000人以上,spark,上海
Java开发专家 - 风控方向,https://www.lagou.com/jobs/7139585.html,杨浦区,30k-50k,上海琅槐商务咨询有限公司,5-10年,本科,国际化发展路径，薪酬福利优厚,"职位描述：1. 负责公司战略级项目（基于流式计算的分布式风控平台）的技术架构规划，设计和实现基于FLINK的大型分布式风控系统，根据可编辑实时生效的规则引擎，建立起静态和动态的风控规则， 为公司提供实时的风控引擎，实时监控公司各条业务线系统的运行、用户行为和安全审计，保护公司系统安全。2. 具备业务的抽象能力，能够抽象、总结沉淀为技术平台能力；对技术风险敏感，对系统潜在的资损、稳定性方面的风险，在预防、监控、线上应急处理等方面有体系化的思考和实践；3. 具备一定的技术难题攻关能力，能持续提升核心系统在高并发、海量请求数下的高处理性能，保证系统的安全、稳定、快速运行。任职要求：1. 精通Java，有8年以上Java开发经验，3年风控系统开发的经验。担任过核心技术骨干,有主导一定规模系统架构设计和核心代码的开发经验 ；2. 熟悉Spring、Kafka、Spark、Flink、Hadoop等开源框架等常用中间件；精通规则引擎，熟悉常用的规则引擎开发技术3. 具备业务抽象和信息建模能力，能够将复杂的业务场景分解、抽象成标准化的业务模型；4. 良好的沟通能力、文档撰写能力、团队合作精神；5. 本科及以上学历，计算机相关专业；6. 有系统安全审计和风控系统相关设计经验优先。",金融,50-150人,spark,上海
项目经理（数据中台方向）,https://www.lagou.com/jobs/7207244.html,长宁区,25k-45k,广州滴普科技有限公司,5-10年,本科,五险一金、节日福利,岗位职责：1、参与及负责大数据项目的实施落地；2、负责大数据产品相关文档编写及培训等工作；3、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；4、协助客户参与各种环境业务系统的投产及技术支持；5、协调项目资源，对于项目实施进度的规划、控制、监督和管理；6、负责与公司内相关部门沟通协调，制定整体方案，推进项目执行；7、负责定期汇报项目状态，跟进项目问题风险。任职要求：1、熟悉Linux操作系统常用命令；2、熟悉Tomcat、Weblogic基本操作及调优；3、熟悉MySQL、Oracle安装及相关配置，熟悉SQL基本操作；4、熟悉Hadoop、Redis、ElasticSearch、HBase、Spark、Storm、Kafka等大数据组件，对离线计算、内存计算和流式计算均有较为深刻理解；5、有一定的Java开发能力者优先；6、熟练掌握Powerpoint、Excel、Project、Visio等工具；7、熟悉软件项目管理过程，具有较强的项目管理能力和沟通协调能力；8、具有较强的大局观，能够统筹跨团队项目，具有丰富的项目组织及人员管理经验，能够有效管理项目团队；9、具备较强的语言表达能力，能与客户顺畅沟通或产品介绍；10、具备较强的学习与动手能力，能够适应出差。,"企业服务,数据服务",500-2000人,spark,上海
售前工程师（大数据方向）,https://www.lagou.com/jobs/3953939.html,徐汇区,15k-30k,上海爱可生信息技术股份有限公司,5-10年,本科,"新三板,团建,技术大牛",岗位职责：1.负责数据中台（含大数据技术）的售前技术支持，包括对合作伙伴和客户的技术支持。2.负责大数据项目的需求调研、功能规划、方案设计。3.与客户沟通，了解业务逻辑，发现用户的痛点和热点问题，收集、分析、引导客户需求，进行架构设计，撰写技术应用方案。4.负责大数据解决方案咨询服务、技术演示以及投标技术支持。5.利用大数据相关的理论和方法，解决用户实际问题。岗位要求：1.热爱数据，了解大数据相关知识，喜欢钻研新产品新业务。2.熟悉业界主流大数据产品，乐于解决具有挑战性的问题。3.较强的文档写作能力，拥有较强的逻辑思维和沟通能力。4.积极主动、认真负责，较强的执行力及抗压能力。5.有数据库、数据仓库、数据集市、开源大数据、Hadoop、Spark、ETL、实时计算、Kafka、挖掘分析 、报表、人工智能等其中一项或多项经验者优先。6.能够熟练编写技术应用方案、擅长PPT演讲者，且具备制造业售前经验者优先。,数据服务,150-500人,spark,上海
大数据高级工程师,https://www.lagou.com/jobs/4650260.html,徐汇区,13k-25k,上海爱可生信息技术股份有限公司,5-10年,本科,"新三板,技术大牛,团建活动","岗位职责：1、负责大数据项目实施以及部分设计开发；2、负责大数据环境的部署、调优以及日常运维；3、负责大数据环境下的数据清洗、转换、建模、分析以及部分开发工作；4、参与数据挖掘业务体系的架构设计、规划及实施。岗位要求：1、熟悉主流关系型数据库系统(Oracle、MySQL等), 并熟练运用SQL进行数据查询管理操作；2、熟悉Hadoop、Spark等大数据平台架构，有实际的项目实施运维经验；3、熟练使用Hive、HBase、Impala等大数据处理系统,了解其内部工作机制,熟悉其系统结构,有排查和解决相关技术问题的经验；4、熟悉Storm、Flink、Spark Streaming等流式数据处理框架，有一定的实施运维能力；5、熟悉ElasticSearch、Solr等分布式搜索引擎，有一定的实施运维能力；6、熟练掌握Linux操作系统，能够熟练使用Linux系统命令，熟悉Shell等脚本编程；7、熟悉Java、Python等编程语言，具备基本的程序设计开发能力；8、掌握非结构化数据的保存、分析、访问、调优，掌握或使用过至少一种Nosql的开源产品，如HBase、Redis等；9、有海量数据的分析能力和处理经验、对数据分析和数据挖掘有浓厚兴趣者优先考虑；10、强烈的责任心和团队合作能力，良好的学习能力，严密的逻辑思维能力并且敢于创新和接受挑战，能够在一定压力下工作。",数据服务,150-500人,spark,上海
NLP算法工程师 (MJ000042),https://www.lagou.com/jobs/6473313.html,徐汇区,20k-40k,星环信息科技（上海）有限公司,1-3年,硕士,弹性工作制 发展前景好,"工作职能：1、负责星环NLP算法库的开发和实现2、负责海量文本信息的知识提取和知识库维护3、负责知识图谱开发和构建职位要求：1、扎实的数据结构、算法基础，扎实的java基础2、熟练使用Linux、熟练掌握Shell脚本3、扎实的机器学习理论基础，有数据建模经验优先4、 熟悉基本NLP库，如nltk，jieba， coreNLP等5、熟悉深度学习库优先，比如MXNet, TensorFlow, Torch, Theano, Keras等6、熟悉分布式平台Hadoop和Spark优先",数据服务,500-2000人,spark,上海
机器学习算法工程师 (MJ000041),https://www.lagou.com/jobs/6473430.html,徐汇区,20k-40k,星环信息科技（上海）有限公司,不限,硕士,弹性工作制 发展前景好,工作职能：1.负责机器学习的理论研究和算法、模型开发，包括但不限于：超参优化、神经网络架构搜索、元学习、迁移学习和强化学习。2.基于分布式计算框架，针对业界经典算法和模型研发分布式实现和性能优化，丰富星环科技内部的通用分布式算法库。3.对机器学习，尤其是对AutoML等前沿问题进行探索与研究，结合未来实际应用场景，提供全面的技术解决方案。4.对计算机视觉和自然语言处理相关领域提供算法支持，进行创新研究。工作要求：1.统计、计算机、数学等相关专业背景，硕士及以上学历，博士优先2.扎实的编程基础(熟悉Scala/Java/Python/C++)，熟练掌握常用数据结构及算法3.在机器学习方向有深厚的技术积累，熟悉算法原理并有实际的应用经验，在顶会上发表过论文者优先。4.熟悉Spark/Hadoop/Tensorflow等分布式计算框架，有分布式算法研发经验者优先。5.了解计算机视觉和自然语言处理相关领域知识。6.较强的沟通和团队协作能力，善于独立分析和解决问题、关注前沿的技术。,数据服务,500-2000人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7120616.html,长宁区,12k-20k,上海亦策软件科技有限公司,3-5年,本科,带薪年假 弹性工作制,工作职责:1.负责大数据平台的基础技术规划，平台的建设，包括环境和框架的规划搭建以及部分核心编码工作；2.负责大数据平台的数据采集、处理、存储的架构实现；3.参与业务需求调研，根据需求设计大数据解决方案并跟进具体实施项目；任职资格:1.本科及以上学历，3年以上工作经验；2.熟悉大数据解决方案包括Hadoop、Spark、Hive、Hbase、SQL-on-Hadoop等大数据解决方案；3.熟悉大数据处理等相关技术和实现方法，熟悉大数据CDH平台；4.了解Scala、spark、Python、R、C中的一种或多种语言；5.有大型数据仓库实施、大数据平台数据开发经验者优先。,数据服务,500-2000人,spark,上海
高级数据仓库工程师 (MJ000178),https://www.lagou.com/jobs/6888519.html,长宁区,20k-35k,上海晓途网络科技有限公司,5-10年,本科,年轻团队 扁平管理 弹性工作,"【岗位职责】1.负责业务的数据仓库ETL开发，构建可扩展的数据仓库和分析解决方案；2.理解业务方的数据需求，提供高质量的面向业务的OLAP、报表、数据提取等数据服务;3.根据数据现状，独立完成工程的优化和迭代性开发，并持续交付高质量易维护的代码。【任职要求】1、本科以上学历，计算机相关专业，3年以上数据仓库相关经验；2、熟悉数据仓库方法论, 熟悉数仓架构和模型设计，精通ETL开发；3、有数据建模基础，并能根据需求独立完成建模数仓架构设计、模型设计；4、有基于hadoop和spark分布式平台的数仓经验；5、熟悉Hadoop Hive／Spark／Storm／Kafka 等的使用和调优；6、掌握Java，Python其中一门开发语言，掌握UDF和Map-Reduce开发者优先；7、具备较强的责任心、抗压能力，良好的沟通协作能力，有独立解决问题的能力；8、具备小团队管理经验者优先。【更多福利】定期分享：组织行业或专业分享会，共同学习才能有进步职业发展：优秀员工、优秀团队、灵活的晋升与调薪机制丰厚奖金：项目奖金、年终奖、期权计划员工关怀：年度体检、生日会、节日礼物、Team Building、结婚生育礼金、抚恤金节日假期：法定假期、额外补充年假、带薪病假、姨妈假、“38”节假期 【我们的团队】信飞科技是一家垂直于航旅领域的消费金融科技公司，致力于“科技让金融更简单”来提高飞行人群的金融体验。在金融领域，信飞是京东金融战略合作伙伴；在航空领域，信飞科技是春秋航空、航班管家、东方航空、首都航空等多家航司的优质合作伙伴，为飞行人群提供在航空场景支付、分期、借贷等金融服务。信飞科技致力于用科技优化航空金融，让更多人在飞行过程中享受更好的权益和服务，越飞越有钱。团队由来自春秋航空、携程、腾讯、阿里巴巴、网易、渣打银行、滴滴出行等行业精英组成，目前业务迅速扩张中。 【工作地点】长宁区淮海西路432号凯利大厦4楼（地铁3号线、4号线、10号线虹桥路站4号出口步行400米）",移动互联网,150-500人,spark,上海
CTO（大数据算法） (MJ000145),https://www.lagou.com/jobs/7183844.html,长宁区,60k-100k,上海晓途网络科技有限公司,5-10年,硕士,弹性工作、扁平管理、晋升通畅、成长空间大,"【岗位职责】1.负责整体技术方案与架构设计，完善优化技术策略，制定信用飞技术发展规划，制定技术部门的战略发展目标和工作方案；2. 负责基于Hadoop/Spark等生态系统的大数据平台的架构设计、技术选型、搭建、开发、管理、监控和性能调优，保证集群高效稳定运行；3.深入理解业务，协助业务部门开展策略研究，针对不同应用场景和业务形态，完成从业务到数据的分析转化，产出各类深入分析报告和产品， 驱动产品、运营策略迭代，对产品和业务提供建设性建议，跟踪模型的实施，定期优化算法和业务策略；4.通过机器学习和数据挖掘研究用户行为和特征，改进信用飞产品；通过数据挖掘建立模型，发现商业价值；5.建立规范、高效的技术开发管理体系并优化完善，持续提升公司整体技术开发能力；6.组织核心技术产品的研究和技术难点攻关工作，组织解决项目开发过程中的重大技术问题；7.对新技术、行业动向保持敏锐的感知度，对公司未来技术走向提出重要建议。 【任职要求】1.硕士以上学历，计算机、数学等相关专业，5年以上技术团队管理经验；2.熟悉至少一门编程语言(Java\Python\Scala等)，对数据结构和AI算法有较为深刻理解；3.有在NIPS, ICML, AAAI, ICCV, ACL，CVPR，EMNLP，KDD，WSDM等高水平学术会议发表过文章者优先；4.具备优秀的执行力和领导力，具备扎实的数学功底和算法功底；5.熟悉人工智能、大数据、云计算等领域的前沿知识，洞察行业发展动态，熟悉市场对大数据产品的需求，制定技术方案并主导落地执行。【更多福利】定期分享：组织行业或专业分享会，共同学习才能有进步职业发展：优秀员工、优秀团队、灵活的晋升与调薪机制丰厚奖金：项目奖金、年终奖、期权计划员工关怀：年度体检、生日会、节日礼物、Team Building、结婚生育礼金、抚恤金节日假期：法定假期、额外补充年假、带薪病假、姨妈假、“38”节假期 【技术团队】技术氛围浓厚，团队成员背景及技术水平优秀，由来自腾讯、阿里、2345、富友支付等行业技术精英组成，团队不定期举办各类技术分享会以及外部技术大牛培训会，擅于分享，一起学习，共同成长~ 【公司介绍】信飞数科是一家以数字化AI服务为核心的科技企业，以大数据、人工智能等时代前沿技术为基础，建立并发展成为拥有大数据风险管理能力、用户运营能力和产业理解能力的数字化解决方案公司。公司秉承“从数据中来，到实体中去”的理念，致力于通过数字化科技服务赋能航旅科技，金融科技、营销科技领域，实现成本降低、运营高效、体验优化、模式升级，助力产业实现互联网化、数字化和智能化。 信飞数科业务发展战略定位：依托航旅客户构建开放式用户生态圈，围绕航旅消费场景、金融和用户权益展开业务布局，成长为行业内头部的“科技+金融+航旅+生活”四轮驱动的数字科技公司。 目前公司核心板块有：金融*数字科技，包含个人消费金融、公司金融、资管科技业务，主要面向持牌机构及核心企业；航空*数字科技，主要包含航空酒店的消费分期、信用支付、飞行钱包产品，以及航旅新分销渠道NDC项目的推进；营销*数字科技，主要通过飞行分对4亿航旅高价值用户进行用户画像评级，实现数字化精准营销，同时打通权益及积分体系，实现权益和积分的开放平台。 旗下产品及服务矩阵：C端产品有首付游/信用飞/飞行卡；开放平台产品有信用支付SDK，社交分销工具SDC，消费信贷飞行贷API；核心能力有灯塔风控系统、航空金融云、飞行信用分等大数据产品。 公司成立于2015年1月，京东数科为战略股东，目前为中外合资结构（已完成B轮融资），2018年已全面实现盈利，年营收过亿。目前已经和东航、国航、南航三大航展开合作，国内航空市场占有率超过70%，持牌机构合作了数10家城商行、消费金融公司及信托保险机构，C端授信用户超过8000万【办公地点】上海市长宁区淮海西路432号凯利大厦4楼（地铁3号线、4号线、10号线虹桥路站4号出口步行400米）",移动互联网,150-500人,spark,上海
推荐系统开发工程师 (MJ000118),https://www.lagou.com/jobs/7056641.html,浦东新区,20k-40k,上海任意门科技有限公司,3-5年,本科,高薪资,"工作职责：1、参与建设和优化soul的推荐系统，提升个性化推荐效果；2、参与匹配、推荐广场等主要业务的策略、逻辑、系统架构的迭代，提升用户体验；职位要求：1、有1年以上服务端开发经验2、具备优秀的编码和算法能力，有良好的代码风格(C++,java至少熟练一种，java优先)3、熟悉spring、redis、MySQL、kafka、message queue等常用工具4、了解并发、多线程、锁、设计模式的应用5、愿意深入了解业务细节，并思考优化和改进，会写基本的sql分析业务数据加分项：了解spark，有大数据处理经验有acm、kaggle参赛获奖经验有推荐系统后台开发经验，社交产品或者信息流产品相关工作经验","社交,文娱丨内容",150-500人,spark,上海
推荐算法工程师 (MJ000076),https://www.lagou.com/jobs/6660430.html,浦东新区,20k-40k,上海任意门科技有限公司,不限,本科,"高薪资,上升空间,扁平管理",职位描述：基于机器学习，优化Soul的匹配和个性化推送等产品核心功能，提升用户体验。职位要求：1.重点本科以上学历，计算机相关专业；2. 1年以上机器学习/数据挖掘相关工作经验，优秀的coding能力、扎实的算法功底3. 熟练掌握至少一门主流语言 C++/JAVA/PYTHON等4. 熟悉机器学习常见算法，如LR、GBDT、DNN，理解相关理论并具备应用能力5. 计算机、电子、数学、统计等相关专业加分项 :1. ACM/ICPC，Kaggle 等比赛获奖者2. 熟悉tensorflow框架3. 熟悉大数据基础工具，Hadoop/hive/spark你将与来自google、阿里等大厂的技术大牛共事，在算法策略、工程、产品上得到全方位的锻炼。,"社交,文娱丨内容",150-500人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7191437.html,长宁区,18k-30k,上海瑛太莱信息科技有限公司,3-5年,本科,定期团建、节假日福利、年度体检等,岗位描述：1、负责完成业务和产品的对接，支持业务需求研发；2、负责完成产品的迭代升级以及底层架构的升级研发；3、完成团队安排的其他相关日常工作任职要求；4、负责产品的实时业务和离线业务的研发；5、支持开源大数据技术在数据系统中的使用，修复、优化增强大数据技术；岗位职责：1、具有分布式系统架构开发能力。熟练使用storm、spark hbase者优先。2、能够使用实时计算平台，进行实时业务数据的研发。3、能够基于已有平台进行离线业务的开发。4、有大数据应用产品研发经验，具有数据决策产品研发经验者优先。,电商,500-2000人,spark,上海
大数据技术经理,https://www.lagou.com/jobs/6769654.html,徐汇区,30k-40k,上海天会皓闻信息科技有限公司,5-10年,本科,弹性工作 福利年假 五险一金,"1、负责大数据平台的设计优化，提高目前大数据存储和计算的效率 ；2、负责大数据平台技术难点攻关，搭建大数据准实时计算引擎flink，满足业务数据分析复杂模型的需求；3、 能够根据业务以及产品运营的需求变化，针对研究行业的解决方案，提出算法模型及实现方案 ；4、负责大数据技术人材培养。包括Hadoop、Hbase、flink、hive、spark等 。职位要求：1、全日制本科及以上学历，211/985院校优先，计算机、软件工程、统计学、数据挖掘、机器学习等相关专业； 2、6年以上开发经验，3年以上互联网数据类产品开发和架构经验，熟悉数理统计、数据分析及挖掘，熟知常用算法；3、熟悉大数据相关技术的原理及使用（包括但不限于：hadoop,hive,hbase,storm,spark, Elasticsearch, Kafka,Flink）； 4、熟悉Java或Python其中一种实现语言，熟练使用Shell、Python等一种以上脚本语言； 5、熟练的英语阅读能力 ；6、良好的逻辑分析能力、沟通能力和协调能力、学习能力强、有激情、不断挑战自己； 7、有数据挖掘、机器学习、人工智能经验者优先。",移动互联网,50-150人,spark,上海
java技术经理,https://www.lagou.com/jobs/6769651.html,徐汇区,40k-50k,上海天会皓闻信息科技有限公司,5-10年,本科,弹性工作 福利年假 五险一金 弹性工作,"1、参与核心业务系统的技术架构设计和技术实现，深入理解业务需求，抽象系统模型，进行系统设计及开发工作，降低需求变更的研发成本，提升研发效率 ；2、熟悉阿里云的云服务架构产品，提出新的架构升级方案，能够帮助现有云平台提升计算能力和服务能力；  3、完善公司SaaS平台服务基础，帮助公司从spring boot微服务架构升级到spring cloud架构，实现全服务管理，监控 ；4、跟踪新技术发展，包括阿里云SAE+ECI的解决方案，Maxcomputer。岗位要求：1、大学本科及以上学历，211、985院校优先，计算机相关专业；6年以上相关开发工作经验，2年以上架构设计经验，有数据类产品开发经验； 2、精通Java, J2EE 开发与设计，熟悉掌握常用的Java类库及框架，如多线程、并发处理、I/O与网络通讯等； 3、对Java虚拟机有较深了解，有运行态JVM分析及调优的实际经验，有Linux下的开发或运行环境操作经验； 4、对BS结构有深入理解，有大并发，大数据的Web项目开发经验。熟悉分布式服务开发，负载均衡，缓存等技术； 5、熟悉Spring Cloud、Spring Boot、Hibernate、MQ等主流技术，有Maven、Git等项目管理工具使用经验； 6、熟悉MySQL数据库以及优化方法，了解常用的NoSQL产品，如Redis，MongoDB，Memcache，能够处理较大数据量的设计、开发； 7、了解并使用过各种大数据相关框架或组件优先，如Kafka、Storm/JStorm、Hadoop/Spark、Hive、HBase等； 8、有分布式系统、SaaS平台开发经验、实时计算开发经验的优先；9、 熟练使用面向对象分析设计方法，熟悉软件设计模式；能够独立设计出灵活的系统架构并成功实施； 10、有良好的沟通、团队协作、计划和主动性思考的能力，在互联网或大数据业界有一定影响力公司的工作经验者优先。",移动互联网,50-150人,spark,上海
大数据开发工程师（python）,https://www.lagou.com/jobs/6419008.html,浦东新区,30k-35k,上海贝耳塔信息技术有限公司,3-5年,本科,股票期权 年终奖 五险二金 前沿科技,岗位职责：1、负责用户行为分析、客户画像、智能推荐等相关大数据分析及运算开发；2、负责大数据分析体系的规划、设计和建设；3、收集、整理、分析、统计各类数据指标；4、负责大数据分析、自然语言处理、机器学习探索和实现； 任职要求：1、本科及以上学历，3年及以上大数据开发经验，软件工程/计算机/通信/数学等相关专业；2、能熟练使用 python脚本语言开发；3、熟悉Oracle、Sqlserver、Postgre等关系型数据库；4、有hadoop、spark、flink等至少一种大数据平台的使用经验；5、有用户行为分析、客户画像、智能推荐、数据仓库建设、商业数据分析、增长项目经验者优先。6、具备较强的表达能力和抽象总结能力，具备极强的逻辑思维能力；7、有自然语言处理、机器学习经验者优先；,金融,50-150人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/4247189.html,闵行区,15k-25k,上海元聚网络科技有限公司,3-5年,大专,"高薪,晋升快","工作职责：1、完成软件系统代码的实现，编写代码注释和开发文档。2、参与公司大数据产品规划,大数据处理分析平台的设计。3、负责数据分析、加工、清理、处理程序的开发                4、负责数据相关平台的搭建、维护和优化。5、根据设计文档或需求说明完成代码编写，调试，测试和维护。6、协助测试工程师制定测试计划，定位发现的问题。      7、配合项目管理人员完成相关任务目标。   任职要求：                  1、良好的java基础、熟悉大数据相关开源项目;      2、海量用户行为数据的分析挖掘，负责过大数据业务的研发和优化工作;             3、熟练使用mapreduce、Spark、Flink等计算框架进行处理离线、实时数据;             4、熟练NOSQL数据库Mongodb、HBase、Redis等;5、参与过用户画像,个性化推荐,有建模经验的优先考虑;6、有良好的敬业精神和团队合作精神,具有技术领域的探索和钻研精神,对技术开发工作有浓厚的兴趣,愿意并努力接受技术挑战或技术创新。湖北，武汉应聘，同等条件优先录取",移动互联网,150-500人,spark,上海
大数据工程师（浦东）,https://www.lagou.com/jobs/6981529.html,浦东新区,15k-20k,上海策推信息技术有限公司,1-3年,本科,"五险一金,带薪年假,餐补",一、岗位要求1.计算机相关专业本科及以上学历；2.2年以上大数据产品或项目开发经验，精通Hadoop生态圈，精通一种流式计算框架（sparkstreaming或flink），熟练使用Spark，HBase、Hive、Kafka、Redis等；3.精通SQL，熟练使用HSQL实现复杂数据处理逻辑，并具备数据处理调优的能力；4.熟悉Linux开发环境，熟悉Linux的shell命令。5.具有良好的逻辑思维能力和严谨的程序开发思想，具备独立问题排查与处理的能力；6.良好的团队精神和合作意识，强烈的责任心，对工作有激情，良好的沟通能力，能吃苦耐劳；7.有大数据项目或产品背景者优先；8.有使用Spark SQL进行数据处理，并具有Spark SQL优化经验者优先。二、职位描述1.负责大数据平台的设计与应用功能开发；2.根据项目或产品的需要，负责离线/实时的数据存储、加工和处理；3.结合项目或产品涉及的具体业务场景，对数据进行清洗、计算与加工；4.思路清晰，可快速响应数据处理的需求，评估并给出合理的解决方案，并采用合理的方式处理需求；5.积极主动，能够与团队成员进行有效沟通，并完成数据处理结果的核对与对接；6.负责前沿或关键技术的研究，完成服务性能优化；7.完成上级交办的工作或任务。,"数据服务,人工智能",50-150人,spark,上海
算法工程师(J10328),https://www.lagou.com/jobs/5944131.html,长宁区,20k-30k,秒针信息技术有限公司,3-5年,硕士,福利待遇 发展前景,"工作职责:1. 推荐系统的工程实施、部署、性能优化2. 现有推荐系统的架构升级和维护任职资格:1. 精通Java, Python，GO（plus)2. 精通linux或unix系统编程3. 具有Hadoop、Spark、Storm等分布式框架开发经验4. 精通SQL，Hive","数据服务,广告营销",2000人以上,spark,上海
数据平台工程师--上海,https://www.lagou.com/jobs/6826978.html,杨浦区,20k-40k,北京熵简科技有限公司,1-3年,本科,五险一金、包含一日三餐、团队年轻、团建,岗位职责：1. 研发、部署、调优基于 Spark 开发的数据处理工具；2. 将数据处理的工具和流程进行封装、抽象，并对外输出；3. 基于 Python 研发后端服务，对 Spark 任务进行调度、状态获取、集群扩缩容等操作；4. 能独立进行需求的调研，提供技术解决方案；5. 与团队配合，对商业化的数据处理工具进行实施落地；任职要求：1. 全日制本科及以上学历，2年以上Spark开发经验，计算机、软件工程等相关专业；2. 了解分布式系统的基本原理和协议；3. 有基于 Scala 的 Spark 开发经验，能独立调优、排查 Spark 应用中的瓶颈和问题；4. 熟悉 Python 语言，了解 Django 框架优先5. 了解 Linux 系统的使用6. 了解 Docker、Elasticsearch、AWS S3、Minio 等开源工具者优先,"金融,数据服务",50-150人,spark,上海
推荐系统工程师,https://www.lagou.com/jobs/7054465.html,杨浦区,20k-25k,舶乐蜜电子商务（上海）有限公司,3-5年,本科,"高手众多,国际团队,晋升潜力大",岗位职责：1. 负责基于大数据个性化推荐的开发和优化；2. 负责模型调优和实际业务场景中的落地工作；3. 应用机器学习等技术，为用户提供推荐和排序，提升推荐效果，改进用户体验。任职要求：1. 本科及以上学历，计算机、数学相关专业，3年以上开发工作经验；2. 在搜索系统、推荐系统或广告等方向有3年以上算法研发经验，有排序或召回等实际项目经验；3. 有 Hadoop / Spark 等大规模分布式计算使用经验；4. 熟悉 Linux 开发环境，熟练使用 Python / Scala / Java等语言；有扎实的编程基础和工程实践；5. 善于思考和学习，对有挑战性的问题充满激情，具有良好的团队合作精神和较强的沟通能力以及执行力。,"移动互联网,电商",150-500人,spark,上海
软件工程师（推荐系统开发）,https://www.lagou.com/jobs/7206877.html,杨浦区,15k-25k,舶乐蜜电子商务（上海）有限公司,3-5年,不限,五险一金 带薪年假 国际团队,岗位职责：1.负责基于大数据个性化推荐的开发和优化；2.负责模型调优和实际业务场景中的落地工作；3.应用机器学习等技术，为用户提供推荐和排序，提升推荐效果，改进用户体验。任职要求：1.本科及以上学历，计算机、数学相关专业，3年以上开发工作经验；2.熟悉 Linux 开发环境；3.熟练使用 Go / Scala / Python 等至少一门编程语言；4.有扎实的编程基础和工程实践；5.善于思考和学习，对有挑战性的问题充满激情，具有良好的团队合作精神和较强的沟通能力以及执行力。加分项1.在搜索系统、推荐系统或广告等项目开发经验；2.有 Hadoop / Spark 等大规模分布式计算使用经验。,"移动互联网,电商",150-500人,spark,上海
java高级开发工程师,https://www.lagou.com/jobs/5450814.html,徐汇区,18k-25k,上海麦杰科技股份有限公司,5-10年,本科,五险1金 做五休二 非外包,岗位职责:1、参与需求分析；熟悉系统开发环境，完成系统框架和核心代码；2、根据开发规范与流程独立完成模块的设计、编码、测试以及相关文档;3、指导软件工程师的日常开发工作；解决开发中的技术问题；4、参与软件需求与设计审核和代码检查；5、参与方案讨论和技术调研、负责方案设计和文档更新。任职要求：1、四年以上java开发经验，本科及以上学历，计算机及相关专业毕业；2、精通java主流开源框架，有读过源代码，如spring boot、shiro、flowable等，对JDK8比较熟悉；3、熟练掌握管理工具Maven、git，编写项目pom文件，掌握Maven插件、项目打包；4、熟练掌握SQL语句，具备oracle、mysql等数据库开发经验；5、熟悉前端框架vue的应用开发；6、熟练掌握SQL语句，存储过程开发，具备oracle、mysql等数据库开发经验，能够进行SQL语句的优化；7、熟悉tomcat，jboss等web应用服务器的配置和部署；8、有分布式并行计算相关经验，熟悉Spark等技术者优先。,"移动互联网,数据服务",150-500人,spark,上海
大数据开发,https://www.lagou.com/jobs/6863272.html,普陀区,25k-50k,上海序章科技有限公司,3-5年,本科,氛围好，业务快，福利多多,"岗位职责：1、对接并梳理业务需求,开发数据仓库模型,设计相关主题的事实表和维度表等；2、使用ETL工具开发数据流；3、使用BI工具以及OLAP工具进行数据可视化的开发和展现；4、深入理解用户的行为，构建用户、商品、社区的画像体系；5、负责社区Feed流推荐算法。任职要求：1、基础扎实，熟悉数据结构和算法；2、有数据库经验,熟悉SQL、了解ETL、数据仓库建模理论为佳；3、有Linux/Shell、Python、Java等编程技能加分；4、有Hive、Hadoop、Spark、Flink相关数据平台经验优先；5、有推荐系统相关经验，熟悉常用的推荐算法，有大规模海量数据机器学习/数据挖掘/计算广告/搜索相关经验者优先；6、具备良好的沟通和表达能力，对推荐的用户体验上有自己的想法，有较好的产品意识者优先。","电商,文娱丨内容",50-150人,spark,上海
数据开发工程师,https://www.lagou.com/jobs/6015861.html,徐汇区,20k-35k,宜家（中国）投资有限公司,3-5年,本科,员工餐厅 企业年金 超长年假 外企福利,"职责描述：• Responsible for designing, building, testing and maintaining data systems, making sure the data structure, ingestion and processing systems, supporting digital product teams’ requirements and user needs;• Responsible for implementing methods to improve data reliability, efficiency and quality;• Act as technical expert in regard to integration and connectivity methods, protocols, security and practices for data management systems;• Responsible for designing and creating the optimal data pipeline;• Work closely with data architects/scientists and other stakeholders on future data handling technologies, including input on risks, costs, benefits;任职要求：• Expert experience with mainstream RDBMS like MySQL(mandatory), PostgreSQL, Oracle and NoSQL such as Redis, HBase;• Familiar with the distributed database architecture, ability to design the OLTP with high availability, scalability and performance; solid hands-on experience with distributed DB products in mainstream Cloud environment like AliCloud DRDS or GCP spanner;  • Extensive experience in big data acquisition, pre-processing, storage, and cleansing technologies including Hadoop (HDFS, MapReduce, Yarn,..), Kafka, Sqoop, Spark, Flink and etc;• Experience with programming languages: Java, Python or Shell;     • Knowledge of Graph Database like Neo4j is a plus;",消费生活,2000人以上,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/5874765.html,徐汇区,20k-35k,上海乐言信息科技有限公司,3-5年,不限,业界**团队 早期期权,岗位职责1. 依据业务模型，负责大数据计算平台的架构设计，以及核心功能的开发，满足实时、离线计算的需求。 2. 负责产品实时计算平台的设计和开发，为实时监控、实时运营数据分析、个性化推荐提供数据支持。任职要求1. 本科以上学历，扎实的计算机专业基础，有3年以上大数据平台开发经验，1年以上的大数据计算/存储设计经验。 2. 熟练掌握Hadoop、Spark、Storm、HBase的原理特性以及适用场景，精通Spark实时计算开发，并具备大规模数据集的实际开发经验。 3. 有大规模数据计算平台的架构设计经验，且精通大规模数据集的存储方案设计优先。 4. 具备用户问题的定位及解决能力，善于归纳总结，对数据敏感。 5. 思维活跃、敢于担当、乐于沟通，具有良好的团队合作精神，积极主动，能承受一定的工作压力。,企业服务,500-2000人,spark,上海
机器学习系统工程师,https://www.lagou.com/jobs/4360929.html,徐汇区,25k-50k,上海乐言信息科技有限公司,3-5年,硕士,"**团队,早期期权",职责1. 负责公司机器学习框架构建，各种ML算法的集成、训练、部署、分发和版本管理，为公司智能产品提供基础支撑2. 负责各种（弱或无）标注数据的收集和使用，训练相应的学习模型供NLP或知识图谱使用3. 支持基于增强学习和主动学习的反馈收集、日志分析的算法持续优化4. 支持用户画像的建模与学习以及自动化推荐应聘要求1. 三到五年相关工作经验2. 硕士研究生及以上学历，计算机相关专业3. 熟悉Java和至少一种脚本语言4. 较强的系统编程能力以及多线程编程能力5. 了解常用机器学习库，例如sklearn、xgboost6. 了解深度学习常用算法，掌握Tensorflow、MXNet、Keras或PyTorch中任意一个7. 有基于MPI或Parameter Server分布式机器学习系统经验，或有Hadoop/Spark等大数据平台实践经验者优先8. 有机器学习或深度学习技术应用于NLP、KG构建和对话系统经验者优先,企业服务,500-2000人,spark,上海
大数据开发实习生,https://www.lagou.com/jobs/7149391.html,黄浦区,4k-5k,上海宏路数据技术股份有限公司,不限,本科,"氛围好,环境好，地铁周边，六险一金","岗位职责：                                  1、负责基于Hadoop（CDH、HDP）平台架构的开发； 2、针对海量的数据开发具有数据收集、统计、分析和挖掘能力的创新型产品； 3、基于MapReduce、Spark等的大数据开发； 4、学习和研究大数据技术最新动向以满足产品、项目的需求。  任职资格 1、计算机相关专业本科及以上； 2、软件基础理论知识扎实，具有良好的数据结构、算法功底； 3、学习了解过大数据相关技术 (MapReduce, Spark, Hive, HBase...) 优先 4、有个人开源项目或参与开源项目者优先； 5、每周可实习5天优先考虑。",移动互联网,150-500人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7149282.html,黄浦区,10k-20k,上海宏路数据技术股份有限公司,不限,本科,"氛围好,环境好，地铁周边，六险一金","岗位职责： 1、参与分布式服务设计及开发； 2、参与大数据组件、中间件设计及开发； 3、参与公司核心产品、项目研发，针对海量数据开发具有数据收集、统计、分析和挖掘能力的创新型产品； 4、学习并研究大数据技术、最新动向以满足产品、项目的迭代需求。   任职资格： 1、扎实的计算机基础，1-3年大数据开发经验，掌握基本设计理念，熟练应用一门以上面向对象开发语言； 2、扎实的数据结构基础，掌握常见算法； 3、对solr、elasticsearch、消息队列等中间件具备基本认识，若有相关领域研究、开发经验则更佳； 4、对关系型/非关系型数据库有一定认识，具备较好数据库的设计理念。 5、对大数据生态有较好认识，具备spark, hive, hadoop, kafka, sqoop, kylin, azkaban等大数据组件开发、调优经验； 6、有docker、k8s等容器使用经验者优先考虑； 7、具备cloudera或hortonworks平台开发、部署经验者优先考虑。 8、拥有个人博客或者有大型项目开发经验者优先考虑。 9、拥有或参与开源项目者优先考虑。 10、基础扎实的应届毕业生优先考虑、培养，共同成长； 11、具备较好的品质，秉持正直、诚实、担当、奉献的价值理念，优秀应届生也可考虑。",移动互联网,150-500人,spark,上海
搜索引擎工程师,https://www.lagou.com/jobs/6956500.html,徐汇区,20k-40k,上海鱼泡泡信息科技有限公司,3-5年,本科,独角兽、快车道、高薪,岗位职责:1、对elastic search使用场景、方式制定合理方案2、负责elastic search集群的维护与调优3、对算法数据的存储、检索作出合理规划 任职要求:1、精通java语言2、有2年以上elastic search的使用经验， 并对es读写性能优化精通3、对elastic search集群的结构、调度方式、数据索引原理比较熟悉4、有一定的大数据基础， 熟悉hadoop、spark、flink等,社交,500-2000人,spark,上海
自动化测试工程师,https://www.lagou.com/jobs/7137950.html,浦东新区,10k-15k,普元信息技术股份有限公司,1-3年,本科,五险一金 带薪年假 项目稳定,岗位职责：1、理解客户需求，参与系统需求讨论及定义；2、设计测试用例、测试工具，编写必要的测试脚本；3、制订测试计划，设计用例，测试执行，跟踪定位问题，推动测试中发现问题及时合理地解决；4、从用户角度，在测试过程中，审查系统的友好程度及可改善点；5、团队协作，积极沟通，为产品最终质量负责。岗位要求：1、本科或以上学历，计算机科学与技术、软件工程相关专业，2年以上测试经验，有自动化或数据测试经验优先；2、具有扎实的测试理论知识及数据库理论知识；3、有大数据相关产品完整的项目测试经验，熟悉数据的抽取，转换以及加载过程(ETL)，对数据仓库有基础的了解;4、熟练掌握SQL语言，熟悉Hadoop、Spark等；5、数据敏感，有一定的数据分析技能和经验，能基于业务理解推动数据测试的落地工作；6、熟悉Linux操作系统及常用命令；7、工作细致负责，具有良好的团队沟通和协作能力。,"企业服务,数据服务",500-2000人,spark,上海
Python开发工程师,https://www.lagou.com/jobs/7085726.html,虹口区,10k-15k,广东省电信规划设计院有限公司,1-3年,本科,平台大 年终奖,工作职责：1、 负责联邦学习、安全多方计算等相关产品中机器学习算法的研究、实现和优化；2、 针对机器学习在实际业务场景落地中的问题，探索高效准备的解决方案，并持续跟进效果和业务价值；3、 从具体市场需求出发，将机器学习算法应用到产品中，以帮助解决互联网、银行、券商、零售、运营商、融合媒体等广泛领域中的机器学习问题，为客户创造业务价值；4、 跟踪业界和学术界最新进展，并且能够快速应用到业务中。岗位要求：1、 良好的编程能力和规范，熟悉Python/Linux，了解Go；2、 有一年以上的机器学习项目开发经验，熟悉机器学习相关算法，例如LR、DT、RF、XGboost、LightGBM、GBDT、KNN等，熟悉一个或多个机器学习工程库，例如：Sklearn、MLLIB；在以下至少一个领域有过实际经验：用户画像、时序预测、个性化推送、推荐系统、精准营销、信用打分；3、 有海量数据的处理和分析经验，熟悉一个或多个大数据处理工具，例如Hadoop、Spark、Hive等；4、 有金融征信、风控项目工作经验更佳；5、 良好的理解能力和学习能力，主动性和责任心强。,"移动互联网,金融",2000人以上,spark,上海
数据建模工程师（机器学习）,https://www.lagou.com/jobs/6948022.html,松江区,15k-20k,上海诺悦智能科技有限公司,1-3年,硕士,五险一金 奖金 餐补 通讯补助等,"岗位职责：1. 利用机器学习相关算法解决数据分析及数据挖掘方面的问题；2. 根据业务需求，参与业务分析、特征分析、模型建立、算法实现等过程，并逐步迭代算法效果。任职资格：1.计算机相关专业；2.两年以上数据挖掘工作经验；3.精通Python语言，熟悉 Java，Linux/Shell等应用场景；4.熟练使用Hadoop、Hive、Spark等大数据平台工具；5.熟练使用SQL，MPP数据库6.精通机器学习常用算法：如决策树、随机森林、协同过滤、SVM、 回归算法、AdaBoost等等；7.熟悉web后端接口框架开发，如Django, Tornado, Flask, Sanic等；8.英语6级以上；9.接受2-3个月的出差；10.熟悉深度学习框架，如Keras、Caffe、Tensorflow等，有过深度学习调参经验者优先；11.有金融行业数据分析经验者优先。",数据服务,50-150人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6647089.html,徐汇区,12k-24k,上海诺悦智能科技有限公司,1-3年,本科,五险一金 奖金 餐补 通讯补助等,任职要求：1.   硕士学历；2.   精通Scala、python语言，有实际编程经验，熟悉Linux 操作系统，熟练使用Shell等脚本语言3.   深入了解分布式系统、大数据平台、消息队列等高可用高弹性架构;4.   对HDFS/Yarn/HBase/Hive/Spark相关组件的性能优化和补丁跟踪等有实际经验5.   良好的英语读写能力6.   强烈的责任心和自我驱动意识，有良好的团队合作精神和沟通协调能力,数据服务,50-150人,spark,上海
Sr. Data Engineer,https://www.lagou.com/jobs/7170532.html,徐汇区,20k-35k,宜家（中国）投资有限公司,5-10年,本科,员工餐厅 企业年金 超长年假 外企福利,"职责描述：• Responsible for designing, building, testing and maintaining data systems, making sure the data structure, ingestion and processing systems, supporting digital product teams’ requirements and user needs;• Responsible for implementing methods to improve data reliability, efficiency and quality;• Act as technical expert in regard to integration and connectivity methods, protocols, security and practices for data management systems;• Responsible for designing and creating the optimal data pipeline;• Work closely with data architects/scientists and other stakeholders on future data handling technologies, including input on risks, costs, benefits;任职要求：• Expert experience with mainstream RDBMS like MySQL(mandatory), PostgreSQL, Oracle and NoSQL such as Redis, HBase;• Familiar with the distributed database architecture, ability to design the OLTP with high availability, scalability and performance; solid hands-on experience with distributed DB products in mainstream Cloud environment like AliCloud DRDS or GCP spanner;  • Extensive experience in big data acquisition, pre-processing, storage, and cleansing technologies including Hadoop (HDFS, MapReduce, Yarn,..), Kafka, Sqoop, Spark, Flink and etc;• Experience with programming languages: Java, Python or Shell;    • Knowledge of Graph Database like Neo4j is a plus;",消费生活,2000人以上,spark,上海
测试开发工程师,https://www.lagou.com/jobs/6815581.html,虹口区,18k-25k,上海芯翌智能科技有限公司,3-5年,本科,带薪年假、团队氛围、年终奖、五险一金,1、参与公司产品测试的全流程，包括参与需求分析、设计评审，制定测试计划，设计和执行测试用例，进行缺陷跟踪和软件质量分析等；2、参与自动化测试工具/框架开发，自动化测试用例设计、执行，自动构建测试环境，持续集成等；3、保证被测系统的质量，并通过测试流程和方法创新，努力提升研发的质量和效率；任职资格：1、工科、计算机或其他相关专业本科以上学历；2、至少3年以上软件开发、自动化测试工作经验；3、精通测试流程和测试用例设计方法，熟练使用主流的压力和接口测试工具，LR、Jmeter、Postman、RF等；4、解决复杂问题和编写自动测试工具和系统的能力；5、熟悉C/C++/Java等至少一种编程语言，有Shell或Python等使用经验者优先；6、有性能、安全、白盒测试、机器学习等专业测试领域经验者优先；加分项：1、有docker相关经验；2、有Hadoop/Spark相关测试经验；3、熟练使用Jenkins持续集成工具,人工智能,50-150人,spark,上海
数据科学家,https://www.lagou.com/jobs/7093586.html,浦东新区,20k-30k,上海冰鉴信息科技有限公司,3-5年,本科,C轮公司+生活和工作平衡+上市计划,1. 负责金融风险管理相关的数据分析，对风险预警异常情况进行深入分析，对业务风险指标进行跟踪分析及优化；2. 负责机器学习模型的构建、维护、和评估；3. 参与公司征信评分模型和征信系统的研发，包括但不局限于反欺诈模型、申请评分、行为评分、催收评分等模型设计开发；4. 对于部门内产品、需求提供数据支持，对于风险规则策略提供建议；5. 配合项目计划，负责建模驻场项目，完成客户需求的任务。任职要求：1. 统计、数学、计算机等理工科相关专业本科及以上学历，至少2年金融业相关工作经验（做过个人征信和企业征信者最佳）；2. 熟悉常用数据挖掘算法与模型，熟悉逻辑回归、神经网络、决策树、聚类等建模方法；3. 熟练使用python、R等数据处理工具，熟悉SQL、hive、spark，Hadoop，了解MapReduce分布式计算，具备扎实的数据分析功底；4. 对数据敏感且对处理大量数据有强烈兴趣，喜欢探索钻研，有独立思考的能力；5. 思维活跃，有创新思考能力，具有良好的逻辑分析能力，能够快速学习新方法，责任心强；6. 注重团队协作，有独立承担项目的经验和能力，具有优秀的职业素养和抗压能力；7. 具有良好的编码能力，具备产品思维，可适应短期出差者优先考虑。,"信息安全,数据服务",150-500人,spark,上海
搜索算法工程师,https://www.lagou.com/jobs/6608319.html,嘉定区,20k-40k,上海寿盈网络科技有限公司,3-5年,不限,五险一金 做五休二,主要要求：（1）熟悉NLP、机器学习的理论基础，有海量数据挖掘、用户画像、知识图谱研发经验优先；（2）在文本分析等领域有丰富经验优先（3）熟悉Scala、Java或Python语言（4）熟悉Hive，Spark，Redis，Cassandra，MongoDB，RabbitMQ，Kafka，RocksDB等多种开源系统架构、原理（5）熟悉NER相关模型算法者优先（6）计算机相关专业，本科及以上学历,"信息安全,软件开发",50-150人,spark,上海
推荐算法工程师,https://www.lagou.com/jobs/6608300.html,嘉定区,20k-40k,上海寿盈网络科技有限公司,3-5年,本科,五险一金 做五休二,主要要求：（1）熟悉机器学习领域常用算法和工具，有良好的建模思维，有大流量场景优化经验者优先；（2）熟悉大规模数据处理的常用方法，熟悉Hadoop/spark/strom等至少一种分布式系统；（3）熟悉Java/Python等编程语言及常用数据结构，具备良好的编程功底；（4）计算机相关专业，本科及以上学历；,"信息安全,软件开发",50-150人,spark,上海
数据分析师,https://www.lagou.com/jobs/5713491.html,徐汇区,10k-20k,久远谦长（北京）技术服务有限公司,不限,本科,"福利待遇优厚，发展空间大,团队氛围好",【职位描述】：*能够在多变的客户环境及系统中准确获取、加工、分析高度复杂的数据；*负责ETL处理、代码编写、数据仓库的建立及维护、数据可视化的实现。 【任职资格】：* 计算机科学、应用数学、统计学、经济学、物理学、天文学、商业分析、信息系统、数据科学或相关本科或以上学历；*良好的团队合作精神与沟通能力，做事细心认真。 【技能要求】：* 具备ETL、数据统计的相关经验，对spark有一定了解；* 能够熟练使用数据分析相关工具平台（Python\SQL）；* 有英语阅读能力。【公司介绍】：-麦肯锡和华为惠普联合团队• 由多位前麦肯锡合伙人以及华为惠普核心工程高管联合创立，打造精品管理咨询传承与科技创新品牌• 同时拥有优质咨询项目资源、丰富咨询经验，及数字化赋能的精尖技术能力，建立从咨询建议到产品/解决方案的全面商业服务模式• 约300位咨询顾问、数据科学家、软硬件工程师常驻北京上海和成都-多行业多商业领域覆盖•主要服务于企业客户，通过结合管理咨询、大数据分析、算法建模与工程落地的能力帮助企业客户实现业务增长•行业覆盖消费品、零售、金融、互联网、医疗与媒体等•与多行业领先企业深度合作，建立长期合作关系，如沃尔玛（获沃尔玛年度最佳供应商称号）、欧莱雅、联合利华、中国农业银行、腾讯、京东、美团等-精尖的数据分析/算法/工程师团队-• 具备数据清洗与挖掘、算法模型和语义分析方面行业领先技术水平与能力• 具备根据客户业务方向搭建中台/后台的工程技术能力与丰富的项目经验• 具备广受行业认可的成熟产品（含已申请专利技术），帮助客户实现数据驱动的效率提升-富有竞争力的职业发展与薪酬福利保障•注重人才培养，提供定期培训分享及深度参与项目机会，加入团队的年轻小伙伴们再也不用担心自己沦为职场“小螺丝钉”•注重员工成长空间，每年二次全员review，半年即有机会享受升职加薪•注重福利保障，包括：五险一金、全额理赔商业补充医保、超长带薪年假、超长带薪病假、书费报销、打车报销、无限量零食饮料畅吃、国内外团建旅游等,"企业服务,数据服务",50-150人,spark,上海
大数据算法工程师,https://www.lagou.com/jobs/7178983.html,徐汇区,15k-30k,久远谦长（北京）技术服务有限公司,不限,本科,福利待遇优厚，发展空间大，团队氛围好,【职位描述】：* 负责算法工程落地；* 负责算法产品的研究和开发；【任职资格】：* 计算机科学、应用数学、统计学、经济学、物理学、天文学、商业分析、信息系统、数据科学或相关专业本科或以上学历；* 优秀的学习能力与发现、分析并解决问题的能力；* 良好的团队合作精神与沟通能力；【技能要求】：* 具备良好的表达能力；* JAVA基础扎实，有相关开发或者实习经验，熟悉IO、多线程、MQ、数据结构与设计模式等；* 熟练掌握Hadoop/Hive/Spark，对于Spark优化等有研究者优先；* 了解Python和Tensorflow生态者优先【公司介绍】：-麦肯锡和华为惠普联合团队• 由多位前麦肯锡合伙人以及华为惠普核心工程高管联合创立，打造精品管理咨询传承与科技创新品牌• 同时拥有优质咨询项目资源、丰富咨询经验，及数字化赋能的精尖技术能力，建立从咨询建议到产品/解决方案的全面商业服务模式• 约300位咨询顾问、数据科学家、软硬件工程师常驻北京上海和成都-多行业多商业领域覆盖•主要服务于企业客户，通过结合管理咨询、大数据分析、算法建模与工程落地的能力帮助企业客户实现业务增长•行业覆盖消费品、零售、金融、互联网、医疗与媒体等•与多行业领先企业深度合作，建立长期合作关系，如沃尔玛（获沃尔玛年度最佳供应商称号）、欧莱雅、联合利华、中国农业银行、腾讯、京东、美团等-精尖的数据分析/算法/工程师团队• 具备数据清洗与挖掘、算法模型和语义分析方面行业领先技术水平与能力• 具备根据客户业务方向搭建中台/后台的工程技术能力与丰富的项目经验• 具备广受行业认可的成熟产品（含已申请专利技术），帮助客户实现数据驱动的效率提升-富有竞争力的职业发展与薪酬福利保障•注重人才培养，提供定期培训分享及深度参与项目机会，加入团队的年轻小伙伴们再也不用担心自己沦为职场“小螺丝钉”•注重员工成长空间，每年二次全员review，半年即有机会享受升职加薪•注重福利保障，包括：五险一金、全额理赔商业补充医保、超长带薪年假、超长带薪病假、书费报销、打车报销、无限量零食饮料畅吃、国内外团建旅游等,"企业服务,数据服务",50-150人,spark,上海
高级大数据测试工程师,https://www.lagou.com/jobs/6688041.html,浦东新区,28k-40k,上海昌投网络科技有限公司,5-10年,本科,加班少 扁平 分享 重技术 业务盈利,"简化版: 角色定位: 大数据测试第1人，技术主导者，团队搭建者，技术布道师团队情况: 属于大数据中台部门，部门规模20人左右技术需求: 2年以上大数据测试经验，精通业务逻辑，最好熟悉Java，实时计算和离线计算的测试都有丰富经验其他需求: 统本相关专业出身，学习能力强，有主导能力，主动性高--------------------------------------------------------------------正式版JD:岗位职责:1. 负责大数据方向相关产品的测试工作，验证业务数据的准确性，对业务数据有一定敏感度，能从测试的角度帮助提升产品质量；2. 根据需求及项目计划制定项目测试计划、确定测试的方法及内容、进行测试需求分析；3. 根据业务逻辑编写测试SQL脚本，独立完成项目中数据指标的测试，保证数据质量和性能；4. 独立设计、开发、执行测试用例，并进行bug的跟踪，根据测试结果完成测试报告，协助开发跟踪、定位产品软件中的缺陷或问题；任职资格:1. 熟悉大数据中间件，如Elastic Search，HBase，mongodb，redis等，熟悉Hadoop、Spark、hbase、kafka等分布式开源项目及工作原理；；2. SQL熟练，能够对复杂SQL进行调优3. 熟悉传统数据仓库开发流程测试,有大数据相关产品完整的项目测试经验；4. 熟悉数据的抽取,转换以及加载过程(ETL),对数据仓库有基础的了解；5. 熟悉Linux环境操作，熟悉自动化测试方法，尤其是分布式软件系统的测试方法,对ETL和报表的自动化实现有经验。6. 具有WEB应用测试经验，熟悉常用的测试工具和Bug管理跟踪软件，版本控制软件；7. 熟悉java,Python优先，有自动化测试经验优先，有白盒测试经验优先。",移动互联网,150-500人,spark,上海
数据仓库模型专家,https://www.lagou.com/jobs/6834917.html,浦东新区,30k-50k,上海昌投网络科技有限公司,5-10年,本科,公司久 盈利 年轻化 新项目多 技术新,"岗位职责：1、主导公司整体数据仓库的模型架构建设：包括数据模型、数据仓库的设计、实现、维护；结合大数据和数据智能化赋能业务发展需求和系统现状，设计符合业务需求和未来发展的高可用模型架构；2、负责各业务线及各应用场景的数据模型设计，并推动开发落地，建立规范化、稳定可靠的数据体系；3、推动建设公司数仓管理系统包括：元数据建设，权限管理，数据血缘关系管理等；4、与业务部门密切配合，探寻数据的业务价值，推动业务数据化、数据业务化的转型；5、能够以数据资产化、数据价值体现、数据全链路价值分析的角度规划和设计模型，实现从数据接入到数据消费全链路的智能数据构建与管理的一站式建设任职要求：1、计算机、数据等相关专业，本科以上学历、8年以上大数据建模的相关工作经验；2、负责过数据仓库整体架构和ETL链路实现过程，精通数据仓库物理模型建设和管理、数据服务标准化（主题式数据服务、指标和维度规范）过程，具备成功的项目案例3、精通各类数据仓库，精通HIVE-SQL,SPARK—SQL,PRESTO-SQL, impala中至少两种及以上,并能进行调优。4、优秀的业务分析和洞察能力，有丰富的业务数据应用经验，优秀的数据、平台、技术理解能力；5、具备良好的团队沟通能力、团队合作精神及项目管理能力，具备较强的执行力及抗压性；6、有扎实的数仓建模和数据集市建模理论知识",移动互联网,150-500人,spark,上海
高级Java开发工程师（数据技术）,https://www.lagou.com/jobs/7205752.html,黄浦区,27k-39k,贝壳金科控股有限公司,5-10年,本科,五险一金，带薪年假,"岗位指责：1. 负责与三方公司做数据对接，为业务提供统一的三方接口服务2. 保障三方对接平台的稳定性和可靠性3. 基于开源产品对大数据工具进行二次开发，保障大数据平台的易用性和稳定性任职要求：1. 具备扎实的计算机理论基础, 对数据结构及算法有较强的功底2. 精通Java语言编程，具备优秀的系统Debug/Profiling能力和经验3. 熟悉Spring Boot,Spring Cloud等后端开发系统4. 良好的沟通协作能力，支持跨团队沟通4. 有React antd 或者 Vue 开发经验者优先5. 熟悉Hadoop/Kafka/Flink/Spark/TiDB等开源大数据技术者优先6. 有强烈上进心和责任心，学习适应能力强，乐观自信，能挑战自我不断追求卓越",金融,500-2000人,spark,上海
大数据开发工程师 (MJ001024),https://www.lagou.com/jobs/7152163.html,黄浦区,21k-39k,贝壳金科控股有限公司,不限,本科,五险一金，带薪年假,"岗位职责：1、理解数据的产品应用场景逻辑，通过统计方法和通用分布式框架工具语言如Spark,TiDB，不断加强数据服务质量；2、负责数据清洗、转换、建模等工作,对海量用户行为数据通过Spark/Flink等进行离线和实时处理；3、参与企业级数据仓库、数据建模等数据开发工作。4、业务数据报表设计、开发及日常维护任职要求：1、丰富的数据仓库建模经验，具有良好的数据分析思维；2、精通SQL，熟练使用MySQL/Hive/Oracle中至少一种数据库3、熟悉大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖掘和数据可视化4、能够自驱，有创新意识，对数据价值应用思路清晰，沟通能力强5、有Spark、hive、TiDB等大数据sql引擎实战经验者优先6、了解java web开发；掌握基础java开发者优先",金融,500-2000人,spark,上海
Python数据开发工程师,https://www.lagou.com/jobs/7167639.html,浦东新区,25k-35k,上海微创软件股份有限公司,5-10年,本科,六险一金工作环境nice技术前沿,"ElectrifAi-Python数据开发工程师 项目描述成立于2004年，是人工智能和机器学习领域的领导者，为行业带来了革命性变化，以帮助客户转变其业务。作为业界首创，ElectrifAi已围绕开源和Spark体系的计算引擎重新设计了其技术平台，该引擎可进行大规模的分布式数据处理和机器学习，并具有嵌入式Zeppelin笔记本功能。现在，ElectrifAi的数据科学家及其客户可以使用任何编程语言对数据进行编码和访问。Docker Containers和Kubernetes的结合使ElectrifAi能够大规模构建和部署混合云企业解决方案，在数周而不是数月内即可看到结果，从而显着增加了企业实现价值的时间。客户来自世界上许多最大的企业和政府部门，其中包括：强生，T移动，美国政府，诺华，安大略省教师退休金计划，万事达卡，花旗银行，美国运通卡，Mercy医院，Bon Secours和联合航空。ElectrifAi可以协助客户将不同的混乱数据转化为实用的见解，从而解决日常问题并通过提高利润，提高绩效和降低风险来推动业务发展。ElectrifAi对全球**行业的公司产生了积极影响，这些行业包括：政府，医疗保健，金融服务，旅行和款待，电信，CPG岗位内容• Design, build and launch efficient & reliable data pipelines to move and transform data.• Securely source external data from numerous partners.• Design scalable implementations of the models developed by Data Scientists.• Optimize existing pipelines and maintain of all domain-related data pipelines.• Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data.岗位要求• BA/BS in Computer Science, Engineering, Mathematics or related field.• 3+ years of SQL (Oracle, Vertica, Hive, etc.) experience and relational databases experience (Oracle, MySQL).• 3+ years of experience in custom or structured ETL design, implementation and maintenance.• Proficiency in Python, minimum 3 years of Python development experience.• Hands-on experience with different data warehouse and processing technologies such as Spark.• Experience working in very large data warehouse environments.• Experience working with applied scientists on machine learning modeling.• Good oral English","企业服务,移动互联网",2000人以上,spark,上海
大数据架构师,https://www.lagou.com/jobs/6271622.html,浦东新区,35k-50k,钰真(上海）信息技术有限公司,5-10年,本科,"福利优厚,五险一金,周末双休,弹性上班",职责描述：1、负责大数据相关平台/应用系统的架构、开发、维护和持续优化；2、负责对接业务团队，解决在业务发展中遇到的产品和平台架构问题；3、负责分布式平台应用开发（Hadoop/Spark/Hive/Hbase等）；4、负责搭建效果监控平台，数据质量监控平台，数据中心建设，算法模型平台化建设； 5、具体领域包括但不限于推荐算法开发、分布式存储、大规模分布式计算、实时计算、跨平台资源调度、大规模分布式算法平台等；。任职要求：1、本科及以上学历，计算机相关专业，具有5年及以上的大数据平台搭建、架构和研发经验；2、熟悉大数据组件的开发、集成、维护以及调优；3、熟练掌握Java或Python编程语言，熟悉大数据架构体系，对Hadoop、HDFS、Hive、HBase、Spark、Kafka等技术中的一个或者多个有深入理解，有海量数据处理经验；4、熟悉HBase和Kafka，有海量日志采集和分析系统搭建经验；5、有数据仓库开发经验/BI系统开发经验者优先；6、有电商行业数据处理与分析平台开发经验者优先。,"电商,其他",150-500人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6293360.html,浦东新区,20k-30k,钰真(上海）信息技术有限公司,5-10年,本科,跨境女装电商行业排名前三90后团队,1、负责数据分析、加工、清理，相关处理脚本和程序的开发；2、负责开发大数据工具，如报表平台、多维度分析工具、ETL平台、调度平台的研发；3、负责分布式大数据平台应用开发（Hadoop/Spark/Hive/HBase等）；4、负责大数据相关平台的维护、优化。任职要求：1、本科及以上学历，计算机相关专业，具有5年及以上的大数据ETL或数据开发经验，熟悉大数据组件的维护以及调优；2、熟练掌握Java或Python编程语言，熟悉大数据架构体系，熟悉Hadoop、HDFS、Hive、HBase、Spark、Kafka等技术中的一个或者多个，熟悉Sqoop、DataX等数据导入工具；3、能熟练使用Hive、HBase、Spark等加工和处理数据，有海量数据处理经验；4、有数据仓库开发经验/BI系统开发经验优先；5、有电商行业数据处理与分析平台开发经验者优先。,"电商,其他",150-500人,spark,上海
BK31VB-架构师,https://www.lagou.com/jobs/7023769.html,浦东新区,15k-25k,平安银行股份有限公司信用卡中心南京分中心,5-10年,本科,"五险一金,年底双薪,定期体检,带薪年假",,金融,500-2000人,spark,上海
Python 后台开发工程师,https://www.lagou.com/jobs/6372641.html,徐汇区,15k-25k,上海媒智科技有限公司,3-5年,本科,年底双薪 股票期权 带薪年假 周末双休,工作职责：1、负责公司产品后台开发工作，主要编程语言是 Python、C++ 和 Go；2、参与架构设计，与平台工程师合作优化新旧服务的性能和稳定性。岗位要求：1、扎实的计算机基础知识，了解常用数据结构和算法；2、对多线程、多进程、系统 IO 等优化有相关经验，有嵌入式开发经验，有树莓派/ARM经验；3、熟悉分布式系统、能处理分布式同步异步问题；4、熟悉 MySQL、Redis、RabbitMQ、Kafka、Elasticsearch 等后端组件的使用，了解基本的设计、优化原则；5、熟悉 Linux 的使用和管理，了解操作系统相关知识；6、熟悉 Git、Jenkins 等持续集成和部署工具，熟悉单元测试；7、热衷性能分析与调优，积极使用新技术提升工作效率；8、良好的团队合作精神与责任感，较好的沟通能力。优先条件：1、开源社区贡献者；2、具备前端开发能力，了解 React、Vue.js 等前端框架；3、具备数据处理和分析能力，了解 pandas、Spark 等使用。,移动互联网,15-50人,spark,上海
数据中台架构师,https://www.lagou.com/jobs/7087999.html,杨浦区,15k-25k,上海道客网络科技有限公司,5-10年,本科,五险一金、补充医疗险、年终奖金,加入 DaoCloud 会负责：                                                                         * 负责企业数据仓库、数据集市的架构设计和项目实施* 负责数据仓库、数据中台底层模型设计和搭建* 负责ETL流程的设计、开发和部署* 负责数据质量管理体系的建设，进行数据质量相关系统的设计，推动实施，迭代* 基于公司及合作伙伴的大数据、数据湖、MDM等产品及解决方案，为客户提供数据中台及大数据等数字化转型技术解决方案实施落地的咨询服务* 行业侧重于金融、零售、快消、地产、政府等DaoCloud 对你的期望：* 本科及以上学历，理工科专业优先* 5年以上工作经验，3年以上数据仓库或BI开发经验，具备从0到1搭建企业级数据仓库的项目经验* 1年以上的项目管理经验具有以下产品及咨询能力者优先：*数据仓库、数据集市、商业智能（BI）、主数据管理、数据治理、数据指标体系、标签库管理、数据挖掘等，熟悉常见等数据中台、数据仓库和BI产品，例如Hadoop、Hive、MySQL、Kylin、Spark、Tableau、PowerBI* 具有优秀的逻辑能力、学习能力和创新能力* 具有很强的工作主动性、自我驱动力、抗压能力和团队工作意识* 可以接受频繁或长期出差的工作安排,"企业服务,数据服务",150-500人,spark,上海
数据开发专家,https://www.lagou.com/jobs/7172255.html,浦东新区,25k-35k,上海上湖信息技术有限公司,5-10年,本科,数据集大，团队牛人多,职位描述1.参与平台数据仓库规划、架构及研发，包括离线、实时的数据模型规划，建设PB级的数据集市和数据平台； 2.数据仓库模型的ETL实施，ETL性能优化、技术攻关等3.参与平台数据治理相关工作，负责数据质量、数据一致性及稳定性保障等建设 ； 4.参与平台标签体系、数据产品与应用的数据研发，发掘数据价值，以数据驱动业务不断发展 。职位描述1.5年以上相关工作经验，计算机等相关专业本科以上学历，具有丰富的数据建模实践经验。2.精通业务建模、数据仓库建模、精通ETL设计开发，具备体系化的数据质量与数据治理相关经验，有大型项目相关领域深入实践经验，能独立主导完成某一业务领域的整体模型设计，具备跨域的沟通协调能。3.精通大数据技术，如MAPREDUCE、HIVE、YARN、SPARK、FLINK等，深入了解背后的实现原理，并能够调优。4.良好的思维逻辑性和语言表达能力，以及良好的项目沟通和协调能力。5.具备一定的JAVA、Python语言的开发能力。,金融,2000人以上,spark,上海
资深研发专家-实时数据,https://www.lagou.com/jobs/6834615.html,浦东新区,20k-35k,上海上湖信息技术有限公司,5-10年,本科,晋升涨薪机会，带薪年假，商业保险,工作职责:1. 充分理解业务需求，结合公司的数据平台的建设和发展，完成数据服务的研发；2. 带领团队规划技术方向，确保数据平台的稳定性和准确性，并能通过数据平台支撑各类数据应用；3. 推动跨部门合作，预测问题并进行防范，及时发现及暴露风险，解决项目中的大部分问题。 岗位资格：1.   计算机或相关专业本科以上学历，有3年以上相关工作经验；2.   掌握实时大数据相关生态组件，如spark、flink、druid、kudu、kylin等实现过大型项目，同时有数仓经验、理解离线计算原理的优先；3.   对数据有一定的敏感，能充分发挥数据价值；理解数据治理、数据服务、数据管控相关方法论；有运营分析、催收分析等相关平台建设经验优先；4.   性格开朗，乐于融入团队，快速理解业务，，具有很好的团队协作精神和沟通能力，能够承担一定的工作压力,金融,2000人以上,spark,上海
大数据高级开发工程师,https://www.lagou.com/jobs/7014700.html,浦东新区,45k-60k,善诊（上海）信息技术有限公司,3-5年,本科,空间大，机会多,岗位职责：1、负责数据仓库规划建设，数据处理和开发工作；2、参与大数据平台的数据架构和ETL流程设计；3、参与构建和维护离线/实时计算平台、分布式调度等平台的架构和开发；4、对接产品和业务人员，深入了解业务背景，抽象业务需求，参与数据服务层的设计和开发；岗位要求：1、重点本科及以上学历，3年以上大数据开发经验，1年以上数据仓库工作经验；2、精通Java/Python/Scala等至少一门语言，熟悉Linux/Unix系统；3、熟悉Hadoop、Spark、Hive、HBase、ElasticSearch等相关技术，并有丰富的开发经验；4、熟悉数据仓库的开发流程、数据仓库的建模理论以及数据层级关系，有数据仓库架构设计经验者优先；5、有强烈的技术热情、良好的逻辑分析能力、工作责任感，不是仅仅把技术作为谋生的手段，有良好的团队合作、创新精神；,"移动互联网,医疗丨健康",150-500人,spark,上海
数据开发工程师（上海）,https://www.lagou.com/jobs/7203009.html,浦东新区,12k-22k,联洋国融（北京）科技有限公司,3-5年,本科,公司有强大背景，稳定 有安全感,岗位职责：1. 负责离线计算任务的部署、资源调度和常态化运行；2. 负责对业务方提交的代码寻找可能存在的性能瓶颈，进行性能优化；3、负责底层数据治理、常规的测试与统计任务等；职位要求：1. 熟悉主流的云计算和大数据产品(Hadoop/Hive/Spark/Flink/Hbase/ES等)，了解kerberos权限认证、调度系统等相关组件；2. 两年及以上数据仓库建模经验，熟悉数据治理、元数据管理、数据质量监控等；3. 掌握spark分布式计算原理，能根据执行计划或pyspark代码分析可能存在的性能瓶颈；对技术怀有强烈热情，有优化的思维和习惯,数据服务,50-150人,spark,上海
Java架构师,https://www.lagou.com/jobs/6417262.html,浦东新区,40k-60k,上海喜马拉雅科技有限公司,5-10年,本科,年终奖丰厚,岗位职责:1. 参与平台的RPC中间件架构设计与开发，搭建平台基础设施；2. 研究新的技术⽅案，调整服务端开发策略和技术架构，使之适应业务平台日益增长的需求。任职要求:1. 至少5年以上大规模分布式系统应用架构设计与研发经验，精通Java技术栈相关技术，精通OOP/设计模式；2. 精通主流开源的RPC框架，精通Netty，对NIO有深刻的理解，对protobuf/thrift/hessian协议中的一种或多种有深入的理解；3. 熟悉unix/linux操作系统，精通TCP/IP协议；4. 熟悉分布式计算平台如storm， spark， flink等；5. 精通缓存数据库，如redis等；6. 有移动互联网架构如移动网关，微服务化等经验者优先；7. 对开源技术有浓厚兴趣，有源代码阅读习惯；8. 具备良好的识别和设计通⽤框架及模块的能力。,"移动互联网,文娱丨内容",2000人以上,spark,上海
高级大数据开发工程师,https://www.lagou.com/jobs/6190884.html,浦东新区,20k-30k,上海喜马拉雅科技有限公司,5-10年,本科,年终奖丰厚 扁平化 技术氛围好,职位描述：1.  为海量数据的处理和分析提供高效解决方案2.  研究Hadoop/Spark/Hbase/Hive等开源项目，对线上任务进行调优，并开发通用组件3.  维持线上服务高效稳定，支撑业务和数据量的快速扩张职位要求：1.  扎实的计算机系统和算法基础知识；良好的英文阅读能力2.  扎实的Java、Scala语言基础，对JVM运行机制有深入了解3.  熟悉Hadoop、Spark并有丰富的开发经验4.  对常见开源框架代码有研究5.  熟悉SQL和noSQL的设计和开发6.  熟悉企业应用设计模式、面向对象的分析和设计技术，包括设计模式、UML建模等7.  善于思考，能独立分析和解决问题，热衷于互联网技术的研究和创新8.  责任心强，具备良好的团队合作精神9.  有深入研究过Hadoop/Spark源码者优先10.  有OLAP系统设计经验者优先,"移动互联网,文娱丨内容",2000人以上,spark,上海
资深算法工程师,https://www.lagou.com/jobs/7045575.html,杨浦区,25k-40k,上海哔哩哔哩科技有限公司,3-5年,本科,大平台 双休,"资深算法工程师（直播）岗位职责:1. 拥有较强的机器学习相关技术功底，包括但不限于传统机器学习模型、深度学习、图像处理、自然语言处理等2. 熟悉一门以上的开发语言：Java/Golang/C/C++等3. 至少有一项实际业务框架搭建经验：推荐/搜索/图像处理 等4. 熟悉TensorFlow深度学习框架, 熟悉特征工程5. 拥有较强 AI 想象力，能够敏锐的发现潜在的 AI 应用场景并有实现思路优先条件：熟悉推荐、ORC算法、计算机视觉 中的一项有五年以上的机器学习、深度学习相关项目经验图像处理、机器学习、深度学习相关专业的本科、硕士学历或以上熟悉 Hive/Hbase/Hadoop/Spark/Storm 等大数据","移动互联网,文娱丨内容",2000人以上,spark,上海
基础架构资深Java开发工程师,https://www.lagou.com/jobs/7082676.html,闵行区,22k-39k,上海阑途信息技术有限公司,5-10年,本科,"发展空间大,工作氛围好",工作职责    【技术专家】帮业务团队排查各种疑难杂症，减少大家后顾之忧；【造轮子】 观察研发同事常碰到的问题，思考通用解决方案，提供稳定好用的中间件产品；【做决定】 参与业务团队的架构选型和方案评选，帮业务开发把好技术关；【攻坚】 核心系统的设计，实现与优化，负责技术难题的解决，成为大家依赖的技术主心骨；【布道】 负责撰写软件系统的相关技术方案，关注研发流程，书写技术文档和开发规范，指导和培训年轻工程师 。职位要求    本科及以上学历，计算机、数学相关专业，强大的编码能力；8年以上Java系统研发相关经验，5年以上系统架构设计或者分布式系统开发相关经验；能制定和规范开发流程，制定技术标准，编写相应的技术文档；有极佳的逻辑思维能力，善于思考，能独立分析和解决问题，具创新意识，强烈的责任心和良好的团队合作精神，较好的沟通能力；熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息等机制，能对分布式常用技术进行合理应用，解决问题；技术栈期望：JVM、RESTful、MQ、Redis、MySQL，熟悉SpringBoot、ElasticSearch、Hadoop、Spark、Docker者优先；最后，希望你是个认真而有趣的人：）,汽车丨出行,2000人以上,spark,上海
算法专家,https://www.lagou.com/jobs/6382566.html,闵行区,40k-60k,上海阑途信息技术有限公司,5-10年,硕士,独角兽 大牛云集 临近地铁 多次调薪,"岗位职责:1. 负责智能算法的研发/管理统筹工作，持续迭代提升转化效果和用户体验；2.带领团队分析和挖掘业务需求，应用统计学、数据挖掘、机器学习等领域的技术建模；3.具体工作包括(但不限于)：搜索列表排序，站内各流量位的个性化推荐，精准lbs营销、信息流推荐等算法研发和工程化落地；4.关注并引入行业前沿技术（工具、方法等），引领团队技术水平；5.负责培育、发展和管理团队；   职位要求：1.掌握业界主流的机器学习和深度学习框架，及hadoop,spark等分布式大数据处理技术；2. 具有统计或数据挖掘背景，并对机器学习算法有全面且深入的理解或研究；3. 扎实的编程基础，熟悉Python/Java/Scala至少一门编程语言；4.具备较强的数据分析能力，能够基于复杂的业务场景快速建模和设计算法；5.优秀的沟通合作能力，踏实和坚持不懈的工作态度；6.本科/硕士研究生毕业5年以上，大型互联网研发背景或具备推荐/搜索/广告等领域经验者优先；",汽车丨出行,2000人以上,spark,上海
大数据专家,https://www.lagou.com/jobs/7141131.html,虹口区,35k-45k,上海维信荟智金融科技有限公司,5-10年,本科,带团队 氛围好,"工作职责：1. 负责基于Hadoop/Spark的大数据平台架构规划、设计、优化、开发、部署；2. 规划和实施海量数据的收集、存储、建模、计算；3. 负责大数据项目的方案设计、需求把控、项目拆解、进度管理和开发；4. 与相关部门紧密合作，推动大数据架构升级，为业务提供高可用服务。5. 规划和落地数据治理、数据仓库建设、高性能数据服务的研发；任职资格：1. 本科及以上学历，五年以上数据研发经验；2. 具备扎实的计算机理论，数据结构和算法基础，优秀的工程能力；3. 具备扎实的Java/Scala或Python语言基础，可开发高效的代码，熟练代码管理工具；4. 熟练使用Hive/Hbase/Kafka/Flume/Spark/ES等大数据相关组件,对分布式储存计算有深入理解；5. 严密的数理思维、突出的分析和归纳能力、优秀和分析和解决问题能力6. 具备良好的项目规划和管理能力，结果导向；有很强的沟通能力。优先考虑：具备丰富的技术团队管理经验。",金融,2000人以上,spark,上海
资深大数据开发工程师,https://www.lagou.com/jobs/7140897.html,虹口区,25k-35k,上海维信荟智金融科技有限公司,3-5年,本科,带团队 氛围好,"工作职责：1、基于hadoop/spark平台架构设计及开发工作2、大数据平台的框架设计及核心代码编写3、基于spark Streaming流式计算的设计及开发4、对海量数据进行收集、存储、管理、分析、建模5、对海量用户数据进行统计分析挖掘，不断提升系统系统运行效率6、负责大数据平台的监控及优化，针对持续增长的数据提供相应的解决方案任职资格:1、四年以上开发经验，三年以上大数据开发经验2、扎实的Java/Scala或Python语言基础，可开发高效可利用的代码，了解虚拟机性能优化策略，熟练代码管理工具。3、具有丰富的Spark开发经验4、熟练使用Hive/Impala/Hbase/Kafka/Flume等大数据相关组件,对分布式储存计算有较深入了解5、熟练编写Shell，Sql,具有Sql优化能力6、严密的数学思维、突出的分析和归纳能力、优秀的沟通表达能",金融,2000人以上,spark,上海
高级Java开发工程师（支付方向）,https://www.lagou.com/jobs/6027527.html,徐汇区,25k-45k,上海印闪网络科技有限公司,5-10年,本科,红杉投资 海外独角兽互金企业,红杉投资 海外头部互金【岗位职责】1. 参与开发高并发支付和财务平台的架构，研究行业最新技术；2. 负责高可用业务模块的设计、实现和优化；3. 负责大流量高难度线上问题的排查、定位和解决，并有效监控和预防。【岗位要求】1. 熟悉Spring、Spring Boot、MyBatis、MySQL、Redis、Zookeeper等开源项目，能够合理进行技术选型，善于解决问题。2. 具有2年以上研发和架构经验，熟悉Java技术栈；3. 有高并发、微服务架构、多线程开发、SQL优化经验者加分；4. 有海外支付领域和财务相关经验者加分(东南亚、南亚地区优先)；5. 展示你的实力，一切条件皆免。【加分项】1. 有财务和支付领域工作经验，具备财务支付相关的技术和专业知识；2. 有大数据特别是Hive/Spark相关经验，或有SQL优化相关经验加分。,"移动互联网,金融",150-500人,spark,上海
大数据科学家,https://www.lagou.com/jobs/4269067.html,徐汇区,20k-40k,上海印闪网络科技有限公司,3-5年,硕士,"上升空间,福利多多,气氛轻松,国际化业务","职位描述：1.负责线上贷款审批的需求调研，了解业务逻辑，进行数据分析从而把需要解决的业务问题转化为机器学习/数据挖掘问题2.负责从数据获取、数据清理、统计分析和数据建模（机器学习模型）整个流程工作3.使用先进的机器学习技术，针对性的设计方案，根据设计的方案部署实施整个机器学习系统，解决客户的核心问题4.负责机器学习模型的构建，并且与工程师合作对模型进行维护、部署和评估；5.设计线上线下实验方案，与客户沟通并完成实验，迭代优化机器学习系统效果职位要求：1.统计学、应用数学、计算机等相关专业硕士及以上学历2.深厚的机器学习基础，2年以上数据科学相关工作经验，精通主流机器学习模型算法，并热衷于利用机器学习技术解决现实问题3.扎实的编程经验，熟练运用Python/R/Java/C++等编程语言4.熟悉Hadoop和Spark平台，熟悉相关工具来处理海量数据，具有互联网行业数据经验优先5.很强的沟通能力，很强的学习能力和动手能力6.思维敏捷，良好的逻辑分析能力、良好的沟通及组织能力优先条件：1.熟练掌握一门编程语言，常用算法和数据结构2.有机器学习、数据挖掘、信息检索等相关领域的理论背景，有研究或应用相关的工作经验3.参加过机器学习与数据挖掘相关竞赛（Kaggle, KDD Cup等）","移动互联网,金融",150-500人,spark,上海
广告-资深算法工程师,https://www.lagou.com/jobs/6576559.html,长宁区,30k-60k,北京奇艺世纪科技有限公司,3-5年,本科,行业领跑 市场竞争力薪酬 挑战成长空间大,岗位职责：1、研究竞价广告前沿理论和技术，实践海量流量变现效率提升方法；2、独立负责项目推进和管理，算法核心模块开发和效果调优；3、业务包括点击率预估、oCPM等。任职要求：1、本科以上学历，3年以上相关工作经验，具备扎实的数学功底，有互联网广告、推荐、搜索相关经验优先；2、良好的沟通能力，优秀的学习和团队协作能力；3、理解常见机器学习、深度学习模型，具备灵活运用能力；4、熟悉Spark、MapReduce等并行编程模型，有实际的海量数据处理和挖掘经验；5、精通任何一种面向对象编程语言，如python，c/c++或java；6、热爱数据分析，喜好专研，擅于应用算法解决实际问题。温馨提醒：如果 7 天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可。,文娱丨内容,2000人以上,spark,上海
大数据工程师,https://www.lagou.com/jobs/7049471.html,杨浦区,15k-25k,上海幂集软件有限公司,3-5年,本科,补充医疗险、带薪休假、员工体检、绩效奖金,"岗位职责：1、负责公司数据仓库的架构设计和开发2、负责数据平台相关数据管理工作，如研发规范、质量规范、保障规范的制定与推动实施落地；3、负责来自业务团队数据需求的研发支撑；4、负责数据仓库的建设和维护,包括需求调研分析、软件规划、概念模型、设计逻辑、物理模型、数据处理（抽取、清洗、转化）、项目实施管控等；5、负责制定数据接入和采集规范制定。任职要求：1、从事大数据领域工作3年以上；2、有阿里云、腾讯云或AWS等云平台的大数据系统的工作经验优先；3、熟悉数据建模、ETL设计与应用、报表开发等，并有实际模型设计及ETL开发经验；具有良好的编程习惯和文档编写习惯；4、熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、性能调优等；5、熟悉常用数据库的性能特点和开发技术，能够灵活运用SQL实现海量数据ETL加工处理；6、了解大数据基础架构和平台，具备相关产品（Hive、HBase、kafka, Spark， flink等）项目应用研发经验；7、熟悉Linux系统，能够熟练运用一种或多种语言进行开发（Java、Scala、Python）；8、对数据敏感，具有良好的逻辑分析、责任心强、良好的对外沟通和团队协作能","文娱丨内容,广告营销",50-150人,spark,上海
算法工程师,https://www.lagou.com/jobs/7080249.html,闵行区,15k-25k,百姓网股份有限公司,1-3年,本科,团队优秀、使命感、成长空间大,"工作职责
 负责广告产品全链条相关算法研发，包括但不限于投放竞价，点击预测，转化预测；
 负责广告关键词库建设的清洗建模，选词建模，分词，推词算法优化；
 负责社交电商业务的用户画像、个性化推荐算法工作；
 指导和培养初级算法同学。
 任职要求
 计算机/数学/统计等相关专业；
 2年以上相关工作经验；
 熟悉NLP或机器学习相关算法及实现原理，对工程实现和优化有一定经验；
 深入理解传统机器学习或数据挖掘类的算法原理，熟悉大数据处理技术（如Hadoop、Spark等）；
 较好的产品sense，具备较强的数据分析能力；
 较好的沟通能力、团队协作能力，积极主动，愿意接受挑战。",移动互联网,500-2000人,spark,上海
高级系统架构师,https://www.lagou.com/jobs/6997576.html,徐汇区,30k-50k,赛仕软件（北京）有限公司,5-10年,硕士,全球最佳雇主,职责：1. 负责SAS产品或解决方案的系统架构设计，安装和部署等工作；2. 负责与客户进行沟通，确定及编写系统架构和部署方案；3. 负责与研发/TS团队进行沟通，解决产品使用时遇到的问题；4. 负责解决方案的应用开发工作；5. 深入理解产品和业务需求，分析和发现系统的关键点，负责设计并推动架构优化。要求：1. 计算机相关专业硕士及以上学历，5年以上复杂IT软件的架构设计及实施经验2. 熟悉Linux操作系统及Shell/Perl脚本，对计算机系统、网络和安全、存储、中间件、HA等有全面的认识，有性能优化经验者优先；3. 熟悉Hadoop/Spark的系统架构设计；理解大数据处理技术（流计算、分布式计算、分布式存储等）及实现方法，有大规模分布式系统经验者优先；4. 熟练掌握一种编程语言，Java或者Python优先；5. 能够快速学习新技术，跟踪技术发展趋势；6. 具备良好的表达和沟通能力，善于解决问题，能够承受较大的工作压力。,人工智能,2000人以上,spark,上海
解决方案顾问,https://www.lagou.com/jobs/6997735.html,徐汇区,20k-40k,赛仕软件（北京）有限公司,3-5年,硕士,全球最佳雇主,岗位职责：1.  负责SAS解决方案的安装配置；2. 负责SAS解决方案的应用开发；3. 负责SAS解决方案和周边对接的开发工作。 任职要求： 1. 计算机相关专业硕士及以上学历，英语口语流利者优先；2. 熟练掌握一种编程语言，Java优先；3. 熟练掌握一种数据库系统，有DBA工作经验者优先；4. 熟练Linux操作系统及Shell/Perl脚本，对操作系统、网络和安全、存储、中间件、HA等有全面的认识，有性能优化经验者优先；5. 熟悉Hadoop/Spark的系统架构设计；理解大数据处理技术（流计算、分布式计算、分布式存储等）及实现方法，有大规模分布式系统经验者优先；6. 具有良好的表达和沟通能力，善于解决问题，能够承受较大的工作压力。,人工智能,2000人以上,spark,上海
高级数据工程师,https://www.lagou.com/jobs/7012302.html,徐汇区,15k-20k,上海讯真信息科技有限公司,5-10年,大专,前景佳,岗位职责： （1）负责大数据平台中资源编目信息的收集、整理、完善和导入等数据治理相关工作； （2）负责原始数据的收集、整理及追踪完善等数据治理工作； （3）负责运维保障大数据平台中各类数据汇聚、资源挂接等数据管理工作； （4）负责提供数据汇聚工作技术支持（如SQL编写及数据服务接口开发等）。 任职要求： （1）具有数据治理或大数据平台管理的工作经验； （2）熟悉数据采集、存储、清洗、分析及挖掘等方面的相关技术及相应的技术提供方； （3）熟悉主流数据库技术，如Oracle、SqlSQL语言； Server、MySQL及PostageSQL等； （4）熟悉ETL架构，了解日常作业的部署和调度，熟悉ETL开发工具，如Datastage、Congos及Kettle等； （5）了解多项大数据处理/分析相关的工具/框架，如Hadoop、 MapReduce、Hive、Storm、Spark、kafka及HBase等。,电商,50-150人,spark,上海
高级数据开发工程师,https://www.lagou.com/jobs/6725117.html,浦东新区,20k-30k,上海七猫文化传媒有限公司,3-5年,本科,公司发展前景好、岗位空间大、领导nice,"岗位职责：1. 参与七猫大数据系统的基础架构和技术体系的规划建设，包括数据采集平台、数据存储体系、数据质量及稳定性保障体系等；2. 参与数据处理流程的设计、开发和持续优化，包括数据ETL、存储、流批处理和实时查询等；3. 负责大数据平台的后端研发工作，包括后台架构方案的选型、设计和开发，要求开发的系统具有高性能和高可用性。任职要求：1、计算机、通信、数学、统计相关专业本科及以上学历，计算机或相关专业，大数据方向3年（至少2年大数据平台）以上相关工作经验；2、有Java项目开发经验，Java基础扎实，熟悉面向对象和设计模式，熟悉Java开源框架，如Spring、Struts等；3、具备丰富的大型互联网日志采集系统设计或架构经验，具备较扎实的理论基础和工程能力，熟悉HTTP、HTTPS等协议；4. 熟悉Hadoop、Zookeeper、HBase、Hive、Flume、Kafka、Sqoop、Spark、MapReduce、HDFS、Druid等开源项目的原理和使用方法, 并有处理TB级以上数据的项目经验；5、有算法实践经验，能够熟练应用算法做数据特征分析及数据建模的优先，基于大数据平台结合算法有精准营销等数据分析挖掘实际成功案例者优先；6、有较强的沟通表达能力，善于学习，能迅速理解产品需求；有较强的责任心和事业心，有严密的逻辑思维，有追求卓越的精神，能够自我驱动。我们的福利：1、提供免费早餐+午餐补贴+提供加班餐2、定期提供健康体检+免费入职体检3、年假+春节带薪路程假4、五险一金+补充商业医疗保险5、通讯补贴+交通补贴","移动互联网,文娱丨内容",150-500人,spark,上海
数据架构师,https://www.lagou.com/jobs/6725130.html,浦东新区,30k-45k,上海七猫文化传媒有限公司,5-10年,本科,公司发展前景好、岗位空间大、领导nice,"岗位职责：1. 参与七猫大数据系统的基础架构和技术体系的规划建设，包括数据采集平台、数据存储体系、数据质量及稳定性保障体系等；2. 参与数据处理流程的设计、开发和持续优化，包括数据ETL、存储、流批处理和实时查询等；3. 负责大数据平台的后端研发工作，包括后台架构方案的选型、设计和开发，要求开发的系统具有高性能和高可用性。任职要求：1、计算机、通信、数学、统计相关专业本科及以上学历，计算机或相关专业，大数据方向5年（至少3年大数据平台架构）以上相关工作经验；2、有Java项目开发经验，Java基础扎实，熟悉面向对象和设计模式，熟悉Java开源框架，如Spring、Struts等；3、具备丰富的大型互联网日志采集系统设计或架构经验，具备较扎实的理论基础和工程能力，熟悉HTTP、HTTPS等协议；4. 熟悉Hadoop、Zookeeper、HBase、Hive、Flume、Kafka、Sqoop、Spark、MapReduce、HDFS、Druid等开源项目的原理和使用方法, 并有处理TB级以上数据的项目经验；5、有算法实践经验，能够熟练应用算法做数据特征分析及数据建模的优先，基于大数据平台结合算法有精准营销等数据分析挖掘实际成功案例者优先；6、有较强的沟通表达能力，善于学习，能迅速理解产品需求；有较强的责任心和事业心，有严密的逻辑思维，有追求卓越的精神，能够自我驱动。我们的福利：1、提供免费早餐+午餐补贴+提供加班餐2、定期提供健康体检+免费入职体检3、年假+春节带薪路程假4、五险一金+补充商业医疗保险5、通讯补贴+交通补贴","移动互联网,文娱丨内容",150-500人,spark,上海
算法工程师（漫画）,https://www.lagou.com/jobs/5982586.html,杨浦区,20k-40k,上海哔哩哔哩科技有限公司,3-5年,不限,"上市公司,福利多多,氛围好,二次元文化",工作职责：负责个性化推荐算法的研发工作，包括但不限于：用户画像、召回算法、排序算法，基于海量数据的分析、挖掘和建模，提升推荐引擎的效果。职位要求：1、计算机相关专业，本科及以上学历，3年以上搜索/推荐/广告的相关研发经验，对推荐引擎有整体的认识和理解；2、熟悉推荐领域常用算法，有良好的建模思维，有大流量场景优化经验者优先；3、熟悉大规模数据处理的常用方法，熟悉Hadoop/spark/strom等至少一种分布式系统；4、熟悉Java/Python等编程语言及常用数据结构，具备良好的编程功底；5、具备良好的学习能力和沟通能力，对算法驱动数据增长怀有热情。,"移动互联网,文娱丨内容",2000人以上,spark,上海
Python数据开发工程师,https://www.lagou.com/jobs/6096855.html,普陀区,15k-30k,上海牛咖信息科技有限公司,3-5年,本科,"领导逗比,氛围欢乐,扁平结构,绩效奖金","岗位职责：1. 参与/负责数据仓库ETL（数据抽取、加载、清洗、转换）处理任务的设计和开发工作；2. 参与/负责数据报表的设计和开发工作；3. 参与/支持相关BI业务分析的开发和实施工作；4. 精通Python/Go开发语言；5. 参与/支持BI后台页面开发;任职要求：1. 计算机、统计学、数学、应用数学相关专业优先；2. 善长多核并行开发;3.掌握数据库基本知识,对数据库底层结构有较深理解和认知；4.善长MongoDB、Mysql、Redis等数据库地使用,具有数据模型设计的能力；5.精通SQL语句编写,并具备优化能力；6.熟悉Linux操作系统常用命令；7.有Hadoop、Spark等海量数据处理工具的工作经验优先；8.有ClickHouse的使用经验优先；9.工作严谨细致,有责任心,勤奋踏实,善于思考问题,具有团队合作精神，能承受一定的工作压力。","移动互联网,社交",150-500人,spark,上海
推荐算法专家,https://www.lagou.com/jobs/6486094.html,普陀区,75k-150k,上海牛咖信息科技有限公司,5-10年,硕士,"领导逗比,氛围欢乐,扁平结构,绩效奖金",岗位职责1、带领团队负责社交网络的用户画像构建2、负责社交网络推荐相关召回模型优化；3、点击率预估和排序模型优化；4、深度学习相关算法优化和应用。5、深入多部门团队合作，能解决实际工作中遇到的产品、开发问题任职资格1、统招硕士级以上学历，计算机相关专业，3-5年社会工作经验2、具有扎实的NLP理论基础和方法，并有至少3年的相关项目经验，包括但不限于意图识别、情感分析、文本分类、对话理解、近义词挖掘、知识图谱等相关算法3、熟练推荐业务常用理论和算法，在一个或多个领域（如排序模型，召回模型，用户画像，深度学习等）有2年以上实际工作经验4、在深度学习领域有较强的理论研究与实践经验，熟练使用tensorflow、pytorch或其他常用深度学习工具5、具有比较强的编程能力，熟练掌握java/c++/python/shell，熟悉hadoop、spark框架6、能跟踪学术界与业界最新进展，具有较强的研究能力，在顶会和期刊，如NIPS、ICML、AAAI、KDD、ACL等发表过论文者优先7、有技术洞察力，有产品意识，优秀的问题分析解决能力，对挑战充满激情面试：报销交通费,"移动互联网,社交",150-500人,spark,上海
数据开发工程师,https://www.lagou.com/jobs/6356775.html,浦东新区,15k-25k,上海新萌网络科技有限公司,1-3年,本科,"发展平台,扁平化,晋升机会,福利待遇","工作职责：1. 参与/负责数据仓库ETL（数据抽取、加载、清洗、转换）处理任务的设计和开发工作2. 参与/负责数据报表的设计和开发工作3. 参与/支持相关BI业务分析的开发和实施工作注：精通shell，有hadoop大数据环境经验,有使用一些组件的经验sqoop datax hive spark azkaban等。岗位要求：1.掌握数据库基本知识,对数据库内部结构有较深理解和认识2.精通mysql数据库及mysql存储过程,具有数据模型设计的能力3.精通sql语句编写,具有1年以上基于数据库开发的经验4.具备数据挖掘,数据迁移,ETL处理,sql语句优化,海量数据处理的工作经验5.熟悉Linux操作系统常用命令6.工作严谨细致,有责任心,勤奋踏实,善于思考问题,具有团队合作精神，能承受一定的工作压力;7.精通hadoop及相关组件，如:sqoop datax hive spark azkaban。8.有良好的人际关系和沟通能力，有大型项目经验优先；",社交,500-2000人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6944144.html,浦东新区,15k-25k,上海新萌网络科技有限公司,3-5年,本科,核心组,"1、使用大数据组件对海量数据进行开发与维护2、对大数据组件进行调优（hbase,hdfs,yarn,spark,jstorm,kafka,flume,azkaban,hive等）3、支撑各业务线数据需求以及实时离线计算需求，维护优化各个大数据组件平台稳定高效运行4、有一定的对大数据组件进行源码调整的能力任职要求：1、具有三年及以上大数据开发经验，熟练使用hbase,hive,flume,spark,mr,storm,kafka中的一种以上大数据组件2、熟练掌握linux常规命令与工具3、对Hadoop、HBase等源码有研究优先4、熟悉java，有并发应用或者分布式应用软件开发经验优先5、熟练使用shell或python编程6、良好的系统分析、架构设计能力7、对数据敏感、对新技术敏感8、对工作踏实，负责，有一定的抗压能力，有一定的团队沟通能力，能吃苦耐劳",社交,500-2000人,spark,上海
Java开发工程师,https://www.lagou.com/jobs/7139833.html,静安区,15k-30k,北京中关村科金技术有限公司,5-10年,本科,技术大牛，五险一金，试用期全薪，年终奖。,1.业务需求系统分析，提出技术研究及可行性报告；2.结合需求设计高扩展性、高性能、安全、稳定、可靠的技术系统 ；3.可以通过配置实现业务需求的变化，跟踪并研究最新技术并应用于产品 4.指导研发工程师的产品开发和技术研究工作，解决各类技术疑难问题主要技术要求如下：1、熟悉高并发架构，有良好的架构思想和落地能力，Java基础扎实；2、熟悉J2EE架构，熟悉Spring框架，熟悉数据持久化、缓存、消息、通讯等的相关开发；3、熟悉主流分布式中间件如：消息队列、分布式缓存、分库分表中间件、分布式事务；4、熟悉主流关系型数据库如MySQL/Oracle，或主流NoSQL数据库、分布式存储等5、了解分布式微服务系统架构，了解数据库分片设计，了解SpingBatch框架，作业管理，调度等6、对大数据相关技术SPARK、FLINK 有一定使用和理解7、有银行项目经验,金融,2000人以上,spark,上海
数据分析师（风险建模）,https://www.lagou.com/jobs/6672878.html,浦东新区,18k-35k,上海冰鉴信息科技有限公司,3-5年,本科,"金融高科技,新兴领域,发展空间大",工作职责：1.     负责金融风险管理相关的数据分析，对风险预警异常情况进行深入分析，对业务风险指标进行跟踪分析及优化；2.     负责机器学习模型的构建、维护、和评估；3.     参与公司征信评分模型和征信系统的研发，包括但不局限于反欺诈模型、申请评分、行为评分、催收评分等模型设计开发；4.     对于部门内产品、需求提供数据支持，对于风险规则策略提供建议；5.     配合项目计划，负责建模驻场项目，完成客户需求的任务。职位要求：1) 统计、数学、计算机等理工科相关专业本科及以上学历，至少2年金融业相关工作经验（做过个人征信和企业征信者最佳）；2) 熟悉常用数据挖掘算法与模型，熟悉逻辑回归、神经网络、决策树、聚类等建模方法；3) 熟练使用python、R等数据处理工具，熟悉SQL、hive、spark，Hadoop，了解MapReduce分布式计算，具备扎实的数据分析功底；4）对数据敏感且对处理大量数据有强烈兴趣，喜欢探索钻研，有独立思考的能力；5) 思维活跃，有创新思考能力，具有良好的逻辑分析能力，能够快速学习新方法，责任心强；6) 注重团队协作，有独立承担项目的经验和能力，具有优秀的职业素养和抗压能力；7）具有良好的编码能力，具备产品思维，可适应短期出差者优先考虑。,"信息安全,数据服务",150-500人,spark,上海
数据产品经理,https://www.lagou.com/jobs/6090120.html,松江区,12k-24k,上海巨人网络科技有限公司,1-3年,本科,发展平台 福利丰厚 一流的办公环境,工作职责:1. 负责BI产品的全过程管理，包括收集用户需求、调研和分析、制定产品规划、具体产品功能的设计、不断优化产品体验; 2. 综合市场和游戏产品业务用户的分析需求，设计并优化业务分析场景、指标、可视化展示，以及数据模型需求，完成指标体系搭建与数据产品设计开发，推动相应数据产品的研发和落地；3. 熟悉数据、数据技术及大数据开发工具，对数据采集、数据建模、数据开发、数据资产管理、数据分析等大数据领域或机器学习等领域有数据产品实战经验； 任职资格:1. 3年以上产品设计或分析经验，具备良好的数据敏感度、业务视野、BI平台搭建能力，具有良好的产品规划、设计与项目落地能力； 2. 熟练使用Axure、Sketch等产品设计工具； 3. 熟悉大数据计算引擎，了解Spark、Hadoop、Kylin 等开源大数据产品；4. 有强烈的上进心和求知欲，善于学习新事物，对技术充满激情；具有较强的团队合作能力，勇于面对和解决挑战性问题;,游戏,500-2000人,spark,上海
052191-大数据开发工程师（经纪业务）,https://www.lagou.com/jobs/6019827.html,徐汇区,15k-30k,平安证券股份有限公司,3-5年,本科,"五险一金,绩效奖金,年终分红,定期体检",,金融,2000人以上,spark,上海
0521F5-算法工程师（智慧投顾项目,https://www.lagou.com/jobs/7203720.html,浦东新区,25k-45k,平安证券股份有限公司,5-10年,硕士,"五险一金,绩效奖金,年终分红,定期体检",,金融,2000人以上,spark,上海
BI产品经理,https://www.lagou.com/jobs/6258644.html,徐汇区,20k-30k,上海众言网络科技有限公司,5-10年,本科,环境好、空间大，奖金丰厚、氛围融洽,工作职责1. 负责通用可视化BI平台规划，完成产品调研、功能设计等工作，推动BI需求产品化；2. 配合行业专家，设计并落地包含BI、大数据在内的客户体验管理分行业解决方案；3. 负责监测BI数据平台运行状况，并据此推动产品或运营改善；4. 及时关注业界内BI类产品以及数据可视化工具的动态；任职要求1. 熟悉企业内部BI分析及互联网大数据分析的功能需求及应用场景，业务及数据敏感性好；2. 精通Tableau、BDP、帆软BI、永洪BI、Qlik、BIEE、BO、Cognos等其中至少一种产品的设计逻辑及功能实现机理；3. 具备通用产品能力（原型能力、流程能力、PPT以及文档能力）；4. 熟悉其中一项或多项常用数据处理工具，如VBA、SQL、Hadoop、Spark、R、SPSS、Python等（2~3年使用经验）且有完整的项目落地经验优先；5. 熟悉常用数据挖掘、机器学习算法，如决策树、聚类、逻辑回归，关联分析、SVM，神经网络的候选人优先；6.全日制本科及以上学历，数学、统计学、计算机、电子和通信工程等理工科专业；有产品团队管理经验优先；,移动互联网,150-500人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6736108.html,徐汇区,15k-20k,上海众言网络科技有限公司,1-3年,本科,发展空间领导nice能力提升主人翁角色,"职责描述：1、负责大数据平台相关产品的设计，开发、文档撰写和项目改进；2、参与大数据平台上业务应用的功能设计及架构规划； 职位要求：1、计算机、数学等相关专业本科以上学历，2年以上相关工作经验；2、精通Hadoop体系结构、对Hadoop生态圈有较全面了解；3、熟悉大数据开发框架，熟练使用HDFS/HBase/Hive/Spark/Spark Streaming/Kafka/Flume等相关技术；有多个或多年大数据项目经验；4、能够使用Java、Scala中至少一门语言进行数据处理;5、熟悉Linux系统以及Shell脚本语言；6、精通MySql,Redis,ES,Mongo等开源缓存和数据库中间件7、具有一定的数据库设计能力,能够撰写规范的技术文档；8、掌握常用的设计模式和架构模式,能够熟练使用建模工具进行系統设计；9、具备良好的自学能力、沟通能力、独立解决问题的能力，有责任心以及团队合作精神；10、有机器学习、数据挖掘经验者优先；11、有（Capture Data Change,CDC）流式处理平台debezium经验优先",移动互联网,150-500人,spark,上海
253121-数据开发工程师,https://www.lagou.com/jobs/6934563.html,浦东新区,13k-26k,上海陆家嘴国际金融资产交易市场股份有限公司,应届毕业生,本科,"五险一金,带薪年假,节日福利",,金融,2000人以上,spark,上海
25210V-数据分析师,https://www.lagou.com/jobs/5500720.html,浦东新区,13k-26k,上海陆家嘴国际金融资产交易市场股份有限公司,3-5年,本科,"五险一金,节日福利,带薪年假,定期体检",,金融,2000人以上,spark,上海
大数据开发（网络金融）,https://www.lagou.com/jobs/7053412.html,长宁区,30k-45k,交银企业管理服务（上海）有限公司张江高科技园区分公司,5-10年,本科,年终奖，银行，补充医疗，公积金,职责：负责据平台建设项目的管理、需求分析、开发实施及维护和优化，确保数据质量，合理规划给外围系统的数据支持。主要工作：1.         负责大数据平台建设项目的需求分析，设计系统架构和物理数据模型，确保技术方案符合相关要求；2.         制定项目实施计划，跟进监督项目执行，保证项目顺利完成；3.         负责并组织协调大数据平台的运维和变更管理，制定并安排系统扩容，确保系统容量和性能满足业务要求；4.         落实监控源数据结构变更机制，组织源数据变更导致的相关调整工作；5.         负责分析和调研新增源数据的业务、数据和功能，梳理与现有系统数据的关联；6.         负责整合、提炼、规划给外围系统的数据支持，确保提供数据的时效性；7.         制定数据质量跟踪监控机制，确保数据准确、完整、一致；8.         制定大数据平台的技术规范，完善相关技术文档；9.         指导和培训团队成员，组织技术骨干攻克技术难点，提升团队能力。资质要求：1.         统招全日制本科及以上学历，计算机相关专业；2.         数据仓库或大数据相关工作经验3年及以上，具有金融行业、互联网行业大数据实施相关经验优先；3.         熟悉关系型数据库，熟悉数据仓库和ETL；4.         熟练使用Linux系统，熟练掌握JAVA/Scala和SQL等编程语言；；5.         具有基于Hadoop的大数据平台的使用和管理能力，熟悉主要组件及其功能，如Hadoop、MapReduce、Hive、Spark、Flink、kafka及HBase等，具有相关认证者优先；6.         具有较强的逻辑思维能力和独立思考能力，具备高度的自我约束和学习能力，能够承担较大的工作压力和责任；7.         具备较强的计划、组织和沟通协调能力，具备良好的文档撰写能力。,"移动互联网,金融",2000人以上,spark,上海
数据分析经理（网络金融）,https://www.lagou.com/jobs/7053338.html,长宁区,20k-30k,交银企业管理服务（上海）有限公司张江高科技园区分公司,3-5年,本科,年终奖，银行，补充医疗，公积金,"主要职责：1.      分析挖掘：对多数据源数据进行挖掘分析，建模并优化，帮助业务发现、分析和解决问题；2.      与业务建立良好沟通机制，为业务提供数据分析服务，与业务部门合作开展业务专题分析；3.      根据实际业务要求，完成深入的专项数据分析并形成分析报告；4.      参与数据挖掘模型的构建、维护、部署和评估；5.      协助数据平台开发人员开展数据仓库和数据统计分析项目的建设；6.      协助其他同事，做好新员工的带教。岗位要求：1.      本科及以上学历，计算机、数学、统计、金融等相关专业，5年以上工作经验；2.      有良好的数据统计和数据挖掘专业知识，能够通过数据分析结果，为业务决策提供支持；3.      熟练使用SQL、R或SAS；4.      抗压力强，具有团队合作精神；5.      丰富的数据分析、挖掘、清洗和建模的经验；6.      有金融工作背景及大数据处理经验，如Hadoop,Hive,Spark等使用经验者优先。","移动互联网,金融",2000人以上,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6914130.html,静安区,20k-25k,易居（中国）企业管理集团有限公司,3-5年,本科,上市公司、创新项目、发展空间大,"岗位职责：1、深入理解公司业务与技术架构，参与规划、建设房地产数据中台，负责日常数据模型设计及ETL开发等；2、主动跟进新业务及业务发展过程中出现的业务问题，对接产品及业务，提供高效的数据支持；任职资格：1、计算机或相关专业本科以上学历，具有扎实的编程基础理论知识；2、熟悉数据仓库建设理论，并有相关实践经验；3、精通SQL，熟练掌握MySql、Oracle、PostgreSQL等至少一种主流关系数据库；有复杂存储过程和sql优化能力的优先；4、具备良好的coding素养和习惯，熟悉Java/Python/Shell中的一种或多种；5、熟悉hadoop及生态（hdfs、hbase、hive等），理解背后工作原理；了解其他常用技术（spark, impala, GreenPlum，presto, Elasticsearch等)；6、对元数据管理、数据质量管理有一定理解，能够保障数据标准及质量符合用户预期；7、具备良好的团队协作精神，良好的沟通能力。","移动互联网,房产家居",2000人以上,spark,上海
大数据平台研发工程师,https://www.lagou.com/jobs/7102669.html,浦东新区,15k-25k,上海引旅金融信息服务有限公司,3-5年,本科,"领导好,办公环境好,活动丰富","岗位职责：1、负责数据平台产品设计、研发。2、负责整体平台功能测试。3、负责维护数据平台稳定性。4、负责协助数据产品完成其它数据需求研发。任职要求：1、3年以上前java工作经验;2、扎实的java编程基础，熟悉SpringBoot等框架，熟悉Java内存模型、多线程、NIO、类加载等, 有Python编程基础。3、熟悉Linux、数据库、NoSQL、分布式存储。4、有Hadoop、Spark、Flink使用经验者优先，有大数据产品研发经验的优先。5、能够独立完成平台功能设计与功能开发。6、有良好的沟通能力。良好的代码规范，与代码管理能力。","移动互联网,金融",150-500人,spark,上海
研发工程师,https://www.lagou.com/jobs/6951024.html,长宁区,15k-22k,上海氪信信息技术有限公司,1-3年,本科,AI金融 业务落地 15天带薪年假,"【岗位职责】1、 参与大数据处理、流数据、图数据处理等工作；2、 开发与维护数据展示、监控与报表系统；3、 基于kubernetes构建大规模机器学习系统；4、 大规模图分析和挖掘算法的计算引擎的设计和开发。 【岗位要求】1、全日制985学校本科或以上学历；2、有扎实的编程功底，至少熟练掌握python, go, java中的一种，熟悉Linux系统； 3、熟练掌握常用数据库技术的应用开发，熟悉 Hive及MySQL 数据库，熟练使用SQL；4、熟悉docker, kubernetes等容器技术，对构建云原生的大数据应用有一定了解；5、熟悉大数据实时处理技术例如spark streaming, flink等，对相应的应用开发有一定了解；6、善于学习和思考，能独立分析和解决问题，具有强责任心。 优先条件 :1、 有大规模数据处理或系统设计开发经验者优先2、 分布式、高并发、高可用性系统设计开发经验者优先；2、对互联网典型机器学习系统实现有深入了解及设计开发经验者优先。",人工智能,50-150人,spark,上海
机器学习系统开发工程师,https://www.lagou.com/jobs/6795674.html,长宁区,18k-30k,上海氪信信息技术有限公司,3-5年,本科,AI金融 业务落地 15天带薪年假,"【岗位职责】1、基于kubernetes构建大规模机器学习系统；2、建立并完善基于图计算的实时反欺诈引擎 ；3、对已有机器学习模型部署系统持续优化。【岗位要求】1、全日制985学校本科或以上学历；2、有扎实的编程功底，至少熟练掌握python, go, java中的一种; 3、熟练掌握常用数据库技术的应用开发，对使用mysql数据库构建高并发、高可用系统有较强的设计能力与实战经验，熟悉常见的性能调优与可扩展性设计，熟悉事务、锁、并发等机制；掌握分布式缓存、消息队列的使用；4、熟悉docker, kubenetes等容器解决方案，对构建云原生的大数据应用有一定了解；5、熟悉大数据实时处理系统如spark streaming, flink等，对基于这些系统构建实时应用有一定了解；6、具备良好的团队合作精神和承压能力，执行力和战斗力强，善于学习和思考，能独立分析和解决问题。优先条件 :1、有大规模分布式、高并发、高可用性系统设计开发经验者优先。2、对推荐系统或互联网广告系统等典型机器学习系统实现有深入了解及设计开发经验者优先。",人工智能,50-150人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6740049.html,黄浦区,25k-35k,百联全渠道电子商务有限公司,5-10年,本科,绩效奖金、 带薪年假、午餐补助、岗位晋升,岗位职责：1、优化现有大数据集群的架构和性能；保证系统的安全、稳定、高效运行；2、负责大数据产品（如CDP等）的架构设计和开发，以及对外数据服务的开发工作；3、与产品经理、测试工程师等其他团队沟通合作，保证大数据产品研发工作的质量和进度；4、参与新技术的技术难题的攻关，带动团队年轻成员共同成长。 岗位要求：1、计算机、数学相关专业全日制本科以上学历；  2、至少5年以上大数据应用系统的开发和设计经验；有知名互联网公司、零售或电商行业工作经验优先；3、熟悉Hadoop，熟练掌握ElasticSearch、HBase、Hive、Flume、Kafka、Flink等大数据技术；4、熟悉实时计算引擎，具有丰富的Spark、Spark Streaming的开发经验；  5、精通Linux环境，精通Java/ Scala开发；具备分布式系统或数据库系统的理论基础，熟悉分布式计算系统的工作机制；   6、善于表达，思维活跃，性格开朗，责任感强。,"电商,消费生活",500-2000人,spark,上海
高级大数据开发工程师,https://www.lagou.com/jobs/3316937.html,青浦区,15k-30k,圆通速递有限公司,3-5年,本科,上市公司，前景好，氛围好，待遇好,"岗位职责：1、流式计算平台的整体架构设计；2、负责技术攻关和创新技术引用，开发具有数据分析、数据挖掘能力的创新型产品；3、负责提升基于Hbase数据存储集群的高可用性、高性能、高扩展特性；4、负责设计和建立基于Storm或Spark实时数据处理框架；5、研究Hadoop/Spark/Hbase/Hive等开源项目，对线上任务进行调优，并开发通用组件；6、维持实时大数据平台高效稳定。 任职要求：1、本科及以上，计算机、软件工程、统计学、数据挖掘、机器学习等相关专业，2年以上大数据架构经验；2、扎实的Java、Scala语言基础，对JVM运行机制有深入了解；熟悉Hadoop、Spark并有丰富的开发经验； 3、熟练使用java语言，并掌握spring、mybatis等开源J2EE框架。使用java、scala、python等开发语言中的一种，有python和scala实际使用经验更佳； 4、有hadoop和spark实际开发经验。了解大数据组件的使用限制和应用场景，如hdfs,yarn,hbase,hive,flume,kafka,zk,impala,kylin,kudu,ES,Storm、MongoDB等。5、熟悉mysql、ElasticSearch、Redis等关系型或NoSQL数据库，了解应用场景和使用限制。有实际调优经验者更佳。6、熟悉linux常用命令，有实际CDH或HDP或apache版本的hadoop部署经验者优先； 7、熟悉并行计算或者分布式计算，熟悉Spark框架,熟练掌握RDD，SQL, Streaming, MLLIB，SparkR编程；8、英文文档阅读无障碍、熟练掌握常用设计模式、熟练使用maven、git；9、有深入研究过Hadoop/Spark源码者优先；10、深入理解MapReduce工作原理，HDFS分布式文件系统架构；熟练掌握Hadoop/Hive/HBASE的运维和调优方法； 11、掌握或使用过Storm、Spark、flume、kafka等工具；",物流丨运输,2000人以上,spark,上海
算法工程师,https://www.lagou.com/jobs/5868416.html,青浦区,20k-30k,圆通速递有限公司,3-5年,本科,上市公司，大牛团队，大平台，机会多,任职要求：1.精通统计类、运筹学相关算法，并能应用到实际；2.精通python、R编程，熟练在spark大数据平台上编写、运行脚本；3.5个以上主导完成的算法预测类或者优化类模型建模，和数据产品；4.积极主动、认真踏实、有良好的沟通能力和团队合作精神，有责任心、抗压；5.有客户画像（ToB/ToC），客户评级等相关建模经验者优先；6.外向性格，沟通能力强,物流丨运输,2000人以上,spark,上海
搜索算法工程师,https://www.lagou.com/jobs/6475635.html,杨浦区,30k-60k,虎扑（上海）文化传播股份有限公司,3-5年,本科,发展空间广阔、晋升完善、地铁周边、大平台,搜索算法工程师工作职责1、负责电商业务中的搜索或推荐算法的研发2、利用算法优化搜索/推荐的排序效果，并提升线上指标技能要求1、至少两年或以上的深度学习算法工作经验，主要开发语言python2、具有搜索或推荐的CTR/CVR/LTR等模型开发经验，并在线上取得了较好的效果3、熟悉机器学习中常见的LR、GBDT、XGBOOT和聚类算法3、熟悉tensorflow、keras框架，并熟悉CNN、RNN、LSTM等常见算法4、至少熟练使用hive、spark、hbase等一种大数据工具，能独立完成数据的拉取5、优秀的数据处理能力，能独立完成对数据的优化6、能独立完成模型的训练、部署、上线并根据效果进行评估优化7、有持续自我学习的能力，热于研究不同领域的算法模型,"移动互联网,文娱丨内容",500-2000人,spark,上海
高级/资深JAVA开发-实时数据工程师（识货）,https://www.lagou.com/jobs/6732436.html,杨浦区,20k-40k,虎扑（上海）文化传播股份有限公司,3-5年,不限,发展空间广阔、晋升完善、地铁周边、大平台,岗位职责1. 独立完成中小型项目的系统分析、设计，核心功能的设计与代码模板编写，开发与维护系统核心模块；2. 技术难题攻关，持续提升核心系统在高并发、下的高处理性能，保证系统的安全、稳定、快速运行；职位要求1. 三年以上大规模分布式系统应用架构设计与研发经验，扎实的Java编程基础、数据结构和算法，熟悉掌握常用的Java类库及框架，如多线程、并发处理、I/O与网络通讯，Spring、Mybatis等;系统排障经验丰富，可以快速排查定位问题；至少对高并发、分布式、缓存、jvm 调优、序列化、微服务等一个或多个领域有过深入研究，并且有相关实践经验。2. 熟练MySQL应用开发，熟悉数据库原理和常用性能优化技术，熟悉常用中间件的原理、使用场景以及限制2. 具备良好的识别和设计通用框架及模块的能力，具备系统调优、性能调优等技能，对疑难技术问题具备较强的排查能力；3. 熟悉unix/linux操作系统，对常用命令运用娴熟，能够根据实际需要快速编写shell脚本；4. 对技术有激情，喜欢钻研，能快速接受和掌握新技术，有较强的独立、主动的学习能力，良好的沟通表达能力和团队协作能力；5. 熟悉常用的大数据组件，如Hadoop、Hive、ElasticSearch、Kafka、Storm、Spark、Flink等，有过大数据产品开发经验优先；,"移动互联网,文娱丨内容",500-2000人,spark,上海
数据开发工程师,https://www.lagou.com/jobs/7025727.html,静安区,40k-80k,上海知息科技有限公司,3-5年,本科,硅谷风 工程师文化 国际化 精英团队,"Who We AreSmartNews is a leading mobile app of news aggregation services. It analyzes millions of articles to deliver most engaging information with high quality in near-real time fashion to millions of users around the world. The data platform team plays a key role of accelerating the products/business developments by building a highly efficient and flexible data platform for analytical, operational and machine learning purposes. The team mission is to create high-level, easy-to-use data services for simplifying access, integration and consolidation of various data sets, and also to build efficient platforms for executing data pipelines of massive scales of TB per day..ResponsibilitiesDesign and build highly efficient, scalable and secured data platforms as the foundation that can power data driven applications in the domains of data-analytics and AI across the companyDesign and build consolidated and integrated high-level data services to help application-developers and data scientists to leverage data for innovations and decision makingDrive architectural decisions and implementation of Data Platform teamLead cross team/cross functional discussions and drive alignment on technology strategyAble to effectively resolve conflict while navigating complex decisionsDefine the bar for data quality and processing efficiency of data platform/services while balancing business impact, operational overhead and cost benefits of design and architectural choicesLead by example to build a culture of engineering excellence and innovationMinimum QualificationsOver 4 years of experience in highly scalable backend development with 2 years of relevant experiences in data platform/servicesAble to distill complex problems and drive toward creative solutions. Able to have deep end-to-end understanding of sophisticated distributed systems/data pipelines and can proactively detect problems and make/implement improvement suggestionsCan solve challenging engineering problems systematically across different services/platformsCapable of designing high quality frameworks/toolings to reduce redundancy and ineffectiveness across components/servicesAble to demonstrate strong leadership and set as an example at team level for engineering excellenceAble to thrive in a dynamic environment where goals and requirements may be changingStrong coding skills in Java, C++ or PythonExperience with open source data platforms including Hive/Flink/Spark, etcExperience with highly scalable data platform/service (>TB/day level)Preferred QualificationsExperience with open source data platforms including Hive/Flink/Spark, etcExperience with highly scalable data platform/service (>TB/day level)","电商,人工智能",150-500人,spark,上海
大数据平台经理,https://www.lagou.com/jobs/7025796.html,静安区,50k-100k,上海知息科技有限公司,5-10年,硕士,硅谷风 工程师文化 国际化 精英团队,"Who We Are：SmartNews is a leading mobile app of news aggregation services. It analyzes millions of articles to deliver most engaging information with high quality in near-real time fashion to millions of users around the world. Our Data Platform is crucial for achieving SmartNew’s vision of delivering high quality content through personalized discovery. The organization’s missions are the following:Build highly efficient, scalable and secured data platforms as the foundation that can power data driven applications in the domains of data-analytics and AI across the companyBuild consolidated and integrated high-level data services to help application-developers and data scientists to leverage data for innovations and decision makingProvide solutions for efficient data sets management and improving data quality for the core operations across companyResponsibilityDirector/Senior Manager of Data Platform is expected to build and lead a strong engineering team to accomplish the above mission:Drive the overarching data platform vision, strategy and execution planManage multiple teams of software engineers and data engineers to build a leading data platform in dimensions of volume, variety and velocityCollaborate with key stakeholders and partners to understand business needs and deliver data-driven solutions and toolings to drive business resultsEstablish and champion a data-driven culture, fostering the use of data for recommendation technologies as well as informing and making key business decisionsRequirementsGenerally 7+ years of experience in software engineering, and 5+ years in data driven platforms, and 5+ years in leading technical teamsGenerally 7+ years of experience in software engineering, and 5+ years in data driven platforms, and 5+ years in leading technical teamsExperienced with big data technologies (e.g. Spark/Flink/Hadoop/Pig, etc…), data integration, data modeling, data visualization and enjoy solving the challenges presented by processing data at big scaleExperienced working with data from various business functions, at different levels of scale, within various architectures & data modelsStrong software engineering and data modeling experience in delivering data engineering solutions for the businessAble to build a strong team through hiring, as well as mentoring/growing engineers by constantly challenging them with solid supportBachelor’s degree in Computer Science or related fieldsGenerally 7+ years of experience in software engineering, and 5+ years in data driven platforms, and 5+ years in leading technical teamsExperienced with big data technologies (e.g. Spark/Flink/Hadoop/Pig, etc…), data integration, data modeling, data visualization and enjoy solving the challenges presented by processing data at big scaleExperienced working with data from various business functions, at different levels of scale, within various architectures & data modelsStrong software engineering and data modeling experience in delivering data engineering solutions for the businessAble to build a strong team through hiring, as well as mentoring/growing engineers by constantly challenging them with solid supportBachelor’s degree in Computer Science or related fields","电商,人工智能",150-500人,spark,上海
数据建模工程师,https://www.lagou.com/jobs/6624040.html,闵行区,15k-30k,万翼科技有限公司,3-5年,本科,"世界五百强,互联网变革,发展空间大",岗位职责：1、负责建设大数据平台数据仓库，包括数据模型设计、数据仓库表研发和测试；2、与业务人员梳理数据字典，建立完善的元数据管理规范，负责数据质量监控设计；3、参与优化数据管理系统，数据流管理（血缘分析）、任务管理、数据管理、OLAP等系统的设计和开发。4、基于对数据的理解和业务需求，对数据进行整理、分析和挖掘。岗位要求：1、计算机相关专业本科及以上学历，有2年以上数据仓库、ETL、数据仓库建模工作经验；2、熟悉Linux环境，熟练运用SQL、Shell等相关技术，了解Java/Python服务端系统开发；3、掌握BI工具或Hadoop/Spark/Hive/Kylin/Superset等大数据技术者优先；4、有海量数据处理、任务调度优化等经验者优先；5、逻辑清晰、对数据敏感，良好的沟通能力和协作能力，敢于接受挑战，能够承受压力。,房产家居,2000人以上,spark,上海
Python大数据开发实习生（2021春招）,https://www.lagou.com/jobs/6849245.html,闵行区,6k-8k,上海莉莉丝科技股份有限公司,应届毕业生,本科,"发展空间大,工作氛围好",岗位职责:1、 负责广告数据/投放系统的功能组件研发2、 负责部分广告数据的分析、清洗等工作3、 负责部分广告投放平台接口对接4、 负责与前端以及产品端协作，共同推进项目研发任职资格:1、计算机相关专业本科及以上学历2、熟悉数据结构与算法，基础扎实3、熟悉python flask、django等web至少一种框架4、熟悉至少一种数据库系统，如mysql、postgresql5、熟悉linux操作系统管理，熟练编写脚本6、具备对工作的正向态度、责任心，有较强的学习、沟通与协作能力，能承受一定的工作压力加分项：1、较强的学习理解和沟通能力，有自己的 作品 / 博客 / github 等2、熟练使用 Git3、熟悉hadoop/spark等分布式系统,"移动互联网,游戏",500-2000人,spark,上海
资深大数据开发工程师,https://www.lagou.com/jobs/6607837.html,浦东新区,25k-45k,艾欧史密斯（中国）热水器有限公司,不限,本科,薪资高 六险一金 免费零食健身 云存储,"【岗位职责】负责数据集群统一的资源分配和管理；负责大数据实时检索分析平台的开发、建设和优化；基于业务场景，推进批处理、实时流计算框架的研发优化；跟踪开源大数据框架、新算法框架的技术选型及平台化预研及架构。【任职要求】5年以上大数据系统开发，设计，架构经验；精通Java/Scala/Golang中至少一门语言；熟悉大数据相关技术：Hadoop,Hive,HBase,ZooKeeper,Spark,ELK,Kafka，并阅读过相关源码；管理过数据量上T级别，大规模数据集群，开发，优化并管理过上T级别的大数据作业；有机器学习、统计学背景的优先。",其他,2000人以上,spark,上海
研发专家（AI算法开发方向）,https://www.lagou.com/jobs/7145946.html,浦东新区,40k-70k,艾欧史密斯（中国）热水器有限公司,5-10年,本科,薪资高 全额五险一金 国企,职责描述：1、负责人工智能相关产品与项目的技术架构、算法的设计、部署和优化；2、关注研究图像处理、NLP、语音识别等人工智能技术，与产品团队协作，探索在智慧园区、智能工厂、智慧城市、智慧交通、智能监控等行业的应用机会并利用技术实现落地；3、辅导团队成员高效完成任务目标。工作要求任职要求：1、全日制统招本科及以上学历，八年以上软件研发类经验，至少两年以上图像识别、语音识别、自然语言处理、数据挖掘等相关算法经验，有机器学习相关经验优先，有人工智能相关产品研发经验优先；2、熟悉机器学习常用算法及深度学习、强化学习等相关领域知识，理解并熟悉常用深度学习网络结构，如ResNet、Inception-ResNet、PyramidNet、 MobileNet等；至少能熟练使用Tensorflow、PyTorch、Paddle、Caffe、MXNet、Theano等深度学习框架中的一种；3、有图像识别、视频分析、问答系统、知识图谱等相关算法研发上线经验优先；4、对云计算、边缘计算、CDN、 Spark、 Hadoop等技术栈有了解的优先，有智慧园区、智能工厂、智慧交通、智能监控等相关项目研发经验优先；5、诚实守信、作风踏实严谨、责任心强；具备良好团队协作能力精神；学习能力强，善于解决复杂问题；6、40周岁（含）以下，身心健康；7、过往工作业绩优秀者、有知名互联网/IT、AI、云服务等相关行业头部企业有工作经验者，年龄、工作年限可适当放宽。,其他,2000人以上,spark,上海
高级大数据测试开发工程师,https://www.lagou.com/jobs/7150416.html,浦东新区,18k-30k,上海擎创信息技术有限公司,5-10年,本科,智能运维领域的领跑者,岗位职责：1，根据测试工作需求编写测试工具、编写测试用例；2，执行服务端和移动端的功能测试、接口测试、性能测试、自动化测试；3，与产品部门，开发部门工作紧密配合。致力于提高测试覆盖度以保证产品快速高质量上线；4，维护现有的自动化测试框架。任职要求：1、本科及以上学历，英语四级及以上，工作经验5-10年，计算机、通信、电子等相关专业，计算机专业优先；2、有较好的测试思维、主动性。熟悉测试流程，能够独立设计并执行测试用例，保证项目质量和进度；3、了解基本的运维知识和相关linux命令或WEB系统基本通信原理和浏览器基本相关知识；4、拥有一年的大数据性能测试经验；5、熟悉loadrunner、jmeter等性能测试工具；6、熟练掌握SQL语法，对Hadoop、spark、hive有实际经验者优先；7、有代码开发基础，会shell/python/scala/java等语言，做过自动化测试优先；8、有搜索、大数据、分布式系统等业务领域测试开发经验者优先。,"企业服务,数据服务",50-150人,spark,上海
数据开发,https://www.lagou.com/jobs/7209496.html,杨浦区,15k-20k,北京新才教育科技有限公司,3-5年,本科,五险一金，双休,"1. 本科及以上学历，计算机、数学相关专业，3年以上开发工作经验；2. 在搜索系统、推荐系统或广告等方向有3年以上算法研发经验，有排序或召回等实际项目经验；3. 有 Hadoop / Spark 等大规模分布式计算使用经验；4. 熟悉 Linux 开发环境，熟练使用 Python / Scala / Java等语言；有扎实的编程基础和工程实践；5. 善于思考和学习，对有挑战性的问题充满激情，具有良好的团队合作精神和较强的沟通能力以及执行力必须具备技能要求：
 在搜索系统、推荐系统或广告等方向有3年以上算法研发经验，有排序或召回等实际项目经验；
 有 Hadoop / Spark 等大规模分布式计算使用经验；","软件开发,物联网",50-150人,spark,上海
【腾讯_上海_优图】测试工程师等,https://www.lagou.com/jobs/6352292.html,徐汇区,10k-20k,腾讯科技（上海）有限公司,不限,本科,"福利好,待遇高,升职空间大","1）.优图AI后台测试工程师岗位职责:1.负责后台服务全流程测试，包括需求分析、设计评审，制定测试计划，设计和执行测试用例，进行缺陷跟踪和软件质量分析等；积极关注线上运营质量，和监控指标，积极响应用户反馈；2.保证被测系统的质量，并通过测试流程和方法创新，努力提升测试质量和方法效率；岗位要求:1.计算机或相关专业，熟悉HTTP协议和互联网应用的工作原理，4年以上工作经验；2.有良好的编程能力（熟悉Python /Shell等脚本编程语言，熟悉C++高级编程语言）； 3.具备扎实的后台测试经验，能够通过接口测试/性能分析等手段，对后台服务进行高效分析，快速发现并准确定位问题，保证上线质量；4.有性能测试、协议测试或白盒测试经验优先； 5.对技术有浓厚兴趣，乐于构建工具或对工具做改造（Hack精神）。6.具有强烈的责任感，良好的沟通和表达能力，优秀的抗压能力；2）.优图大数据后台开发工程师岗位职责： 1.负责支持各类AI数据的接入、清洗、存储管理、计算处理2.参与部门数据存储应用平台的研发，支撑部门各个业务场景对数据使用的需求岗位要求： 1.精通c++/go/java/python中一门以上编程语言，有良好的代码规范，熟悉git；2.掌握Linux操作系统原理，有使用及参与开源项目的经验更佳；3.熟练掌握TCP/IP协议，进程间通讯编程，熟悉Linux下常用架构设计方法；4.熟悉Mysql等数据库运用、管理以及开发；5.对hadoop/spark大数据技术栈有基础，熟悉大数据平台或有相关开发经验优先；6.具备良好的团队合作精神，善于协调沟通，具备较强的问题推动及解决能力；7.具备不错的工作抗压能力，富有激情，责任心强，做事客观公正。3）.优图系统测试工程师岗位职责：1.负责图像相关算法SDK/后台服务的质量保证工作，包括用例设计、接口测试、性能测试、自动化测试等，输出算法核心技术指标；2.负责AI相关算法的效果及质量评测，能够针对AI落地的不同场景针对性设计效果评价指标，通过技术手段快速给到效果评价数据；3.负责测试相关工具的设计与开发，提升工作效率与效果。岗位要求：1.计算机/信息/软件工程相关专业本科以上学历；2.熟悉C/C++,熟悉脚本语言如python至少一种，能熟悉常用的数据结构、算法和设计模式；3.有机器学习/图像/AI算法与平台测试等技术背景者优先，或了解相关模型评价指标者优先；4.良好的沟通表达能力和团队协作能力，优秀的分析和解决问题能力，强烈的求知欲和上进心。",移动互联网,2000人以上,spark,上海
bi开发工程师,https://www.lagou.com/jobs/7217855.html,浦东新区,12k-18k,上海鑫炜网络科技有限公司,3-5年,本科,项目奖金 各种津贴 福利,岗位职责：1.负责数据仓库模型的需求分析、建模：运用BI工具，根据场景业务需求，生成相应的统计报表。2.维护线上报表，针对业务需求方提出问题，能快速定位并解决。岗位要求：1.本科及以上学历，3年以上经验，至少2年BI工作经验，最好有金融行业工作经验。2.熟悉掌握：Hive SQL、Oracle等主流数据库SQL开发、性能调优及存储过程开发。3.精通数据仓库架构及原理，能进行数据仓库数据模型设计、开发，熟悉ETL开发流程。4.精通COGNOS等主流BI工具，有CUBE多维报表的开发经验，有较强的报表UI设计思想。5.熟悉掌握Hadoop Spark HBASE大数据平台构建、使用。6.有银行业相关数据集成项目实施经验，了解一定的银行业务知识。7.有较强的学习和创新能力，具备较强的沟通和问题处理能力，工作态度积极，有数据可视化系统开发经验者优先。,数据服务 软件开发,15-50人,spark,上海
软件开发工程师,https://www.lagou.com/jobs/7162004.html,浦东新区,9k-15k,上海咪啰信息科技有限公司,1-3年,本科,"Java,大数据,港口,航运","岗位职责：1、参与核心业务系统的技术规划和业务规划工作，深入理解业务需求，抽象系统模型，进行系统设计及开发工作；2、在保障系统的稳定性，可维护性的基础上，快速响应业务需求；3、协助产品经理，完成所分配的各项工作任务；4、负责大数据平台和业务系统平台产品研发。5、跟踪新技术发展，并将其应用于产品中；6、指导其它技术人员解决业务及技术问题。任职要求：1、1年以上Java工作经验，具有良好的编程习惯；2、熟悉Spring Boot,  Spring Cloud,  Mybatis等主流开发框架；有过使用Spring Cloud实践开发经验；3、具有扎实的java功底，熟悉jvm、web开发、缓存、分布式架构、分布式事务、消息中间件等技术；有大并发开发经验，了解集群等常用技术；4、深入理解面向对象的编程，了解常见的设计模式，熟悉微服务的架构模式，熟悉敏捷开发的开发模式，熟练使用面向对象分析设计技术和工具，如UML等。5、熟练使用主流关系型数据库（例如：Oralce、MySQL、PostgreSQL），掌握关系型数据库管理常识，了解NoSQL数据库的使用；6、熟练Linux常用命令，熟练编写Shell脚本；7、了解DevOps相关知识，对Docker有一定了解者优先；8、了解大数据相关组件，如HDFS，MR，Spark, Impala，ES 等优先；9、熟悉K8s优先；10、具有创新思维，具有良好的沟通、团队协作、计划和主动性思考的能力；能够独立开展新产品、功能、模块的设计研发。","企业服务,数据服务",15-50人,spark,上海
JAVA高级工程师,https://www.lagou.com/jobs/5248481.html,浦东新区,12k-24k,上海咪啰信息科技有限公司,3-5年,本科,"Java,大数据,港口,航运","岗位职责：1、参与核心业务系统的技术规划和业务规划工作，深入理解业务需求，抽象系统模型，进行系统设计及开发工作；2、在保障系统的稳定性，可维护性的基础上，快速响应业务需求；3、协助产品经理，完成所分配的各项工作任务；4、负责大数据平台和业务系统平台产品研发。5、跟踪新技术发展，并将其应用于产品中；6、指导其它技术人员解决业务及技术问题。任职要求：1、3年以上Java工作经验，具有良好的编程习惯；2、熟悉Spring Boot,  Spring Cloud,  Mybatis等主流开发框架；有过使用Spring Cloud实践开发经验；3、具有扎实的java功底，熟悉jvm、web开发、缓存、分布式架构、分布式事务、消息中间件等技术；有大并发开发经验，了解集群等常用技术；4、深入理解面向对象的编程，了解常见的设计模式，熟悉微服务的架构模式，熟悉敏捷开发的开发模式，熟练使用面向对象分析设计技术和工具，如UML等。5、熟练使用主流关系型数据库（例如：Oralce、MySQL、PostgreSQL），掌握关系型数据库管理常识，了解NoSQL数据库的使用；6、熟练Linux常用命令，熟练编写Shell脚本；7、了解DevOps相关知识，对Docker有一定了解者优先；8、了解大数据相关组件，如HDFS，MR，Spark, Impala，ES 等优先；9、熟悉K8s优先；10、具有创新思维，具有良好的沟通、团队协作、计划和主动性思考的能力；能够独立开展新产品、功能、模块的设计研发。","企业服务,数据服务",15-50人,spark,上海
资深算法专家,https://www.lagou.com/jobs/7213285.html,杨浦区,40k-80k,上海册念电子技术有限公司,5-10年,硕士,五险一金 补充公积金,"具体职能面议职责描述：1. 负责分析和评估人工智能在特定业务场景下应用的需求和可行性；2. 负责运用人工智能算法，完成业务智能相关应用的研究、设计和实现；3. 支持数据技术团队完成业务智能应用相关的工程化；4. 负责国内外人工智能公共基础算法的跟踪、验证和原型开发；5. 支持数据技术团队完成新基础算法的工程化；6. 支持智能应用团队、数据产品团队对于核心算法的选择和应用。任职要求：1. 计算机、数学、统计学及相关专业全日制博士学历,应用数学或计算数学专业、模式识别专业、计算机专业优先；2. 熟悉人工智能相关的算法和理论,特别是神经网络、深度学习、增强学习及迁移学习等；3. 熟悉SAS,R, Python, Spark SQL, Spark ML等数据分析工具和语言；4. 熟悉软件工程领域知识;精通Java或C+开发者优先；5. 学习能力强,对业务需求的理解力强，可以对业务问题做出快速地判断和定位；6. 具有良好的计划组织能力，问题解决能力，沟通能力和知识传递能力；7. 博士论文的研究方向或工作经验与人工智能应用相关者优先。","电商,企业服务",50-150人,spark,上海
大数据开发实习生,https://www.lagou.com/jobs/7101046.html,闵行区,5k-7k,唯品会（中国）有限公司,应届毕业生,本科,"弹性工作,包三餐,大牛带队,转正机会","工作职责负责大数据平台及相关大数据组件的二次开发及维护工作，数仓开发和优化，保证平台各核心服务运行的稳定、高效。任职要求1.本科及以上学历，计算机和电子信息相关专业。2.大数据相关语言有一定基础：SQL，Java，Scala。3.理解大数据相关组件(Spark,Hive,Hadoop等)的优先考虑。4.阅读过相关大数据组件源码的优先考虑。5.熟练应用Linux常用命令，有过shell编程经验。",电商,2000人以上,spark,上海
web后端开发工程师,https://www.lagou.com/jobs/7206504.html,浦东新区,10k-20k,上海狮尾智能化科技有限公司,5-10年,大专,五险一金、13薪、年终奖、项目奖、季度奖,"Web后端开发工程师岗位要求：● 本科及以上学历，计算机、软件、通信、电子、等相关专业，1-3年工作经验● 熟悉JAVA开发，熟悉JVM、多线程、Socket编程、NIO等技术，有良好的编码习惯● 至少熟悉一种主流分布式开源技术，如RPC,Netty,Dubbo,MQ,Spring Cloud,Zookeeper,ES,Haoop,Spark等● 对redis，MySQL，Cassandra等的其中一种数据库有一定了解，有实际使用经验优先● 有后台系统设计和开发经验者优先，有物联网平台后端工作背景优先● 具有良好的沟通能力和团队合作能力；逻辑思维清晰，有责任心● Java后台开发经验，有政务、公安、应急、城管、社区、警务、大数据等行业开发经验者优先工作职责：● 设计、开发、维护无人机物联网云平台● 参与业务需求讨论，完成相应的方案设计和接口设计● 设计与开发新系统、新特性，进行各版本迭代，支撑无人机IoT业务的不断发展● 性能优化设计，熟悉视频后端处理，支持系统性能的水平扩展● 负责Web后端全过程开发，具有后端开发能力● 云平台日常运营和维护，分析并快速解决线上问题",移动互联网,少于15人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6942609.html,闵行区,17k-22k,弘衍信息科技（上海）有限公司,1-3年,本科,作五休二，项目前景好,职位描述：1、基于业务需求，持续进行数据模型和算法的分析优化2、应用机器学习等方法，从海量客户数据中挖掘潜在的规律与关系3、建立和完善分析体系，跟踪模型的实施，优化算法和分析策略，提供建设性建议4、推进推荐、数据挖掘、机器学习技术在行业数据的应用 岗位要求：1、数学、统计、计算机等相关理科专业，全日制本科及以上学历； 2、二年以上海量数据下数据挖掘和算法实施相关工作经验；3、熟练运用python或者spark、SAS进行数据建模，熟悉hiv、hadoop大数据处理技术的优先考虑；4、有教育领域经验的优先考虑,"教育,企业服务",15-50人,spark,上海
Data Analyst,https://www.lagou.com/jobs/6751322.html,静安区,30k-55k,易得碧计算机技术（上海）有限公司,3-5年,本科,扁平化管理,工作职责：负责交付高级分析，报告和BI应用程序提供数据洞察力，以推动有关营销活动，产品运营等方面的日常数据知情决策。支持和管理业务部门的数据请求–可以了解业务变更需求并评估这些变更的影响工作可能会因项目而异 基本资格：3年以上工作经验；定量或工程学士学位及以上学历，并具有相关领域的专业工作经验较强的分析思维和沟通能力熟悉使用常见分析工具（例如SQL，R和Python）具有DW/BI的经验，对数据仓库和维度建模有很好的了解至少具有一种数据可视化工具（Tableau，Qlik，PowerBI等）的丰富经验熟悉大数据技术（Hadoop，Redshift，Spark，Presto）与跨职能团队合作以收集需求和设定工作优先级的能力方面的经验良好的业务意识和逻辑思维。能够综合信息和概括模式优先任职资格：金融交易和衍生产品分析方面的经验,"金融,软件开发",150-500人,spark,上海
大数据平台技术专家,https://www.lagou.com/jobs/6845358.html,静安区,40k-60k,易得碧计算机技术（上海）有限公司,5-10年,本科,扁平化管理,"岗位职责:打造业界领先的通用数据平台，包括实时数据流、数据仓库、调度系统、查询引擎，用户行为分析，abtest 实验系统等，降低数据的使用门槛，实现数据的最大价值打造业界领先的存储、计算等分布式系统，为海量数据和大规模业务系统提供可靠的基础设施负责大数据平台的架构设计和实现，保证平台的稳定、高效运行；针对不同业务场景使用合适的大数据技术和开源产品；及时定位和排除大数据平台各类故障和潜在风险；研究前沿技术，对性能、可用性、扩展性等方面进行深度优化。任职资格:具有5年以上大数据平台的设计和开发经验；熟悉大数据流水线架构，包括批处理ETL和实时流数据处理，任务调度系统等；熟悉大数据平台各个技术组件，有深入调优和故障诊断经验，包括Hadoop, Hive, Spark, Spark Streaming, Presto, Hbase, Elastic Search, Kafka, Zookeeper, Redis, Airflow等；主导过大数据平台产品的设计与实施，包括数据中台、数据仓库、查询分析平台、实时流应用、用户画像、推荐系统、交易系统风控等，有PB级数据处理经验；精通Scala、Python等大数据相关语言，精通SQL；精通Spark原理、调优和Spark Streaming开发、调优经验者优先；良好的分析能力和团队协作能力，积极主动，乐于接受挑战和持续学习，能应对突发应急情况。","金融,软件开发",150-500人,spark,上海
大数据资深开发,https://www.lagou.com/jobs/7166625.html,闵行区,60k-70k,天寶集團控股有限公司,5-10年,本科,知名企业 持牌公司 全牌照,"本科及以上学历，具备扎实的数学和计算机编程功底；8年以上工作经验，5年以上大数据相关工作经历；
 严密的数据思维，优秀的问题分析能力，热衷技术创新；
 掌握Hadoop，HBase，Hive或Spark等主要大数据技术；具有用户画像及用户管理相关领域大数据开发经验者优先；
 优秀的建模能力，在模型特征提取，模型建立/评估/部署/监控上具有丰富的实践经验；
 具有丰富的大数据商业实战经验，具备企业大数据处理业务场景分析、解决方案实施，综合技术应用经验；具有金融行业大数据相关工作经历者优先；
 具有良好的学习和研发能力，针对大数据技术与应用场景相融合，推动应用研发落地、技术支持与创新；
 有互金公司大数据/风控/模型开发经验优先。","移动互联网,社交",2000人以上,spark,上海
推荐算法工程师,https://www.lagou.com/jobs/7216592.html,杨浦区,16k-25k,西安鼎力信息技术有限责任公司,3-5年,本科,五险一金,1. 本科及以上学历，计算机、数学相关专业，3年以上开发工作经验；2. 在搜索系统、推荐系统或广告等方向有3年以上算法研发经验，有排序或召回等实际项目经验；3. 有 Hadoop / Spark 等大规模分布式计算使用经验；4. 熟悉 Linux 开发环境，熟练使用 Python / Scala / Java等语言；有扎实的编程基础和工程实践；5. 善于思考和学习，对有挑战性的问题充满激情，具有良好的团队合作精神和较强的沟通能力以及执行力岗位职责：1. 负责基于大数据个性化推荐的开发和优化;2. 负责模型调优和实际业务场景中的落地工作;3. 应用机器学习等技术，为用户提供推荐和排序，提升推荐效果，改进用户体验。,"企业服务,其他",50-150人,spark,上海
NLP自然语言工程师,https://www.lagou.com/jobs/6988704.html,浦东新区,25k-30k,尤盛信息技术（上海）有限公司,3-5年,本科,海外旅游、公司氛围好,工作职责：1.应用NLP技术分析处理海量用户文本数据2.对资讯内容的特征提取、语义理解、详情提取、摘要提取等算法研究及实现3.构建机器学习模型区分用户行为，进行个性化推荐任职要求：计算机或相关专业，具有一年以上自然语言处理相关的工作经验熟悉python、golang及相关机器学习工具熟悉常见sql/nosql数据库，以及全文检索技术精通统计语言模型和相关机器学习核心算法熟练掌握自然语言处理的算法和技术，具有分词、新词发现、实体词抽取、文本分类、舆情分析等相关的项目经验熟悉hadoop、spark等分布式平台,游戏,15-50人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7216190.html,浦东新区,15k-20k,天津所托瑞安汽车科技有限公司,3-5年,本科,全额五险一金，周末双休，午餐补助，年终奖,岗位职责：1、 精通常见数仓（维度建模，范式建模）建模理论，并有数仓实际设计开发经验2、负责数据平台数仓的设计、规划、建设、实施、管理，包括离线、实时的数据架构、数据模型规划、数据质量保障；3、深入理解数据业务，分析用户需求，负责数据平台核心数据资产内容的设计与开发工作，实现高质量数据的互通与共享；4、数据仓库模型的ETL实施，ETL性能优化，主导技术难题攻关；5、针对数据一致性、准确性、及时性，制定数据管理与治理机制，监督保障数据的生产与运维任职要求：1.从事大数据开发或挖掘领域至少3年以上，熟悉数据仓库模型设计与ETL开发经验，掌握维度建模设计方法，具备海量数据处理经验；2.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发工具与方法、数据质量、主数据管理；3.熟悉数据库技术，熟练运用SQL及其他语言，能高效的与业务团队进行沟通；4.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop 、Hive 、Spark 、Flink 、Storm、Kafka等大数据生态系统5.对常规统计与机器学习问题具有一定的理解，熟悉常用的模型，有数据挖掘相关工作经验者优先；6.熟悉Linux系统，掌握一门或多门编程语言，如Java、Python、Shell；7.有线上大数据开发经验,"硬件,移动互联网",50-150人,spark,上海
开发DBA工程师,https://www.lagou.com/jobs/7200283.html,杨浦区,20k-40k,信熠宏能源科技（上海）有限公司,5-10年,本科,自动驾驶,工作职责                                         1．架构搭建：负责数据库系统架构的设计和实施，参与项目中的数据库逻辑结构设计，参与大数据平台的架构设计；                                         2．方案设计：基于产品需求说明书，设计审核并创建数据库存储结构、数据库对3．程序开发：根据业务需求批量更新数据；开发和维护数据库定时任务；使用spark SQl等技术，开发数据分析功能；                                         4．产品运维：监控并及时发现TOP SQL，通过优化索引结构提高性能或给研发人员提出优化建议；                                   5．技术支持：为企业信息化和其他内部相关业务提供相关技术支持。 任职资格                                         1．工作经验： 5年以上工作经验；有物联网、移动互联网等高并发场景、从0到1大型平台开发工作经历；                                    2．学历要求：本科以上，优选本科985或211院校（不含专升本）                      3．知识技能： 精通Mysql 数据库，3年以上大型数据库开发经验，2年数据库架构设计经验；熟悉常用Redis、mongodb等No Sql数据库，能根据具体应用设计完成数据库建模；熟悉Hadoop/Spark/Flink等大数据框架；熟悉常用的数据库优化方法，有具体的项目优化经验；熟悉公有云数据库产品和技术；熟悉高性能、分部式系统设计，有相关的设计经验，有大型计算集群的基础设施开发维护经验者优先；熟练掌握Python、java、shell等语言中的一项以上者优先。                                         4．语言能力：可使用英语进行日常沟通交流，读写能力强；                                       5．素质要求：踏实稳重，责任心强，良好的沟通协作能力。,"信息安全,软件开发",500-2000人,spark,上海
Java工程师（大数据方向）,https://www.lagou.com/jobs/7164157.html,浦东新区,20k-30k,上海引旅金融信息服务有限公司,3-5年,本科,"领导好,办公环境好,活动丰富","岗位职责：1、负责数据平台产品设计、研发。2、负责整体平台功能测试。3、负责维护数据平台稳定性。4、负责协助数据产品完成其它数据需求研发。任职要求：1、3年以上前java工作经验;2、扎实的java编程基础，熟悉SpringBoot等框架，熟悉Java内存模型、多线程、NIO、类加载等, 有Python编程基础。3、熟悉Linux、数据库、NoSQL、分布式存储。4、有Hadoop、Spark、Flink使用经验者优先，有大数据产品研发经验的优先。5、能够独立完成平台功能设计与功能开发。6、有良好的沟通能力。良好的代码规范，与代码管理能力。","移动互联网,金融",150-500人,spark,上海
数据开发,https://www.lagou.com/jobs/7190620.html,黄浦区,26k-40k,上海聚勉网络科技有限公司,5-10年,本科,发展前景,工作职责1、全面深入理解公司各类现有数据，洞察现有数据体系与客户业务匹配中的待优化点，并不断改善；2、负责建设并完善数据管理体系，涵盖数据生命周期的标准、模型、质量和数据存取全流程；3、负责数据仓库的设计、开发、维护，有效管理整合各类数据；4、负责基于公司大数据平台进行开发，并对数据进行优化处理，支撑业务需求；5、负责公司及行业数据技术标准制定和落地。工作要求1、全日制本科及以上学历，计算机、数学相关专业；有3年以上数据领域相关工作经验；2、熟悉数据仓库方法论、理解维度建模，有ETL相关开发工作经验，能够牵头完成数据管理相关工作；3、有分布式平台相关开发经验，如Hadoop、Spark、Storm等；4、具有强烈的求知欲，有较强的沟通和组织协调能力，具备良好的文档编写能力；5、有数据服务公司技术管理背景或相关数据平台开发工作经验，熟悉证券行业数据治理者优先。,电商、通讯电子,500-2000人,spark,上海
大数据产品经理,https://www.lagou.com/jobs/7215635.html,闵行区,17k-27k,上海慧士嘉信息技术有限公司,3-5年,本科,工业互联网新创平台，良好的上升空间,职位描述：1、主导数据平台、数据标准&治理、数据加工等功能的规划、界面设计工作；2、组织和推动产品团队和业务团队，将平台产生的大量数据进行整合利用，主动创造数据价值；3、协调产品团队和开发团队，快速完成解决方案产品化工作，梳理提供PRD、产品架构图、需求列表、开发计划、技术白皮书、用户手册等文档 。岗位要求：1、 计算机专业本科以上学历，3年以上术类产品经理工作经验；2、 有产品设计和数据分析经验，能够独立承担产品规划工作；3、 具备产品原型设计能力，熟练掌握AXure RP原型设计工具；4、 良好的逻辑能力和沟通能力，具有很强的问题分析和解决能力，对工作充满激情；5、 熟悉Hadoop、Hive、Spark、Mahout等技术。有大数据研发经验者优先；6、 有大数据平台、数据治理、数据加工等产品设计经验者优先；,"数据服务,企业服务",50-150人,spark,上海
机器学习平台研发工程师,https://www.lagou.com/jobs/7129857.html,徐汇区,25k-40k,上海一条网络科技有限公司,3-5年,本科,调性佳 平台佳 技术大牛,"岗位职责:1. 负责算法实验平台研发，为搜索/推荐/广告等服务中用的模型和数据提供平台支持。2. 优化算法模型上线流程，实现实验平台和模型上线的无缝对接。3. 对各业务线模型用到的特征的构建和管理方案进行优化 岗位要求:1. 熟悉Java/Scala/C++中⾄少⼀门编程语⾔，具有良好的工程能力与编码习惯;2. 熟悉spark、hadoop、tensorflow、flink等常用计算框架，并对其原理具有一定深入的了解。3. 良好的团队合作和分享精神，较强的沟通能力以及抗压能力;4. 在机器学习、深度学习、分布式机器学习以及在搜索、广告、推荐、机器翻译等领域有经验者优先；5. 熟悉常用分布式计算架构，如alreduce, parameter server等。",电商,150-500人,spark,上海
实时大数据开发,https://www.lagou.com/jobs/7002598.html,徐汇区,25k-30k,上海一条网络科技有限公司,3-5年,本科,平台佳 技术大咖,岗位职责：1、负责大数据平台的规划设计，负责spark、flink、hadoop集群的开发、调优、监控；2、负责数据基础架构和数据处理体系（实时和离线）的升级和优化，不断提升系统的稳定性和效率；3、挖掘数据层面的业务价值，开发实现数据相关报表，推动产品、业务优化改进任职要求：1、本科以上学历，计算机或相关专业，2年以上大数据平台工作经验；2、熟练掌握Java或Scala开发；3、熟悉Hadoop平台相关技术原理（Spark、Flink、Kafka、HDFS、Yarn、Hive、Mapreduce等）；4、了解Linux操作系统及常用命令，具备基本的系统运维经验；5、具备线上Hadoop集群运维经验者优先；6、有vertica数据库使用经验，优先考虑7、具备数据仓库领域知识和技能者优先，包括但不局限于：数据建模、元数据管理、数据开发测试工具与方法、数据质量管理；8、具有快速定位问题的能力和较强的学习能力；9、能自我驱动，有较强的沟通能力及团队合作精神，强烈的责任感及进取精神,电商,150-500人,spark,上海
大数据架构师,https://www.lagou.com/jobs/7209828.html,杨浦区,30k-60k,上海册念电子技术有限公司,3-5年,本科,五险一金 补充公积金,"1. 负责大数据项目整体架构规划，包括应用架构、技术架构、物理架构和数据架构等；2. 负责指导工程师进行技术验证与实现，核心技术问题的攻关，解决项目开发过程中的技术难题；3. 根据项目业务需求，设计架构方案，撰写核心代码，并为系统提供性能调优、架构优化重组，解决关键问题和技术难题；4. 根据公司项目和业务发展特点，负责研究相关大数据前沿技术；5. 负责项目对外技术沟通，负责营造团队技术氛围，推动技术能力的沉淀；6. 持续挑战新的技术方向，攻克大数据量，高并发，高稳定性，易用性等各种技术难点。要求：1. 全日制本科以上学历，8年以上工作经验，其中5年以上大数据相关经验；2. 有丰富的大数据及服务端项目研发和架构经验；3. 精通Java、scala等主流编程语言，熟悉JVM原理及调优；4. 精通Hadoop生态及高性能缓存相关的各种工具并有实战经验，包括但不限于hadoop/hive/spark/impala/elasticsearch/druid/redis/hbase/kafka/flume等，有Flink经验者更佳；5. 熟悉微服务(如SpringBoot)，熟悉开源服务框架(如Dubbo/Grpc)；6. 熟练使用Linux/Unix等操作系统,具备编写shell的能力；7. 有超PB级别大数据处理实战经验，熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖掘和数据可视化，以及架构设计、开发、部署、自动化运维等工作；8. 有优秀的业务理解能力，能理解清楚业务并进行合理的架构设计；9. 具有较强的沟通能力,工作态度积极主动、细致、有全局观，有较强的抗压能力，良好的团队合作意识。","电商,企业服务",50-150人,spark,上海
服务端开发工程师,https://www.lagou.com/jobs/6913999.html,浦东新区,15k-20k,上海大智慧股份有限公司,1-3年,大专,福利待遇、发展前景,"岗位职责：1.参与大智慧广告相关系统DSP、SSP、ADX等基础组件开发和设计工作；2.负责设计相关服务的api和文档编写；3.保证系统的效率和可靠性以及代码质量和可维护性；4.协调配合产品、测试、运维和其它开发人员；5.根据功能需求和设计方案进行开发，完成代码编写和调试工作。岗位要求：1.2年以上系统开发经验，大专以上学历；2.精通java/Go/nodejs语言至少其中一种；3.精通各种设计模式，具有面向对象的分析能力以及编码能力，精通HTTP协议，熟悉HTTP Client 等常用实现；4.熟悉常用算法和数据结构，有一定的系统架构设计经验；5.熟练使用Linux操作系统, 熟悉rpc调用；6.熟悉Redis、MongoDB、Memcache等nosql技术、熟悉beego、etcd、gRPC等第三方库；7.拥用良好的编码规范，有良好的文档编写能力与代码组织能力，熟悉Git；8.熟悉前端技术vue,大数据spark优先考虑。","移动互联网,金融",500-2000人,spark,上海
大数据测试工程师,https://www.lagou.com/jobs/6919125.html,浦东新区,10k-20k,上海大智慧股份有限公司,1-3年,大专,福利待遇、发展前景,"岗位职责：1、按照软件设计需求和开发文档编写合理有效的测试方案，测试计划，测试用例和测试报告。2、能按照测试用例严格执行测试，分析缺陷并跟踪解决。3、进行详细的功能测试和性能，异常，安全性测试。4、对大数据产品系统进行测试。5、对数据进行分析和挖掘。6、保障产品质量。任职条件：1、大专以上计算机相关专业，2年以上测试工作经验。2、具备清晰的逻辑思维能力，复杂的数据计算能力。3、熟悉数据仓库和数据建模的相关技术细节，有编程经验，熟悉JAVA语言；熟悉SQL/Hadoop/Hive/Hbase/Spark/oozie等大数据工具。4、具有海量数据处理经验，或有互联网行业数据挖掘工作经验者优先。5、熟悉常用数据库功能和集群配置操作（redis,mysql,mongo等）。6、具有股票期货知识人员优先考虑。","移动互联网,金融",500-2000人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7214671.html,杨浦区,16k-20k,北京新才教育科技有限公司,3-5年,不限,周末双休,岗位职责：1. 负责基于大数据个性化推荐的开发和优化;2. 负责模型调优和实际业务场景中的落地工作;3. 应用机器学习等技术，为用户提供推荐和排序，提升推荐效果，改进用户体验。任职资格：1. 本科及以上学历，计算机、数学相关专业，3年以上开发工作经验；2. 在搜索系统、推荐系统或广告等方向有3年以上算法研发经验，有排序或召回等实际项目经验；3. 有 Hadoop / Spark 等大规模分布式计算使用经验；4. 熟悉 Linux 开发环境，熟练使用 Python / Scala / Java等语言；有扎实的编程基础和工程实践；5. 善于思考和学习，对有挑战性的问题充满激情，具有良好的团队合作精神和较强的沟通能力以及执行力,"软件开发,物联网",50-150人,spark,上海
java高级开发工程师,https://www.lagou.com/jobs/7212038.html,浦东新区,20k-30k,福建省瀚华投资有限公司,3-5年,本科,期权加现金激励,职位描述1.  根据业务需求，参与产品方案讨论与技术调研，给出解决方案；可独立完成技术可行性报告、概要设计、详细设计、并撰写相关文档；2.全面主持公司技术研发管理工作，负责组织公司核心技术产品的研究和攻关工作，指导并参与核心代码的书写，组织解决项目开发过程中的重大技术问题；岗位要求：1.3年以上Java语言编程经验，Java基础扎实，理解IO、多线程、集合等基础知识，对JVM原理有一定的了解2.熟悉Python/Shell等一种或多种脚本语言3.熟悉MySQL等数据库技术，对SQL优化有一定的经验4.有Java服务端开发经验，熟悉Spring、MyBatis等常用Java开源框架5.了解分布式系统的设计开发，有Hadoop、Storm、Spark、Pig、Sqoop、HBase、Hive、ZooKeeper、ElasticSearch等相关开发经验佳6.有以下经验者优先考虑：大并发、分布式队列、分布式任务分发框架、全文检索及分词技术、性能优化、海量数据存储与分布式存储技术7.能适应快速成长型技术团队的要求，具备自我管理能力和创业精神，能够承担一定的工作压力。,"房产家居,软件开发",500-2000人,spark,上海
大数据开发工程师(J10443),https://www.lagou.com/jobs/7028349.html,浦东新区,15k-25k,上海驻云信息科技有限公司,3-5年,本科,超多年假 年终奖 免费零食 做五休二,"工作职责:岗位职责：1、参与数据平台的构建工作,演进现有数据平台基础设施；2、参与数据相关的软件开发工作,迭代现有数据运营工具；3、负责或参与项目开发过程中的技术攻关和性能调优。任职资格:1、全日制统招本科及以上，计算机、通信工程等专业背景优先；2、2年以上的大数据开发经验，熟悉zeppelin flink spark等大数据中间件的使用和部署；3、熟悉虚拟化应用的部署与运维并有实际经验，如k8s/Docker等技术；4、熟练使用shell/python等脚本语言开发相关运维管理工具；5、有算法及数据结构基础者优先。","移动互联网,企业服务",150-500人,spark,上海
系统测试工程师（数据算法方向）,https://www.lagou.com/jobs/7179999.html,浦东新区,13k-18k,上海壹佰米网络科技有限公司,3-5年,本科,快速增长的公司，扩张的团队，发展前景,【工作职责】1、负责算法部销量预测和调拨算法各项输出的测试工作，参与大数据产品的测试；2、参与影响算法的上下游系统的需求分析和需求变更评审；3、分析测试需求，编写测试用例，搭建环境并执行测试；4、进行缺陷定位、跟踪管理和统计分析；5、配合研发进行调试，推动问题及时合理的解决及验证。【岗位要求】1、全日制本科或以上学历，计算机、数学或相关专业；2、至少3年软件测试工作经验，熟悉测试流程、方法和工具；3、掌握Python语言，熟练使用SQL，了解Golang、Java、Scala或Spark尤佳；4、懂大数据和算法基本知识，最好有具体的项目经验；5、具备良好的学习能力、问题分析和解决能力、沟通能力以及团队合作意识；6、工作责任心强，细致耐心有激情，能够胜任重复性工作，能够承受较大的工作压力；7、沟通能力、书面撰写能力好者优先。,消费生活,2000人以上,spark,上海
大数据架构师,https://www.lagou.com/jobs/6882260.html,浦东新区,30k-50k,上海小牛互娱智能科技有限公司,5-10年,不限,年底双薪 加班晚餐 免费打车,"工作职责1.主导数据ETL、数仓建设； 2.主导新业务和行业的数据商业化探索和数据价值挖掘; 3.负责海量数据采集、处理及存储、技术选型及架构实现；4.参与代码的实现，并带领团队追踪大数据和云计算技术的最新科技成果，并应用于内部业务实践。任职要求:1.本科及以上学历，五年以上相关行业经验；2.熟悉数据仓库产品，对数据处理、维度建模、数据分析等有深刻认识和实战经验;3.有较强的编程能力和编程经验,精通Java，熟悉Hadoop分布式计算框架（HDFS、Hbase、Hive、Mapreduce、Storm/Spark、Flink、kudu等)；4.具备较好沟通协调能力，主动建立与业务的紧密合作，推动业务升级；5.有商业变现，DMP数仓建设和维护经验的优化。",移动互联网,500-2000人,spark,上海
高级系统架构师,https://www.lagou.com/jobs/6901721.html,静安区,30k-40k,北京九章云极科技有限公司,5-10年,本科,AI行业，Geek氛围，大牛多，技术前沿,工作职责：1.负责大数据系统的架构方案设计和评审、性能调优、资源规划2.负责探索新的技术发展方向，发现并解决重大故障及性能瓶颈3.参与公司产品架构设计的支持，负责公司产品的落地集成架构设计4.核心架构搭建与核心编码开发或支持5.负责解决方案层面的技术深度支持6.负责对系统架构团队进行指导，实现团队能力的综合提升任职资格1.精通LINUX系统，熟悉shell编程，在操作系统、计算机网络和安全方面具备系统化的知识体系。2.具有3年以上系统架构经验和6年以上开发经验，至少熟悉一种编程语言（Python/Java/Scala等）。3.熟悉大数据技术（Hadoop、hive，hbase，yarn，spark等），有CDH/HDP等大数据集群的使用、运维和调优经验。4.熟悉容器化相关技术（docker等）5.熟练掌握软件设计工具（架构、流程）6.主动尝试和学习新的技术，并能够快速应用7.高度责任心和自驱力，良好的协作精神，优秀的表达沟通能力；8.良好的沟通能力、业务理解能力与写作能力。9.良好的英语读写能力。,数据服务,150-500人,spark,上海
大数据运维工程师,https://www.lagou.com/jobs/6901705.html,静安区,15k-20k,北京九章云极科技有限公司,3-5年,本科,AI行业，Geek氛围，大牛多，技术前沿,"岗位职责 1.负责公司产品的部署；2.负责大数据平台及生态圈相关组件的的搭建与运维；3.负责公司产品及系统的部署安装与配置；4.其他大数据运维相关任务；任职资格 1.熟悉Linux shell及SQL语言；2.熟悉常用编程语言，包括Python等；3.熟悉Hadoop,spark,mongo,hive,hbase等大数据组件运维；4.熟悉mysql,oracle,postgres,db2等传统数据库部署运维；5.熟悉数据仓库数据流监控、故障自动化定位及运维；6.了解云，虚拟化，容器等相关技术；7.强烈的责任心与求知欲，愿意学习新技术并能快速应用；8.有较强的书面与口头表达能力，独立分析和解决问题的能力；9.做事认真负责，自学能力强；10.能够接受出差；11.有开发基础者优先；12.有英语文档阅读能力者优先。",数据服务,150-500人,spark,上海
数据仓库工程师,https://www.lagou.com/jobs/6813276.html,杨浦区,20k-35k,达疆网络科技（上海）有限公司,3-5年,本科,平台稳定，团队快速发展,工作职责：1、参与数据仓库和大数据平台的环境搭建、架构设计和程序开发2、参与分布式结构化数据的数模设计3、负责离线和在线数据的采集、清洗和加载4、负责分布式批量计算、分布式内存计算、数据仓库类SQL查询统计等离线计算5、参与实时数据流的数据处理、查询统计和分析预测等在线计算6、基于公司业务，构建模型算法，发掘数据的价值7、满足公司各部门日常的数据需求 职位要求：1、本科及以上学历，计算机、软件工程或相关专业出身，工作2年以上，具有Hadoop、Spark、Flink开发与应用经验，熟悉Flume与Kafka等数据采集和消息通道技术，熟练掌握Hadoop、Hbase、Hive、Spark及Spark SQL等大数据技能，熟悉Spark Streaming/Flink等流计算技术2、有较好的Java或者SCALA基础3、熟悉Linux环境及脚本开发（Python/Perl/Shell等）4、熟悉MySQL，Redis，ES，能够快速的理解业务模型及数据模型5、理解ETL过程，拥有DW项目开发经验，熟练掌握SQL/HQL6、积极主动参与讨论、发现并解决问题7、学习能力强，拥有优秀的逻辑思维能力、良好的理解和表达能力、较强的抗压能力8、能迅速融入团队，与其他团队成员保持良好的合作,消费生活,2000人以上,spark,上海
后端研发工程师,https://www.lagou.com/jobs/7198326.html,徐汇区,15k-18k,再惠（上海）网络科技有限公司,1-3年,不限,年底双薪,"岗位要求1.计算机或其他相关专业正规统招本科及以上学历，1~3年后端开发经验。2.计算机基础扎实，数据结构等基础知识掌握牢固，代码习惯良好。3.熟练使用 Java 语言以及 Spring/Spring Boot/mybatis 等常用开发框架或者 Python 及后端框架。4.了解 Linux/Unix 系操作系统，熟悉容器化及其部署。5.了解一种关系型数据库如 MySQL/PostgreSQL 等；熟悉一种非关系型数据库 Redis/MongoDB 等。优先考虑：了解数据仓库建设，有数仓开发经验了解 Spark, Hadoop 生态，有使用和开发经验*岗位职责1.参与后端的迭代开发全流程，包括参与需求分析、设计评审、技术设计、技术实现、代码审查、发布上线、修复问题的软件开发全流程。2.参与基础设施的维护和建设，提供和保障高可用的基础设施3.参与数据仓库建设和开发，能根据需求提供高质量的数据输出","移动互联网,企业服务",500-2000人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7209685.html,杨浦区,10k-15k,上海晏鼠计算机技术股份有限公司,1-3年,本科,公司氛围好,"工作内容：1.基于Hadoop/Hbase/Spark/Hive的大数据离线/实时数据平台的开发和维护；2.参与公司大数据平台的数据仓库系统建设；3.参与公司大数据集群的性能优化，以及大数据平台架构的整体设计与改进；4.参与对数据挖掘及业务开发团队提供技术支持，协助方案规划；5.参与大数据平台相关技术攻关和创新技术引用。任职要求：1.计算机相关专业，本科及以上学历；2.2年以上Java或Scala编程经验，熟悉流行的大数据编程框架，有大数据处理和应用开发的相关经验；3.精通Hive,hbase,mongoDB,redis等关系型数据库和非关系型数据的使用和优化；4.熟悉Linux系统，精通Shell脚本语言；5.了解Hadoop相关技术的部署维护及安全管理；6.较强的学习能力以及快速解决问题的能力。",消费生活,500-2000人,spark,上海
Python数据处理工程师,https://www.lagou.com/jobs/6302180.html,浦东新区,20k-40k,上海海知智能科技有限公司,3-5年,本科,人工智能 知识图谱,"工作职责： 1、参与大数据处理系统的数据存储、计算、分析模块的开发与编码工作。 2、参与基于大数据平台的应用的开发，承担部分模块的设计、编码、性能调优。 3、参与公司数据产品的开发与维护。  任职要求： 1、计算机相关专业本科以上学历 2、熟练掌握Python 3、 熟练掌握SQL，至少熟悉一种常用数据库，包括但不限于Mysql、Oracle、MongoDB等。 4、有耐心、进取心，对技术热诚，工作有责任感，有团队协作意识。 5、有志于在数据处理与数据分析方向发展  加分项： 了解数据治理、数据质量管理，有实践经验者更佳 了解常用机器学习、深度学习模型，有文本分类、NLP处理经验者优先 有图数据库或知识图谱应用开发经验者优先 了解Hadoop生态圈技术体系，对离线计算、流式计算有深入理解和数据应用开发经验。 了解Hadoop、Spark、Hive、Impala、Hbase、Elasticsearch、Kafka等常见大数据组件的使用。 了解docker ,k8s。","移动互联网,数据服务",50-150人,spark,上海
大数据专家,https://www.lagou.com/jobs/6627127.html,闵行区,28k-40k,上海沐瞳科技有限公司,5-10年,本科,技术空间大；待遇好,"工作职责：1. 负责大数据平台的规划、设计、实施，包括但不限于采用合理技术实现ETL、数据仓库、实时分析、离线分析、自助分析、报表、用户画像、智能推荐、机器学习等。工作要求：1. 计算机或相关专业本科及以上学历，5年以上大数据相关工作经验2. 精通大数据生态相关技术，熟悉内在技术的优劣, 具有长时间的实战经验，具备使用、维护、调优的能力，包括但不限于Hadoop, Spark, Kafka, ELK, Cassandra等3. 精通实时大数据平台相关的编程技能, 比如python, golang, scala, java, shell, sql等, 能独立承担较大模块的设计、核心功能开发、上线工作4. 热爱学习，具备开阔的技术视野, 了解大数据领域最新技术动态5. 较强的抗压能力",游戏,500-2000人,spark,上海
数据开发工程师,https://www.lagou.com/jobs/6901229.html,浦东新区,18k-22k,上海盘古餐饮管理有限公司,5-10年,本科,五险一金 双休 带薪年假 员工内部折扣,"1. 负责业务需求,参与业务模块开发，参与数据仓库模型设计，数据仓库脚本开发；2.  负责对接业务进行业务数据需求整理，需求开发以及部分业务数据分析；3.  负责数据采集，任务调度等ETL工作；4、负责对各业务线数据提供可视化BI开发与支持；职位要求：1.  全日制本科/以上学历，计算机或数学相关专业；2. 5年及以上数据开发经验；3. 拥有丰富的离线数仓分层设计和使用经验，具有实时数仓使用经验者更佳；4. 拥有较好的SQL编写和优化能力，且Shell能力尚可；5. 拥有丰富的Hadoop、Spark、Flink等技术栈；6. 至少熟悉一种常用的BI工具；7. 熟悉Java、Scala等多门开发语言，有过Spring boot开发经验者更佳。8. 良好的沟通能力、团队合作精神,优秀的学习能力、分析问题和解决问题的能力。安排远程视频面试，可选择在家办公模式",消费生活,2000人以上,spark,上海
全栈JAVA开发工程师,https://www.lagou.com/jobs/4628493.html,浦东新区,15k-20k,上海盘古餐饮管理有限公司,5-10年,本科,"五险一金,团队氛围好,技术点多","岗位职责：1、负责与组员共同完成公司网络点单产品云pos的开发2、与组员共同完成公司产品关键技术突破3、平台类产品、应用类产品开发4、技术栈：ReactJs、SpringBoot、Mybatis、Redis、WebSocket、MongoDB、Spark、Hadoop生态 岗位要求：1、5年以上的 J2EE 应用开发经验,对主流开发框架,如 Spring、SpringMVC、Mybatis、SpringBoot等有全面的了解和掌握2、熟悉前端流行框架，如JavaScript、Freemarker、VUE、jquery、HTML+CSS、AJAX等3、精通MySQL、Oracle等常用关系数据库开发，能针对项目特性设计性能较优的数据库结构4、具有RESTful、Netty、Mina、RPC、node.js、微服务等的使用及开发经验5、 熟悉前后端分离开发模式,能独立完成功能模块的研发和编码,具有良好的代码风格、安全意识、代码洁癖6、熟悉常用的分布式缓存及消息队列技术，如Memcached、Redis、分布式任务调度平台XXL-JOB等，并运用于实际环境的优先考虑7、熟悉相关负载代理软件，如Nginx、HAproxy、F5等，了解集群高可用HA等技术优先考虑8、熟悉大型电商企业Web优化方案、调优、问题跟踪定位、监控等优先考虑9、有电商系统开发经验、有CRM会员系统、商品系统、订单系统开发经验优先10、熟练使用maven\git\svn\ jenkins，优先考虑11、熟练使用Dubbo以及阿里云等优先考虑岗位职责：1、负责与组员共同完成公司网络点单产品云pos的开发2、与组员共同完成公司产品关键技术突破3、平台类产品、应用类产品开发4、技术栈：ReactJs、SpringBoot、Mybatis、Redis、WebSocket、MongoDB、Spark、Hadoop生态 岗位要求：1、2年以上的 J2EE 应用开发经验,对主流开发框架,如 Spring、SpringMVC、Mybatis、SpringBoot等有全面的了解和掌握2、熟悉前端流行框架，如JavaScript、Freemarker、VUE、jquery、HTML+CSS、AJAX等3、精通MySQL、Oracle等常用关系数据库开发，能针对项目特性设计性能较优的数据库结构4、具有RESTful、Netty、Mina、RPC、node.js、微服务等的使用及开发经验5、 熟悉前后端分离开发模式,能独立完成功能模块的研发和编码,具有良好的代码风格、安全意识、代码洁癖6、熟悉常用的分布式缓存及消息队列技术，如Memcached、Redis、分布式任务调度平台XXL-JOB等，并运用于实际环境的优先考虑7、熟悉相关负载代理软件，如Nginx、HAproxy、F5等，了解集群高可用HA等技术优先考虑8、熟悉大型电商企业Web优化方案、调优、问题跟踪定位、监控等优先考虑9、有电商系统开发经验、有CRM会员系统、商品系统、订单系统开发经验优先10、熟练使用maven\git\svn\ jenkins，优先考虑11、熟练使用Dubbo以及阿里云等优先考虑",消费生活,2000人以上,spark,上海
算法leader,https://www.lagou.com/jobs/7063483.html,黄浦区,40k-75k,简阳联盟凯睿企业管理有限公司,5-10年,本科,做五休二 （早10晚8）,岗位职责：1、带领团队构建长视频内容推荐系统；2、负责长视频内容拉新留存、观看时长等目标优化；3、带领团队拓展算法在业务领域的应用，并逐步优化算法模型；4、建立用户画像，为业务的个性化和智能化提供基础保障。任职要求：1、5年以上工作经验；2、熟练掌握数据挖掘、机器学习的基础理论、基础算法和方法，有丰富的相关研究经验；3、对于召回、排序等算法有深入理解和实际业务使用经验；4、在机器学习或数据挖掘方向有较强的积累，熟悉经典算法并有实践经验；5、熟练使用Hadoop/MapReduce/Spark/Hive等常用大数据处理工具；6、熟练掌握至少一种编程语言:Java/C++/Scala/Python，熟悉tf建模；7、优秀的推动力、强大的自驱力，优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激情；8、有用户画像、广告、推荐、智能营销相关经验的人优先。,"企业服务,人工智能",150-500人,spark,上海
计算引擎研发专家 (MJ000159),https://www.lagou.com/jobs/6853669.html,浦东新区,30k-50k,上海七牛信息技术有限公司,不限,本科,六险一金、绩效奖金、弹性工作、发展空间大,职位描述1、打造业界领先、PB级的机器数据分析产品2、负责七牛自研计算引擎的架构设计和内核的深度优化职位要求1、熟悉使用Java、Scala；2、熟悉 Spark、Presto、Druid、Kylin、Hive、GreenPlum、ElasticSearch等主流大数据系统原理及源码，其中一项或者多项；3、熟悉主流的计算引擎的优化原理，向量化执行、代码生成、谓词下推等；4、有一定的大规模系统故障排查、性能调优、系统稳定性处理经验5、较强的自我驱动能力6、有开源项目代码贡献经历优先,"移动互联网,数据服务",150-500人,spark,上海
资深大数据开发工程师 (MJ000029),https://www.lagou.com/jobs/6654368.html,浦东新区,30k-45k,上海七牛信息技术有限公司,5-10年,本科,六险一金、绩效奖金、弹性工作,"职责描述：1.负责数据集群统一的资源分配和管理；2.负责大数据实时检索分析平台的开发、建设和优化；3.基于业务场景，推进批处理、实时流计算框架的研发优化；4.跟踪开源大数据框架、新算法框架的技术选型及平台化预研及架构。任职要求：1.5年以上大数据系统开发，设计，架构经验；2.精通java;scala;golang中至少一门语言；3.熟悉大数据相关技术：Hadoop, Hive, HBase, ZooKeeper, Spark, ELK, Kafka，并阅读过相关源码；4.管理过数据量上T级别，大规模数据集群，开发，优化并管理过上T级别的大数据作业；5.有机器学习、统计学背景的优先。","移动互联网,数据服务",150-500人,spark,上海
JAVA高级工程师,https://www.lagou.com/jobs/2742019.html,长宁区,15k-20k,上海麦图信息科技有限公司,3-5年,本科,"股票期权,带薪年假,弹性工作,扁平管理",【岗位职责】1.主导行业项目及相关产品开发;2.需求转化，设计输出，代码实现；3.小组管理，质量控制，技术演进；4.协助架构师推进公司的研发作业标准化进程；【岗位要求】1.计算机或信息化相关专业；2.3年以上独立开发经验，精通J2SE；3.兼顾Scala、Python等开发语言者优先；4.精通SpringCloud、SpringBoot等技术框架；5.对OO、MVC、SOA、分布式等概念及其应用有深刻理解；6.熟悉Spark、Flink等计算框架者优先；7.熟悉常用数据库及优化，熟悉常用缓存、NoSql技术；8.熟悉Hadoop体系、ElasticSearch等数据处理相关技术；9.熟悉Zookeeper、MQ等组件；10.具备标准化作业意识，有团队组织能力者优先；11.具有扎实的架构和功能设计能力，能够输出标准化作业文档；12.较强的沟通能力和逻辑表达能力，良好的分析、解决问题的能力；13.善于学习，视野开阔，有进取心；14.具备标准化作业意识，有较好的设计能力和文档功底；,数据服务,15-50人,spark,上海
AI科学家,https://www.lagou.com/jobs/6850874.html,徐汇区,35k-50k,上海游昆信息技术有限公司,5-10年,硕士,大数据行业 TB级数据存量,工作内容：•人工智能和机器学习应用的前沿研究•将算法应用在业务中落地实施•在大规模业务数据上设计开发解决方案•领导和建设公司的自主研发的AI平台* 任职资格：•211&985及以上Computer Science博士学位。2年相关行业实际工作经验或项目实践经验。•AI / ML出版物的经验。•有以下任何(至少3中)经验：计算机视觉，视频处理与理解，图像处理，语音识别，自然语言理解，机器学习，深度学习，算法优化基础，人机交互，数据挖掘。•有以下一种或多种编程经验：C，C ++，Python。•熟悉大数据生态圈组件，如Spark，hive，Hadoop等备注：优先条件：•海外Top50高校PHD背景优先。•解决现实世界机器学习问题的经验。•分析复杂和动态模式的经验。•熟悉分布式算法计算引擎和框架以及解决方案。,"数据服务,广告营销",150-500人,spark,上海
算法专家（广告平台）,https://www.lagou.com/jobs/6851929.html,徐汇区,25k-40k,上海游昆信息技术有限公司,5-10年,硕士,大数据行业 TB级数据存量,工作内容：1.开发、优化广告平台项目DSP部分的广告召回策略及CTR/CVR预测模型2.开发CTR/CVR模型所用的用户标签的开发、落地3.负责大规模模型在线训练及离线训练的落地及优化4.优化广告平台反作弊模型效果* 任职资格：1.计算机相关专业本科及以上学历，扎实的计算机基础知识，优秀的编码能力，较强的逻辑能力和学习能力2.有3年以上在线广告行业模型开发经验，计算广告、推荐算法领域优先，处理过日度亿级请求优先3.有CTR/CVR预测模型开发项目经验、Spark开发经验优先4.有较强的抗压能力，善于团队协作,"数据服务,广告营销",150-500人,spark,上海
大数据开发（云南出差岗）,https://www.lagou.com/jobs/7113953.html,浦东新区,20k-40k,亮风台（上海）信息科技有限公司,5-10年,本科,五险一金、年终奖、扁平化管理、绩效奖金,"岗位职责：1、负责智慧高速相关项目的需求分析、架构设计、核心框架及组件的编码等开发工作；2. 主要负责对数据平台进行开发，数据优化以及高效率分布式计算；3、能独立完成大数据系统的整体架构设计，开发，维护，数据优化工作。岗位要求：1、25-40岁，计算机、软件、电子、信息、自动化等相关专业，统招本科及以上学历，3年Java工作经验，至少2年以上大数据开发经验；2、熟悉MQ（kafka， rabbitMQ）；熟悉Hbase， 有Hadoop， Spark分布式计算平台开发经验；3、熟悉 Redis， PGSQL, Mysql， 分库分表，读写分离；熟悉Netty，对TCP/IP了解优先；4、掌握Spring MVC， 熟悉Spring Boot，Spring Cloud；","移动互联网,数据服务",150-500人,spark,上海
大数据开发,https://www.lagou.com/jobs/6300552.html,静安区,18k-35k,上海倍业信息科技有限公司,1-3年,本科,年度旅游、年度体检 、年度调薪,1、参与实时大数据平台的分布式数据存储与计算开发，打造稳定可靠的平台化、可视化、自动化交互式平台2、设计开发大数据产品，包括实时计算平台、数据审核平台、数据监控平台、数据标签化处理平台；3、负责数据仓库/数据平台的技术性维护工作，处理数据相关业务需求的实现与支持4、 负责提升Haddoop/Spark/Druid/Hive/Hbase集群的高可用性、高性能特性岗位要求：1、 计算机相关专业，全日制本科及以上，1年以上大数据开发经验2、 对流式计算、离线计算有深刻理解，精通MapReduce，Spark，Spark Streaming，Storm数据分析引擎至少一种的原理与使用，熟练应用kafka、redis等消息中间件/缓存技术3、 精通hadoop、druid、hive、hbase等大数据/时序数据库存储和技术的一种或多种的原理与使用4、 熟练应用python、java、scala等一种或多种开发语言进行数据仓库应用的开发，有2年以上实际项目经验5、 熟悉数据仓库/数据平台理论体系，熟悉建设数据仓库/数据集市相关方法论6、 对数据和业务逻辑映射敏感，梳理优化数据产品业务功能的逻辑7、 有hadoop、spark、druid、hbase等相关技术源码研究经验和成果的，优先考虑,"移动互联网,广告营销",15-50人,spark,上海
广告算法,https://www.lagou.com/jobs/6660848.html,静安区,25k-50k,上海倍业信息科技有限公司,不限,本科,五险一金,"职位描述：1.针对计算广告，内容推荐，用户画像等业务，开发机器学习算法原型系统，开展线上算法实验； 2.对实验数据进行处理和分析，发现现有系统和算法的不足，提出改进并推动实现；任职要求1. 计算机或相关专业硕士以上学历，有较丰富的程序开发经验；2．熟悉linux，java获C/C++开发；熟悉python。 3. 需要具备以下领域之一的背景：机器学习/数据挖掘/信息检索/自然语言处理/统计分析/图像处理，2年以上相关研发经验；4. 良好的主动性，逻辑思维能力和沟通能力。 5. 熟悉R、Python等编程语言，熟悉Hadoop, spark,Hive等大数据处理工具。","移动互联网,广告营销",15-50人,spark,上海
技术架构师（知识图谱方向）,https://www.lagou.com/jobs/6678063.html,静安区,30k-50k,鼎捷软件股份有限公司,3-5年,本科,"专业培训,五险一金,大型项目,好团队",职位描述：1、负责知识图谱相关技术架构方案；2、负责搭建工业领域知识图谱，设计方案将领域知识图谱与行业应用相结合；3、负责高并发下数据导入、更新、删除、查询等数据一致性架构设计；4、负责设计支持在线检索、离线分析相结合的高性能知识图谱技术架构；5、关注大数据、知识图谱方面的前沿技术，为公司相关产品发展提供技术选型方案。职位要求:1、数据挖掘/计算机科学/数学相关专业本科以上学历；2、熟悉知识图谱概念和相关技术，熟练使用neo4j等主流图数据库，了解其构建架构原理，2年以上知识抽取/知识图谱/知识推理相关研发经验；3、具备良好的业务理解能力和逻辑思维能力，能够根据对业务的理解将行业知识进行建模，转化为知识图谱；4、具有扎实的数据结构知识及算法基础，对实体抽取、实体属性属性值抽取、实体关系抽取有深刻见解；5、熟练掌握JAVA语言，尤其是大数据量高并发下的编程技术，熟悉Linux开发环境和Shell；6、熟练掌握ElasticSearch，Mongodb等Nosql数据库，了解Hadoop，Spark等大数据处理框架；7、具备工业互联网公司、制造业创新部门、IT技术公司等大数据相关研发部门从业经历者优先。,其他,2000人以上,spark,上海
算法应用工程师,https://www.lagou.com/jobs/6561315.html,浦东新区,30k-50k,招商银行股份有限公司信用卡中心,3-5年,本科,职位晋升 各类补贴 年度体检 年度旅游,岗位职责：1.负责项目中机器学习相关的研发工作，能有效挖掘业务需求，梳理业务逻辑，抽象出合适的问题模型，并选择合适的模型或算法进行相应的开发工作，并针对项目特点进行定向优化。2.参与到项目系统开发中，完成与算法相关的数据加工、清理、处理、分析等工作，并完成部分功能性需求。3.对主流算法的思路原理有较好的理解，能够面对具体业务场景进行针对性的改进，参与新算法的讨论及研发，并能转换成实际的应用服务。岗位要求：1. 熟练掌握经典及深度机器学习算法，具有3年或以上的相关工作经验。2. 熟练java\scala\Python其中任意一种语言。编程能力强，代码爱好者优先。3. 了解Unix/Linux/Win32环境，熟练使用shell或其他工具辅助开发。4. 熟悉Spark ML/Tensorflow等机器学习框架，有大数据处理经验优先。5. 具有良好的沟通能力，有责任心，有良好的学习能力，具备优秀的沟通能力和团队精神。,金融,2000人以上,spark,上海
大数据开发实习生,https://www.lagou.com/jobs/6774372.html,松江区,3k-5k,上海闵行区青悦环保信息技术服务中心,不限,大专,"有师傅带,实习证明,职业路径多,进步快",职位描述：工作职责:1、协助资深研发工程师参与大数据系统设计和开发；2、负责大数据平台的优化维护、协助进行数据仓库平台的模型设计和开发维护；3、负责后台日常数据统计分析；任职资格:1、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等） ；2、熟悉数据仓库理论与技术，对ETL及BI有概念并具有丰富的实际操作经验，熟悉ETL开发流程； 3、熟悉BI项目，具有数据仓库、BI系统开发经验者优先； 4、熟练操作linux系统，熟悉shell脚本或python； 5、有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题；,数据服务,少于15人,spark,上海
开发DBA工程师,https://www.lagou.com/jobs/7119571.html,杨浦区,20k-35k,嬴彻科技（上海）有限公司,5-10年,本科,自动驾驶公司,工作职责                                         1    架构搭建：负责数据库系统架构的设计和实施，参与项目中的数据库逻辑结构设计，参与大数据平台的架构设计；                                         2    方案设计：基于产品需求说明书，设计审核并创建数据库存储结构、数据库对3    程序开发：根据业务需求批量更新数据；开发和维护数据库定时任务；使用spark SQl等技术，开发数据分析功能；                                         4    产品运维：监控并及时发现TOP SQL，通过优化索引结构提高性能或给研发人员提出优化建议；                                        5    技术支持：为企业信息化和其他内部相关业务提供相关技术支持。  任职资格                                         1    工作经验： 5年以上工作经验；有物联网、移动互联网等高并发场景、从0到1大型平台开发工作经历；                                        2    学历要求：本科以上，优选本科985或211院校（不含专升本）                            3    知识技能： 精通Mysql 数据库，3年以上大型数据库开发经验，2年数据库架构设计经验；熟悉常用Redis、mongodb等No Sql数据库，能根据具体应用设计完成数据库建模；熟悉Hadoop/Spark/Flink等大数据框架；熟悉常用的数据库优化方法，有具体的项目优化经验；熟悉公有云数据库产品和技术；熟悉高性能、分部式系统设计，有相关的设计经验，有大型计算集群的基础设施开发维护经验者优先；熟练掌握Python、java、shell等语言中的一项以上者优先。                                         4    语言能力：可使用英语进行日常沟通交流，读写能力强；                                      5    素质要求：踏实稳重，责任心强，良好的沟通协作能力。,人工智能,150-500人,spark,上海
开发DBA,https://www.lagou.com/jobs/7091817.html,杨浦区,20k-25k,嬴彻科技（上海）有限公司,5-10年,不限,自动驾驶公司,工作职责                                         1    架构搭建：负责数据库系统架构的设计和实施，参与项目中的数据库逻辑结构设计，参与大数据平台的架构设计；                                         2    方案设计：基于产品需求说明书，设计审核并创建数据库存储结构、数据库对3    程序开发：根据业务需求批量更新数据；开发和维护数据库定时任务；使用spark SQl等技术，开发数据分析功能；                                         4    产品运维：监控并及时发现TOP SQL，通过优化索引结构提高性能或给研发人员提出优化建议；                                        5    技术支持：为企业信息化和其他内部相关业务提供相关技术支持。  任职资格                                         1    工作经验： 5年以上工作经验；有物联网、移动互联网等高并发场景、从0到1大型平台开发工作经历；                                        2    学历要求：本科以上，优选本科985或211院校（不含专升本）                            3    知识技能： 精通Mysql 数据库，3年以上大型数据库开发经验，2年数据库架构设计经验；熟悉常用Redis、mongodb等No Sql数据库，能根据具体应用设计完成数据库建模；熟悉Hadoop/Spark/Flink等大数据框架；熟悉常用的数据库优化方法，有具体的项目优化经验；熟悉公有云数据库产品和技术；熟悉高性能、分部式系统设计，有相关的设计经验，有大型计算集群的基础设施开发维护经验者优先；熟练掌握Python、java、shell等语言中的一项以上者优先。                                         4    语言能力：可使用英语进行日常沟通交流，读写能力强；                                      5    素质要求：踏实稳重，责任心强，良好的沟通协作能力。,人工智能,150-500人,spark,上海
模型开发工程师,https://www.lagou.com/jobs/7040225.html,虹口区,20k-35k,杭银消费金融股份有限公司,5-10年,本科,"大数据平台,福利待遇好,管理规范",1. 负责使用常用数据分析及数据挖掘算法支持大数据应用风控场景。2. 参与或负责模型技术设计、评估到最终模型实施的项目全生命周期，解决不同场景下的风控业务问题；3. 开拓前沿的机器学习技术，深入文本挖掘分析、社交网络分析等前沿算法开发，从大数据中挖掘客户行为特征属性，识别异常并分析与风险的关联度，据此产生创新应用。4. 与风控团队配合，提供数据驱动风控策略方面的专业咨询方案。1．本科及以上学历，应用数学、统计学、金融工程等专业优先 ； 2．具有3年以上数据分析、数据挖掘及模型开发经验，参与过金融类风控模型产品研发者优先；3. 熟练应用SQL 、R等分析语音，熟悉Python ；了解Hadoop/Spark/Hive等常用大数据处理工具，有前沿机器学习算法经验的优先 4．具备良好的沟通协调能力、量化分析能力、逻辑思维能力； 5. 能适应高强度、快节奏的工作氛围。,金融,150-500人,spark,上海
BI分析主管/分析师,https://www.lagou.com/jobs/7002990.html,虹口区,15k-25k,杭银消费金融股份有限公司,3-5年,本科,"大数据平台,福利待遇好,管理规范",岗位职责:1. 负责风险分析相关的数据仓库和集市的搭建，支持报表分析、模型开发和业务应用的研发；2. 负责支持策略日常迭代的数据需求，包括从数据库、大数据平台、以及其他数据组件中抽取、汇总、计算、存储、查询等工作以及相关工具的研发；具备扎实的数据分析技能。熟练使用SQL、Python编程语言，熟练使用Tableau，hive，impala，spark等分析工具及性能调优等相关经验3. 负责线上产品申请、授信、支用、贷后等全流程转化的报表研发；4. 支持风险策略实时监控的报表开发；5. 负责风险日报、周报、月报的研发；6. 负责支持线上业务管理者决策的其他的监控报表研发。任职资格:1. 本科及以上学历，主管要求5年以上工作经验，以及2年以上的管理经验（分析师要求2年以上报表研发经验）；2. 有hive、mysql的相关研发经验；3. 熟练使用Tableau或类似的可视化软件；4. 有风险管理报表例如PQR报表的相关研发经验优先；5. 具备优秀的分析问题的能力。,金融,150-500人,spark,上海
后台开发工程师,https://www.lagou.com/jobs/7194841.html,浦东新区,15k-30k,百度（中国）有限公司,1-3年,硕士,后台支撑大流量业务场景（日流量十亿级别）,岗位描述：负责业务后台的功能设计、实现，性能优化等工作。岗位要求：1 扎实的 JAVA/GO 语言基础。2 熟悉 Linux 系统，可熟练使用各种常用 Linux 操作系统命令。3 熟悉 Mysql、Redis 等数据存储服务，了解数据库索引，查询优化，对 Cassandra 熟悉者更佳。4 熟悉并具有流式计算经验者更佳（Flink、Spark）。5 熟悉 Kafka 或其他消息队列存储服务的基本原理和概念，能够覆盖工作日常使用需要。 6 了解 分布式系统、密码学基础、计算理论基础，数据库系统实现 等了解者优先。7 上进心强，愿意拥抱变化，学习能力强。7 较高的抗压能力，较强的责任岗，工作态度认真、严谨，具有较好的表达沟通能力者更佳。,工具,2000人以上,spark,上海
高级大数据开发工程师,https://www.lagou.com/jobs/7108881.html,闵行区,17k-32k,上海扩博智能技术有限公司,5-10年,本科,人工智能 智慧零售 带薪年假,"工作职责:1、扩博大数据平台研究与开发，编写符合规范的开发设计等技术文档，代码开发，单元测试等2、对接业务部门，完成业务数据治理（包括产品SKU数据，图片数据，标注数据，模型数据）以及BI需求开发工作  职位要求：1、计算机相关专业，三年以上互联网行业公司大数据平台后端开发和设计经验2、熟练使用大数据Hadoop平台及其相关生态组件HBase/Hive/Spark，熟悉Azure Data Factory, HDInsight, Power BI是加分项3、技术基础扎实，有较强的分析和解决问题能力，精通C#/Java/Python/Go中的至少一种编程开发4、有强烈的上进心和求知欲，善于学习和运用新知识，有良好的团队意识和较强的抗压能力","移动互联网,数据服务",50-150人,spark,上海
架构师,https://www.lagou.com/jobs/7102182.html,浦东新区,30k-60k,上海浦东发展银行股份有限公司信用卡中心,5-10年,本科,五险一金；年假；绩效奖金；年度体检,"职责描述：（1）负责制定浦发卡中心信息科技发展规划并构建管理企业架构模型，确保相关架构的可实施性及稳定性，提升科技业务交付能力；（2）负责制定信息系统标准规范的编制和管理，以及系统设计、开发等过程的规范编制和管理,参与信息系统项目建设过程中关键环节和关键文档的评审工作;（3）负责参与关键性项目建设，指导并监督项目组按照分布式架构及业务领域驱动设计原则进行建设及改造工作；（4）负责调研技术团队工作痛点并进行诊断，协助并解决核心技术问题，主导技术分享和培训技术人员；（5）负责参与核心系统稳定性及性能调优工作，确保系统具备高可用、高性能、高安全等架构特性。任职要求：（1）计算机相关专业本科（含）以上学历，至少5年以上Java技术开发经验且从事2年以上金融领域系统架构设计开发管理工作，以及大型项目规划经验；（2）熟悉银行信用卡主要业务，熟悉领域驱动设计理念并有相关实战经验，具有对业务领域进行建模、抽象、规划及设计能力；（3）精通SpringCloud/ServiceMesh微服务开源框架标准或Hadoop\Spark\Storm\Flink大数据开发架构，掌握分布式技术架构，包括分布式消息、缓存、事务等中间件；（4）具备高并发，高负载，高可用性系统设计开发经验，了解网络、安全、数据库、云平台、自动化测试等相关知识；（5）具有高度的责任心与自驱力，较强的分析思维、归纳思维及创新能力，以及良好的沟通协调、应急响应与处理问题的能力，能够通过技术能力解决业务问题;（6）热爱研究技术，拥有工作激情、责任心和引导能力，能承受较强的工作压力；（7）具备专业的技术文档和研究报告的编写能力。",金融,2000人以上,spark,上海
数据平台工程师（实时方向）,https://www.lagou.com/jobs/6930044.html,黄浦区,25k-45k,行吟信息科技（上海）有限公司,3-5年,本科,年底双薪、绩效奖金、租房补贴、带薪年假,职位描述：一起构建公司的实时数据平台，用强壮的实时数据架构赋能业务我们需要你具备这些基础技能- 熟悉 Linux 和基础的应用性能调优方法- 熟悉大数据应用开发/调优，不限于 Spark / Flink / Storm- 熟练的编码能力，不限于 JAVA/Scala/Python- 了解业务需求，并将其转化为平台服务- 渴望快速成长同时在以下任一方向做的好即可- 熟悉离线计算调优、或者存储调优- 熟悉 k8s- 开发过高吞吐/并发 服务你能得到这些成长机会- 丰富技术视角比如 计算平台、数据库、OLAP、多数据中心计算平台 等- 怎样构建/迭代实时数据平台- 即面向业务了解痛点，又接触底层了解原理和调优- 怎样用技术赋能不同的业务部门- 和来自 FB / Google 的同事同台竞技,消费生活,500-2000人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7134451.html,杨浦区,20k-40k,上海跃橙文化传播有限公司,3-5年,本科,Dataworks、大数据集群运维,工作职责:1、大数据平台工具如调度系统、数据质量系统等的开发、维护，大数据基础平台的维护和调优；2、数据埋点系统的开发和维护；3、负责海量数据分析、挖掘、加工、清理、处理程序的开发；1、计算机相关专业，本科及以上学历，3年以上大数据相关工作经验；2、熟悉Linux/Unix系统环境下的操作，熟悉Java、Scala、Python编程语言的一种或多种，至少有3年以上开发使用经验；3、熟悉阿里云集群（MaxCompute、DataWorks）产品及使用调优，有实际操作经验；4、精通Hadoop，Spark，Flink，HBase，Hive，Kafka，Druid等大数据组件的原理和调优，至少有3年以上的运维和开发经验；5、熟悉Flink、Spark Streaming，对于实时计算平台的架构设计有一定的理解，熟悉Flink优先；6、熟悉OLAP、OLTP引擎如Druid、Kylin、Presto，熟悉主流数据整合、治理技术和工具；7、熟悉Spring Boot框架，并能熟练开发后台程序；8、熟悉日志采集系统，对个性化埋点系统有一定经验；,移动互联网,50-150人,spark,上海
高级java工程师,https://www.lagou.com/jobs/6739546.html,闵行区,15k-30k,上海电科电器科技有限公司,5-10年,本科,工业互联网，完善的薪酬福利体系，上市公司,"岗位描述：1、主导业务、技术改造等类项目的系统分析、设计工作，负责平台核心功能、公共模块的规划及架构设计、核心开发等。2、能提供架构、性能优化的解决方案，并主导平台和产品的快速迭代和优化。能够应对复杂业务场景、大数据高并发环境下的技术挑战。3、参与系统架构设计、接口规范制定、技术文档编写等。对所负责系统进行规划和技术创新，并结合项目不断优化和升级，提高系统运行性能、稳定性、可用性和扩展性；任职要求：1、计算机或相关专业，全日制硕士（985/211）及以上学历。2、5年以上Java软件开发经验。3、精通spring,springboot。4、熟悉Spring，JavaEE，JBoss，Tomcat等。5、熟悉MySQL、Oracle等关系型数据库，及MongoDB、Cassandra等非关系型数据库。6、熟悉Redis, Kafka, RabbitMQ等中间件。7、了解Hadoop、Spark、Python等大数据和数据挖掘工具。具备Linux, Windows等操作系统知识。8、了解Subversion, Git, Maven，Jira，Confluence等工具链。高度责任感和团队合作精神。","人工智能,物联网",150-500人,spark,上海
数据建模科学家,https://www.lagou.com/jobs/7105196.html,浦东新区,35k-40k,第四范式（北京）技术有限公司,3-5年,硕士,六险一金 、AI独角兽、各种福利,"岗位职责：1. 通过对数据的观察，行业背景的理解，以及客户需求的把握，发现业务问题，并使用最先进的AI建模技术解决该问题，证明AI技术可为业务带来的真正价值2. 将AI建模方案在实际生产中投产，为业务产生实际价值3. 结合银行/保险/证券/制造业等行业背景中的机器学习问题，将要解决的问题做到通用性，设计端到端的整体解决方案，并孵化成产品任职要求:1. 计算机、数学、统计、物理等相关专业硕士及以上学历，3年以上建模工作经验。2. 对机器学习原理有扎实的理解，熟悉 LR，GBDT，DNN 等常用机器学习算法，并具备实际业务场景的机器学习实践落地经验，对使用机器学习技术解决业务问题抱有极大的兴趣。3. 熟悉linux基本操作，掌握Python/R/Scala等常用建模编程语言的至少一种4. 具备较强数据分析能力，对于数字背后的逻辑具备相当敏感度5. 很强的学习能力和动手能力6. 思维敏捷，良好的逻辑分析能力，较强的沟通表达能力【加分项】1. 有咨询公司/数据服务公司/平台公司等工作经历，具备客户成功意识2. 项目经验丰富，所做项目涵盖行业包括但不限于银行、保险、零售、能源、制造、运营商、医疗等，3. 熟悉 TensorFlow, scikit-learn 等开源算法库，能熟练使用 Hadoop，Spark，Hive 等框架。4. 参加kaggle等数据竞赛取得较好的名次，或者有多个或大型机器学习建模和应用策略相关经验优先",企业服务,500-2000人,spark,上海
数据开发工程师,https://www.lagou.com/jobs/7160666.html,虹口区,15k-25k,上海豹云网络信息服务有限公司,5-10年,本科,年终奖、平台快速发展,岗位职责：1，负责公司大数据平台开发和实现，包括并不限于离线和实时平台的搭建和实现、数据的调度平台、数据质量和数据安全等。2、负责大数据相关新技术的调研，关注大数据技术发展趋势、研究开源技术、将新技术应用到大数据平台，推动数据平台发展；岗位要求：1、计算机、数学等专业本科及以上学历；具有5年及以上数仓建设和数据平台研发相关工作经验；2、具有扎实的大数据的理论功底，基于Hadoop的大数据体系有深入认识，具备相关产品的理论知识和实践经验（Hadoop、Hive、HBase、Spark、Storm、Flume、Kafka、ES、Kylin等）； 3、有过阿里云MaxComputer、DataWorks等相关经验者优先；4，有程序开发经验，精通一种或多种开发语言，例如Java、Python、Scala等5、自驱力强、优秀的团队意识和沟通能力，对新技术有好奇心，学习能力和主动性强，有钻研精神，充满激情，乐于接受挑战；6、有过互联网公司大数据数仓设计和大数据平台设计和开发工作经验者优先,金融,50-150人,spark,上海
云平台部署专家,https://www.lagou.com/jobs/7176134.html,徐汇区,40k-70k,OPPO广东移动通信有限公司,10年以上,本科,"各种团建,工作氛围好,发展空间大","职位职责：1. 负责AI平台架构设计与工程实施，持续建设优化平台，丰富平台能力；2. 对接各类AI算法，提供AI领域数据处理、在线训练、模型服务能力；岗位要求1. 独立完成大中型项目的架构设计、编写核心代码、确保技术方案按要求高质量完成；2. 精通Java, 熟悉常用Java技术框架; 熟悉C/C++, Python开发语言优先考虑；3. 有Kubernetes，Docker等容器化技术产品开发背景；4. 熟悉数据库原理和SQL，熟悉主流数据库，如MySql;5. 熟悉大数据引擎以及机器学习框架优先，如 tensorflow, flink, spark, hive；6. 对高并发、高稳定可用性、高性能、机器学习、大数据处理有过实际项目及产品经验者优先考虑；7. 具有较强的问题分析和处理能力、比较强的动手能力，对技术有强烈追求者优先考虑；",硬件,2000人以上,spark,上海
高级开发工程师技术专家,https://www.lagou.com/jobs/6902803.html,浦东新区,30k-60k,支付宝（中国）网络技术有限公司,3-5年,本科,3-6奖金,职位描述:1、进行数字金融业务技术风险行业领域分析和建模，设计搭建核心风险防控系统，守护资金资产安全；2、主导技术风险防控数据分析与设计工作，承担系统核心功能代码开发，维护系统公用核心模块；3、持续在风险数据智能平台、高可用、资金数据等方面沉淀，并能实际运用到金融业务中。职位要求:1. 计算机、软件工程、电子信息等相关专业背景，3年+工作经验；2. 扎实的java编程基础，熟练单元测试技术和TDD，精通Java EE、SOA、Spring等相关技术；3. 熟悉Hadoop，MapReduce等分布式并行处理技术，具备 Storm、Flink、Spark、Kafka、Elastic Search等大数据开发实施经验4. 具备良好的通用框架及模块设计及实现的能力；5. 较强的表达和沟通能力，较强的学习能力，对技术有热情，工作认真、严谨、敬业。有很强的分析问题和解决问题的能力，有强烈的责任心。加分项：1. 优秀的统计基本知识，丰富的数据分析从业经历，熟练Hive SQL语言；2. 了解传统机器学习算法、深度学习等算法建模优先，数学基础良好优先。,移动互联网,2000人以上,spark,上海
机器学习量化,https://www.lagou.com/jobs/6989560.html,浦东新区,30k-60k,深圳智融信达科技有限公司,不限,硕士,公司过往业绩优秀，团队实力强大,岗位职责：1. 利用机器学习、深度学习和人工智能的方法在公司研究平台上对大量历史性的数据进行研究、分析和统计，并从中找到相关的趋势和规律2. 针对包括A股市场研究和挖掘各种市场中性Alpha模型/因子，并在此基础上进行一系列测试3. 在发掘足够多的模型/因子的基础上，研究因子组合方法。优秀者可参与因子组合管理4. 紧跟领域前沿，独立或与其他投资人员合作来推动算法的改进5. 其他与量化交易相关的工作岗位要求：1. 国内外重点大学人工智能、数学、统计、计算机、信号处理、金融工程等相关专业硕士及以上学历；**大学本科学历特别优秀者也可2. 具备基本的金融投资知识和市场洞察力，熟悉传统机器学习与深度学习算法原理及应用场景3. 具有扎实的数学建模能力及编程能力，能熟练通过Python、R等语言建立机器学习模型4. 思路清晰，逻辑性强，善于发现并提出独特观点，并有良好的沟通表达能力和合作的态度职位要点：1、计算机相关专业（本科计算机就行）；2、大数据研究和处理项目经验（最好大厂，接触过spark\hadoop）；3、机器学习应用经验（对具体算法有研究者更好）；4，互联网背景的做AI研究工作的匹配度高，过来做股票量化策略研究，优秀的团队，薪资open可谈。,"移动互联网,数据服务",50-150人,spark,上海
数据算法工程师/专家,https://www.lagou.com/jobs/7082778.html,杨浦区,25k-38k,国泰财产保险有限责任公司,3-5年,本科,蚂蚁控股、互联网行业、发展空间大,,金融,500-2000人,spark,上海
APM大数据开发工程师,https://www.lagou.com/jobs/6592908.html,徐汇区,25k-50k,腾讯科技（深圳）有限公司,3-5年,本科,福利待遇/年终奖/职业发展,"岗位职责：1. 负责WeTest APM大数据平台的后台架构方案的选型、设计和开发；2. 负责数据处理流程的设计、开发和持续优化；3. 负责大数据处理模块核心功能的开发。岗位要求：1. 计算机相关专业，具有3年以上大数据工具的使用和开发经验；2. 熟悉Unix/Linux操作系统下的C/C++/Java，Python，Go，Shell中的一种或多种语言； 3. 熟悉MySQL开发，熟悉TCP/IP协议相关知识，精通网络编程；4. 熟悉面向对象的大型分布式系统设计与开发；5. 熟悉Hadoop,HBase,Spark,Storm,Elasticsearch,Kafka等大数据处理平台流程；6. 有过互联网行业大规模后台或大数据平台建设及优化实际工作经历者优先。",社交,2000人以上,spark,上海
Golang开发工程师,https://www.lagou.com/jobs/6669499.html,虹口区,15k-25k,奇虎360科技有限公司,3-5年,本科,环境好、沟通氛围好、免费三餐,工作职责：1. 负责多个项目的后端应用与平台开发；2. 根据用户需求或产品功能进行模块细部设计与应用平台功能开发；3. 对接各产品，第三方平台，完成整体解决方案集成工作。任职要求：1. 本科或以上学历，计算机相关专业，3年以上相关工作经验；2. 具备良好的计算机基础，熟悉常见数据结构与算法；3. 熟练使用Golang/Python/PHP/C++中的至少一门编程语言；4. 熟悉常见数据库的原理及使用，如Redis/MySQL/MongoDB等；5. 熟悉计算机网络，熟悉多种网络协议，有丰富的开放性API开发经验；6. 良好的分析及解决问题的能力，良好的团队合作精神。加分项：1. 了解Kafka/ES/HBase/Spark的使用及相关知识；2. 了解网络安全知识；3. 了解Docker/Swarm/Kubernetes的使用及相关知识。,信息安全,2000人以上,spark,上海
到店技术-算法团队负责人,https://www.lagou.com/jobs/6788428.html,长宁区,40k-70k,北京三快在线科技有限公司,10年以上,硕士,大平台，管理岗，有趣的业务,,消费生活,2000人以上,spark,上海
到店技术-高级系统开发工程师-数据业务,https://www.lagou.com/jobs/6201169.html,长宁区,30k-45k,北京三快在线科技有限公司,5-10年,本科,丰富的业务场景，专业的团队,,消费生活,2000人以上,spark,上海
高级Java开发工程师,https://www.lagou.com/jobs/5323896.html,静安区,10k-16k,上海海万信息科技股份有限公司,3-5年,本科,五险一金，带薪年假，年终奖，旅游节日礼金,1、五年以上Spring MVC，Spring，MyBatis等开源框架的开发经验，精通Memcache、Redis缓存技术；2、熟练使用 SVN、MAVEN 等项目版本管理及构建工具；3、熟练掌握HTML、CSS、JavaScript、Ajax、jQuery、Easyui、bootstrap、ExtJs等前台开发技术；4、熟练掌握如MySQL、Oracle、PostgreSQL等大型数据库，熟悉No-sql数据库如HBase、MongoDB者优先；5、从事过Zookeeper、Dubbo、RabbitMQ等技术的项目开发，了解Kafka、Spark等大数据体系相关技术者优先;6、针对有过大型互联网应用架构设计，并且参与过并发量超过10W+的项目开发经验者优先；7、熟悉Python开发者优先；8、有过Spring Cloud和SpringBoot等微服务开发者优先；,"移动互联网,金融",500-2000人,spark,上海
大数据开发,https://www.lagou.com/jobs/3431632.html,静安区,12k-18k,上海海万信息科技股份有限公司,3-5年,大专,"五险一金,旅游体检,年终奖,过节费",岗位职责：1、 负责大数据业务需求开发；2、 负责大数据平台系统设计和开发；3、 参与数据平台的监控、维护及优化。 基本要求：1、 计算机相关专业本科及以上学历，2年及以上数据开发经验；2、 精通Hadoop相关技术，包括Mapreduce，Hive，Spark，Storm等；3、 熟悉shell，python等至少一种脚本语言使用；4、 对大数据技术和开发有热情，工作认真负责，有较强的学习能力和团队合作意识；5、 有实时计算平台开发或NoSQL工作经验者优先。,"移动互联网,金融",500-2000人,spark,上海
搜索模型专家,https://www.lagou.com/jobs/7061499.html,浦东新区,40k-80k,上海基分文化传播有限公司,5-10年,硕士,大平台,1、负责电商业务中搜索或推荐算法的研发，并在各垂直业务中上线应用，包括排序算法/召回优化/相关性建模/数据挖掘等工作，提升线上指标，用户体验以及商业化业务赋能等。2、计算机，自动化，电子通信，数学统计等相关专业本科以上学历，超过一年互联网搜索，推荐，流量或相关领域工作经验。扎实的机器学习/深度学习/自然语言处理/数据挖掘理论基础，并且在某个方向上有深入的研究和积累。3、熟悉Go/C++/Java等其中之一开发工具，熟悉shell/python脚本语言，熟悉Spark/flink等其中之一大数据处理平台，熟悉tensorflow/pytorch/mxnet等深度学习框架中的一个，有独立特征处理，模型训练，部署等实际工程经验更佳；能够跟踪机器学习、自然语言处理、数据挖掘等领域的前沿动向，有自己的洞察力。4、具有落地向量召回/类目预测/CTR/CVR/LTR等工作经历加分；具有大型搜索、广告或者推荐系统的实际研发经验者加分；在人工智能/机器学习/自然语言处理等领域**会议或者学术期刊发表论文者加分。5、优秀的分析和解决问题的能力，思路清晰，对工作上的挑战充满激情，具有强烈的工作责任感和团队合作精神。,文娱丨内容,500-2000人,spark,上海
搜索算法,https://www.lagou.com/jobs/6636496.html,浦东新区,25k-50k,上海基分文化传播有限公司,1-3年,硕士,大平台,1、负责电商业务中搜索或推荐算法的研发，并在各垂直业务中上线应用，包括排序算法/召回优化/相关性建模/数据挖掘等工作，提升线上指标，用户体验以及商业化业务赋能等。2、计算机，自动化，电子通信，数学统计等相关专业本科以上学历，超过一年互联网搜索，推荐，流量或相关领域工作经验。扎实的机器学习/深度学习/自然语言处理/数据挖掘理论基础，并且在某个方向上有深入的研究和积累。3、熟悉Python/Go/C++/Java等其中之一开发工具，熟悉Flink/Spark/Hadoop等其中之一大数据处理平台，能够把握机器学习、自然语言处理、数据挖掘等领域的前沿动向，有自己的洞察力。4、具有落地向量召回/类目预测/CTR/CVR/LTR等工作经历加分；具有大型搜索、广告、或者推荐系统的实际研发经验者加分；在人工智能/机器学习/自然语言处理等领域**会议或者学术期刊发表论文者加分。5、优秀的分析和解决问题的能力，思路清晰，对工作上的挑战充满激情，具有强烈的工作责任感和团队合作精神。,文娱丨内容,500-2000人,spark,上海
监控OLAP引擎研发工程师,https://www.lagou.com/jobs/6563675.html,闵行区,25k-50k,北京字节跳动科技有限公司,3-5年,本科,六险一金，弹性工作，免费三餐，租房补贴,,文娱丨内容,2000人以上,spark,上海
大数据测试工程师,https://www.lagou.com/jobs/6756199.html,闵行区,15k-30k,北京字节跳动科技有限公司,1-3年,本科,"六险一金,餐补",,文娱丨内容,2000人以上,spark,上海
移动客户端部_数据研发工程师,https://www.lagou.com/jobs/7162481.html,浦东新区,20k-40k,百度在线网络技术（北京）有限公司,不限,不限,AIG；六险两金；团建福利；发展空间大,工作职责-负责数据仓库建设，通过流式计算、离线计算等方进行海量数据采集、清洗、入库等工作 -负责数据治理和数据报表系统建设，优化计算和分析效率，提升数据易用性及数据质量，理解并抽象业务需求，发挥数据价值 -应用机器学习、自然语言处理等技术，进行海量数据分析挖掘和建模，助力业务效果提升任职要求-具备大型数据架构设计、模型设计、ETL设计的相关经验 -熟练使用Hive、HBase、Spark、Spark Streaming，具备海量离线计算、实时计算处理及性能调优经验 -熟练掌握Python/Shell/SQL等开发语言，有大型工程项目或大规模数据开发经验者优先 -熟悉机器学习、深度学习算法，有模型训练和优化项目经验者优先 -具备快速的业务学习和理解能力，有较好的数据敏感性，有良好的沟通能力,工具,2000人以上,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6700601.html,浦东新区,15k-28k,上海华钦信息科技股份有限公司,3-5年,不限,全球型外资企业平台，牛人大咖云集,教育背景：本科 科班工作年限：2-4Y技能要求：1.  熟悉 hdfs、mapreduce、yarn 等 hadoop 生态体系相关技术。能独立完成集群环境的部署以及 mapreduce 程序的开发。2. 熟悉Spark 分布式计算框架原理和编程模型，zookeeper 分布式协调服务的使用。3. 熟悉Hbase， Hive 的原理，使用和性能优化策略，能够使用 SQL 进行数据分析及调优。4. 熟悉 Java or scala 语言，可以编程开发。5. 可独自完成 spark 集群环境搭建，了解 spark 核心源码实现，对 Spark-Streaming 以及 spark-Sql 有一定的了解与使用经验。 6. 熟悉Linux 系统， 使用shell完成大数据一键部署。,"数据服务,金融",500-2000人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6808046.html,浦东新区,18k-25k,上海华钦信息科技股份有限公司,3-5年,本科,15天年假，房贷补贴，六险一金,"职位描述：Key responsibilities :-          Responsible for developing regulatory reporting application.-          Follow instruction from team lead or senior team member to get assigned job done on time with good quality.-          Be able to handle task independently with good patience, clear mind. Qualifications :-          Bachelor or above degree in computer science, information technology, or similar.-          Solid computer science fundamentals in data structure, algorithms.-          2 ~ 5 years of software development experience.-          Solid knowledge of core java.-          Good knowledge on RDBMS like Oracle/MySQL etc, knowing NoSQL like MongoDB is a plus.-          Good knowledge on Spark and also familiar with Spark ecosystem like Hadoop/Impala/Hive etc.-          Have experience in solving data process in big data approach, be able to locate the potential problem, tune performance.-          Good written and verbal communication skills is preferred.","数据服务,金融",500-2000人,spark,上海
java开发工程师,https://www.lagou.com/jobs/6802403.html,浦东新区,15k-25k,奥解思信息科技（上海）有限公司,3-5年,本科,外企办公环境，薪资福利好，技术前沿。,1.计算机科学、数学或相关专业的学士、硕士或博士学位。2.2-5年软件开发工作经验，至少1-3年Java编程经验。3.熟悉数据结构，算法，OO编程，一些基本的设计模式。4.有上进心和出色的解决问题的能力。学习能力强，有良好的团队合作精神。5.熟悉分布式系统、大数据项目，如Hadoop、Spark、Kafka等。6.英语读写能力良好，口语流利者优先。7.对开源有贡献的经验是一个巨大的加分项。8.有跨国公司工作经验者优先。9.有Spring/React/NodeJS工作经验者优先。,金融,500-2000人,spark,上海
python开发工程师,https://www.lagou.com/jobs/6816417.html,浦东新区,18k-36k,深圳平安综合金融服务有限公司,5-10年,本科,公司福利好，周末双休，平台稳定,"岗位职责：1，后台权限管理系统接口开发2，业务监控系统接口开发 。 3，业务监控数据汇聚平台开发。4，基础关联数据整合接口开发。5，报警结果接口及流程控制接口开发。岗位要求：1, 熟悉python、django, spark 框架者优先。2、对面向对象编程、设计模式、软件工程等有较深入的理解，对产品交付和用户体验有高要求；         3、了解TCP/IP、网络、多线程。多进程。协程编程、异步编程模型，了解线程安全和线程可见性，能编写正确且高效的并发代码 ；   4、熟悉计算机网络的基本知识及互联网上常见的通讯协议，熟悉常用数据结构与算法、Socket编程、多线程编程等；        5、熟练掌握mysql数据库，了解一些非关系型数据库；         6、有较强的自学能力、分析及解决问题能力，良好的团队合作能力以及需求分析能力；         7、对新技术保持热情，持续学习并乐于分享；具有良好的沟通能力和项目管理意识；        8、有很强的学习能力，有主动性和上进心，能承担压力；",金融,2000人以上,spark,上海
高级运维工程师,https://www.lagou.com/jobs/6291803.html,徐汇区,20k-35k,北京市商汤科技开发有限公司,3-5年,本科,人工智能 公司氛围好 扁平管理,1、负责IT项目运维；2、严格按照制定的流程及规范实行运维操作；3、负责系统部署上线、系统优化；4、负责运维报告的整理以及相关文档的编写；任职资格：1、3年以上linux系统运维工作经验，熟悉并使用过阿里云产品者优先；2、精通docker容器技术、熟悉k8s，熟悉ceph、kafka、spark等组件的运维。3、熟悉主流数据库，善于分析解决问题。4、具有良好的产品学习能力；5、具有独立分析解决问题的能力、团队合作意识及良好的文档记录习惯。,人工智能,2000人以上,spark,上海
java,https://www.lagou.com/jobs/7070247.html,闵行区,13k-15k,上海汉得信息技术股份有限公司,3-5年,本科,无,"1.计算机或相关专业，全日制本科及以上学历。2.1-2年Java软件开发经验。3.精通spring,springboot。4.熟悉Spring，JavaEE，JBoss，Tomcat等。5.熟悉MySQL、Oracle等关系型数据库，及MongoDB、Cassandra等非关系型数据库。6.熟悉Redis, Kafka, RabbitMQ等中间件。7.了解Hadoop、Spark、Python等大数据和数据挖掘工具。8.具备Linux, Windows等操作系统知识。9.了解Subversion, Git, Maven，Jira，Confluence等工具链。10.高度责任感和团队合作精神。","企业服务,数据服务",2000人以上,spark,上海
大数据架构师(J11511),https://www.lagou.com/jobs/7108691.html,徐汇区,30k-50k,秒针信息技术有限公司,5-10年,本科,上升空间大，团队氛围融洽,工作职责:1. 负责大数据基础架构和技术体系的规划建设，包括数据采集、数据治理、数据质量及稳定性保障体系2.负责数据平台的架构设计，并指导大数据工程师进行部署和开发任职资格:1，教育背景本科以上，3年以上大数据开发管理经验。2，有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关开发经验，有Spark/Flink的开发经验尤佳；3，较为丰富的数据平台的架构经验，精通数据建模理念和实战能力；有较为系统的海量数据性能处理经验，在数据产品和应用一定的成功经验；4，具备较扎实的理论基础和工程能力，具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力尤佳；5，良好的思维逻辑性、语言表达能力,"数据服务,广告营销",2000人以上,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6455095.html,浦东新区,17k-22k,奥解思信息科技（上海）有限公司,1-3年,本科,福利好,-计算机科学，信息技术或类似专业的本科或以上学历。,金融,500-2000人,spark,上海
JAVA高级研发工程师,https://www.lagou.com/jobs/6933912.html,浦东新区,20k-40k,百度在线网络技术（北京）有限公司,3-5年,本科,薪酬福利好，发展空间大,岗位描述· 负责展示广告业务平台及其相关系统的研发· 负责现有系统的问题分析和改进，提高系统性能，保证系统稳定性· 持续改进系统架构、核心算法或者核心技术等，保证系统高性能、高可用性和高可扩展性· 新技术预研，完成项目的选型和设计，难点攻关任职资格· 全日制大学本科以上学历，硕士优先，计算机、软件工程及相关专业毕业· 精通java编程语言，熟悉python/shell等脚本语言，有两年以上java相关的工作经验· 熟悉springmvc或springboot等应用框架，并了解工作原理；对spark、redis、kafka等有一定的了解· 具备良好的计算机基础，对数据结构和算法有较深刻的理解· 具备良好的代码阅读能力和编码能力；熟悉软件开发流程，具备一定的文档能力· 有技术热情，责任心强，和团队合作精神；思路清晰，能充分理解用户需求和功能描述，具备优秀的分析和解决问题能力,工具,2000人以上,spark,上海
数据测试工程师,https://www.lagou.com/jobs/7145226.html,杨浦区,14k-22k,上海识装信息科技有限公司,1-3年,本科,独角兽、福利待遇优、高成长、年轻团队化,职位描述：1.负责各项业务数据质量保证工作，以及各类数据质量测试方法的探索和效率提升；2.根据实际测试业务需求进行各类数据的测试工作，并持续进行已有数据质量的优化验证；3.确保数据生命周期和业务指标的SLA，确保数据正确性以及合理性。职位要求：1.本科或以上学历，1年以上数据测试经验；2.熟练掌握SQL语言，熟悉Hadoop、Spark等；3.数据敏感，有数据分析技能和经验，能基于业务理解推动数据测试的落地工作；4.工作细致负责，具有良好的团队沟通和协作能力。5.写过Java代码（会写即可），了解Spring 或者 MyBatis 至少一种（不需要精通，会用即可）；6.对开发提交的代码能Review，避免开发提测代码与实际测试代码不一致；7.有单元测试经验；8.加分项：有做过 性能测试 经验，通过 系统性能 分析，结合代码、JVM、数据库等 给出 优化建议；（熟练使用postman/jemter进行接口测试） 9.精通搭建服务器环境（sql，nginx，java，nodejs），和服务器日志查询；10.熟悉常用mvc和前端框架（vue，angar，react会一个就行）,"移动互联网,电商",500-2000人,spark,上海
前端开发工程师,https://www.lagou.com/jobs/7158115.html,浦东新区,14k-18k,上海微创软件股份有限公司,3-5年,本科,六险一金 福利假期 外企,"项目描述 成立于 2004 年，是人工智能和机器学习领域的领导者，为行业带来了革命性变化，以帮助客户 转变其业务。作为业界首创，ElectrifAi 已围绕开源和 Spark 体系的计算引擎重新设计了其技术 平台，该引擎可进行大规模的分布式数据处理和机器学习，并具有嵌入式 Zeppelin 笔记本功能。 现在，ElectrifAi 的数据科学家及其客户可以使用任何编程语言对数据进行编码和访问。Docker Containers 和 Kubernetes 的结合使 ElectrifAi 能够大规模构建和部署混合云企业解决方案， 在数周而不是数月内即可看到结果，从而显着增加了企业实现价值的时间。岗位内容• Work closely with our backend developers to ensure the integrity of the UI throughout the development lifecycle.• Scope project and provide accurate estimates for the implementation of features/functionality requests. • Design and build components as part of a large code base, maintain clear documentations. • Perform testing at the page and source for presentation layer defects • Review feature coding and plan future website upgrades. 岗位要求 • Bachelor’s degree in Computer Science or related technical field. • Proficient in front-end web technologies including HTML5/CSS3, JavaScript, jQuery, LESS/Sass, Bootstrap and Angular JS UI JavaScript Frameworks. • 2+ year of work experience with React. • Good understanding of asynchronous request handling, partial page updates, and AJAX. • Familiarity with full stack technologies including Node.js API development and working with relational databases (MySQL). • Working experience with using git version control and DevOps tools. • Working experience with cross-browser and cross-device development. • Familiar with CI/CD process. • Good at English reading/writing. • Oral English","企业服务,移动互联网",2000人以上,spark,上海
高级自动化测试工程师,https://www.lagou.com/jobs/6859969.html,浦东新区,18k-22k,上海微创软件股份有限公司,3-5年,本科,外企氛围好 发展平台好,"项目描述：成立于2004年，是人工智能和机器学习领域的领导者，为行业带来了革命性变化，以帮助客户转变其业务。作为业界首创，ElectrifAi已围绕开源和Spark体系的计算引擎重新设计了其技术平台，该引擎可进行大规模的分布式数据处理和机器学习，并具有嵌入式Zeppelin笔记本功能。现在，ElectrifAi的数据科学家及其客户可以使用任何编程语言对数据进行编码和访问。Docker Containers和Kubernetes的结合使ElectrifAi能够大规模构建和部署混合云企业解决方案，在数周而不是数月内即可看到结果，从而显着增加了企业实现价值的时间。客户来自世界上许多最大的企业和政府部门，其中包括：强生，T移动，美国政府，诺华，安大略省教师退休金计划，万事达卡，花旗银行，美国运通卡，Mercy医院，Bon Secours和联合航空。ElectrifAi可以协助客户将不同的混乱数据转化为实用的见解，从而解决日常问题并通过提高利润，提高绩效和降低风险来推动业务发展。ElectrifAi对全球**行业的公司产生了积极影响，这些行业包括：政府，医疗保健，金融服务，旅行和款待，电信，CPG，零售和娱乐。ElectrifAi的创新方法完全采用了开源技术，提供了比其竞争对手更快的实用解决方案。总部位于泽西城，在波士顿，圣地亚哥，上海和新德里设有办事处，业务遍及全球。Requirements：1.熟练掌握和运用测试用例设计理论和方法，对需求和设计进行分解，并进行全面准确的测试用例设计 ；2.熟悉自动化测试理论和实践，熟悉功能、性能、安全和接口测试的方法和工具；3.熟悉业界流行的测试框架和工具（如Appium Selenium, Robotium等等），具备丰富的测试框架使用和搭建经验；4.具有较强的编码能力和白盒测试能力，熟悉一种或以上编程语言如Java，Python等 ；5.有很强的责任心和目标驱动的工作方式；6.良好的沟通能力和团队合作精神，英语读写良好熟悉SaaS产品、分布式计算系统的架构和测试原理；7.有听说能力者优先","企业服务,移动互联网",2000人以上,spark,上海
资深数仓工程师(漫画),https://www.lagou.com/jobs/6974772.html,杨浦区,20k-35k,上海哔哩哔哩科技有限公司,5-10年,本科,福利年假 带薪病假 年终奖,岗位职责：1.负责数据研发工作，针对业务情况，依据开发规范，进行海量数据模型设计、数据开发，整合和处理海量数据；2.参与或负责制定数仓规范，如研发规范、质量规范、保障规范的制定与推动实施落地；3.数据质量监控，保障数据任务的及时产出，参与或负责制订数据预警体系4. 同产品、BI等协作深度挖掘数据商业价值，建设公共数据服务，实现高质量数据共享，推动部门数据应用能力；任职要求：1. 具有丰富的数据研发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验。2. 较为丰富的数据仓库架构经验，精通数据仓库建模及ETL设计开发；有较为系统的海量数据性能处理经验；3. 有从事分布式数据存储与计算平台应用开发经验，有Hadoop、Spark、Storm 等离线计算、实时计算数据研发经验，对Flink有一定了解者优先。4. 具备较扎实的理论基础和工程能力，具备一定的JAVA、Python语言的开发能力；5. 责任心强，做事细致，较强的沟通协作能力和快速学习能力,"移动互联网,文娱丨内容",2000人以上,spark,上海
资深后端应用工程师,https://www.lagou.com/jobs/6943986.html,浦东新区,30k-45k,美银宝网络信息服务（上海）有限公司,3-5年,硕士,外企职业发展前景好,"You will closely work with the various world-class data driven e-payment related businesses by using the cutting-edge technologies and advanced data solution. E.g., risk control, customer services, privacies and etc.  You will face the complex big data challenges or problems for reg-tech industry domain, which turns the big data to more valuable business insights, like customer profiling, risk assessment/vetting and so on. You will develop the enterprise-level algorithms and solutions for huge amount of data, various types of data for more business insights. o    Works with PayPal business units and Product Dev teams to design, develop and deliver solutions on one of the largest data platforms in the world. Design and develop prototypes for innovative ideas.Join in the design and development of applications, to support PayPal business units for compliance and risk management, fraud detection, business insights, predictive analysis, etc.Collaborate with other teams or groups to identify challenges and design solutions. Basic QualificationsMajor in Computer Science or EngineeringSolid knowledge and at least 5-year experience in Java development and software engineering.Solid knowledge and experience in basic algorithms.Familiar with web related frameworks.Good understanding of database principles and SQL beyond just data access.Analytical thinking and problem-solving skills.Excellent oral and written communication skills in English. Preferred QualificationsExpert in multiple programming/scripting languages, including Unix/Linux shell scripting, Perl, Python, C++, Java, Python, Ruby, Scala and etc.Familiar with various big data technologies, open source data processing frameworks. E.g., Spark, Hadoop, HBase, Elastic Search, Pig, Hive, and so on.Familiar with frontend development, e.g. html, javascript, etc.Knowledge on the following business domains: Risk, Payments, e-commerce","移动互联网,金融",2000人以上,spark,上海
数据开发工程师,https://www.lagou.com/jobs/7158580.html,浦东新区,20k-40k,美银宝网络信息服务（上海）有限公司,3-5年,本科,外企福利好，发展前景大,"The Data Engineer will be based out of Shanghai office and will support in the development and execution of strategic transformation programs & initiatives, strategic engineering architecture design, resource allocation, and platform performance monitoring.  Ideal candidate is a technologist who believes that use of technology is in its infancy and the best is yet to come. The nature of role is strategic, analytical and highly collaborative, working with team members across the World and as a liaison for Global projects. Responsibilities: ·       Build scalable systems, lead technical discussions, participate in code reviews, guide the team in engineering best practices. Must be able to write quality code and build secure, highly available systems. 75% of the job requires production quality coding.·       Provide technical insights and contribute to the definition, development, integration, test, documentation, and support across multiple platforms ·       Highly detailed with a systematic approach, sense of responsibility and strong, positive customer focus. ·       Must be results focused and highly energetic to drive the defined team and organizational goals·       Establish a consistent, project management framework and development processes to deliver high quality software, in rapid iterations, for business partners in multiple geographies·       Manage a team that designs, develops, troubleshoots and debugs software programs for databases, applications, tools, networks etc.·       Must have demonstrably strong interpersonal and communication skills (both written and verbal), to include speaking clearly and persuasively in positive or negative situations·       Experienced in balancing production platform stability, feature delivery, and retirement of technical debt across a broad landscape of technologies Qualifications:·       Undergraduate degree in Computer Engineering or equivalent from a leading university and preferably with a Masters or MBA·       5+ years of post-college working experience as a developer and architect in Engineering, or Data-Mining organization·       4+ years of Hadoop / ETL experience is required·       4+ years of strong SQL working experience is required·       4+ years of SPARK/HIVE experience is preferred·       2+ years of Linux/Unix/Python coding experience (including scripting) is required·       Strong conceptual and creative problem-solving skills; ability to work with considerable ambiguity; ability to learn new and complex concepts quickly. Relentlessly resourceful and scrappy·       A great communicator, strong project management skills, and superb attention to details·       Mandarin and English speaking mandatory","移动互联网,金融",2000人以上,spark,上海
大数据算法工程师,https://www.lagou.com/jobs/6740581.html,徐汇区,15k-30k,久远谦长（北京）技术服务有限公司,不限,本科,福利待遇优厚，发展空间大，团队氛围好,【职位描述】：* 负责算法工程落地；* 负责算法产品的研究和开发； 【任职资格】：* 计算机科学、应用数学、统计学、经济学、物理学、天文学、商业分析、信息系统、数据科学或相关专业本科或以上学历；* 优秀的学习能力与发现、分析并解决问题的能力；* 良好的团队合作精神与沟通能力； 【技能要求】：* 具备良好的表达能力；* JAVA基础扎实，有相关开发或者实习经验，熟悉IO、多线程、MQ、数据结构与设计模式等；* 熟练掌握Hadoop/Hive/Spark，对于Spark优化等有研究者优先；* 了解Python和Tensorflow生态者优先 【公司介绍】：-麦肯锡和华为惠普联合团队• 由多位前麦肯锡合伙人以及华为惠普核心工程高管联合创立，打造精品管理咨询传承与科技创新品牌• 同时拥有优质咨询项目资源、丰富咨询经验，及数字化赋能的精尖技术能力，建立从咨询建议到产品/解决方案的全面商业服务模式• 约300位咨询顾问、数据科学家、软硬件工程师常驻北京上海和成都 -多行业多商业领域覆盖•主要服务于企业客户，通过结合管理咨询、大数据分析、算法建模与工程落地的能力帮助企业客户实现业务增长•行业覆盖消费品、零售、金融、互联网、医疗与媒体等•与多行业领先企业深度合作，建立长期合作关系，如沃尔玛（获沃尔玛年度最佳供应商称号）、欧莱雅、联合利华、中国农业银行、腾讯、京东、美团等 -精尖的数据分析/算法/工程师团队-• 具备数据清洗与挖掘、算法模型和语义分析方面行业领先技术水平与能力• 具备根据客户业务方向搭建中台/后台的工程技术能力与丰富的项目经验• 具备广受行业认可的成熟产品（含已申请专利技术），帮助客户实现数据驱动的效率提升 -富有竞争力的职业发展与薪酬福利保障•注重人才培养，提供定期培训分享及深度参与项目机会，加入团队的年轻小伙伴们再也不用担心自己沦为职场“小螺丝钉”•注重员工成长空间，每年二次全员review，半年即有机会享受升职加薪•注重福利保障，包括：五险一金、全额理赔商业补充医保、超长带薪年假、超长带薪病假、书费报销、打车报销、无限量零食饮料畅吃、国内外团建旅游等,"企业服务,数据服务",50-150人,spark,上海
数据分析师,https://www.lagou.com/jobs/6969870.html,徐汇区,12k-18k,久远谦长（北京）技术服务有限公司,不限,本科,福利待遇优厚，发展空间大，团队氛围好,【职位描述】：-能够在多变的客户环境及系统中准确获取、加工、分析高度复杂的数据；-负责ETL处理、代码编写、数据仓库的建立及维护、数据可视化的实现。【任职资格】：-计算机科学、应用数学、统计学、经济学、物理学、天文学、商业分析、信息系统、数据科学或相关本科或以上学历； -良好的团队合作精神与沟通能力，做事细心认真。【技能要求】：-具备ETL、数据统计的相关经验，对spark有一定了解；-能够熟练使用数据分析相关工具平台（Python\SQL）；-有英语阅读能力。【公司介绍】： -麦肯锡和华为惠普联合团队• 由多位前麦肯锡合伙人以及华为惠普核心工程高管联合创立，打造精品管理咨询传承与科技创新品牌• 同时拥有优质咨询项目资源、丰富咨询经验，及数字化赋能的精尖技术能力，建立从咨询建议到产品/解决方案的全面商业服务模式• 约300位咨询顾问、数据科学家、软硬件工程师常驻北京上海和成都-多行业多商业领域覆盖•主要服务于企业客户，通过结合管理咨询、大数据分析、算法建模与工程落地的能力帮助企业客户实现业务增长•行业覆盖消费品、零售、金融、互联网、医疗与媒体等•与多行业领先企业深度合作，建立长期合作关系，如沃尔玛（获沃尔玛年度最佳供应商称号）、欧莱雅、联合利华、中国农业银行、腾讯、京东、美团等-精尖的数据分析/算法/工程师团队-• 具备数据清洗与挖掘、算法模型和语义分析方面行业领先技术水平与能力• 具备根据客户业务方向搭建中台/后台的工程技术能力与丰富的项目经验• 具备广受行业认可的成熟产品（含已申请专利技术），帮助客户实现数据驱动的效率提升-富有竞争力的职业发展与薪酬福利保障•注重人才培养，提供定期培训分享及深度参与项目机会，加入团队的年轻小伙伴们再也不用担心自己沦为职场“小螺丝钉”•注重员工成长空间，每年二次全员review，半年即有机会享受升职加薪•注重福利保障，包括：五险一金、全额理赔商业补充医保、超长带薪年假、超长带薪病假、书费报销、打车报销、无限量零食饮料畅吃、国内外团建旅游等,"企业服务,数据服务",50-150人,spark,上海
数据库挖掘工程师,https://www.lagou.com/jobs/6597327.html,虹口区,25k-40k,众安在线财产保险股份有限公司,3-5年,本科,福利待遇好、扁平化管理,"岗位职责：1. 负责海量数据的分析处理，结合公司业务需求和行业趋势，探索与研究有效的数据模型；2. 通过聚类分析、图挖掘与社交网络分析等方法，进行贷前反欺诈, 智能催收等功能实现；3. 基于信贷审批数据和征信数据源，应用逻辑回归、随机森林、XGBoost等机器学习算法建立风险预测模型，帮助金融机构构建基于大数据的信用风控模型；4. 通过金融数据库或爬虫获取互联网上特定信息，并利用自然语言处理技术进行解析，建立机器学习模型，分析特定领域、行业或主体的风险指数。任职标准：1. 硕士及以上学历，计算机、数学或统计相关专业，一年及以上互联网行业数据挖掘、算法相关工作经验者优先；2. 对机器学习和大数据行业充满兴趣，愿意不断学习新的知识；3. 精通数据挖掘算法及其原理，对常见分类聚类算法—LR、GBDT、XGBoost、GMM、DBSCAN等有很好的理解；4. 熟悉机器学习算法模型的构建流程；5. 熟练使用Python、SQL，有使用Sklearn、Pandas等常见python包的经验； 对大数据平台Spark，Hadoop有一定的了解；6. 具有良好的逻辑分析能力、沟通能力和文字表达能力，良好的执行力；7. 能够积极创新， 乐于面对挑战，负责敬业,优秀的团队合作精神；诚实， 勤奋， 严谨；",金融,2000人以上,spark,上海
大数据工程师实习生 (MJ000623),https://www.lagou.com/jobs/7210153.html,徐汇区,3k-5k,星环信息科技（上海）有限公司,应届毕业生,本科,大数据领航者+可转正+双休弹性工作制,"岗位职责：1、SLA：推进产品问题解决，保障公司内部 SLA 流程机制;2、AIOPS 运营：参与问题复盘，分类分级，运营产品使用与诊断知识库、跟进汇总产品版本已知 问题和 PATCH;3、巡检报告分析系统：AIOPS 中集成分析系统，对客户的巡检报告进行分析，披露潜在风险， 并生成建议措施，并在系统提供跟踪能力。4、AIOps、巡检分析、巡检工具等系统开发工作5、合作伙伴的解决方案对接和验证岗位要求：1、计算机或相关专业本科（或以上）学历；2、掌握C/C++,Java,Python等任一编程语言，java优先;3、熟悉Linux操作系统和shell脚本编写；4、熟悉SQL语言，有常用数据库oracle、mysql等基础；5、了解Hadoop，熟悉Hadoop，HBase，Hive，Spark基本使用优先；6、熟悉Docker/Kubernetes原理知识及基本操作者优先；7、做事认真负责，沟通能力良好，自学能力较强你将获得：大数据相关：**个月：通过TU相关大数据课程培训及组内培训并通过考试；掌握集群安装、部署、升级，掌握k8s基本使用，大致了解各组件的使用场景。撰写日报。第二个月：深入了解组件知识，技术架构，原理，典型使用场景和运维场景。第三个月及以后：能够依靠个人技术的成长，借助知识库和工具解决组件问题，参与技术方案对接和原型验证。",数据服务,500-2000人,spark,上海
数据工程师实习生 (MJ000627),https://www.lagou.com/jobs/7217126.html,徐汇区,3k-5k,星环信息科技（上海）有限公司,应届毕业生,本科,大数据领航者+可转正+双休弹性工作制,"岗位职责：1. 实施大数据/数据云产品的产品功能验证与性能验证2. 制定大数据/数据云产品测试方案，设计测试用例及测试数据3. 基于开源大数据产品进行功能、性能、解决方案的分析与对比4. 梳理大数据/数据云产品的最佳实践方案并整理相应方案文档5. 对项目问题进行跟踪分析和报告，推动产品验证中发现问题及时合理地解决6. 管理运维大数据/数据云集群岗位要求：计算机或相关专业本科（或以上）学历；掌握C/C++,Java,Python等任一编程语言;熟悉Linux操作系统和shell脚本编写；熟悉SQL语言，有常用数据库oracle、mysql等基础；了解Hadoop，熟悉Hadoop，HBase，Hive，Spark基本使用优先；熟悉Docker/Kubernetes原理知识及基本操作者",数据服务,500-2000人,spark,上海
数据仓库架构师,https://www.lagou.com/jobs/7146781.html,黄浦区,30k-45k,众安在线财产保险股份有限公司,5-10年,本科,"上市公司,互联网保险,六险一金,福利完善",工作职责：1、负责众安保险内部数仓各层逻辑模型的设计、建设与维护，构建可扩展的数据仓库公共模型2、负责公司数据处理流程的优化、定位并解决有关技术问题3、对接公司财务、精算、运营等团队，协调并满足各部门对于各维度数据的需求4、参与制定公司与事业部数仓规划、数据研发规范、以及数据治理与指标的管理方案岗位要求：1、5年以上数据仓库工作经验，熟悉数据仓库模型设计方法论，有实际搭建公司层级数仓的经验，有互联网公司或者金融企业数仓建设经验优先2、精通数据仓库有关领域知识，例如元数据管理、主数据管理、ETL工作流、SQL性能调优等3、精通SQL、熟悉Shell、具备海量数据加工经验，有阿里云MaxCompute工作经验优先、熟悉Hive/Flink/Spark等开源大数据工具优先4、有较强的问题抽象、概括、总结能力，独立思考并能以产品的思路提出解决方案5、具有较好的沟通理解能力，团队协作和创新能力6、有一定团队管理经验优先。,金融,2000人以上,spark,上海
广告策略算法工程师,https://www.lagou.com/jobs/6856499.html,闵行区,30k-60k,上海触乐信息科技有限公司,3-5年,本科,美股上市 牛人团队 亿级日活 福利待遇佳,岗位职责：1、利用数据挖掘和机器学习方法设计和优化广告变现产品策略；2、参与用户、素材画像、商品属性等方面的海量数据清洗和特征工程，为广告精准定向提供数据支撑；3、参与各类排序、回归、分类、和优化算法的开发与迭代，以及在线serving；4、应对全球化，多数据中心的技术挑战，研发全球一体的广告系统；5、研究并解决的在线广告生态体系中涉及的各种问题，更好地服务各类型广告主；任职要求：1、具备相关3年以上从业经验，计算机、数学等相关专业本科及以上学历；2、有数理分析方面良好的素养以及数理统计基础，对数据结构和算法设计有较为深刻的理解，具备编写复杂算法的能力；3、熟练掌握数据挖掘、机器学习、优化算法的基础理论和方法，了解Embbeding等方法理念；4、丰富的海量数据处理和挖掘经验，熟练使用Hive、Hadoop、Spark等工具；5、良好的编程功底，精通至少一门面向对象编程语言（golang、python、c/c++），熟悉Linux平台；6、良好的英文文献阅读能力，有算法调研与实现经验；7、对创新和挑战的工作有激情，有良好的沟通能力和团队管理能力，具备出色的规划、执行力、团队责任感以及优秀的学习能力,"移动互联网,数据服务",500-2000人,spark,上海
广告策略算法专家,https://www.lagou.com/jobs/6332341.html,闵行区,60k-100k,上海触乐信息科技有限公司,5-10年,本科,美股上市 牛人团队 亿级日活 福利待遇佳,岗位职责：1、利用数据挖掘和机器学习方法设计和优化广告变现产品策略；2、开发和实施可并行的排序、回归、分类、和优化算法；3、提升广告CTR/CVR模型预估精度，提高在线广告的相关性、用户体验、投放效果及变现能力；4、负责流量控制、广告pacing算法、广告竞价机制的研究与实现；5、应对全球化，多数据中心的技术挑战，研发全球一体的广告系统；6、研究并解决的在线广告生态体系中涉及的各种问题，更好地服务各类型广告主；任职要求：1、具备相关4年以上从业经验，计算机、数学等相关专业本科及以上学历；2、熟悉计算广告理论，从事过广告竞价机制及预估模型优化相关工作；3、有数理分析方面良好的素养以及数理统计基础，对数据结构和算法设计有较为深刻的理解，具备编写复杂算法的能力；4、熟练掌握数据挖掘、机器学习、优化算法的基础理论和方法；5、丰富的海量数据处理和挖掘经验，熟练使用Hive、Hadoop、Spark等工具；6、良好的编程功底，精通至少一门面向对象编程语言（golang、python、c/c++），熟悉Linux平台；7、良好的英文文献阅读能力，有算法调研与实现经验；8、对创新和挑战的工作有激情，有良好的沟通能力和团队管理能力，具备出色的规划、执行力、团队责任感以及优秀的学习能力。,"移动互联网,数据服务",500-2000人,spark,上海
系统工程师,https://www.lagou.com/jobs/7204351.html,浦东新区,20k-35k,上海擎创信息技术有限公司,5-10年,本科,绩效奖金 期权激励 弹性工作 扁平管理,岗位职责：    1、 售前协作：负责配合售前顾问完成智能运维（AIOps）项目的实施方案等；    2、 现场实施：负责完成AIOps项目的调研、设计、实施、培训和上线等；    3、 产研协作：负责提取AIOps项目中客户对于产品的需求和改进意见并反馈给产研团队等；    4、 项目协作：负责编制AIOps项目的实施文档和知识文档，并在项目组之间分享经验等；    5、 客户关系：负责配合项目经理解决客户碰到的问题，提高客户满意度等；    任职要求：    1、计算机相关专业，5年以上工作经验，本科及以上学历；    2、3年及以上linux相关工作经验（linux测试／linux开发皆可）   3、熟练掌握一门脚本／开发语言（python／shell／Java／C／Scala），熟练掌握SQL数据库语言，如HiveSQL/Mysql/Sqlserver    4、熟悉Hbase/Hive/Hadoop/Spark或等主流分布式开发平台，有高性能集群设计和开发经验，对分布式计算的架构有深入的理解者优先。    4、有数据挖掘算法实施经验，熟练掌握大规模数据挖掘、机器学习优先。    5、对技术有激情，喜欢钻研，能够快速接受和掌握新技术，有良好的团队合作精神、能够承受较大的工作压力。,"企业服务,数据服务",50-150人,spark,上海
大数据运维工程师,https://www.lagou.com/jobs/7042852.html,浦东新区,18k-30k,上海擎创信息技术有限公司,3-5年,本科,绩效奖金 期权激励 弹性工作 扁平管理,岗位职责：    1、 售前协作：负责配合售前顾问完成智能运维（AIOps）项目的实施方案等；    2、 现场实施：负责完成AIOps项目的调研、设计、实施、培训和上线等；    3、 产研协作：负责提取AIOps项目中客户对于产品的需求和改进意见并反馈给产研团队等；    4、 项目协作：负责编制AIOps项目的实施文档和知识文档，并在项目组之间分享经验等；    5、 客户关系：负责配合项目经理解决客户碰到的问题，提高客户满意度等；    任职要求：    1、计算机相关专业，3年以上工作经验，本科及以上学历；    2、3年及以上linux相关工作经验（linux测试／linux开发皆可）    3、熟练掌握一门脚本／开发语言（python／shell／Java／C／Scala），熟练掌握SQL数据库语言，如HiveSQL/Mysql/Sqlserver    4、熟悉Hbase/Hive/Hadoop/Spark或等主流分布式开发平台，有高性能集群设计和开发经验，对分布式计算的架构有深入的理解者优先。    5、对Elasticsearch和Kafka等开源组件有较丰富的运维经验。    6、3年以上ES及Kafka维护经验，有大数据量大规模集群维护经验者优先。    7、有数据挖掘算法实施经验，熟练掌握大规模数据挖掘、机器学习优先。    8、对技术有激情，喜欢钻研，能够快速接受和掌握新技术，有良好的团队合作精神、能够承受较大的工作压力。,"企业服务,数据服务",50-150人,spark,上海
JAVA开发工程师（大数据业务）,https://www.lagou.com/jobs/6875144.html,徐汇区,10k-20k,东方财富信息股份有限公司,1-3年,本科,上市公司,,金融,2000人以上,spark,上海
数据平台工程师,https://www.lagou.com/jobs/7005339.html,杨浦区,15k-25k,达疆网络科技（上海）有限公司,1-3年,本科,平台稳定，团队快速发展,工作职责：1、参与数据仓库和大数据平台的环境搭建、架构设计和程序开发2、参与大数据平台的自主组件的研发及日常运行维护工作3、参与离线计算基础平台的封装及开放工作4、参与数据服务总线的统一封装及可用性保障5、基于公司业务，构建模型算法，发掘数据的价值5、满足公司各部门日常的数据需求职位要求：1、本科及以上学历，计算机、软件工程或相关专业出身，工作3年以上2、有扎实的Java基础，熟悉Spring MVC、Spring Boot框架及MyBatis框架3、负责过某个大数据平台的系统研发，如调度系统、元数据、数据交换、数据质量、报表等4、熟悉主流大数据计算和存储引擎，如Hive、Spark、Presto、Flink、Hbase、HDFS及ES等5、熟悉基于Hadoop的数据仓库建设过程及原理6、积极主动参与讨论、发现并解决问题7、学习能力强，拥有优秀的逻辑思维能力、良好的理解和表达能力、较强的抗压能力8、能迅速融入团队，与其他团队成员保持良好的合作加分项：-有大型互联网公司流量项目开发经验者尤佳-有Linux操作系统及Tomcat中间件运维经验-熟悉CDH集群管理并有kerberos及sentry权限管理经验-有过Hadoop开源项目经历,消费生活,2000人以上,spark,上海
Golang开发工程师,https://www.lagou.com/jobs/5927083.html,虹口区,20k-40k,奇虎360科技有限公司,5-10年,本科,六险两金 年终奖 牛人云集 带薪年假,工作职责：1. 负责多个项目的后端应用与平台开发；2. 根据用户需求或产品功能进行模块细部设计与应用平台功能开发；3. 对接各产品，第三方平台，完成整体解决方案集成工作。任职要求：1. 本科或以上学历，计算机相关专业，3年以上相关工作经验；2. 具备良好的计算机基础，熟悉常见数据结构与算法；3. 熟练使用Golang/Python/PHP/C++中的至少一门编程语言；4. 熟悉常见数据库的原理及使用，如Redis/MySQL/MongoDB等；5. 熟悉计算机网络，熟悉多种网络协议，有丰富的开放性API开发经验；6. 良好的分析及解决问题的能力，良好的团队合作精神。加分项：1. 了解Kafka/ES/HBase/Spark的使用及相关知识；2. 了解网络安全知识；3. 了解Docker/Swarm/Kubernetes的使用及相关知识。,信息安全,2000人以上,spark,上海
Java高级开发工程师,https://www.lagou.com/jobs/7055881.html,徐汇区,20k-30k,东方财富信息股份有限公司,3-5年,本科,上市公司，大平台,"工作职责：1、参与业务需求分析，参与确定技术方案；2、根据设计要求进行中后台应用的开发、调试与集成；3、负责中后台独立功能模块的需求分析、技术设计和开发任务；4、参与对运行系统的性能调优、BUG分析及修正等优化工作；5、完成公司交办的其他工作。任职资格：1、全日制统招本科及以上学历，计算机相关专业；2、3年以上基于java的服务器端系统开发经验，熟悉面向对象编程思想、常用设计模式；3、牢固掌握Java基础，包括集合，io流，多线程等； 4、熟练掌握Spring Cloud、Dubbo(RPC)、SOFA等开源框架，熟悉SSM整合技术；5、有丰富使用mysql，Oracle，sql server，mongoDB等数据库的经验；6、熟悉linux/UNIX等操作系统，有JVM性能调优经验者优先；7、有Hadoop, HBase, Hive, Spark, Storm等使用经验者优先；8、有信息流、实时运营、资讯加工、推荐算法等经验者优先；9、有高并发、高吞吐、强事务、高秒杀、中间件等经验者优先；10、有写过开源项目、技术框架、技术专利等项目经验者优先。",金融,2000人以上,spark,上海
数据仓库工程师,https://www.lagou.com/jobs/6523918.html,浦东新区,20k-30k,达疆网络科技（上海）有限公司,3-5年,本科,团队氛围好，技术发展空间大,工作职责：-参与数据仓库主题的规划，负责某个具体业务方向的数仓建设-负责数据仓库及数据集市的数模设计及元数据完善-负责数据仓库ETL开发，包括离线、准实时及实时的任务开发-负责数据集市的报表数据开发及接口数据开发-帮助分析师团队及业务团队熟悉并理解数据仓库模型-参与大数据部门的日常数据运行保障，提出改进意见职位要求：-本科及以上学历，计算机、软件工程或相关专业出身，工作3年以上-较好的数据仓库理论基础，良好的业务素养，愿意持续在数仓方向发展-具有Hadoop大数据相关项目开发与产品应用经验-有较好的Java或者SCALA基础，扎实的SQL基础-熟练掌握Hbase、Hive、Spark、Presto等大数据技能-熟悉Flume与Kafka等数据采集和消息通道技术-熟悉Spark Streaming/Flink等流计算技术-熟悉MySQL、Redis、ES、Druid、Clickhouse等数据引擎-熟悉Linux环境及脚本开发（Python/Shell等）-学习能力强，有较强的抗压能力-能迅速融入团队，积极主动参与讨论、发现并解决问题加分项：-有电商零售或者物流相关数据仓库建设-参与过重要数据产品的数据解决方案实施,消费生活,2000人以上,spark,上海
资深大数据运维工程师,https://www.lagou.com/jobs/6389696.html,杨浦区,30k-60k,上海哔哩哔哩科技有限公司,5-10年,本科,"公司好,发展快,氛围好,空间大,领导好",工作职责：1.    维护大数据系统：Hadoop集群及HBase/Hive集群；2.    大数据资源的调度和优化；3.    数据平台各种组件的docker容器化改造；4.    负责公司大数据系统各个组件（包括Hadoop集群，HBase集群，Hive集群等）的业务监控，数据迁移，持续交付，应急响应，容量规划等。职位要求：1.    计算机相关专业，本科以上学历，有三年以上大数据平台运维经验；2.    深入理解linux系统，运维体系结构，精于容量规划、架构设计、性能优化；3.    熟悉主流大数据计算引擎(Hadoop、Spark等），深刻理解内部机制和原理；4.    熟练掌握Hdfs、Hive、Hbase、Sqoop、Spark等组件，具有较大规模集群（节点数大于50）的设计、部署和调优经验；5.    能维护Hadoop源码，有Hadoop 源代码BUG修复或者源代码优化经验者优先；6.    熟练掌握python、shell。,"移动互联网,文娱丨内容",2000人以上,spark,上海
数据仓库专家,https://www.lagou.com/jobs/7087414.html,长宁区,25k-35k,携程计算机技术（上海）有限公司,5-10年,本科,品牌雇主 潜力行业 活力团队 发展空间,"职责描述：1、基于互联网行业特点构建企业级数据仓库架构,建设PB级共享数据平台2、负责数据平台相关数据研发及管理工作，参与制定EDW相关规范并推动实施落地3、对海量数据处理的需求进行评估及方案设计实现4、其他数仓及风险管理数据相关工作任职要求：1、具备5年以上数据仓库开发及管理经验，3年以上互联网/电商行业经验2、精通数据仓库建设方法论，有大型数据仓库建设项目经验（PB级以上）3、熟悉HADOOP、HIVE、HBASE、SPARK、FLUME等工作原理，精通HiveSQL，有较丰富的HiveSQL性能调优经验4、至少熟练使用Shell、Python、Perl等脚本语言之一5、工作认真、负责，具备良好的团队合作、分析及沟通能力6、有金融相关知识和机器学习模型项目经验、处理大量互联网复杂业务关系经验者优先",旅游,2000人以上,spark,上海
Hadoop架构师,https://www.lagou.com/jobs/6842903.html,长宁区,40k-60k,上海远景科创智能科技有限公司,5-10年,本科,上班弹性 福利好 奖金多 技术好,"职位描述：职位描述：1、负责大数据架构设计、技术选型、技术难点攻关；2、负责大数据产品在企业中规划与落地；3、负责大数据安全技术方案与落地职位要求：1、具备扎实的计算机理论基础, 对数据结构及算法有较强的功底。2、精通Java语言编程，具备优秀的系统Debug/Profiling能力和经验，熟悉常见的面向对象设计模式，具备优秀的系统架构设计能力。3、精通多线程编程。有分布式开发经验值优先。4、精通HDFS/Yarn/HBase/Hive/Spark中任意一种，有系统的源码阅读经历。有开源社区开发经验者优先。5、熟悉常用的大数据组件，如：Kafka、Zookeeper、Ranger、KMS、Kylin、ElasticSearch、Ozone等。6、熟悉Kubernetes者优先","人工智能,物联网",500-2000人,spark,上海
数据平台架构师,https://www.lagou.com/jobs/6403037.html,长宁区,30k-55k,上海远景科创智能科技有限公司,5-10年,本科,上班弹性 福利好 奖金多 技术好,"岗位职责：1.实现PB级数据生命周期管理2.确保数据采集与储存质量，制定数据采集与分发游戏规则3.支撑TB级别的日终数据处理能力，以及实时校验转化处理与数据分发能力4.确保数据仓库稳定可用，制定灾备与巡检策略5.为数据分析团队提供高效etl界面6.为业务团队提供实时与批量数据api访问层任职要求：1.重点大学硕士研究生以上学历2.精通java3.精通关系数据以及nosql数据工具至少一种产品，如mysql，redis等4.了解hadoop，spark, zookeeper设计原理，并具有实操经验5.熟悉linux操作系统工作原理，具备一定的系统维护能力","人工智能,物联网",500-2000人,spark,上海
大数据产品经理,https://www.lagou.com/jobs/7086314.html,浦东新区,15k-30k,上海帆一尚行科技有限公司,3-5年,本科,"汽车云,发展空间大,扁平化管理","职责描述：1、参与大数据平台的整体设计和核心模块研发；2、负责完成大数据平台存储计算分离的架构设计和实现；3、实现计算资源弹性扩容，提高资源利用效率，降低成本；4、维持线上服务高效稳定，支撑业务和数据量的快速扩张。任职要求：1、熟练掌握 Golang 语言开发，具备 Python，Java 等其他一种或多种语言开发经验；2、熟悉 Kubernetes/Docker生态，熟练掌握Kubernetes容器调度相关技术和相关项目代码实现；3、有hadoop和spark实际开发经验。了解大数据组件的使用限制和应用场景，如hdfs,yarn,hbase,hive,flume,kafka,zk,impala,Alluxio等。4、熟悉linux常用命令，有实际CDH或HDP或apache版本的hadoop部署经验者优先；5、有大数据组件容器化经验优先；6、本科及以上学历，计算机及软件等相关专业，两年以上大数据相关工作经验。","企业服务,数据服务",50-150人,spark,上海
AI系统工程师,https://www.lagou.com/jobs/7086391.html,浦东新区,20k-40k,上海帆一尚行科技有限公司,5-10年,本科,"汽车云,发展空间大,扁平化管理",职责描述：1，上汽iGear AI平台的设计与开发，包括海量数据存储平台、标注平台、训练平台、仿真平台等模块的开发设计2，图像和视频自动预标注、图像算法开发、工业质检、模型推理服务实施等算法类开发3，大数据存储和分析、数据分析和挖掘4，自动驾驶平台、智能网联、智能制造等业务相关项目任职要求：1，有扎实的服务开发基本功，熟悉至少一门编程语言(Java/Python/Go/C++)和一个Web框架，熟悉kubernetes概念和使用优先2，熟悉至少一个机器学习框架(Tensorflow/Pytorch/Mxnet等)，了解主流的机器学习算法，了解基本深度学习算法，特别是图像处理的相关算法，有较强的工业实践能力，参与过算法实施项目优先，熟悉Cuda编程优先3，熟悉大数据技术栈开发优先(Hadoop栈/Spark/Storm/Flink)4，有责任心，能够快速学习，勇于面对新的技术挑战,"企业服务,数据服务",50-150人,spark,上海
c++开发工程师,https://www.lagou.com/jobs/7192793.html,长宁区,25k-35k,北京京东世纪贸易有限公司,3-5年,本科,发展好,工作内容： 1、负责团队的技术选型、开发、架构及风险评估、性能优化等工作； 2、负责应用服务系统开发工作、后台风控系统开发工作； 3、根据开发规范与流程独立完成模块的设计、编码、测试以及相关文档; 4、参与软件需求与设计审核和代码检查； 5、遵循公司技术标准、规范，高质量完成设计、开发任务；任职资格： 1、本科及以上学历，计算机相关专业，优先考虑211及以上学校毕业生。3年以上C++开发经验、熟悉C++ Web开发框架，操作系统、网络原理，包括内存模型、性能优化以及可用性保证； 2、精通使用关系型数据库MYSQL或者ORACLE，熟悉大数据相关技术如Hadoop、Spark、Kafka，Hive、Redis，HBase、Elasticsearch等，并有实际工作经验，对开源社区有贡献优先； 3、具有良好的文档撰写能力和编码规范，熟悉软件开发规范与流程，有团队协作意识； 4、具有较强的团队合作能力和责任心，能够主动高效的完成任务，性格开朗，乐于沟通，具有良好的学习能力，敢于创新和接受挑战。,电商,2000人以上,spark,上海
JAVA软件开发工程师,https://www.lagou.com/jobs/6878333.html,长宁区,20k-30k,北京京东世纪贸易有限公司,3-5年,本科,平台,职责介绍：1、负责工程的技术选型、开发、架构及风险评估、性能优化2、负责应用服务系统开发工作、后台业务系统开发；3、根据开发规范与流程独立完成模块的设计、编码、测试以及相关文档;4、参与软件需求与设计审核和代码检查；5、遵循公司技术标准、规范，高质量完成设计、开发任务；任职要求：1、本科及以上学历，计算机相关专业，优先考虑211及以上学校毕业生。3年以上JAVA开发经验、熟悉JAVA Web开发框架，JVM原理，包括内存模型、类加载机制以及性能优化；2、精通使用关系型数据库，熟练大数据相关技术如Hadoop、Spark、Kafka，Hive、Redis，HBase、Elasticsearch等，并有实际工作经验，对开源社区有贡献优先；3、熟悉Hadoop相关技术，深刻理解MapReduce原理和过程；精通Hive SQL 和MySQL；4、具有良好的文档撰写能力和编码规范，熟悉软件开发规范与流程，有团队协作意识；5、具有较强的团队合作能力和责任心，能够主动高效的完成任务，性格开朗，乐于沟通，具有良好的学习能力，敢于创新和接受挑战。,电商,2000人以上,spark,上海
后端开发工程师,https://www.lagou.com/jobs/6488304.html,浦东新区,15k-25k,建信金融科技有限责任公司,5-10年,本科,五险一金，发展前景好,任职要求：1. 本科及以上学历，有3~5左右的java web开发经验。2. 熟练使用springboot，springcloud，springmvc，mybatis等开源框架。3. 有基于zookeeper开发分布式应用经验者优先。4. 熟悉hadoop，spark，flink等大数据框架者优先。,"金融,软件开发",2000人以上,spark,上海
前端开发工程师,https://www.lagou.com/jobs/6488271.html,浦东新区,15k-25k,建信金融科技有限责任公司,5-10年,本科,五险一金，发展前景好,职责描述：负责互联网+政务服务平台手机端或电脑端或移动端门户、各平台用户界面和管理界面的研发和测试。任职要求：岗位要求：1. 本科及以上学历，有3~5左右的java web开发经验。2. 熟练使用springboot，springcloud，springmvc，mybatis等开源框架。3. 有基于zookeeper开发分布式应用经验者优先。4. 熟悉hadoop，spark，flink等大数据框架者优先。,"金融,软件开发",2000人以上,spark,上海
数据平台工程师,https://www.lagou.com/jobs/6886115.html,浦东新区,25k-40k,上海尧信惠达信息科技有限公司,3-5年,本科,股东背景强大 发展前景好 有上市计划,岗位职责：1. 使用大数据相关的技术解决相关的业务问题；2. 开发并维护数据平台的产品和系统；3. 大数据平台的日常运维；4. 与业务部门密切配合，寻求数据层面的业务价值，利用数据分析结论推动产品优化；5. 研究大数据技术领域最新进展并结合业务需求进行合理的应用和实践。任职要求：1、全日制本科及以上学历，3年以上Java开发经验，计算机、软件工程等相关专业；2、了解分布式系统的基本原理和协议；3、有Hadoop使用经验，了解HDFS运行机制；4、有Spark使用经验，使用过Spark SQL和Spark Streaming并了解其原理；5、有HBase使用经验，了解HBase的各个模块，以及大致的工作流程；6、有图数据库Neo4j使用经验；7、有kafka/flume/hive/mongo/zk/sqoop/presto等大数据相关框架使用经验。,"金融,数据服务",50-150人,spark,上海
数据平台工程师,https://www.lagou.com/jobs/6886116.html,浦东新区,25k-40k,上海尧信惠达信息科技有限公司,3-5年,本科,股东背景强大 发展前景好 有上市计划,岗位职责：1. 使用大数据相关的技术解决相关的业务问题；2. 开发并维护数据平台的产品和系统；3. 大数据平台的日常运维；4. 与业务部门密切配合，寻求数据层面的业务价值，利用数据分析结论推动产品优化；5. 研究大数据技术领域最新进展并结合业务需求进行合理的应用和实践。任职要求：1、全日制本科及以上学历，3年以上Java开发经验，计算机、软件工程等相关专业；2、了解分布式系统的基本原理和协议；3、有Hadoop使用经验，了解HDFS运行机制；4、有Spark使用经验，使用过Spark SQL和Spark Streaming并了解其原理；5、有HBase使用经验，了解HBase的各个模块，以及大致的工作流程；6、有图数据库Neo4j使用经验；7、有kafka/flume/hive/mongo/zk/sqoop/presto等大数据相关框架使用经验。,"金融,数据服务",50-150人,spark,上海
Java（全链路监控方向）,https://www.lagou.com/jobs/6819210.html,虹口区,40k-70k,上海掌小门教育科技有限公司,5-10年,本科,奖金丰厚,"岗位职责1. 负责公司全链路分布式应用监控告警系统平台的规划，设计、研发、及推广。2. 构建从前端/移动端到服务端上下游全链路拓扑，提高业务线技术故障及时发现，及时排障的能力3. 持续优化监控告警平台，提高告警准确率，覆盖率，减少误报漏报3. 参与App、h5、pc多端性能监控平台建设推广4. 参与客户端android，ios相关视频组件埋点监控建设 职位要求：1.全日制本科以上学历，5年以上工作经验，3年监控告警平台设计开发经验2.熟悉Linux系统、常用Linux命令，熟练掌握Java/Go/Python/cpp 任意一种语言；3.熟悉CAT，Skywalking，Pinpoint，zipkin等主流分布式全链路跟踪系统中一种或几种，对CAT或者 Skywalking做过二次开发4. 熟悉ELK及相关技术：Logstash ,Filebeat，kafka，ElasticSearch，kibana，Grafana 等5. 了解Spring cloud微服务技术体系，了解Strom，Spark，flink等实时计算框架6. 对监控系统有比较深刻的理解，有监控产品平台思维6. 责任心强, 自我驱动, 强烈的 Owner 意识, 对结果负责, 良好的沟通与团队协作能力","移动互联网,教育",2000人以上,spark,上海
Java架构师（基础架构）,https://www.lagou.com/jobs/6821587.html,虹口区,30k-60k,上海掌小门教育科技有限公司,5-10年,本科,广阔的发展前景，领导nice,职责：1.负责基础架构部核心系统的技术选型，架构设计、研发、调优，解决开发中各种系统架构问题；2.负责核心基础组件研发如缓存，消息，数据中间件，日志监控等定制开发；3.负责项目中关键技术难点的攻关和预研；4.解决基础架构系统遇到的大数据量、高并发、高稳定性等带来的各种挑战及技术难关； 要求：1. 至少4年服务端开发经验，Java技术功底扎实，有多线程，NIO，集合，内存调优等技术的实际项目经验，了解技术的底层实现原理。2. 熟悉缓存（redis/Memcached），消息中间件(kafka/RocketMQ/rabbitMQ)，数据库中间件，zookeeper，Elasticsearch，spark，Hbase等互联网主流技术中的一种或多种的使用和底层实现原理。3. 熟悉主流微服务技术的架构方案和实现，有SpringBoot、SpringCloud等框架的搭建和使用经验，或者了解其实现机制和原理；4. 熟悉设计模式，有一定的抽象架构思维。5. 对基础架构方向感兴趣，对技术有探索专研精神。6. 有服务治理，全链路监控系统实际项目经验的优先。7. 阅读研究过某个主流中间件框架源码的优先。,"移动互联网,教育",2000人以上,spark,上海
AI高级算法工程师（广告算法方向）(J11868),https://www.lagou.com/jobs/6627274.html,浦东新区,20k-40k,上海喜马拉雅科技有限公司,3-5年,硕士,公司规模大 福利待遇好 晋升空间大,,"移动互联网,文娱丨内容",2000人以上,spark,上海
大数据高级开发工程师（推荐系统方向）,https://www.lagou.com/jobs/6627288.html,浦东新区,20k-40k,上海喜马拉雅科技有限公司,3-5年,本科,公司规模大 福利待遇好 晋升空间大,,"移动互联网,文娱丨内容",2000人以上,spark,上海
高级大数据开发工程师,https://www.lagou.com/jobs/7075116.html,浦东新区,17k-32k,中国电信股份有限公司云计算分公司,3-5年,大专,大数据 人工智能,岗位职责：1、负责大数据基础平台的组件研发与性能优化；2、负责大数据Pass平台、资源调度等容器相关服务的平台研发及应用研发；3、负责大规模数据集群的运维平台开发，包括大规模Hadoop集群的自动化、可视化、一体化部署、运维运营等；4、根据业务需求参与技术预研并推动技术落地。任职资格：1、全日制统招本科及以上学历，计算机类专业优先；2、五年以上软件研发经验，至少两年以上大数据相关系统研发经验；3、有扎实的Java语言基础，熟悉Linux系统，能够熟练使用shell/python/ansible脚本处理工具，具备成熟的调优经验；4、对大数据相关组件如HDFS、YARN、Ambari 、Spark、Hbase、Flink、Hive，Kafka等2至3种组件的架构与底层实现有一定理解；有开源社区参与经验、Kubernetes集群运维经验及相关的源码开发经验优先；5、诚实守信、作风踏实严谨、责任心强；具备良好团队协作能力精神；学习能力强，善于解决复杂问题；6、35周岁（含）以下，身心健康；7、过往工作业绩优秀者、有知名互联网/IT、AI、云服务等相关行业头部企业有工作经验者，年龄、工作年限可适当放宽。,数据服务,500-2000人,spark,上海
Java技术专家/高级技术专家P7P8,https://www.lagou.com/jobs/7160381.html,浦东新区,30k-60k,支付宝（杭州）信息技术有限公司,不限,本科,"期权激励,靠谱团队,技术驱动",团队简介：我们隶属于蚂蚁金服-技术风险部（不是安全风控，简介可参考蚂蚁金服公众号文章： https://mp.weixin.qq.com/s/RX_63WILQpd__DvzqdGwxA ），大部门的主要工作是负责蚂蚁全站系统的“高可用（从线程级到 IDC 级的故障自动感知定位和恢复决策）”和“资损防控（蚂蚁所有 BU 业务资金流的实时自动核对和快速止损）”这两个课题。 在蚂蚁金服这样庞大的系统部署规模和数据体量、频繁的新特性新功能变更频率、多 BU 并存乃至跨国的错综复杂的业务和资金流大背景下，可以预见这两项工作无法通过传统互联网公司堆人的方式快速应对，即便是很有经验的领域专家。所以大方向以数据驱动和智能化的思路来破局，一方面需要构建夯实且数据健全的基础平台设施，包括刻画整个蚂蚁生产环境的元数据，以及刻画每一笔业务请求的实时数据流，支撑全站全量数据的高可靠近线传输、组织、存储与计算。另一方面则需要结合场景去运用业界较为前沿的风险防控建模与算法理论经验，针对问题域的智能分析，达到人工辅助甚至自动决策执行。经过一段时间的探索与建设，我们已经有一个较好的起步和基础支撑，但从追求**的角度还有很多挑战尚未攻克。具体方向上区别于业务功能开发团队，我们主要面向蚂蚁全局构建基础设施平台，涉及到 Java 工程，大数据计算，海量数据存储，领域建模，图计算与算法应用等子领域。职位描述：1.负责蚂蚁金服技术风险数据基础设施的研发建设，包括刻画整个蚂蚁 SaaS/PaaS/IaaS 环境拓扑结构的元数据，以及刻画每一笔用户请求的实时数据流。2.对全链路稳定性和数据质量负责，进行实时监控，分析，最终提供保障数据的质量，包括低延时，高可用等指标。3.参与数据流建设，满足实时数据流上的各种复杂计算需求，包括图计算，多流合并，以及各种常见 transform 计算。4.参与蚂蚁双十一等大型活动，通过平台能力保障蚂蚁系统在极限压力下的高可用与资金安全。5.持续对接数据平台上的各类技术风险防控业务方，满足不断发展的业务需求。职位要求：1.扎实的计算机专业基础，包括算法和数据结构，操作系统，计算机网络，计算机体系结构，数据库等。2.扎实的 Java 或相关编程语言基础，良好的编程素养，对代码有美感和**的追求。3.理解实时流计算（ 比如 Spark/Storm/Flink ）或海量数据处理（ 比如 Hadoop/HBase/Hive ）、图计算相关经验优先考虑。4.强烈的技术热情和工作责任感，热衷于创新和分享，逻辑清晰并具备批判性思维能力和习惯。5.计算机软件或相关专业毕业，本科或以上学历； 211/985 优先。工作地点：上海，浦东新区南泉北路，支付宝大厦编程语言：Java招聘范围：社招（ P7P8 ）,"金融,移动互联网",2000人以上,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7127479.html,闵行区,15k-25k,上海电科电器科技有限公司,3-5年,本科,工业互联网，完善的薪酬福利体系，上市公司,"岗位职责：负责设计、实现和测试工业互联网系统中的大数据分析应用。岗位要求：1、计算机或相关专业，全日制本科及以上学历。2、3年以上Java、Python或Scala软件开发经验。3、熟悉MySQL、Oracle等关系型数据库，及MongoDB、Cassandra等非关系型数据库。4、 熟悉Hadoop、Spark、Flink等大数据组件和数据挖掘工具。5、熟悉Kettle、DataX等ETL工具。6、具备Linux, Windows等操作系统知识。7、了解Subversion, Git, Maven，Jira，Confluence等工具链。8、 高度责任感和团队合作精神。 薪资为平台发布需要，具体以实际面试情况为准！","人工智能,物联网",150-500人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7018906.html,黄浦区,10k-20k,武汉理工数字传播工程有限公司,5-10年,本科,16薪、补充医疗险、节日福利、周末双休,岗位要求：1. 负责各种网络资源数据的采集、清洗、整合和大数据的分布式存储；2. 负责大数据类产品的系统分析与架构设计，配合产品经理完成产品的快速研发与交付；3. 负责大数据平台各组件的性能优化工作和部分设计、开发文档的编写工作；4. 负责大数据项目的开发、维护等工作；5. 负责大数据相关数据架构规划、数据建模、数据库设计以及大数据产品研发工作，并为应用开发团队提供技术支持、模型分析；6. 熟悉Hadoop、Hive 、Spark、Hbase 、Storm、Flume、ElasticSearch、Neo4J、Kafka等框架组件，深刻理解分布式数据处理技术原理；7. 熟练掌握Java、Python、Scala等语言中的一种。岗位职责：1.5年以上相关工作经验；2.参与大数据分布式应用系统服务器端或客户端软件开发工作（需求开发、故障解决和性能优化等）；3.承担建设基于Hadoop/Spark生态的大数据离线/实时处理平台；4.参与业务数据、生产日志的抽取、转储、检索等相关工作；5.跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景。,"移动互联网,电商",150-500人,spark,上海
数据仓库工程师,https://www.lagou.com/jobs/7122969.html,静安区,15k-25k,上海定卓网络科技有限公司,5-10年,本科,五险一金、绩效奖金、定期体检、弹性工作,岗位职责：1.负责数据平台数仓的建设，包括离线、实时的数据架构、数据模型规划、数据质量保障；2 深入理解数据业务，分析用户需求，负责数据平台核心数据资产内容的设计与开发工作；3.数据仓库模型的ETL实施，ETL性能优化；4.针对数据一致性、准确性、及时性，制定数据管理与治理机制，监督保障数据的生产与运维；5.有机器学习相关经验优先；职位要求：1.从事数据仓库或挖掘领域，5年及以上工作经验，熟悉数据仓库模型设计与ETL开发经验，掌握维度建模设计方法，具备海量数据处理经验；2.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发工具与方法、数据质量、主数据管理；3.熟悉数据库相关技术，熟练运用SQL语言，能高效的与业务团队进行沟通；4.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验者优先，如DataStudio、Hdfs、MapReduce、Hive、Hbase、Kylin、Spark、Flink；5.对常规统计与机器学习问题具有一定的理解，熟悉常用的模型，有数据挖掘相关工作经验者优先；6.熟悉Linux系统，掌握一门或多门编程语言，如Java、Python、Shell；7.良好的数据敏感度，能从数据中发现问题并解释，较强的数据、平台、技术理解能力；8.良好的语言沟通协调能力、团队协作精神和自我驱动动力，对海量数据处理和分析有热情。,房产家居,15-50人,spark,上海
搜索算法工程师,https://www.lagou.com/jobs/7110301.html,黄浦区,40k-50k,行吟信息科技（上海）有限公司,5-10年,本科,弹性工作,【职位描述】1、负责小红书搜索NLP与排序算法方面工作2、包括query处理/理解、文本信息抽取、语义学习表示、相关性排序等相关算法任务【岗位要求】1、计算机／数学／统计学／模式识别相关专业，硕士以上或有3年算法工作经验以上；2、熟悉NLP、机器学习的理论基础，有搜索相关算法经验优先；3、具有优秀的编程能力，熟悉Python、Java以及常用脚本语言，熟悉深度学习框架譬如tensorflow、pytorch等4、有大规模并行计算/数据挖掘经验者优先，譬如hadoop/spark等5、责任心强，积极主动，有良好的沟通能力和团队合作能力。,消费生活,500-2000人,spark,上海
数据仓库研发工程师,https://www.lagou.com/jobs/6756376.html,徐汇区,13k-20k,东方明珠新媒体股份有限公司,3-5年,本科,国有上市公司 互联网传媒头部公司,工作职责：1.    负责数据采集和接入数据湖，开展业务数据质量探查；2.    负责数据中台数据仓库、数据集市的模型设计和搭建；3.    负责ETL流程的设计、开发和部署，特别是海量日志的处理、分析和挖掘；负责ETL数据准确性验证、ETL线上任务的优化和运维。任职资格：1.    全日制本科及以上学历，计算机或相关专业；2.    具有2年以上Java开发经验、1年以上Scala开发经验，具备基本的Python开发经验，精通SQL；3.    掌握Hadoop、Spark、Hive、Presto、Kafka等相关大数据技术，具备1年以上Spark ETL任务开发经验；4.    熟悉ETL开发过程和规范，至少熟悉一种调度工具(如Airflow)；5.    熟悉数据仓库理论，熟悉维度建模，至少具有2年大型数据仓库开发经验；6.    熟悉Oracle、MySQL或Redshift等关系型数据库，有较强的SQL编写能力；7.    有AWS，阿里云使用经验者优先；8.    有Spark Streaming、Flink实时数据处理经验者优先；,文娱丨内容,500-2000人,spark,上海
java工程师,https://www.lagou.com/jobs/6886259.html,徐汇区,15k-20k,东方明珠新媒体股份有限公司,3-5年,本科,国有上市公司 互联网传媒头部公司,此岗位为东方明珠新媒体旗下上海东方龙新媒体有限公司招聘岗位岗位职责1.      负责公司基于JAVA的应用系统开发；2.      负责解决开发过程中的技术问题；3.      负责技术文档编写和相关申报中技术文件提供；4.      参与系统产品开发小组，依据系统产品开发计划实施产品设计工作。任职资格1.     全日制本科及以上学历，计算机相关专业，3年以上Java开发经验；2.     熟练掌握SSH、SSM开发框架，熟悉其底层架构和原理；3.     熟练掌握Mysql、Oracle的开发，了解数据库性能优化；4.     熟练掌握MQ、Redis的使用，有多线程、高并发场景的处理经验；5.     熟悉大数据处理平台Hadoop/Spark/Storm等优先。,文娱丨内容,500-2000人,spark,上海
自动化测试工程师,https://www.lagou.com/jobs/6804079.html,长宁区,20k-40k,携程计算机技术（上海）有限公司,3-5年,本科,公司平台 发展潜力,"资深系统测试工程师（AI方向） 职位描述： 1、 基于AI产品的后台技术架构和需求，制定和实施测试工作； 2、 负责测试用例设计、评审、编写、执行 3、 参与AI产品需求和架构设计评审，确保产品的可测试性； 4、 对部门内测试流程、方法策略以及工具进行优化，提升测试的质量和效率，完善测试流程； 岗位要求：1、 5年以上测试工作经验，且具备丰富的自动化测试经验； 2、 精通主流的自动化测试开源框架和工具，能对框架和工具进行维护、和持续优化； 3、 熟练掌握功能测试、接口测试、性能测试等流程和规范；4、 熟悉python、Java、scala开发语言其中一种 ，精通sql,熟悉git代码管理工具； 5、 在Linux、 windows平台下有丰富测试环境搭建经验；6、 良好的沟通能力和逻辑思维能力，极强的责任心和团队协作能力； 优先条件： 1、 有推荐系统，聊天机器人等AI产品测试经验； 2、 熟悉大数据计算相关平台/框架：hadoop、spark、hive、flink等",旅游,2000人以上,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6522872.html,静安区,15k-25k,上海晶确科技有限公司,3-5年,本科,弹性工作、下午茶、工作氛围好、发展空间大,"Responsibilities：1、参与大数据平台的研发；2、负责系统设计代码的编写；3、负责海量数据的清洗、处理和挖掘工作，支持数据分析师和算法工程师的数据需求；4、参与维护大数据平台，并能快速高效解决遇到的问题, 保障平台正常稳定运行；5、完成上级交办的其他工作。Requirements：1、3年以上相关工作经验，大学本科以上学历；2、熟悉掌握hadoop、hive、hbase、MapReduce、Flume、Kafaka、Sqoop、Zookeeper，spark core，spark Sql等大数据相关技术；熟悉Kylin等开源项目、性能调优；3、能独立架构大数据系统能力，熟悉Linux操作系统；4、熟悉Linux系统工作；熟悉Python编程，掌握Java/Scala其中至少一种，能够编写脚本解决日常问题，包括自动化的工作流设计；5、熟悉BI项目，具有数据仓库BI系统开发经验，较强的sql能力。综合：1、工作态度积极主动，有一定的抗压能力。2、优秀的自我管理和学习能力，进取心强。3、善于与他人合作，良好的团队合作意识。4、有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题。加分项：熟悉Hadoop生态和常见的开源分布式计算/存储相关技术，包括但不限于Flink，Yarn, Hbase，SparkSQL等。",数据服务,50-150人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7192400.html,浦东新区,15k-30k,卓望数码技术（深圳）有限公司,5-10年,本科,扁平化管理 项目稳定 待遇好,1、基于业务需求之上，进行数据仓库的模型设计，以实现最佳的数据存储和检索、维护2、基于多种来源的海量数据，设计高可靠、高性能的数据采集、清洗、统计计算等解决方案3、与需求方确定需求，把业务需求转为技术要求，对需求开发任务进行分解，管控开发的进度及质量4、参与系统的日常监控维护，及时解决大数据相关应用中的技术问题、数据问题，对应用进行优化改进技能要求：1、熟悉数据仓库系统的建设开发，熟悉数据仓库模型设计、数据架构设计2、熟悉Hive数据仓库应用的开发，能够从模型设计、存储设计、SQL脚本、参数配置等方面对Hive数据处理进行优化；熟悉Hive/Spark/MR的原理，对Hive/Spark/MR运行过程中的问题定位及解决有丰富经验3、了解大数据技术栈，对Hadoop/Hbase/Sqoop/flume/spark/kafka/elasticsearch等技术有部署及应用经验，能够解决应用中的各类问题4、熟悉oracle/mysql/postgresql中的任一数据库，熟悉java/scala/python中的任一编程语言5、熟悉Linux操作系统的使用，了解shell脚本编程6、有一定的英文阅读能力，能够阅读一般的英文技术文档7、有较强的责任心及执行能力，工作认真细致，并具有良好的学习能力、团队沟通与协作能力,"信息安全,数据服务",2000人以上,spark,上海
数据开发工程师（上海）,https://www.lagou.com/jobs/6880002.html,浦东新区,20k-30k,上海淇毓信息科技有限公司,3-5年,本科,上市公司，3-9个月年终奖,职责：1、负责360金融数据中台常规业务数据开发和支持；2、参与对各业务线数据提供可视化BI开发与支持；3、参与部分数据中间件和基础服务的开发与维护；4、与小伙伴们一起实践业界热门组件和技术（Flink、Spark、Clickhouse、Kudu等）.职位要求：1、全日制本科/以上学历，计算机或数学相关专业；2、3年及以上数据开发经验或4年及以上混合开发经验（2年及以上数据）；3、拥有丰富的离线数仓分层设计和使用经验，具有实时数仓使用经验者更佳；4、拥有较好的SQL编写和优化能力，且Ｓhell能力尚可；5、拥有丰富的Hadoop、Spark、Flink等技术栈；6、至少熟悉一种常用的BI工具，熟悉tableau更佳；7、熟悉Java、Scala等多门开发语言，有过Spring  boot开发经验者更佳。,金融,500-2000人,spark,上海
安全技术岗（安全开发）,https://www.lagou.com/jobs/7164177.html,浦东新区,15k-30k,广州叶子皮具有限公司,3-5年,本科,大平台，绩效奖金,工作职责：1. 负责建设公司安全自动化平台、安全管理系统开发，实现安全日常工作的自动化；2. 负责安全监控数据、系统日志及业务日志的数据分析平台开发；3. 负责内网异常流量监控、漏扫、基线、情报等系统的部分开发工作；4. 持续优化系统架构，提供更准确、更稳定、更可靠的安全系统。任职资格：1. 对安全技术感兴趣，拥有至少一年以上的开发经验；2. 熟练C/C++/Python/Java至少1种编程语言；3. 熟悉常见开源组件的使用，包括但不限于Redis，MQ，MongoDB，elk、kafka、spark等；4. 有安全产品、内部安全系统相关开发经验优先5. 具备机器学习、海量数据处理等相关开发经验优先,消费生活,500-2000人,spark,上海
高级运维工程师,https://www.lagou.com/jobs/7131213.html,杨浦区,15k-30k,爱上租 （上海）科技有限公司,5-10年,不限,做五休二 五险一金 带薪培训,"工作职责1、负责基于产品的业务系统的维护与优化，确保业务系统的稳定性、高可用性和可扩展性；2、负责制定相关的运维操作流程与规范，并监督执行，同时能够通过运维自动化的不断迭代，使之能够高效稳定的被执行；3、负责对运维团队开发的devops设施进行不断迭代与优化，以此提升运维和整个研发团队的工作效率；4、负责运维数据的分析，找出瓶颈，评估容量，完成扩容、架构改造等工作；5、负责运维团队日常管理，不断优化运维规范、工作流程、风险控制，应急预案等。任职资格1、5年以上的大中型网站的运维经验；2、精通Linux操作系统和常用组件（Nginx,Tomcat,Elasticsearch,Redis,nacos,Prometheus,slb,nas,oss,rocketmq等）的部署优化，以及故障定位和处理；3、对Docker容器技术相关的操作系统基础设施（文件系统，网络，cgroups等）有深入的理解，并熟悉k8s编排工具的使用；4、精通Shell脚本语言，至少掌握python/java/go中的一种编程语言，有实际的devops系统开发经验；5、有较强的抗压能力，能够并行处理多项工作6.有熟练的大数据维护经验，有多年CDH，hive，hadoop，flick，spark，storm，hbase的维护经验","移动互联网,企业服务",500-2000人,spark,上海
算法工程师,https://www.lagou.com/jobs/6569279.html,浦东新区,40k-80k,湖北信信通通讯科技有限公司,不限,本科,公司晋升快 福利待遇好,"工作职责1.针对计算广告，内容推荐，用户画像等业务，开发机器学习算法原型系统，开展线上算法实验；2.对实验数据进行处理和分析，发现现有系统和算法的不足，提出改进并推动实现；任职要求1. 计算机或相关专业硕士以上学历，有较丰富的程序开发经验；2．熟悉linux，java获C/C++开发；熟悉python。3. 需要具备以下领域之一的背景：机器学习/数据挖掘/信息检索/自然语言处理/统计分析/图像处理，3年以上相关研发经验；4. 良好的主动性，逻辑思维能力和沟通能力。5. 熟悉R、Python等编程语言，熟悉Hadoop, spark,Hive等大数据处理工具。",电商,150-500人,spark,上海
数据分析,https://www.lagou.com/jobs/7075795.html,虹口区,8k-12k,上海怡高科技服务有限公司,3-5年,不限,五险一金 周末双休 带薪年假,数据分析（BI报告）ETL + Python + BI工具责任： 实施端到端报告系统，开发业务逻辑并可视化仪表板。 为来自不同部门的业务请求者执行BI报告。与Business Data Analyst合作，以实施数据模型。 确定新兴技术和工具以增强报告功能。 支持制定管理决策和管理报告。 生产经理分配的其他任务资质： 1、2-3年的脚本语言Python经验 2、4-6年的使用传统DBMS（SQL Server，Oracle）和BI功能的经验，以及Hadoop生态系统（Hadoop / Spark）的经验。 3、NoSQL知识 敏捷软件开发过程的知识。 4、具有与PowerBI合作的经验，优先考虑 有效沟通和有效协作的能力。 5、快速学习者。能够根据需要学习新技术。 6、优秀的团队合作伙伴，具有强烈的责任感，并在需要时担任领导角色。,企业服务,500-2000人,spark,上海
Java 平台技术总监,https://www.lagou.com/jobs/7087329.html,长宁区,30k-45k,瀚御投资（上海）有限公司,10年以上,本科,六险一金,"岗位职责1.     负责打造和管理智能网联（车联网）平台技术团队，构建高效、高质、有能力，能打硬仗的平台开发技术团队；2.     参与公司大型智能网联（车联网）平台的技术方案实施和功能实现；3.     协同架构师（业务架构，技术架构）完成系统分析和架构设计，指导相关技术团队实现平台业务功能，规划并预研平台未来技术方向；4.     负责或参与全局性、前瞻性的技术架构设计，及技术细节的实现，解决业务发展遇到的技术难题，持续提升系统平台稳定性、可用性、先进性；5.     带领技术团队解决平台产品、项目研发期间出现的技术难题；6.     制定高效、实用的开发规范，包括管理规范、过程规范、技术规范等。岗位要求1.     计算机相关专业，本科或以上学历；6年以上JAVA开发及软件开发经验；4年以上互联网项目开发经验；4年以上技术团队管理经验；2.     具备优秀的系统分析能力，抽象思维和逻辑思维能力，独立分析问题解决问题的能力；有抽象设计能力，能够用面向对象原则组织代码；具备文档编写能力，能够编写详细设计文档；3.     精通JAVA语言，熟悉J2EE相关技术，精通SpringMVC、Mybatis、Hibernate ，easyUI或JQuery，Vue， React等常用前后端框架；精通微服务开发，掌握Spring Boot, Spring Cloud;4.     精通多种数据库系统，如mysql，MongoDB等; 熟练掌握主流应用服务器架构体系、数据库以及各种中间件技术及性能调优；5.     有车联网项目开发经验，有平台安全开发经验，以及高性能平台开发经验优先；6.     有大数据平台开发经验，了解Hadoop, Spark, Storm等方案优先； 7.     能承受压力，自驱动、沟通能力、团队精神、快速学习、系统性思考、和热爱技术。",企业服务,150-500人,spark,上海
Java后端开发高级工程师,https://www.lagou.com/jobs/6419631.html,杨浦区,20k-40k,嬴彻科技（上海）有限公司,5-10年,本科,自动驾驶 机器学习基础架构,"You'll get a chance to build large-scale infrastructure and distributed system from the ground up. You will have an opportunity to imagine and build ML infrastructure. You will be an important member of our overall R&D organization, collaborating on a daily basis with a highly skilled group of engineers working on computer vision, deep learning, perception, planning, localization systems for an autonomous driving system solution.Job ResponsibilitiesBuild and maintain scalable and reliable service (e.g. job scheduling services, databases/caches, distributed storage, etc) to support the rapid changing R&D environment.Develop software to manage large-scale dataset and machine learning models.Develop training, inference and evaluation pipeline for ML models and automate ML processes used on the self-driving car.Take a key role in attracting talent and screening additional members of the project as it expands.Provide leadership and guidance to engineers and apply trends in application developmentKey QualificationsHands-on experience in building distributed systems, including real-time streaming and batch data processing.Experience with Kubernetes, Linux, Docker, Micro services.Familiar with one or more batch scheduling tools such as Airflow or Azkaban.Strong Experience with designing service oriented architecturesIn-depth knowledge to leverage various data stores (blob, NoSQL and RDBMS)Strong OOP programming skills with one or more language: (Java, Golang, C++, etc)Experience with big data technologies (Hadoop ecosystem, Spark, etc) is a plusExperience with Machine Learning Pipeline and/or Automated Machine Learning is a plus.Excellent communication, interpersonal and presentation skills with meticulous attention to detail. BS/MS/PhD Degree in Computer Science or a related field工作地址",人工智能,150-500人,spark,上海
数据分析师实习生,https://www.lagou.com/jobs/7054939.html,徐汇区,2k-4k,上海博弋信息科技有限公司,应届毕业生,本科,"做五休二,五险一金,带薪年假,团队出省游","职位描述：1.针对系统日志、应用日志、安全日志以及其他监控数据进行深入的数据分析和数据挖掘；2.基于ELK、Ambari/Hadoop/Spark搭建大数据可视化和分析平台；3.对原始数据进行数据清洗、ETL和导入， 并提出合理化建议；4.根据安全场景以及威胁模型，在平台中实现数据分析算法,实施数据挖掘；5.对模型数据和分析结果进行解读、评估、优化，以及基本的可视化工作。任职要求：1.具备独立思考能力，思维敏捷,逻辑清晰，愿意从事研究性、探索性的工作；2.全日制本科或研究生(在读参与实习)，计算机、应用数学、统计学等相关专业；3.数学基础扎实,核心课程成绩优秀,具备独立阅读、精读英文论文的能力；4.熟练使用matlab、 python、 java、 scala中的一 种或多种，其他语言也可作为加分项；5.对图嵌入和图特征提取有一定了解者优先；6.对RNN/LSTM等深度学习算法有一 定了解和实践者优先。","信息安全,数据服务",15-50人,spark,上海
.NET工程师,https://www.lagou.com/jobs/3401822.html,杨浦区,10k-20k,玑脉（上海）数据技术有限公司,3-5年,本科,"年终奖,饭贴,老板好","工作描述:1）使用C#语言设计开发BS应用；2）为客户端（h5/app/winform）提供服务接口（Web API）;3）对系统性能进行优化;4）协助相关架构和数据库设计工作5）单元测试、模块测试及开发文档撰写；要求:1）2-5年工作经验，本科及以上学历，计算机相关专业。2）熟练使用C#, .net framework和ASP.NET。3）熟悉数据库技术，如SQL Server/MySql。4）熟悉TCP/IP和HTTP通讯协议，熟悉多线程编程。5）有Redis, ElasticSearch开发经验优先。6）了解Storm, Spark等流式框架开发经验优先。7）有.net core项目经验者优先。8）遵守代码规范，工作认真负责，追求完美，独立性强。9）沟通能力好，有团队协作精神。10）善于发现和解决问题，思路清晰。",数据服务,15-50人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6841183.html,浦东新区,15k-25k,上海华钦软件技术有限公司,3-5年,本科,双休，福利待遇好等,1.3年及以上工作经验2.熟练掌握大数据，懂spark和Hadoop3.英语良好4.有金融或银行互联网等相关经验,"金融,企业服务",500-2000人,spark,上海
公共-大数据系统开发工程师,https://www.lagou.com/jobs/6246271.html,长宁区,25k-45k,北京三快在线科技有限公司,3-5年,本科,上市公司 大牛云集 核心部门,,消费生活,2000人以上,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6121631.html,浦东新区,14k-18k,上海海万信息科技股份有限公司,3-5年,本科,"五险一金,体检旅游,年终奖金,节日礼金","岗位职责：1、负责大数据平台数据处理脚本编写、测试、投产；2、负责业务需求的数据分析，数据集市模型设计（维度建模）；3、负责生产问题核查；4、熟悉敏捷开发流程。任职资格：1、3年以上hadoop平台开发经验，精通hive,hbase,熟悉spark；2、两年以上数仓开发经验;3、有crm、客户类数据处理项目实施经验更佳；4、精通shell、java、sql、python等语言。","移动互联网,金融",500-2000人,spark,上海
数据测试,https://www.lagou.com/jobs/6756198.html,闵行区,10k-20k,北京字节跳动科技有限公司,1-3年,本科,"六险一金,弹性工作,免费三餐,餐补",,文娱丨内容,2000人以上,spark,上海
大数据测试,https://www.lagou.com/jobs/7076663.html,浦东新区,11k-17k,上海海万信息科技股份有限公司,3-5年,本科,"节日礼金,体检旅游,年底双薪,五险一金",职责：1. 安排整理测试计划，收集整理测试进度，协助测试经理管理测试工作2. 全流程参与系统研发，包括需求分析、开发与业务团队沟通以及设计评审要求：1、全日制本科以上学历，计算机/通信/电子等相关专业；2、3年或以上测试工作经验，以及至少一年以上接口测试工作经验；3、数据oracle、mysql、Hive等常用数据库，熟练使用sql语句；4、熟悉http协议以及linux常用命令，熟悉postman、jmeter常用测试工具；5、有大数据相关产品测试经验，熟悉数据ELT的测试方法及测试点，对数据仓库有基本了解；6、熟悉大数据流式计算经验优先考虑，如spark、hbase、kafka等分布式工作原理；7、具备工程化的前端思维，具备较好的问题分析与解决问题的能力，对技术有强烈的进取心，具有良好的沟通能力和团队合作精神。,"移动互联网,金融",500-2000人,spark,上海
流媒体大数据工程师,https://www.lagou.com/jobs/5687411.html,徐汇区,20k-35k,北京字节跳动科技有限公司,3-5年,本科,六险一金，弹性工作，免费三餐，扁平管理,,文娱丨内容,2000人以上,spark,上海
广告数据资深研发工程师,https://www.lagou.com/jobs/6797083.html,浦东新区,40k-60k,上海基分文化传播有限公司,3-5年,本科,六险一金；绩效奖金,工作职责：1、负责广告基础数据建设，包括数据系统搭建、基础数据模型建设、实时计算体系建设2、负责离线/实时数据报表开发，为广告产品提供大数据存储、分析、计算支持3、负责持续改进现有数据系统架构，保证系统高性能、高可用、高可扩展4、负责新技术预研，完成项目的选型和设计，项目难点攻坚任职要求：1、本科及以上学历，计算机相关专业，4年以上大数据开发经验，精通至少一门编程语言（Java、Scla、C/C++等）2、具备丰富的大规模分布式系统设计开发经验（有百亿级数据接入经验、PB级数据处理经验者优先）3、对大数据技术体系有深入的理解，精通大数据相关技术（包括但不限于Hadoop、Spark、Flink、Hive、HBase、Kafka等，熟悉源码者优先）4、有极强的责任心和技术攻坚能力，能够针对广告数据平台的疑难问题提出解决方案5、有广告业务数据体系建设开发经验者优先,文娱丨内容,500-2000人,spark,上海
广告引擎研发架构师,https://www.lagou.com/jobs/6627916.html,浦东新区,45k-65k,上海基分文化传播有限公司,5-10年,本科,六险一金；午餐补贴,【工作职责】         1、    承担趣头条广告引擎的设计、研发和持续优化，打造一流的商业变现平台。        2、    实现与优化针对不同广告位置的投放策略，不断提高流量变现效率。        3、    支撑过亿请求压力的高可靠系统的研发，支持毫秒级流量分发和响应。        4、    解决海量商业数据分布式处理、高效查询、数据一致性等方面的技术挑战。         5、    紧跟业界领先技术，关注open source发展。        【任职要求】         1、    大学本科以上学历，计算机或相关专业，3年以上工作经验；         2、    精通任一门编程语言，golang/C++优先；        3、    熟悉常用的算法/数据结构，熟悉网络编程和多线程编程；        4、    熟悉mysql/redis/mongoDB/Hbase任意一种存储系统者优先；         5、    了解hadoop/storm/spark/kafka等分布式计算框架者优先；        6、    学习能力强，思维敏捷，有较强的分析问题和解决问题的能力；        7、           有广告系统工作经验者优先；,文娱丨内容,500-2000人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/5812383.html,浦东新区,15k-30k,上海华钦信息科技股份有限公司,3-5年,本科,"六险一金,最新技术,海量数据,弹性工作","Job Responsibilities· Big data collection, extract, transformation and storage, support business intelligence.· Design and develop big data solutions to help product and business teams to make data driven decisions.· Support end-to-end efforts to design, development and implementation data integration processes.· Has strong programming development background, master of Unix, Python.· Building data processing applications within Hadoop System using Java, Python, Shell or Hive, Spark should be common knowledge to the big data engineer. Requirements:· Bachelor¡¯s Degree in Computer Science or equivalent degree· Good understanding of data warehousing concepts including data modeling, ETL· Knowledge of Hadoop ecosystem open software such as Hive/Spark/HBase/ES· Knowledge of a programming language such as Shell/Python/Java· Demonstrate fast learning ability, have sense to delivery on time· Demonstrate good team work","数据服务,金融",500-2000人,spark,上海
Senior Software Engineer,https://www.lagou.com/jobs/6995222.html,浦东新区,20k-40k,上海华钦信息科技股份有限公司,5-10年,本科,后端,"Responsibilities1.       Communicate with clients on requirement and design; deliver creative and innovative projects with good quality and productivity.2.       Develop all areas of Middle-Tier and Back-end system programming, designing and coding, testing and troubleshooting, supporting.3.       Provides strong technical solution and comprehensive system design and proposal to global team.4.       Conduct code review.5.       Help and guide junior team members.6.       Help TL to manage development lifecycle including development process, program progress, software quality, program release and application supporting.Communicate and work closely with      peer developers of global team  Skill required·         More than 8 years J2EE development experience·         Be skilled at Core Java or JavaEE technologiesCore Java:Concurrent programing experience (Multiple Thread).Cluster based environment programing experience.Pure standard alone Java programing experience (Without Spring boot).JavaEE:Web Service (JAX-WS/JAX-RS) experience.EJB·         Experience in designing and architecture, be familiar with design pattern.·         App Server Skill :Weblogic (12c),  Solid knowledgeable to setup DS, Security realm, application deployment and system tuning.Tomcat/JBoss, able to maintain application server basic lifecycle, providing maintains solutions.·         Master in Linux based environment development. (MUST HAVE):·         Master in shell scripts reading & writing (shell/perl/py. etc) (MUST HAVE):·         Good skill in configuration management related tools:Ant/Maven/GradleGit/BitBucketTeamcity/Jenkins/uDeploy·         Good understanding in MicroService related technology·         Other Java Skills:Spring framework (SpringBoot, MVC, SpringCloud)Testing framework: JunitJMX/RMIMicroService related framework:                Eureka/Zuul/Zookeeper/openshift·         Java Based Middleware Product Line (JMS) (MUST HAVE):- IBM MQ (Setup port, channel, queueManager)- TIBCO RV (manage multicast address, send/receive messages)- TIBCO EMS (topic, queue, bridge, routes across multiple EMS instances)- Other JMS projects (RabbitMQ/Apache ActiveMQ/Apache RocketMQ/..)- Kafka or Spark (OPTIONAL)·         Strong experiences in SQL, SP and JDBC is a must, be familiar with OR-Mapping tools as well as data modeling.·         Rich experience on performance tuning and multi-threading for different layer.·         Good communication skills and English skills, proficient in both spoken and written English, especially can explain technical details in English clearly.","数据服务,金融",500-2000人,spark,上海
java开发工程师,https://www.lagou.com/jobs/6463475.html,浦东新区,15k-25k,奥解思信息科技（上海）有限公司,1-3年,本科,500强 弹性工作,"KEY RESPONSIBILITIES:• Join a team as a Java developers and work effectively as part of a large global team delivering firm and regulatory critical risk management solutions• Develop modules for Stress Testing  application including Market Risk and Counterparty Credit Risk across the technology stack and full breadth of SDLC• Deliver high quality technical solutions to multiple global stakeholders in a fast paced environment QUALIFICATIONS     • Minimum 2 years’ experience as a Java developer• Computer science or related engineering degree is required• Good track record of relevant experience in design and development of Java based systems.• Strong knowledge of JAVA (Core JAVA, Multi-threading, Spring, Restful Services)• Experience with Mongo DB, Spark will be a big plus.• Expertise in Messaging Services (JMS, Tibco EMS) and Websphere application server is preferred.• Databases – Oracle or equivalent with SQL,PL/SQL programming expertise.• Experience with Maven, GIT, Hudson, JUnit and other similar technologies.• Unix/Linux scripting skills (Korn shell)• Good understanding of finance and risk management is plus.• Excellent time management and ability to multi-task/balance parallel work streams.• Committed to Unit testing, good design approach and work with a team or independently.• Work with teams in other time zones and the challenges of time, language and culture.• Good communication skills.",金融,500-2000人,spark,上海
数据平台研发工程师,https://www.lagou.com/jobs/7075968.html,浦东新区,20k-40k,百度在线网络技术（北京）有限公司,1-3年,本科,良好发展前景，福利优厚,"【工作内容】  -对海量数据做采集、存储、管理、查询、分析、挖掘、建模等处理，对内提供大数据平台，对外提供云端数据管理解决方案  -高性能服务器软件开发与优化  -探索大数据可视化的展现方式，帮助用户更加直观深入地了解数据的内容【任职要求】 -熟练使用C++、Java、Python中至少一种编程语言,熟悉脚本编程，了解常见面向对象设计模式  -编程基础扎实，熟悉常用算法和数据结构，熟悉分布式系统原理,了解大规模数据分析相关技术或对业界的云服务有一定了解  -计算机、工程、数据统计分析相关专业，本科及以上学历  -有较强的学习和动手能力，有责任心，具备良好的沟通和协同工作能力  具有如下条件之一优先考虑：    -互联网广告、搜索引擎方向相关背景和工作经验    -大规模数据的处理相关经验，熟悉Hive、Spark、Storm、HBase、Kafka等分布式系统    -数据分析、数据挖掘、机器学习、人工智能相关经验",工具,2000人以上,spark,上海
java开发工程师（美资投行）,https://www.lagou.com/jobs/6624869.html,浦东新区,15k-25k,奥解思信息科技（上海）有限公司,1-3年,本科,13薪 全额缴纳社保公积金,本科学历，英语读写能力ok，有外企工作经验优先考虑1、2年以上Java开发经验，良好的基于Java系统设计和开发相关经验。2、本科及本科以上计算机相关专业3、熟悉JAVA(核心JAVA、多线程、Spring、Restful服务)4、熟悉Maven、GIT、Hudson、JUnit等类似技术。5、数据库- Oracle或具有SQL、PL/SQL编程经验。6、unix /Linux脚本编写技巧(Korn shell)7、具有Mongo DB经验，会Spark优先考虑8、有消息服务(JMS、Tibco EMS)和Websphere application server方面经验优先。,金融,500-2000人,spark,上海
高级ETL工程师,https://www.lagou.com/jobs/6911691.html,闵行区,25k-40k,上海触乐信息科技有限公司,3-5年,本科,美股上市公司，团队牛人多,岗位职责：1.参与用户增长平台数据产品和应用的数据开发，打造**体验的数据产品；2.基于公司业务，构建业务模型和算法，发掘数据的价值，推动业务增长；3.负责离线和在线数据的采集、清洗和加载，助力数据化运营业务，构建丰富多样的运营场景应用；任职要求：1.2年及以上大数据处理领域开发经验，计算机相关专业本科及以上学历；2.熟练掌握Python/Java/Scala编程语言，代码实现能力强；3.能灵活运用SQL实现海量数据加工处理 ，并有优化数据计算执行效率的能力；4.能够根据复杂业务场景进行数据建模；5.具有Hadoop/Spark/Flink开发与应用经验，熟悉Kafka/Flume等消息通道和数据采集技术，熟练掌握Hadoop/Hive/Spark及Spark SQL等大数据技能；6.善于协作，学习能力强，拥有严密的逻辑思维能力、良好的理解和表达能力、较强的抗压能力。,"移动互联网,数据服务",500-2000人,spark,上海
高级大数据开发工程师,https://www.lagou.com/jobs/6827642.html,闵行区,25k-40k,上海触乐信息科技有限公司,3-5年,本科,美股上市公司，团队牛人多,岗位职责：1.参与用户增长平台数据产品和应用的数据开发，打造**体验的数据产品；2.基于公司业务，构建业务模型和算法，发掘数据的价值，推动业务增长；3.负责离线和在线数据的采集、清洗和加载，助力数据化运营业务，构建丰富多样的运营场景应用；任职要求：1.2年及以上大数据处理领域开发经验，计算机相关专业本科及以上学历；2.熟练掌握Python/Java/Scala编程语言，代码实现能力强；3.能灵活运用SQL实现海量数据加工处理 ，并有优化数据计算执行效率的能力；4.能够根据复杂业务场景进行数据建模；5.具有Hadoop/Spark/Flink开发与应用经验，熟悉Kafka/Flume等消息通道和数据采集技术，熟练掌握Hadoop/Hive/Spark及Spark SQL等大数据技能；6.善于协作，学习能力强，拥有严密的逻辑思维能力、良好的理解和表达能力、较强的抗压能力。,"移动互联网,数据服务",500-2000人,spark,上海
Java资深开发工程师（天天基金）,https://www.lagou.com/jobs/7056801.html,徐汇区,30k-40k,东方财富信息股份有限公司,5-10年,本科,五险一金 定期体检 节日福利 上市公司,,金融,2000人以上,spark,上海
（Senior）Java Engineer,https://www.lagou.com/jobs/5826710.html,浦东新区,20k-40k,美银宝网络信息服务（上海）有限公司,不限,硕士,"955不加班，互联网金融, 大平台","Job Description SummaryPayPal is the faster, safer way to pay and get paid online. The service allows people to send money without sharing financial information, with the flexibility to pay using their account balances, bank accounts, credit cards or promotional financing. With 165 million active accounts in 203 markets and 26 currencies around the world, PayPal enables global ecommerce. More information about the company can be found at PayPal.com. The Product & Technology, China team is looking for strong technologists to join the team in ShanghaiThe ideal candidate is a self-starter and self-motivated individual with strong passion and experience in software development lifecycles for Financial systems. The candidate should have the technical expertise to lead software and architecture discussions and guide cross-functional product and engineering teams through functional definition, solution, and integration stages on large scale. The candidate should possess deep understanding of financial services and associated platforms and technology. Responsibilities·       Own implementation of a module/application/product·       Participate complex architectural discussions that involve multiple systems·       Identify any product/functionality gaps and collaborate internal product and technology teams to define the necessary development to support solution delivery.·       Drive integration efforts and lead critical work streams of strategic initiatives sponsored by senior executives·       Drive engineering excellency through CI/CD·       Pro-active response in identifying and troubleshooting integration or technical issues.  Qualifications·       Minimum of 3+ years' hands-on experience developing software with 1+ years in FinTech·       Familiarity with languages and technologies needed for web services development, including Java, C++, REST, Hadoop, Spark, NoSQL Databases.·       Experience in architecture, design and implementation of Financial Systems/Platforms such as Core Banking, Back-end Payment Hubs, Financial reconciliation and reporting·       Expertise in designing for reliability, availability, scalability and performance in highly regulated Financial Services industry preferred.·       Strong analytical and problem-solving skills.·       Ability to create structure and drive progress in an ambiguous environment·       Superb communication skills; ability to comfortably interact with tech and non-tech colleagues·       Demonstrated ability to scope, create and successfully deploy new strategy/ initiatives / capabilities·       Experience to interact with engineering teams from multiple geo-locations·       Ability to communicate in English","移动互联网,金融",2000人以上,spark,上海
推荐系统开发工程师（电商）,https://www.lagou.com/jobs/6802674.html,杨浦区,20k-40k,上海哔哩哔哩科技有限公司,3-5年,本科,空间大,"岗位描述：1从事B站电商平台推荐系统的设计与研发工作，优化推荐系统架构，负责系统的性能调优工作。2负责在线推荐系统的研发，能够对高QPS场景进行优化。3负责离线数据的存储、传输以及计算，提升推荐系统的时效性和性能。岗位要求：1计算机相关专业，211本科及以上学历，有过2年以上的互联网工作经验2具备良好的需求分析能力和设计能力，善于主动推进项目进展并落地。3熟练使用java，C++中的一种，有良好的数据结构基础，有服务端编程经验，有机器学习线上server开发经验者更佳4熟悉分布式系统原理和设计，熟悉redis，activemq，zookeeper等开源项目。熟悉hadoop, spark等大数据处理工具，能够合理进行技术选型，善于解决问题。5有较好的沟通能力，有独立分析和解决问题的能力，有强烈的责任心和团队协作精神，能够主动快速融入团队加分项1熟悉大数据处理，有相关的工作经验2对JVM，Mysql，Redis等有过性能调优经验3熟悉微服务架构，并且在生产环境中有过相关实践4对机器学习算法有一定了解，实践中有tensorflow线上使用经验者优先","移动互联网,文娱丨内容",2000人以上,spark,上海
高级数据开发工程师（商业化）,https://www.lagou.com/jobs/6292467.html,杨浦区,15k-30k,上海哔哩哔哩科技有限公司,3-5年,本科,团队优秀，大牛多，发展好，前景佳,工作职责：1、广告产品的DMP用户画像平台搭建2、广告产品的商业智能BI系统搭建3、数据产品基础设施的架构、研发、优化职位要求：1、5年以上大数据及分布式计算研发经验，对海量数据、数据仓库技术具有浓厚的兴趣；2、熟悉Oracle 、Mysql等关系型数据库，能独立完成数据仓库结构设计、ETL设计和开发；3、熟悉Hadoop 、Spark、Storm、Flink、Kafka、Redis等分布式计算架构体系；4、熟悉Impala、Druid等实时OLAP大数据查询和分析系统；5、熟悉Linux 环境，熟悉 Shell脚本开发，能进行分布式环境的搭建、日常维护和问题处理；6、热衷开源社区，有开源作品者优先；有优秀技术博客者优先。,"移动互联网,文娱丨内容",2000人以上,spark,上海
web前端开发工程师,https://www.lagou.com/jobs/7150962.html,浦东新区,11k-17k,上海微创软件股份有限公司,3-5年,本科,人工智能项目,"本职位外派驻场于ElectrifAi项目描述ElectrifAi成立于2004年，是人工智能和机器学习领域的领导者，为行业带来了革命性变化，以帮助客户 转变其业务。作为业界首创，ElectrifAi 已围绕开源和Spark 体系的计算引擎重新设计了其技术 平台，该引擎可进行大规模的分布式数据处理和机器学习，并具有嵌入式Zeppelin 笔记本功能。 现在，ElectrifAi的数据科学家及其客户可以使用任何编程语言对数据进行编码和访问。Docker Containers 和Kubernetes 的结合使ElectrifAi 能够大规模构建和部署混合云企业解决方案， 在数周而不是数月内即可看到结果，从而显着增加了企业实现价值的时间。岗位内容• Work closely with our backend developers to ensure the integrity of the UI throughout the development lifecycle.• Scope project and provide accurate estimates for the implementation of features/functionality requests.• Design and build components as part of a large code base, maintain clear documentations.• Perform testing at the page and source for presentation layer defects• Review feature coding and plan future website upgrades.任职要求• Bachelor’s degree in Computer Science or related technical field.• Proficient in front-end web technologies including HTML5/CSS3, JavaScript,TypeScript, jQuery, ES6,LESS/Sass, Bootstrap and Angular JS UI JavaScript Frameworks.• 2+ year of work experience with React.• Used react to do mature projects, independently responsible for a certain scale of product front-end.• Familiar with GIT and webpack, have own opinions on modularization and component development.• Good understanding of asynchronous request handling, partial page updates, and AJAX.• Working experience with cross-browser and cross-device development.• Familiar with CI/CD process.• Good communication skills, team work awareness and positive attitude.• Good programming habit, clear structure, standard naming, low code redundancy, able to independently complete high-quality code.• Good at English reading/writing(At least passed CET-4).","企业服务,移动互联网",2000人以上,spark,上海
python开发工程师,https://www.lagou.com/jobs/7184343.html,浦东新区,23k-34k,上海微创软件股份有限公司,5-10年,本科,大数据AI项目，外企机会,"本职位外派驻场于ElectrifAi现场。项目描述成立于2004年，是人工智能和机器学习领域的领导者，为行业带来了革命性变化，以帮助客户转变其业务。作为业界首创，ElectrifAi已围绕开源和Spark体系的计算引擎重新设计了其技术平台，该引擎可进行大规模的分布式数据处理和机器学习，并具有嵌入式Zeppelin笔记本功能。现在，ElectrifAi的数据科学家及其客户可以使用任何编程语言对数据进行编码和访问。Docker Containers和Kubernetes的结合使ElectrifAi能够大规模构建和部署混合云企业解决方案，在数周而不是数月内即可看到结果，从而显着增加了企业实现价值的时间。客户来自世界上许多最大的企业和政府部门，其中包括：强生，T移动，美国政府，诺华，安大略省教师退休金计划，万事达卡，花旗银行，美国运通卡，Mercy医院，Bon Secours和联合航空。ElectrifAi可以协助客户将不同的混乱数据转化为实用的见解，从而解决日常问题并通过提高利润，提高绩效和降低风险来推动业务发展。ElectrifAi对全球**行业的公司产生了积极影响，这些行业包括：政府，医疗保健，金融服务，旅行和款待，电信，CPG岗位内容• Design, build and launch efficient & reliable data pipelines to move and transform data.• Securely source external data from numerous partners.• Design scalable implementations of the models developed by Data Scientists.• Optimize existing pipelines and maintain of all domain-related data pipelines.• Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data.岗位要求• BA/BS in Computer Science, Engineering, Mathematics or related field.• 3+ years of SQL (Oracle, Vertica, Hive, etc.) experience and relational databases experience (Oracle, MySQL).• 3+ years of experience in custom or structured ETL design, implementation and maintenance.• Proficiency in Python, minimum 3 years of Python development experience.• Hands-on experience with different data warehouse and processing technologies such as Spark.• Experience working in very large data warehouse environments.• Experience working with applied scientists on machine learning modeling.• Good oral English","企业服务,移动互联网",2000人以上,spark,上海
高级商业分析师,https://www.lagou.com/jobs/7025383.html,浦东新区,15k-20k,上海喜马拉雅科技有限公司,3-5年,本科,"音频独角兽,发展平台,技术大牛,丰厚福利",1、岗位职责:1.对产品和业务部门进行需求咨询，设计核心业务指标，制定业务内容看板和跟踪频次； 2.通过数据分析对现有业务提供商业洞察，找出新的产品改进点或业务增长点； 3.通过运营量化管理方法，帮助企业实现精细化运营，进行有效的成本核算； 4.利用前沿数据处理技术和数据增长方法论，加强企业的数据竞争力。要求:1.2~4年工作经验，本科及以上学历；2.统计、金融、或工科类专业优先；3.熟悉SQL、R或matlab优先，如果有过python、spark经验者更佳；4.学习能力强，在校学习成绩好，渴望新知识者优先；5.具备良好的沟通能力，热衷于数据驱动业务的工作方式6.具备切换视角的能力。,"移动互联网,文娱丨内容",2000人以上,spark,上海
数据仓库应用工程师,https://www.lagou.com/jobs/7124674.html,浦东新区,15k-25k,上海喜马拉雅科技有限公司,3-5年,本科,"音频独角兽,发展平台,技术大牛,丰厚福利","岗位职责:1. 负责喜马拉雅商业智能中心数据基建工作，参与数据仓库建设，开发ETL流程等数仓工作。2. 深入理解业务需求，利用大数据技术为部门提供技术支持，参与相应的数据产品建设。岗位要求:1. 对数据技术有兴趣，对技术有钻研精神，具备优秀的分析和解决问题的能力。2. 熟悉数据仓库方法论, 理解数据建模理论，对数据敏感，对业务负责，有数据处理开发或分析经验。3. 熟悉SQL, Python，Java等，有较强工程代码的快速学习和上手能力。4. 熟悉分布式计算平台如Hadoop, Spark, Hive, Kafka, Flink 等生态优先。","移动互联网,文娱丨内容",2000人以上,spark,上海
java开发工程师,https://www.lagou.com/jobs/7181245.html,杨浦区,6k-10k,上海海阳医疗服务集团有限公司,应届毕业生,大专,领导NICE、团建、股权激励、年终奖金,1、负责医疗软件前期技术研发工作；2、对hadoop集群上spark/hive/flume/kafka/zookeeper/flink/hbase等组件 的搭建与集群维护；3、完成基于医疗/大数据平台的业务项目的开发、实施和维护工作；4、负责高并发的大数据业务架构设计，在线和离线海量数据分析平台的开发， 处理各种线上bug； 5、参与数据仓库设计，根据业务需求实现高效查询； 6、研究大数据前沿技术，确保系统的稳定性和可运维性。7、参与安卓客户端产品的需求分析和产品设计，提供实现评估以及系统设计等；8、与前端及后端工程师协作完成API等设计任职条件：1、计算机或相关专业本科及以上学历，2年以上hadoop大数据平台实际生产 环境经验、一年及以上Android 相关开发经验； 2、掌握hadoop技术栈，熟悉大数据生态技术，如Hive，spark，Impala，Sqoop， flink，kafka，zookeeper，hbase等组件，有高并发、大存储和实时流的开发 及运维经验，能根据业务场景设计合适的技术栈完成需求； 3、java基础扎实，熟练掌握多线程，熟练Android开发、JVM调优，数据结构算法等； 4、熟悉unix/liunx操作环境； 5、熟练掌握shell/java/scala/python中的两种及以上； 6、热爱技术，勇于钻研，善于沟通，有责任心和团队精神。 熟悉深度学习算法的基本概念和原理，有深度学习算法经验优先；医疗软件、呼叫中心、养老系统平台经验优先,医疗丨健康,500-2000人,spark,上海
物流数据中心架构师(P7、p8),https://www.lagou.com/jobs/6911383.html,普陀区,30k-50k,拉扎斯网络科技（上海）有限公司,5-10年,本科,组内直招，开发内推，p7/p8岗位多,岗位职责1.  主导并参与数据中心领域业务后端服务架构、设计、核心功能开发、系统优化等工作；2.  参与数据中心平台化建设，参与技术决策、技术选型、技术风险评估；3.  推进平台架构升级、稳定性建设、高性能优化、数据质量保障等工作，并负责制定技术规划和落地推进；4.  负责技术难点调研和攻关，解决系统中关键的设计、性能等问题；5.  制定团队目标，拆解排期，规划人力和落地执行；任职资格1.本科及以上学历（985/211优先），扎实的计算机基础。2.3年及以上Java开发工作经验，1年以上大数据经验，深入了解大数据计算平台常规架构和相关产品组件（Hadoop、Hive、Spark、Storm、Kafka、Elasticsearch等）原理、使用和应用场景。并有实际大数据项目经验3.深入使用Java，熟悉掌握常用的Java类库及框架，如多线程、并发处理、I/O与网络通讯，Spring、Mybatis等;系统排障经验丰富，可以快速排查定位问题；至少对高并发、分布式、缓存、jvm调优、序列化、微服务等一个或多个领域有过深入研究，并且有相关实践经验4.精通MySQL应用开发，熟悉数据库原理和常用性能优化技术，以及NoSQL，Queue的原理、使用场景以及限制5.对技术有激情，喜欢钻研，能够快速接受和掌握新技术，擅长使用开源框架，可以完成技术选型、新技术落地等工作6.具备良好的业务sense，能够站在业务、产品的角度深入发掘内在逻辑，进行合理的抽象与建模，做出合适的架构设计决策；7.  具有良好的沟通、团队协作、计划和主动性思考的能力，在互联网或业界有一定影响力公司的工作经验者优先,消费生活,2000人以上,spark,上海
数据开发工程师,https://www.lagou.com/jobs/6912186.html,长宁区,30k-50k,上海寻梦信息技术有限公司,3-5年,本科,公司发展势头良好,岗位职责：1、深入理解流式sql原理及应用场景，并实现完备的流式sql功能；2、负责流式sql查询优化、运行时优化、问题诊断等；3、负责流计算引擎flink的调度优化、执行优化，支撑高吞吐、大状态作业的稳定运行；4、负责实时计算在业务上的应用，如实时多维分析、实时异常监控排查等；5、负责业务线实时数仓的规划、设计以及建设；任职要求：1、本科及以上学历，2年及以上大数据相关开发经验；2、熟悉大数据实时计算生态体系，对hdfs、flink、spark等有深入理解；3、有flink，数据库，sql查询优化，性能优化相关经验者优先；4、具有清晰数据分析思路，有认真的技术态度，积极沟通，懂得团队协作；,"电商,移动互联网",2000人以上,spark,上海
Junior Data Engineer,https://www.lagou.com/jobs/7175544.html,静安区,10k-12k,创愿（上海）信息技术有限公司,3-5年,本科,"五险一金,领导好,福利好,团建","Job Responsibilities:1. Create and maintain ETL pipelines using Airflow/Python2. Build and update big data pipelines to maintain Kargo’s data lake3. Ensure that users have the right level of access to our data assets4. Coordinate with the insights team to extract data for adhoc reporting5. Design and create impactful visualization using a variety of BI tools6. Detect and clean any deviation in the data7. Communicate technical and business topics, as appropriate, using written, verbal and/or presentation materials as necessaryJob Requirements:1. Experience in Big Data processing using Apache Hadoop/Spark ecosystem applications like Hadoop, Hive, Spark, Kafka and HDFS preferable2. Must have strong experience in Data Warehouse ETL design and development, methodologies, tools, processes and best practices3. Strong experience in stellar dashboards and reports creation for C-level executives4. You should love and be passionate about data. You should be able to demonstrate your experience with engaging with truly large data sets.5. Strong experience in Cloud Technologies like AWS, Azure or Aliyun6. Strong experience in creating data pipelines using Python, Airflow or similar ETL tools7. Strong experience in Data Modelling8. Expert SQL skills9. Good command of Linux10. Have a strong learning ability. You can demonstrate the skills required to research and gain extensive knowledge about a subject and an appreciable level of expertise on the subject.11. A Bachelor degree is required unless you have substantial work experience or real-life experience.12. Good communication skills in English and Chinese.","企业服务,消费生活",50-150人,spark,上海
etl工程师,https://www.lagou.com/jobs/6901028.html,青浦区,13k-25k,上海则一供应链管理有限公司,1-3年,本科,年轻团队 带薪年假 做五休二 法定假日,"岗位职责：1、根据公司业务需求，构建可扩展的数据仓库，负责数据模型的规划,设计,实现和优化。2、负责业务数据的采集，清洗，特征抽取。3、负责ETL的维护工作，发现故障及时诊断、定位、分析和调试，保证数据准确、稳定。4、根据业务需要，提供面向业务的报表、数据提取等数据服务。任职要求: 1、精通linux脚本2、全日制本科及以上学历，三年以上数据仓库／ETL／数据处理相关开发经验。3、具备hadoop、hive、hbase、spark大数据开发及调优经验优先。4、熟练使用datax，Kettle，talend等etl工具5、至少熟练使用一种主流的BI工具，如Tableau、FineBI等。6、具备良好的学习能力，善于沟通，具备较强的业务推动能力和执行力。7、有良好的快速学习能力和团队协作能力。8、精通Java开发，熟悉Spring、Spring mvc、Spring Boot、mybaits、Struts、hibernate等框架中的一两种或以上",其他,500-2000人,spark,上海
java开发工程师（大数据方向）,https://www.lagou.com/jobs/6900999.html,青浦区,14k-25k,上海则一供应链管理有限公司,3-5年,本科,年轻团队 带薪年假 做五休二 法定假日,"岗位职责：1. 负责大数据开发平台建设，构建数据开发、管理和服务的统一平台2. 负责数据的数据仓库建设和数据分析，支持业务场景和应用解决方案开发任职要求1. 计算机或相关专业本科及以上学历，3年以上软件开发经验，精通Java开发。2. 熟练掌握常用的关系型数据库、非关系性数据库和数据仓库，具有SQL性能优化经验；；3. 熟悉Spring、Spring mvc、Spring Boot、mybaits、Struts、hibernate等框架中的一两种或以上 熟悉Redis的开源中间件技术4. 熟悉Jetty、Tomcat、Nginx等应用服务器的配置与运用；5. 了解微服务开发理念、实现技术，熟悉常见设计模式，熟练掌握SSH开发框架，熟悉多线程编程；6. 熟悉Maven项目管理工具SVNGit等其中一种版本管理工具;7. 熟悉Hadoop/Spark/Hive/HBase等大数据工具，对数据处理、数据建模、数据分析等有认识和实战经验,有过大型数据平台建设者优先；8. 思维敏捷，对新技术敏感，有较强的钻研学习能力；9. 具备良好的团队协同、沟通交流及抗压能力，善于独立分析和解决问题。",其他,500-2000人,spark,上海
高级算法工程师,https://www.lagou.com/jobs/7075128.html,浦东新区,17k-32k,中国电信股份有限公司云计算分公司,3-5年,本科,大数据 人工智能,职责描述：1、参与人工智能相关产品与项目的算法研发、应用部署和性能优化；2、参与算法平台等相关工具的研发；任职要求：1、全日制统招本科及以上学历，计算机类相关专业优先；2、五年以上软件研发类经验，至少两年以上图像识别、语音识别、自然语言处理、数据挖掘等相关算法经验，有机器学习相关经验优先，有人工智能相关产品研发经验优先； 3、熟悉机器学习常用算法及深度学习、强化学习等相关领域知识，理解并熟悉常用深度学习网络结构，如ResNet、Inception-ResNet、PyramidNet、 MobileNet等；至少能熟练使用Tensorflow、PyTorch、Paddle、Caffe、MXNet、Theano等深度学习框架中的一种； 4、有图像识别、视频分析、问答系统、知识图谱等相关算法研发上线经验优先； 5、对云计算、边缘计算、CDN、 Spark、 Hadoop等技术栈有了解的优先，有智慧园区、智能工厂、智慧交通、智能监控等相关项目研发经验优先；6、诚实守信、作风踏实严谨、责任心强；具备良好团队协作能力精神；学习能力强，善于解决复杂问题；7、35周岁（含）以下，身心健康；8、过往工作业绩优秀者、有知名互联网/IT、AI、云服务等相关行业头部企业有工作经验者，年龄、工作年限可适当放宽。,数据服务,500-2000人,spark,上海
【上海专场】数据平台技术专家/架构师P7P8,https://www.lagou.com/jobs/7146620.html,浦东新区,30k-60k,支付宝（杭州）信息技术有限公司,不限,本科,"期权激励,靠谱团队,技术驱动",团队简介：我们隶属于蚂蚁金服-技术风险部（不是安全风控，简介可参考蚂蚁金服公众号文章： https://mp.weixin.qq.com/s/RX_63WILQpd__DvzqdGwxA ），大部门的主要工作是负责蚂蚁全站系统的“高可用（从线程级到 IDC 级的故障自动感知定位和恢复决策）”和“资损防控（蚂蚁所有 BU 业务资金流的实时自动核对和快速止损）”这两个课题。 在蚂蚁金服这样庞大的系统部署规模和数据体量、频繁的新特性新功能变更频率、多 BU 并存乃至跨国的错综复杂的业务和资金流大背景下，可以预见这两项工作无法通过传统互联网公司堆人的方式快速应对，即便是很有经验的领域专家。所以大方向以数据驱动和智能化的思路来破局，一方面需要构建夯实且数据健全的基础平台设施，包括刻画整个蚂蚁生产环境的元数据，以及刻画每一笔业务请求的实时数据流，支撑全站全量数据的高可靠近线传输、组织、存储与计算。另一方面则需要结合场景去运用业界较为前沿的风险防控建模与算法理论经验，针对问题域的智能分析，达到人工辅助甚至自动决策执行。经过一段时间的探索与建设，我们已经有一个较好的起步和基础支撑，但从追求**的角度还有很多挑战尚未攻克。具体方向上区别于业务功能开发团队，我们主要面向蚂蚁全局构建基础设施平台，涉及到 Java 工程，大数据计算，海量数据存储，领域建模，图计算与算法应用等子领域。职位描述：1.负责蚂蚁金服技术风险数据基础设施的研发建设，包括刻画整个蚂蚁 SaaS/PaaS/IaaS 环境拓扑结构的元数据，以及刻画每一笔用户请求的实时数据流。2.对全链路稳定性和数据质量负责，进行实时监控，分析，最终提供保障数据的质量，包括低延时，高可用等指标。3.参与数据流建设，满足实时数据流上的各种复杂计算需求，包括图计算，多流合并，以及各种常见 transform 计算。4.参与蚂蚁双十一等大型活动，通过平台能力保障蚂蚁系统在极限压力下的高可用与资金安全。5.持续对接数据平台上的各类技术风险防控业务方，满足不断发展的业务需求。职位要求：1.扎实的计算机专业基础，包括算法和数据结构，操作系统，计算机网络，计算机体系结构，数据库等。2.扎实的 Java 或相关编程语言基础，良好的编程素养，对代码有美感和**的追求。3.理解实时流计算（ 比如 Spark/Storm/Flink ）或海量数据处理（ 比如 Hadoop/HBase/Hive ）、图计算相关经验优先考虑。4.强烈的技术热情和工作责任感，热衷于创新和分享，逻辑清晰并具备批判性思维能力和习惯。5.计算机软件或相关专业毕业，本科或以上学历； 211/985 优先。工作地点：上海，浦东新区南泉北路，支付宝大厦编程语言：Java招聘范围：社招（ P7P8 ）,"金融,移动互联网",2000人以上,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/4648083.html,浦东新区,15k-25k,上海浦东发展银行股份有限公司信用卡中心,1-3年,本科,"潜力,高薪",1.计算机及相关专业本科以上学历。2.掌握数据建模语言，并且具有良好的建模能力；熟悉hadoop生态系统，熟练应用hive、spark、hbase、ES等。3.有分布式大数据平台开发经验，对CDH/HDP等大数据集群的应用、运维和调优有相当的经验。4.拥有良好的沟通能力和团队协作能力，勇于接受挑战，自我驱动，具备较强的学习能力、创新应用能力。5.三年及以上海量数据的数据挖掘、机器学习算法建模经验，具有较强的数据整合，数据分析/挖掘和解决业务问题的能力。,金融,2000人以上,spark,上海
高级数据仓库开发工程师,https://www.lagou.com/jobs/4648122.html,浦东新区,25k-35k,上海浦东发展银行股份有限公司信用卡中心,3-5年,本科,"高薪,大平台",职位描述：工作职责：1、负责公司内部数仓分层逻辑模型的设计、建设与维护，构建可扩展的数据仓库底层模型2、负责公司数据处理流程的优化、定位并解决有关技术问题3、参与制定公司数仓规划、数据研发规范、以及数据治理体系管理方案 岗位要求：1、5年以上数据仓库工作经验，熟悉数据仓库模型设计方法论，有实际搭建公司层级数仓的经验，有互联网公司或者金融企业数仓建设经验优先2、精通数据仓库有关领域知识，例如元数据管理、主数据管理、ETL工作流、SQL性能调优等3、精通SQL、熟悉Shell、具备海量数据加工经验，熟悉Hive/Flink/Spark等开源大数据工具优先4、有较强的问题抽象、概括、总结能力，独立思考并能以产品的思路提出解决方案5、具有较好的沟通理解能力，团队协作和创新能力6、有一定团队管理经验优先。,金融,2000人以上,spark,上海
资深推荐算法工程师,https://www.lagou.com/jobs/6295121.html,徐汇区,35k-60k,上海匹卓科技服务中心,不限,本科,五险一金，年终奖，双休,"岗位职责：1、利用机器学习技术，优化短视频的推荐、用户匹配、广告系统，以及用户的体验；2、分析基础数据，挖掘用户兴趣，增强推荐、广告系统的预测能力；3、分析用户商业意图，挖掘流量潜在商业价值，提升流量变现；岗位要求：1、3年及以上工作经验，本科及以上学历，计算机、机器学习，数学和模式识别相关专业；2、热爱计算机科学和互联网技术，对人工智能类产品有浓厚兴趣；3、具备强悍的编码能力，熟悉 linux 开发环境，熟悉 C++ 和 Python,Scala, Matlab语言优先；4、有扎实的数据结构和算法功底，熟悉机器学习、自然语言处理、数据挖掘、分布式计算、计算机视觉中一项或多项；5、对用户画像、推荐系统、计算广告、搜索引擎、图像和视频处理相关技术有经验者优先；6、有hadoop/spark等大数据开发经验优先7、优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激情。",移动互联网,50-150人,spark,上海
算法挖掘专家,https://www.lagou.com/jobs/6849929.html,普陀区,25k-40k,上海拉扎斯信息科技有限公司,3-5年,硕士,知名互联网公司，福利丰厚,"职责描述：1、 从系统应用的角度，在大数据环境下利用机器学习、深度学习等理论和方法，对海量结构化、非结构化数据进行挖掘并发现数据的价值；2、 负责算法模型的搭建、落地和维护；3、 参与AB测试，对算法模型进行持续迭代。 任职条件：1、硕士以上学历，扎实的数学基础，熟悉线性代数、统计、运筹优化等；2、对常用机器学习算法理解透彻；3、有相关算法工作经验3年+，能贴近业务对实际问题提出算法模型的解法；4、熟悉Python, R及有相关工程经验，使用过Pytorch,Tensorflow等工具，熟悉Hadoop/Hive/HBase/Spark/Storm等系统，有实际成果并发表在国际**会议期刊",消费生活,2000人以上,spark,上海
大数据运维工程师,https://www.lagou.com/jobs/6510201.html,徐汇区,16k-22k,深圳市易博天下科技有限公司,3-5年,大专,发展好 年终奖金 团队氛围好,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行； 2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长； 3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具； 4、负责Hadoop/Hbase/Spark/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。招聘要求1、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP等协议； 2、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具； 3、熟悉Hadoop大数据生态圈，包括但不限于CDH/Ambari/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Flume/Elasticsearch/kibana/MySQL/Redis等； 4、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台； 5、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用； 6、熟悉常用运维监控工具，包括但不限于nagios/ganglia/zabbix/grafana/open-falcon等，和相关插件的开发。比如邮件、短信、微信报警插件等； 7、熟悉常用运维自动化工具，包括但不限于ansible/puppet/SaltStack等代理工具的使用和优化； 8、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力； 9、有大数据开发经验和阅读源码能力者优先。,"移动互联网,消费生活",150-500人,spark,上海
（高级）机器学习工程师,https://www.lagou.com/jobs/6608866.html,浦东新区,20k-35k,上海数禾信息科技有限公司,1-3年,硕士,行业领先 补充公积金 大牛多 弹性不打卡,职责描述：1，负责用机器学习或深度学习技术建模，给公司的业务部门提供各类模型支持2，模型开发覆盖需求讨论，取数&数据处理、建模调参、测试反馈分析、上线&迭代。3，持续跟踪机器学习、深度学习最前沿技术，能够不断提出挑战模型，持续改善线上模型效果任职要求：1. 机器学习、深度学习领域2年及以上的研发经验。2. 硕士及以上学历，数学、统计学、计算机等相关专业。3. 掌握逻辑回归，xgboost，lightgbm等机器学习算法的原理并在实际工作中使用过4. 有dsp，dmp计算广告经验的会有加分5.熟悉sql和spark,金融,500-2000人,spark,上海
机器学习专家,https://www.lagou.com/jobs/5511282.html,浦东新区,30k-60k,上海数禾信息科技有限公司,5-10年,不限,移动金融，未来金矿，精英团队，助力成长,工作职责： 1.带领数据团队分析和挖掘业务需求，应用统计学，数据挖掘，机器学习等领域的成熟技术建立模型，解决互金领域场景的实际问题。2.对算法模型进行持续测试，评估，分析，调优工作。3.带领工程团队，完善公司内部机器学习工程化平台，为业务部门的模型团队，提供底层的平台化服务。4.与学术界保持联系，跟踪相关领域的最新进展，推动把新进的理念及成熟的技术引用于实际业务场景之中。  任职要求： 1.五年以上机器学习或算法相关工作经验，能够结合业务创新性的提出解决方案，能独立完成项目。2.有较高的数据敏感度和数据分析能力，熟悉机器学习，数据挖掘及相关领域的理论和技术。3.扎实的编程基础，至少精通一门编程语言，熟悉Hadoop、Spark等为佳，熟悉tensorflow、pytorch、MXNet等为加分项。4.在互联网金融风控反欺诈、C端营销获客、用户经营等领域有丰富经验者优先；5.具备强烈的责任心，优秀的沟通能力和执行能力。,金融,500-2000人,spark,上海
物流数据中心架构师(P7),https://www.lagou.com/jobs/6875658.html,普陀区,30k-50k,阿里巴巴(中国)有限公司,5-10年,本科,固定13薪+奖金绩效(0~6个月年终奖),奖金绩效：按部门/公司年度绩效和个人年度绩效评估发放0~6个月不等的年终奖职位描述：岗位职责1.  主导并参与数据中心领域业务后端服务架构、设计、核心功能开发、系统优化等工作；2.  参与数据中心平台化建设，参与技术决策、技术选型、技术风险评估；3.  推进平台架构升级、稳定性建设、高性能优化、数据质量保障等工作，并负责制定技术规划和落地推进；4.  负责技术难点调研和攻关，解决系统中关键的设计、性能等问题；5.  制定团队目标，拆解排期，规划人力和落地执行；任职资格1.本科及以上学历（985/211优先），扎实的计算机基础。2.5年及以上Java开发工作经验，1年以上大数据经验，深入了解大数据计算平台常规架构和相关产品组件（Hadoop、Hive、Spark、Storm、Kafka、Elasticsearch等）原理、使用和应用场景。并有实际大数据项目经验3.深入使用Java，熟悉掌握常用的Java类库及框架，如多线程、并发处理、I/O与网络通讯，Spring、Mybatis等;系统排障经验丰富，可以快速排查定位问题；至少对高并发、分布式、缓存、jvm调优、序列化、微服务等一个或多个领域有过深入研究，并且有相关实践经验4.精通MySQL应用开发，熟悉数据库原理和常用性能优化技术，以及NoSQL，Queue的原理、使用场景以及限制5.对技术有激情，喜欢钻研，能够快速接受和掌握新技术，擅长使用开源框架，可以完成技术选型、新技术落地等工作6.具备良好的业务sense，能够站在业务、产品的角度深入发掘内在逻辑，进行合理的抽象与建模，做出合适的架构设计决策；7.  具有良好的沟通、团队协作、计划和主动性思考的能力，在互联网或业界有一定影响力公司的工作经验者优先。,电商,2000人以上,spark,上海
算法工程师,https://www.lagou.com/jobs/6818441.html,浦东新区,22k-29k,深圳平安综合金融服务有限公司,3-5年,本科,带薪年假，年度体检，旅游,工作职责：1、负责银行零售业务场景的模型的设计、开发验证和实施2、参与业务需求分析，负责数据模型算法的方案设计和开发；3、负责与产品、运营、系统开发等部门的对接，保证模型正确上线和常规维护；4、负责根据产品需求，并结合业务场景对模型进行优化；任职要求：1、计算机、统计学、数学、物理学等相关专业；2、熟悉分类、聚类、回归、图计算等机器学习算法；3、熟练掌握SQL语言，掌握python、R、Java等建模语言4、积极主动，保持好奇心，有持续学习的动力，关注前沿技术的发展；5、有分布式数据处理平台经验(hadoop、spark)优先6、互联网及金融从业背景优先,金融,2000人以上,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6978935.html,浦东新区,13k-20k,深圳市博奥特科技有限公司,3-5年,本科,金融项目经验，薪资待遇好,"大数据开发初，中，高3个级别，学信网可查1. 3年大数据工作经验，熟悉hive,spark组件2.数据采集，能快速融入开发任务3.做过Java开发的优先","移动互联网,金融",150-500人,spark,上海
数据组研发负责人-广告,https://www.lagou.com/jobs/7203884.html,浦东新区,35k-65k,连尚（北京）网络科技有限公司,5-10年,本科,"弹性工作,技术驱动","1. 负责公司广告数据线的数仓设计规划及建设工作；2. 参与大数据平台的建设，优化数据处理流程的具体工作（实时/批）；3. 负责数据收集、质量监控、任务调度、数据存储、查询性能的优化等工作；4. 统筹运营人员的数据需求，以报表等形式提供业务支撑；5. 设定团队目标，指导团队成员，持续提升团队能力。1. 本科5年以上大数据场景下的工作经验；2. 良好的沟通协作及团队管理能力，2年以上团队管理经验，熟悉各类项目管理工具；3. 3年以上以hadoop/hbase/hive为核心的大数据组件相关开发经验；4. 3年以上基于kafka/flink/spark等流计算平台的实时数据开发经验；5. 掌握数据仓库理论知识及建模方法，具备良好的抽象思维能力及数学功底；6. 掌握至少一项大数据场景下的olap方案并具备实施经验，例如，Kylin/Clickhouse；7. 具备十亿级数据处理的经验, 具备应对海量数据产生的各类挑战的能力；8. 熟悉互联网计算广告原理者优先。","移动互联网,消费生活",500-2000人,spark,上海
大数据算法工程师,https://www.lagou.com/jobs/7073613.html,虹口区,20k-35k,威比网络科技（上海）有限公司,3-5年,硕士,大型互联网教育公司,"工作职责：1. 通过挖掘、分析海量数据，建立具备解释力和预测力的算法模型，解决业务问题；2. 大规模机器学习模型的建模、特征工程和模型调优工作；3. 对算法上线的效果进行监控分析，并持续优化;4. 行业发展前沿的跟踪，选择适合公司实际业务需求的算法加以应用，创造业务价值。 任职要求：1. 全日制硕士或以上学历，统计学、计算机及相关专业；2. 2-5年以上大数据算法相关工作经验；3. 掌握系统的数据分析和机器学习方法论，深入理解算法原理，有过用数据分析和机器学习方法成功解决业务问题的项目经验；4. 有推荐、搜索或广告算法研发经验者优先，有NLP经验者优先；5. 熟练编写SQL进行数据分析；6. 熟练使用Spark/Python/R/TensorFlow/Pytorch进行数据分析和机器学习, 能自己编写算法者优先；7. 熟悉linux环境程序开发，熟悉Hadoop大数据环境；8. 有良好的书面和口头表达能力。","移动互联网,教育",2000人以上,spark,上海
大数据开发工程师（上海）,https://www.lagou.com/jobs/7131308.html,徐汇区,16k-24k,深圳市易博天下科技有限公司,3-5年,本科,双休；五险一金；年终奖金；团队氛围好,1.构建及实施公司BI项目；2. 参与大数据处理系统或应用的设计、开发、维护。  3. 参与大数据相关项目建设，参与架构讨论并推进技术演进和优化；4. 开发数据统计系统，为实时监控、实时运营数据分析、个性化推荐提供数据支持。任职资格：1. 计算机相关专业本科及以上学历，3年以上大数据项目经验。2. 精通Java编程，具备扎实的数据结构与算法功底。3. 熟练掌握Hadoop、Spark、Storm、HBase的原理特性以及适用场景，精通Spark实时计算开发，并具备大规模数据集的实际开发经验。 4. 有大规模数据计算平台的架构设计经验，且精通大规模数据集的存储方案设计优先。 5. 具备用户问题的定位及解决能力，善于归纳总结，对数据敏感。 6. 思维活跃、敢于担当、乐于沟通，具有良好的团队合作精神，积极主动，能承受一定的工作压力。,"移动互联网,消费生活",150-500人,spark,上海
机器学习/Python专家,https://www.lagou.com/jobs/7174660.html,黄浦区,20k-40k,神谱科技（上海）有限公司,3-5年,本科,技术大牛，蓝海市场，行业前景好，公司期权,"工作职责：1.   负责联邦学习、多方安全计算等相关产品中的机器学习算法的研究、实现和优化；2.  针对机器学习在实际业务场景落地中的问题，探索高效准确的解决方案，并持续跟进效果和业务价值；3.  从具体市场需求出发，将机器学习算法应用到产品中，以帮助解决互联网、银行、券商、零售、广电、融合媒体等广泛领域中的机器学习问题，为客户创造业务价值；4.  跟踪业界和学术界最新进展，并且能够快速应用到业务中。岗位要求：1.   良好的编程能力和规范，熟悉 Python / Go / Linux2.  有三年以上的机器学习项目开发经验，熟悉一个或多个常见的神经网络开源工具库，例如：Tensorflow, Keras，PyTorch，Caffe 等；3.  熟悉机器学习、自然语言处理、推荐系统等相关算法，在以下至少一个领域有过实际经验：用户画像、时序预测、个性化推送、推荐系统；4.  有海量数据的处理和分析经验，熟悉一个或多个大数据处理工具，例如 Hadoop，Spark，Hive 等；5.  有网络安全领域算法研发经验优先，有金融风控项目工作经验更佳；6.  良好的理解能力和学习能力，主动性和责任心强。","移动互联网,区块链",少于15人,spark,上海
大数据产品开发工程师,https://www.lagou.com/jobs/7137277.html,杨浦区,15k-30k,优刻得科技股份有限公司,3-5年,不限,互联网行业 福利完善,工作职责：1负责云上大数据产品架构设计与开发2跟踪并解决用户使用产品过程中的问题3.跟踪大数据社区发展动态任职资格：1熟练掌握java开发，熟悉常用的JAVA开源框架（Spring/Spring Boot等）2.熟悉Hadoop/spark/flink/presto/elasticsearch/greenplum/kylin/hbase其中之一的原理、架构和应用3.熟悉一门脚本语言（Shell、Python、JavaScript等）4熟悉Linux开发环境，熟悉常用的命令以及运维工具5.有基于开源的大数据做二次开发经验的优先6.有数据集成/数据开发/数据治理经验的优先,企业服务,500-2000人,spark,上海
系统运维工程师,https://www.lagou.com/jobs/7176023.html,虹口区,20k-30k,上海顺如丰来技术有限公司,5-10年,本科,职责明确 高效,岗位职责：1、开发自动化运维平台及定制化运维工具，提高运维效率，节省日常维护时间；2、运维安全策略制订与维护，运维审计系统开发，保障线上数据安全和操作安全；3、参与公司线上项目部署与维护，保障系统安全；4、设计、制定后台并发服务架构、分布式系统架构、优化模块系统架构任职要求：1、精通Linux操作系统管理和网络原理(centos、ubantu)；2、熟悉常用的开源软件Nginx、MongoDB/Mysql/MariaDB、LVS、redis、NSQ等3、熟悉大数据相关组件和技术，如kafka、Hadoop生态系统、Spark生态系统等4、熟悉Ansible/Puppet/SaltStack/Jenkins等自动化运维部署工具；5、熟悉监控和告警相关工具（如 Nagios/Zabbix/Prometheus等）6、熟悉ELK技术栈。7、掌握交换机、路由器、防火墙等网络设备的配置与管理，熟悉网络设计与优化、网络安全、网络运行监控；8、熟悉NoSQL数据库(如Redis/MongoDB、hbase等)9、有大规模分布式集群系统维护和优化相关经验，对类似ZooKeeper等工具有所了解10、较强的团队协作能力，优秀的执行能力11、熟悉容器相关技术（docker/CoreOS，kubernetes等）12、高度的责任感，较强的故障分析及排除能力，善于在工作中学习，能够承受较大工作压力。,"数据服务,物联网",150-500人,spark,上海
算法工程师,https://www.lagou.com/jobs/6710189.html,虹口区,20k-40k,上海顺如丰来技术有限公司,3-5年,本科,智慧供应链,工作职责: 1.基于海量数据和真实客户需求，与咨询师团队合作对供应链业务问题进行准确定义、数据分析、方案制定及实施；2.对物流供应链相关各环节进行分析、预测，并负责相关机器学习、深度学习、强化学习或运筹优化模型的研发、设计和部署等工作，配合工程团队产出企业级的供应链算法产品；3.负责跟进供应链运营、供应链优化、库存优化、机器学习、数据挖据、数据可视化等技术并持续跟踪研究，最终运用到产品系统中；4.项目内容包括但不限于销量预测、仓网规划、选址问题、路径规划、车辆调度、门店组货、定价策略等。岗位要求: 1.熟练掌握java/python/C/C++等编程语言中至少一种，精通Hadoop、spark、Hive等大数据处理工具，熟悉各种数据库及sql使用；2.运筹优化方向：熟悉运筹优化领域主要问题、理论工具及常用解决方法，对LP、MIP、DP、Meta-Heuristics有较深入了解，有求解引擎建模求解经验；3.机器学习方向：掌握常见的机器算法模型及原理，如LR、D/R Tree model、Boosting、Bagging、SVM、Clustering、PCA等，熟悉工程应用中GBDT、XGBoost关键参数；4.具备较强的数据敏感性、业务理解能力及抽象能力，能快速理解问题并设计解决方案；5.自我驱动，具有较强学习能力、责任感和团队协作精神。,"数据服务,物联网",150-500人,spark,上海
蚂蚁集团-数据技术（高级）专家,https://www.lagou.com/jobs/7106485.html,浦东新区,30k-60k,支付宝（杭州）信息技术有限公司,3-5年,本科,长期激励 大平台 团队氛围 快速成长,职位描述1、负责蚂蚁数据全域业务数据资产建设，包含数字金融、本地生活、IOT、支付业务、消费金融、金融风险、收索营销、商业银行、会员/商家/企业运营等业务领域。洞察行业趋势和消费者价值，支撑数字化、智能化商业决策及运营，实现数据价值最大化使命；2、参与大数据基础架构和技术体系的规划建设，包括统一采集、数据资产建设与管理和数据质量及稳定性保障体系、数据处理智能化和自动化体系的建设。职位要求1、3年以上工作经验，计算机等相关专业本科以上学历 ，具有丰富的数据建模实践经验；2、精通业务建模、数据仓库建模、精通ETL设计开发，具备体系化的数据质量与数据治理相关经验，有大型项目相关领域深入实践经验，能独立主导完成某一业务领域的整体模型设计，具备跨域的沟通协调能；3、精通hadoop/yarn/hive等大数据体系，深入了解起背后的实现原理，并能够调优；具有超大规模数据项目，有百万级TPS数据处理经验尤佳；4、掌握实时计算技术体系包括数据采集、计算引擎storm/spark/flink，对实时计算所涉及的事务、容错、可靠性有深入理；5、良好的思维逻辑性和语言表达能力，以及良好的项目沟通和协调能力；6、具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力尤佳 。,"金融,移动互联网",2000人以上,spark,上海
数据分析师,https://www.lagou.com/jobs/5870002.html,长宁区,15k-30k,携程计算机技术（上海）有限公司,1-3年,本科,五险一金 节假日福利 带薪年假 年终奖,"1. 通过研究并分析数据，挖掘业务增长点，规划并设计改进方案，用数据驱动增长；2. 观察和分析航空业变化趋势，优化流程，设计营销方案，提升项目产量；3. 跨部门沟通和合作，推进方案落地。任职要求：1. 统计、计算机、数学等相关专业本科及以上学历；2. 热爱互联网，对数据应用抱有浓厚的兴趣，有强烈的上进心和求知欲，善于学习和运用新知识 ；3. 有1年以上数据分析经验，熟悉SQL，熟悉或使用过至少一种统计分析/数据挖掘软件（R, Python等）者优先；4. 有大数据处理经验，如Hive/Spark/Hadoop等使用经验者优先 。",旅游,2000人以上,spark,上海
算法经理（机票）,https://www.lagou.com/jobs/4322688.html,长宁区,30k-50k,携程计算机技术（上海）有限公司,5-10年,本科,"算法,机器学习,数据挖掘",工作职责:1.带领团队分析和挖掘业务需求，应用统计学，数据挖掘，机器学习等领域的算法建立数据模型，解决航空领域的实际问题；2.对算法模型进行持续测试，评估，分析，调优工作；3.与学术界保持联系，跟踪相关领域的最新进展，把领先成果转化为专利或学术论文。任职资格:1.五年以上算法相关工作经验，能够结合业务创新性的提出解决方案，能独立完成项目；2.有较高的数据敏感度和数据分析能力，熟悉机器学习，数据挖掘及相关领域的理论和技术；3.扎实的编程基础，至少精通一门编程语言，熟悉Hadoop、Spark等为佳；4.具备强烈的责任心，优秀的沟通能力和执行能力。,旅游,2000人以上,spark,上海
产品经理（大数据）,https://www.lagou.com/jobs/6239628.html,虹口区,20k-35k,上海掌小门教育科技有限公司,3-5年,本科,14薪，独角兽，大牛云集，,【职位描述】：1.负责掌门1对1平台数据产品的需求整理、原型设计以及产品的快速迭代；搭建数据指标体系，保证数据指标口径统一和数据准确性；2.深入理解业务数据，参与数据模型的设计，包括数据平台、数据产品、数据服务开发，与开发团队一起，规划和完善数据分析平台，满足业务决策和业务分析在应用数据过程中的功能述诉求；3.完成所负责数据产品线的业务规划、功能逻辑设计、竞品分析、数据验证、产品运营、效果分析，协调产品开发、测试进行迭代优化和问题评估；4.根据用户对数据的应用场景，抽象出功能模块及功能依赖关系，制定功能优先级，负责推进数据产品迭代和产品进度； 5.执行UAT验证，跟踪上线产品的数据效果、用户反馈，收集和主动挖掘改进需求，根据业务需要持续改进产品，提升产品价值。 【任职资格】1.本科及以上学历，统计学、数学、计算机专业优先；2.5年以上数据产品相关经验；熟悉BI/ DW原理和实施，有BI项目经历，有数据仓库构建和使用经验者优先；3.优秀的交互设计能力和数据可视化设计能力，精通Axure RP等产品设计工具，对数据敏感，有良好的沟通协调能力、逻辑思维能力和产品执行力；4.熟悉Hadoop(HDFS/MapReduce/Hive)、Spark、HBase、Storm、Kafka、Flume等框架技术，有大数据产品、报表平台、数据仓库规划建设经验者优先。,"移动互联网,教育",2000人以上,spark,上海
数据分析,https://www.lagou.com/jobs/6620608.html,虹口区,10k-20k,上海掌小门教育科技有限公司,1-3年,本科,独角兽,工作职责：1-负责数据报表的开发。2-负责各部门总监的数据分析任务和业务决策支持。工作要求：1-本科以上学历，有1-3年以上互联网公司工作经验。2-可以快速熟悉业务，进行数据提取和数据分析。3-熟练掌握hive-SQL编程，shell脚本开发，理解Hadoop，spark等原理。4-有BI报表开发经验，熟练使用excel。5-沟通表达好，可以适应高强度工作优先。,"移动互联网,教育",2000人以上,spark,上海
2621HD-应用架构师,https://www.lagou.com/jobs/5913761.html,浦东新区,18k-30k,平安好医投资管理有限公司,5-10年,本科,"五险一金,带薪年假,节日福利,定期体检",,金融,500-2000人,spark,上海
高级算法工程师,https://www.lagou.com/jobs/7144633.html,杨浦区,25k-40k,薪海科技（上海）有限公司,5-10年,本科,企业福利好,职责描述：1、负责人工智能产品与项目的技术架构、算法的设计、部署和优化；2、关注研究图像处理、NLP、语音识别等人工智能技术，与产品团队协作，探索在智慧园区、智能工业、智慧城市、智能安防、视频监控等行业的应用机会并利用技术实现落地；任职要求：1、全日制本科及以上学历，5年以上人工智能、数据挖掘等相关项目经验； 2、熟悉机器学习常用算法及深度学习、强化学习等相关领域知识， 理解并熟悉常用深度学习网络结构，如ResNet、Inception-ResNet、PyramidNet、 MobileNet等； 3、掌握机器学习、深度学习等相关知识，至少能熟练使用Tensorflow、PyTorch、Paddle、Caffe、MXNet、Theano等深度学习框架中的一种； 4、有图像识别、问答系统、知识图谱等实际项目经验； 5、 对云计算、边缘计算、CDN、 Spark、 Hadoop等技术栈有了解的优先，有智慧园区、工业大数据、智慧交通、智能监控等相关项目研发经验优先。,企业服务、金融,50-150人,spark,上海
数据分析师,https://www.lagou.com/jobs/7056421.html,黄浦区,20k-40k,众安在线财产保险股份有限公司,5-10年,本科,丰厚年终奖、海外团建,主要职责：1、健康险业务场景中，基于大数据风控手段，为业务风险进行有效防范；2、体系内外的数据探查分析，发现对健康险业务风险的影响因素；3、承保前后风险筛查，并对各类风险人群进行追踪，进行全面风险防范；4、理赔阶段风险筛查，有效识别理赔欺诈和逆选择，降低理赔风险；5、已上线风控规则优化，提高数据风控效率。岗位要求：1、有5年以上数据分析、风控岗位经验，优先考虑健康险、医疗健康等行业背景；2、了解Hadoop或Spark等大数据平台，熟练使用Hive、SQL等工具开发；3、熟练掌握逻辑回归、决策树、贝叶斯、聚类等算法基础原理，并在项目中有成功经历，至少掌握R、Python、SAS等统计建模工具中的一种；4、敏锐全面的洞察力，清晰缜密的逻辑思维能力，以及独立的分析调研能力；5、良好的数据分析能力，善于总结问题并能积极推进问题的解决。,金融,2000人以上,spark,上海
JAVA开发（AI工程方向）,https://www.lagou.com/jobs/7060158.html,浦东新区,20k-40k,平安健康互联网股份有限公司上海分公司,3-5年,本科,上市公司 知名互联网企业,"岗位职责1、负责业务平台关系统的开发工作；2、快速解决运行过程中出现的故障和问题，保证系统稳定运行；3、持续重构优化和改进系统；4、重点项目的设计方案支持与评审，难点攻关5、了解NLP、机器学习、深度写相关算法6、设计过人机对话方案设计和数据模型设计优先任职要求1. 3年以上Java服务端开发经验；2. 熟悉大型分布式环境的服务端应用框架；3. 熟悉Spring, MySQL, MyBatis等主流开源框架；4. 熟悉Linux/Unix环境和基本命令的使用；5. 善于理解业务，逻辑思维清晰，能够独立完成业务模块的设计；6. 良好的编码习惯和工程习惯，熟悉git、maven、jenkins等日常工具；7. 良好的沟通能力和团队协作能力；8. 追求高效，同时有效应对的压力；9. 熟悉Hadoop/Hbase/Hive/Zookeeper/Spark等开源项目，有patch源代码经验者优先；","移动互联网,医疗丨健康",2000人以上,spark,上海
大数据研发,https://www.lagou.com/jobs/6499833.html,浦东新区,20k-35k,上海微汇金融信息服务有限公司,5-10年,本科,"弹性工作,补充公积金,补充医疗","岗位职责:1. 参与公司数据开发平台、BI产品等大数据产品的设计和开发;2. 负责数据开发平台、BI产品等大数据产品的部署和维护，保证其稳定和可靠;3. 关注和参与大数据方向开源产品的技术动态与演进，推动产品与技术架构持续更新;任职要求:1. 计算机相关专业，本科及以上学历，5年以上软件开发经验，3年以上互联网产品或分布式系统开发设计经验;2. 精通Java, Python, Scala等一种或几种编程语言, 并熟悉Linux操作系统及Bash Shell编程;3. 有Hadoop/Spark/Hive/Presto/HBase/ElasticSearch/Kafka等使用经验, 并熟悉上述常用的分布式系统架构设计和原理;4. 熟悉微服务框架及相关技术, 如Dubbo, SpringCloud等;5. 熟悉MySQL、Redis, 并了解或接触过其他数据库如 Oracle, SqlServer, PostgreSQL, MongoDB等;6. 了解容器技术, 如Docker, Kubernetes;7. 具有一定的软件设计能力, 热爱大数据和技术，相信技术改变世界，学习能力强，认同数据价值，有面向业务的思维, 较强的自主学习能力和英文技术文档阅读能力;8. 良好的沟通能力、团队精神及服务意识，勇于接受挑战，能承受较大的工作压力;9. 有生产环境快速trouble-shooting的经验和能力者优先;10. 有OLAP，多维度数据分析经验优先，有对数据仓库有较强的理论基础和理解者优先;",金融,150-500人,spark,上海
大数据运维工程师,https://www.lagou.com/jobs/6569875.html,浦东新区,15k-25k,上海派拉软件股份有限公司,3-5年,不限,发展双通道,岗位职责：1.负责大数据平台日常运维、巡检、故障处理等；2.负责简单的数据处理，脚本编写工作。岗位要求：1.本科以上学历，3年以上相关工作经验；2.熟悉Apache Hadoop、Spark、Storm、Kafka、HBase、Hive等大数据组件的安装部署、故障处理、性能调优；3.熟悉MySQL、Redis、MongoDB等数据库；4.熟悉Kettle、Sqoop等ETL工具;5.熟悉Linux、Shell、Python;6.2年以上CDH平台使用经验6.能适应出差。,数据服务,150-500人,spark,上海
数据库开发工程师,https://www.lagou.com/jobs/6097590.html,嘉定区,10k-16k,上海派拉软件股份有限公司,3-5年,本科,年终13薪、年度体检、年度旅游、团建,岗位职责：1、主要是编写SQL和存储过程；2、协助开发人员排查相关问题，线上数据运维，数据同步等。职位要求：1.熟悉MySQL、Oracle数据库2.熟悉Linux、Shell、Python3.熟悉Hadoop、Yarn、Spark、Hive、HBase、Datalake等大数据技术4.熟悉阿里云RDS、DRDS、AnalyticDB、MaxCompute、E-MapReduce者优先5.有DBA证书者优先6.三年以上相关工作经验。,数据服务,150-500人,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/6880040.html,徐汇区,13k-18k,深圳市拓保软件有限公司,3-5年,本科,五险一金，年假，年终奖,1、计算机相关专业优先，三年以上开发经验2、至少熟悉一门开发语言，比如：Java、Scala、Shell、Python等3、熟悉 Oracle，熟练掌握常见SQL、NoSQL数据库设计和优化；4、至少熟悉一种数据同步工具，如：KETTLE、DataStage、Sqoop等5、对大数据系统、分布式服务系统有一定了解、有企业大数据服务的互联网从业经历者优先，有健康险或是保险行业BI经验的优先6、熟悉大数据处理相关技术（Hadoop、Hive、Spark、Hbase等）的优先,数据服务,2000人以上,spark,上海
Java开发工程师,https://www.lagou.com/jobs/6839085.html,浦东新区,20k-40k,平安银行股份有限公司,3-5年,本科,福利好，上升空间大,1.熟悉常用的设计模式和中间件，如责任链，模版，适配器和nginx，tomcat，mq等2.熟练掌握jdk基本工具和原理，理解锁原理3.熟练掌握常用的spring全家桶套餐4.熟悉大数据和流式计算，如Hadoop，hdfs，spark，flink等5.能够洞见问题本质，用最深刻的理解从根本上解决问题5.熟悉常用的代码管理和开发集成工具；表达简洁明了，沟通顺畅有效，追求**代码7.有大型系统和高并发高可用系统架构经验者优先8.了解广告系统基本原理和运营规则优先9.211本科学历或者硕士学历者优先,金融,2000人以上,spark,上海
nlp算法工程师,https://www.lagou.com/jobs/6811243.html,长宁区,30k-60k,上海寻梦信息技术有限公司,不限,本科,16薪，业务发展迅速,岗位描述：1. 参与商品语义理解/主题挖掘/商品推荐等方向的研究与系统开发；2. 根据项目需求实现、优化算法，解决实际工程问题。任职要求：1. 具备自然语言处理/搜索/推荐/数据挖掘/知识图谱等领域的项目经验，熟练掌握自然语言处理方法，如句法分析/语义分析/结构化抽取等；2. 掌握主流机器学习和深度学习方法，熟练使用至少一种深度学习框架，如Tensorflow/Pytorch等；3. 熟悉Python/C++/Java，具备良好的算法基础和代码习惯；4. 熟悉Hadoop/Spark等数据框架。,"电商,移动互联网",2000人以上,spark,上海
大数据开发工程师,https://www.lagou.com/jobs/7205568.html,虹口区,15k-18k,上海威士顿信息技术股份有限公司,3-5年,本科,智能制造 大项目 稳定成长 烟草行业,"1、掌握数据库Mysql\Oracle\SqlServer，熟练掌握使用常用的SQL语言，并有应用其处理数据经验者；2、熟悉linux操作系统的使用，对常用命令比较熟悉者；职位要求：1、具备扎实的计算机理论基础，对数据结构及算法有较强的功底。2、具有丰富的数据加工处理经验，对数据处理、数据清洗、数据建模、数据分析等有深刻认识和实战经验。3、有时序数据处理开发经验者，如：influxdb，opentsdb。4、精通多线程编程，有分布式开发经验值优先。5、精通使用Python,Spark,Java,Pig等开发，有系统的源码阅读经历，有开源社区开发经验者优先。6、熟悉常用的大数据组件，如：Sqoop、Kafka、Zookeeper、flume、solr、Kylin、ElasticSearch、azkaban、phoenix、StreamSets等。7、有平台搭建和平台优化经验者优先。","移动互联网,企业服务",150-500人,spark,上海
分布式计算工程师（高级） (MJ000110),https://www.lagou.com/jobs/5271962.html,徐汇区,20k-40k,星环信息科技（上海）有限公司,不限,本科,技术平台好 成长机制完善,工作职责：1. 负责星环分布式计算系统的设计，开发与运维工作；2. 负责分布式计算系统的查询优化，运行优化，分布式调度等工作。职位要求：1、本科及以上学历，计算机/软件工程专业，三年以上相关工作经验2、熟练掌握Java语言、SQL语言3、熟悉Linux平台4、有良好的操作系统、数据结构和算法功底5、具备一年以上，任意分布式存储系统(包括但不限于HBase/Mongdb/ceph)开发经验6、具有良好的沟通能力和良好的团队合作精神7、工作积极主动，自我驱动能力强，负责认真，主动思考8、熟悉spark、hadoop、hive、hbase者优先,数据服务,500-2000人,spark,上海
云计算资深架构师 (MJ000530),https://www.lagou.com/jobs/6599092.html,徐汇区,35k-65k,星环信息科技（上海）有限公司,5-10年,不限,云架构,"职责：1、总体把握云计算的技术方向、整体架构、解决方案和未来规划；2、负责云平台整体架构设计和高可靠性和高可扩展性设计；3、负责云平台整体解决方案设计；4、负责云平台以及相关服务PaaS的技术调研及技术决策；5、负责云平台关键模块的技术攻关以及新技术探索；6、负责云计算技术团队培训及建设；任职资格：1、计算机相关专业的本科或硕士学历，5年及以上云计算领域研发经验，有中大型云计算产品的系统架构设计者优先；2、熟悉主流虚拟化技术（KVM,XEN,VMware、OpenStack等），熟悉Docker、Kubernetes等容器技术者优先；3、深刻理解IaaS、Paas服务架构；4、熟悉c/c++、python、golang、nodejs等开发语言，熟悉开源分布式存储技术CEPH者优先；5、熟悉 Hadoop生态圈，深入理解大数据平台框架，对Kafka, Spark Streaming、Hive, HBase, Spark等技术有深入研究；6、关注云计算技术发展，具备优秀的学习能力，良好的问题分析与解决能力；7、优秀的人际沟通、团队协作能力；",数据服务,500-2000人,spark,上海
架构师java,https://www.lagou.com/jobs/6867335.html,普陀区,35k-50k,多点生活（中国）网络科技有限公司,5-10年,本科,复杂零售数字化业务场景,"岗位职责：1.负责新零售相关业务系统的设计和规划；2.保障系统的高可用性、强安全性、高扩展性；3.协助定位、解决开发过程中遇到的技术疑难问题，关键技术决策；4.负责Code Review，技术培训及指导，提升团队技术效率；5.关注领域内的技术发展趋势，负责研发团队新技术、工具的引入；岗位要求：1.计算机专业本科及以上学历，5年及以上互联网相关工作经验；2.拥有3年以上作为系统架构师直接负责电商或线下零售核心系统架构设计和实施的经验3.精通分布式、高并发系统的设计与开发；4.扎实的Java编程基础，对各种开源的框架如Spring Boot、Spring Cloud、Dubbo等有深入的了解，对框架本身有过开发或重构者可优先考虑；5.熟悉Redis、Kafka、Mongodb、Hadoop、Spark、ElasticSearch等大数据技术；6.优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激情；7.良好的团队合作能力、沟通意识和抗压能力，责任心强。","电商,消费生活",500-2000人,spark,上海
算法工程师,https://www.lagou.com/jobs/7206147.html,黄浦区,15k-30k,上海恺士佳信息科技有限公司,3-5年,硕士,弹性工作 节假日福利 生日会 年终奖金,职位描述：1、精通机器学习算法，了解算法原理；2、精通Python；3、熟悉并行化集群化算法处理及相关平台和类库（如Spark、TensorFlow等）；4、熟悉时间序列模型，有统计学专业知识；5、熟悉软件工程和OOP代码编写规范，能够编写适合产品化的软件产品；7、了解Agile敏捷开发流程；职位要求：1、2年以上机器学习、深度学习算法产品编写经验；2、有时间序列相关的大数据分析，xgbm、随机森林、LSTM等模型经验者优先；3、有语义分析，主要针对从互联网爬取的大量数据经验者优先。,企业服务,15-50人,spark,上海
大数据技术经理,https://www.lagou.com/jobs/6841538.html,松江区,20k-35k,海尔集团,5-10年,本科,大平台、稳定性高，薪酬福利完善,职责：大数据平台底层框架搭建优化，二次开发，支撑业务场景运用1、负责大数据产品技术的规划、设计、开发和优化工作，实现高质量数据的互通与共享；2、负责数据模型体系构建及数据主题设计和开发，搭建离线、实时数据公共层3、负责数据产品与应用的数据研发，发掘数据商业价值，打造**体验的数据产品；4、深入理解数据产品的使用场景，为业务方在可用性、成本上做更好的设计做参考；5、团队成员的搭建与培养，任务划分，进度监控，代码规范，质量保证；6、具有优秀的沟通、文档、表达能力； 四、关键能力/经验1、5年以上技术开发经验，3年以上大数据开发/管理经验，大学本科以上学历2、有作为技术负责人系统化解决问题的成功案例；有海量数据建模实践经验；有很强的数据设计抽象能力，善于从复杂的数据问题中找到关键路径，能够开发创新而实际的分析方法以解决复杂的商业问题；3、熟练掌握Hadoop、Spark、Flink、HBase的原理特性以及适用场景，精通流式计算开发，有开源二次开发经验；熟悉TensorFlow、Theano、Caffe、Keras等机器学习框架4、从事大数据分布式存储/应用服务的设计和开发，挑战大规模、高并发、易运维的分布式系统设计构建；5、解决海量数据高效处理、交互式查询、流式分析等技术难点，对现有系统的不足进行分析，难点攻关；6、跟踪评估数据产品线上效果，参与各业务部门的产品设计讨论，跟踪、促进大数据产品的广泛落地各产品线;7、性格积极乐观，诚信，能自我驱动，优秀的文档与项目沟通、管理能力,"物联网,电商",2000人以上,spark,上海
高级算法工程师,https://www.lagou.com/jobs/6841830.html,松江区,25k-40k,海尔集团,3-5年,本科,大平台、稳定性高，薪酬福利完善,"职责：大数据相关工程类与机器学习类算法研究、开发，新技术调研与推广。支撑业务场景运用1、负责Ai产品研发，效果优化，保障相关场景有良好的用户体验和持续的指标提升；2、研究计算机视觉、语音、自然语言理解等领域的前沿算法，结合业务做算法改进和技术创新3、参与研发、优化大规模分布式机器学习平台, 在大规模特征提取与数据并行训练等方面推进产品研发;4、参与公司各AI项目的数据探查, 数据处理, 特征工程与模型训练及评估工作.5、具有优秀的沟通、文档、表达能力 四、关键能力/经验1、计算机相关专业，本科及以上学历，5年以上算法研发经验；2、熟悉机器学习领域常用算法和工具，有良好的建模思维，有大流量场景优化经验者优先；熟悉TensorFlow、Pytorch、Theano、Caffe、Keras等机器学习框架，对音频、视觉、工业算法方向有深入研究，掌握CNN/RNN/LSTM等深度学习模型和具备相关算法优化能力3、熟悉大规模数据处理的常用方法，熟悉flink/spark/hbase等至少一种分布式系统；4、熟悉人工智能、深度学习、工程算法实施等实际工作经验5、较强的数据分析能力, 动手能力强, 对算法研究有极大热情, 具备良好的学习能力;6、性格积极乐观，诚信，能自我驱动，有较强的语言、文档、表达能力。","物联网,电商",2000人以上,spark,上海
Java开发工程师,https://www.lagou.com/jobs/7183683.html,嘉定区,10k-15k,上海翼葵网络技术有限公司,3-5年,本科,工作环境优，有发展前景，同事优秀可爱,岗位职责:1、负责JAVA后台应用开发工作，包括接口文档编写、业务接口实现；2、支持Web或移动项目，包括编码，单元测试，应用发布；3、负责高并发基础服务设计开发；4、负责处理线上版本紧急技术问题，线上版本bug处理5、参与公司技术架构、技术规范、开发流程的规范和执行。岗位要求：1、3-5年左右Java开发经验，计算机本科相关专业；。2、深入理解ios、多线程、集合等基础知识，熟悉分布式、缓存、消息等机制；3、熟悉MySQL数据库以及优化方法，有MySQL读写分离的实战经验，了解常用的NoSQL产品，如MongoDB，Redis，Memcache；4、熟悉web编程，熟悉tomcat、resin等至少一种http服务器的配置和性能优化；熟悉springMVC，springCloud，springBoot，dubbo，mybatis等第三方开源框架；熟悉linux操作系统和shell；熟悉vue、react、Jquery等常见web开发框架中的一种，能快速高效实现各种交互效果；5、熟悉大数据spark开发者优先,电商,50-150人,spark,上海
高级大数据,https://www.lagou.com/jobs/6905581.html,长宁区,16k-22k,上海坤亿信息技术有限公司,5-10年,本科,五险一金 节日福利 周末双休,岗位职责：1. 理解业务需求和现有系统数据流，设计大数据相关方案，如hive、hbase选择，存储格式（ORC、parquet），如何做partition、bucket2. 设计从Oracle、mysql同步数据，全量、增量方案，如何提升性能，3. 负责方案具体实现，包括设计表、写sql、开发etl程序4. 基于任务调度框架airflow管理和调度任务任职要求：1.本科及以上学历，具备 5年年以上大数据相关工作经验；2.熟悉java，Python，shell开发3.熟练掌握 SQL 及 linux shell 开发技能；熟练主流关系数据库中的一种（如 Oracle、MySQL、PostgreSQL）4.熟悉 Hadoop，熟练掌握 HDFS、HBase、Hive、Spark 等开发技能5.强烈烈责任心，善于协作，具有团队合作精神；6.最好是有带团队的经验,"电商,企业服务",150-500人,spark,上海
口碑-Java技术专家（风控方向）,https://www.lagou.com/jobs/3805368.html,浦东新区,20k-40k,口碑（杭州）信息技术有限公司,3-5年,本科,"移动互联网,O2O,风控",岗位描述： 1、参与口碑风控体系的建设，承担口碑风控平台的系统设计与核心模块的研发工作，持续提升系统在大规模分布式系统环境下高并发、海量请求数下的高处理性能。 2、以数据为驱动，运用海量数据，通过离线清洗、实时计算等大数据处理引擎提高风险评估决策的准确性和时效性。 3、与口碑风控的产品团队、业务运营团队紧密协同，高质量地完成业务需求之外，共同完善风控模型和特征体系的建设。  岗位要求： 1、本科或以上学历，计算机软件或相关专业，三年以上互联网JAVA服务端开发经验；  2、精通Java语言及J2EE体系结构，掌握面向对象、反射、多线程等基础知识，熟悉JVM调优、性能问题分析的方法；  3、掌握Spring、SpringMVC、iBatis等开源框架，熟悉IoC、AOP、事务等核心组件； 4、熟悉MySQL、Oracle等传统数据库原理，熟悉SQL调优和数据库性能优化方案，了解各种NoSQL的特性和使用场景； 5、熟悉大容量、高并发的分布式系统设计，使用过消息、分布式缓存、分布式事务、分布式锁等技术框架； 6、了解Flink、Storm、Spark、MapReduce、Hive等大数据生态体系，有分布式数据存储与实时计算经验者优先；  7、有O2O领域背景，风控安全应用研发、风险数据实时计算经验者优先； 8、有良好的分析设计能力和表达沟通能力，以及较强的学习能力和自我驱动能力；,"移动互联网,消费生活",2000人以上,spark,上海
商业数据分析师,https://www.lagou.com/jobs/6626949.html,长宁区,8k-16k,上海威超广告有限公司,1-3年,本科,五险一金 国外旅游 补充医疗保险,"1.  岗位期望：通过业务理解和数据理解/数据挖掘，在商业环境中产生的数据里，找到为不同企业提升价值的机会点。 2. 工作职能：      与业务人员/团队沟通，了解业务数据的产生及日常业务运营的流程。负责分析运营核心数据，发现问题并进行深度诊断，为用户增长、活跃、价值转化提出方案。      通过运营工作思考与数据分析，制定运营优化策略，能独立对接各团队，协调资源，并对执行结果进行监控分析，不断优化迭代      通过我们自主研发的大数据挖掘工具，完成数据挖掘及输出结果。 3. 候选人要求：a. 业务理解：我们不一定需要有资深业务经验或行业经验的运营人员，但需要如下·       逻辑思考能力-能将问题进行拆解，定义，找出其相互关系。·       关联思考能力-能快速举一反三，将自己熟悉的技能应用在新学习的领域。·       快速学习能力-清楚如何最快地能找到学习一件新事情的方法。 b. 数据理解：我们不一定需要懂R/PYTHON/SQL/数据库/SPARK/HADOOP的程序猿，更需要数据敏感度-知道如何从宏观及微观的角度理解数据源。  c. 其它：·       统招本科及以上 专业不限。以上 [工作职能] 类似经验 为加分项。·       If you prefer grow strong in feature engineering even more than modeling and algorithms, by understand this sentence with meaning behind in 5 sec. gives you a language plus.·       我们欢迎应届大学毕业生！ 4. 我们提供的工具-自主研发数据挖掘产品：基于分布式存储/计算的大数据挖掘平台，集成前沿的机器学习主流算法。可视化数据挖掘及算法实现过程，简易上手，高效运行，无需懂代码，也能完成数据挖掘和建模。 5. 未来和你一起工作的团队：产品研发及数据团队 来自宇宙中心五道口职业技工学校贵系的 技术大牛数据大牛算法大牛，带你跑数带你飞！业务运营团队搞定过好奇, NIKE, 麦当劳, 乐高, 德芙, 百事, LEVI’s, 益达... (此处省略200来号品牌), 等你用数据带着我们飞！","电商,广告营销",50-150人,spark,上海
Python 后台开发工程师,https://www.lagou.com/jobs/6267387.html,徐汇区,15k-25k,上海媒智科技有限公司,3-5年,本科,年底双薪 股票期权 带薪年假 周末双休,工作职责：1、负责公司产品后台开发工作，主要编程语言是 Python、C++ 和 Go；2、参与架构设计，与平台工程师合作优化新旧服务的性能和稳定性。 任职资格：1、扎实的计算机基础知识，了解常用数据结构和算法；2、对多线程、多进程、系统 IO 等优化有相关经验；3、熟悉分布式系统、能处理分布式同步异步问题；4、熟悉 MySQL、Redis、RabbitMQ、Kafka、Elasticsearch 等后端组件的使用，了解基本的设计、优化原则；5、熟悉 Linux 的使用和管理，了解操作系统相关知识；6、熟悉 Git、Jenkins 等持续集成和部署工具，熟悉单元测试；7、热衷性能分析与调优，积极使用新技术提升工作效率；8、良好的团队合作精神与责任感，较好的沟通能力。 加分项：1、开源社区贡献者；2、具备前端开发能力，了解 React、Vue.js 等前端框架；3、具备数据处理和分析能力，了解 pandas、Spark 等使用。,移动互联网,15-50人,spark,上海
