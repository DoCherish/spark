job_name,job_url,job_location,job_salary,job_company,job_experience,job_class,job_given,job_detail,company_type,company_person,search_key,city
大数据开发工程师,https://www.lagou.com/jobs/7200591.html,海淀区,20k-40k,北京拉勾网络技术有限公司,5-10年,不限,"发展空间大,弹性工作制,领导Nice",岗位要求：1、计算机或相关专业本科及以上学历，5年以上大数据运维或开发工作经验；2、熟悉linux开发环境，熟练掌握JAVA/GO/Python语言中的一种;3、熟练掌握大数据常用开源组件的技术原理，有现网的hadoop、kafka等开源大数据组件运维或开发经验；4、有较强的逻辑思维能力，思想上开放，主动积极有责任感，能够承担工作压力；有hadoop、kafka、spark、flink等开源组件源码优化经验优先；岗位职责：负责大数据平台消息中间件/Hadoop/实时计算/OLAP的运营支撑和架构优化。,企业服务,500-2000人,hadoop,北京
高级大数据开发工程师,https://www.lagou.com/jobs/7195249.html,海淀区,35k-40k,北京拉勾网络技术有限公司,5-10年,本科,"发展空间大,弹性工作制,领导Nice",岗位要求：1、计算机或相关专业本科及以上学历，5年以上大数据运维或开发工作经验；2、熟悉linux开发环境，熟练掌握JAVA/GO/Python语言中的一种;3、熟练掌握大数据常用开源组件的技术原理，有现网的hadoop、kafka等开源大数据组件运维或开发经验；4、有较强的逻辑思维能力，思想上开放，主动积极有责任感，能够承担工作压力；有hadoop、kafka、spark、flink等开源组件源码优化经验优先；岗位职责：负责大数据平台消息中间件/Hadoop/实时计算/OLAP的运营支撑和架构优化。,企业服务,500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6986318.html,东城区,30k-60k,北京默契破冰科技有限公司,5-10年,本科,"七险一金,弹性不打卡,免费午餐,季度旅游",岗位描述：1、参与大数据平台建设，完成大规模数据存储设计、实现；2、负责大数据采集、处理、转换、分析、业务需求等相关开发；3、设计面向业务的OLAP，完成企业级数仓的建设；4、负责大数据作业优化及质量保障；5、参与大数据系统及应用架构设计及新技术调研。岗位要求：1、本科学历，计算机、数据科学等与大数据相关专业，5年以上工作经验；2、精通Hadoop相关技术，包括Spark，Hbase，HDFS，Hive，Yarn，Kafka，Flume，Spark、Flink，Storm等；3、精通java、scala开发语言，精通SQL，熟悉MySQL，熟悉shell，python等脚本语言，熟悉git，jira等工具；4、具有优秀的开发规范意识，对大数据技术和开发有热情，工作认真负责，有较强的学习能力和团队合作意识；5、参与过数据处理、分析、挖掘等相关项目，熟悉阿里云日志系统。,社交,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6741505.html,海淀区,30k-60k,北京微聚未来科技有限公司,5-10年,本科,"牛人团队,带薪年假,16薪考核,快速成长",职责：1.负责建设、维护、优化基于Hadoop生态技术的大数据集群和计算框架；2.通过提供平台化的计算框架，支撑海量数据分析、数据挖掘、机器学习工作；3.负责数据产品平台的设计、开发；4.关注开源技术动态，预研、评测大数据生态新技术，引进新的技术框架，满足业务需求并不断提高工作效率及质量； 要求: 1.  计算机、信息系统、数学或相近专业本科以上学历，4年以上大数据研发经验；2.  精通java/scala，精通Hadoop生态并有实战经验，包括但不限于hadoop/flink/hive/spark/impala/hbase/kafka等；3.  有大规模集群维护经验，能够快速处理hadoop或spark等相关技术栈的问题；4.  熟悉大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖掘和数据可视化，能够设计、开发平台化数据产品；5.  有优秀的业务理解能力，对数据敏感，对金融风控有较深入的认识；6.  有关键技术攻关的决心和能力，能够适应和享受高压力的工作；7.  有OLAP产品开发经验优先。,"移动互联网,金融",500-2000人,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/7219163.html,海淀区,20k-40k,北京字节跳动科技有限公司,1-3年,本科,各种福利待遇，大佬云集，期待你的加入！,职位描述1、负责字节跳动电商相关业务数据仓库的开发与优化；2、基于Hive/Flink等平台建设数据仓库，实时数仓建设；3、负责数据模型的设计，etl实施，etl性能优化以及相关技术问题的解决；4、负责面向业务的olap，报表，数据提取工具等开发工作。职位要求1、熟悉大数据相关技术：Kafka/Flink/Hadoop/Druid/HBase/Hive 等；2、熟练使用 Java、Go、Python语言中的一种或者多种；3、具备数据库系统理论知识，掌握主流数据库管理和应用，精通SQL；4、有高性能分布式平台开发经验，有电商行业经验优先。,文娱丨内容,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7005187.html,海淀区,20k-35k,北京音娱时光科技有限公司,3-5年,本科,团队优秀；海外市场；免费餐饮；租房津贴；,岗位职责：1、基于对公司业务的广泛理解，负责各个业务模块的数据提取和报表开发；2、跟进维护大数据平台软件栈的技术发展，围绕业务需求作合适的选型及开发；3、能够全局性地理解数据仓库及业务数据，整合需求，为业务方提供系统化、可持续的数据解决方案。任职资格:1、重点统招本科及以上学历; 2、有扎实的计算机基础，熟悉常用数据结构、算法、设计模式；3、熟悉hadoop、hive、hbase、spark等大数据开源工具的架构;了解数据仓库建设的基本思路; 4、精通hivesql，有丰富的hivesql性能调优经验;掌握python脚本语言; 5、具备出色的需求分析能力及快速学习能力，能深入理解复杂的业务逻辑; 6、具备良好的团队合作精神，具备出色的沟通能力。,移动互联网,50-150人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7045440.html,海淀区,30k-60k,上海基分文化传播有限公司,3-5年,本科,领导nice ，氛围好,岗位名称：大数据开发工程师职位描述1、负责趣头条数据中台，全公司各类业务数据仓库的构建；2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；3、负责构建用户主题、各业务线主题、推荐主题、广告主题、数据门户系统；4、负责各产品线数据维护，提升数据资产质量。职位要求1、计算机、数学相关专业本科及以上学历，2年以上大数据开发工作经验；2、 深入理解常用的数据建模理论，可独立把控数据仓库的各层级设计；有数据挖掘，机器学习，推荐相关经验优先；3、熟悉Aerospike和Clickhouse的同学优先考虑，熟练掌握Hive/SQL，熟悉Spark/Map-Reduce分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；4、有产品sense，主动思考基于业务场景下的数据体系建设，而不单单只会做执行；5、工作认真，负责，良好的团队合作精神和解决问题分析能力，钻研技术克服困难，勇于挑战。,文娱丨内容,500-2000人,hadoop,北京
高级大数据开发工程师,https://www.lagou.com/jobs/7122194.html,海淀区,25k-50k,北京转转精神科技有限责任公司,3-5年,本科,"六险一金,牛人共事,弹性工作,成长空间大",岗位职责1、基于海量日志及 hadoop 生态圈相关组件，开发大数据分析平台的后台服务，支持部门的数据统计、分析业务；2、构建基于spark/flink的实时数据处理平台，支撑上层业务使用，如：数据监控、日报展现、统计分析、接口调用等；3、负责海量的三方数据监控、统计与分析；4、高并发、海量数据场景下的数据接入基础服务、工具研发。任职资格1、熟练掌握 Java 编程语言、有一定的后台服务、工程开发经验，对Python、Linux shell熟悉者优先；2、熟悉 Hive、Spark、Flink 等hadoop生态圈大数据框架至少一种，并有相关的使用、开发经验；3、熟练掌握Java网络编程、多线程知识，并有相关实践经验者优先；4、具备一定 Android反编译、逆向工程、爬虫经验者优先；5、有一定Java web开发经验，熟悉 SpringBoot 开发流程并有相关项目经验优先；,"移动互联网,消费生活",500-2000人,hadoop,北京
数据中台测试开发工程师/专家 -【开发工具链方向】,https://www.lagou.com/jobs/6839881.html,海淀区,25k-50k,北京达佳互联信息技术有限公司,3-5年,本科,"六险一金,免费食堂,免费健身","职位描述1. 主要负责快手大数据产品相关的测试和质量保证工作；2. 根据数据产品需求和设计，进行需求分析，并制定测试计划、设计测试数据和测试用例，执行测试用例，能够快速定位和解决问题；3. 对线上问题进行持续追踪，并从中得出一些优化监控、测试方案/框架提升等改进措施；4. 在项目中积极与产品经理、开发工程师和用户进行有效沟通，推动问题及时合理地解决。任职要求1. 本科以上（包含本科）学历 ，3年以上测试开发经验；2. 具有良好的沟通能力和团队合作精神、快速的学习能力、执行力强、工作责任心强；3. 熟练运用Java语言，熟悉常用web前端开发框架，如React，Spring Boot等；4. 熟悉常用的Java和Web测试框架，有复杂系统的测试经验；5. 熟悉常用的自动化测试工具，有能力改进和研发自动化测试工具。 符合以下条件优先： 
对性能测试/稳定性测试/兼容性测试等有独到见解；有数据产品测试和研发经验；有数据仓库建设相关经验。",文娱丨内容,2000人以上,hadoop,北京
数据中台测试开发工程师 -【开发工具链方向】,https://www.lagou.com/jobs/6934676.html,海淀区,20k-30k,北京达佳互联信息技术有限公司,3-5年,本科,"平台大,福利好",,文娱丨内容,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7165405.html,海淀区,20k-40k,微梦创科网络科技（中国）有限公司,3-5年,不限,"大平台福利,带薪年假,快速成长",1. 负责大数据平台的架构设计与研发2. 根据业务需求设计高扩展性、高性能的系统架构和应用架构技能要求：1. 计算机相关专业，本科及以上学历2. 具备良好的沟通能力和表达能力3. 熟悉常用的算法和数据结构4. 熟悉Linux系统，具备shell/python/java/scala/golang等一种或几种语言的开发能力5. 熟悉常见的开源分布式计算/存储相关技术，包括yarn，mapreduce，spark，kafka，hive等6. 有大数据系统项目经验，掌握如何搭建分布式处理系统，有海量数据处理和分析经验7. 学习能力强，热衷开源技术，有团队观念，具备独立解决问题的能力8. 具备对大数据任务性能优化经验者优先9. 在大数据集群平台维护、服务体系构建以及性能调优等方面有经验者优先,文娱丨内容,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7162506.html,海淀区,22k-32k,海致网络技术（北京）有限公司,5-10年,本科,金融大数据 独角兽 固定奖金+项目奖金,岗位职责：1、负责核心大数据业务功能开发及图算法挖掘工作；2、对系统的技术架构持续进行改进和优化。任职要求：1、统招本科及以上学历，计算机相关专业，三年以上大数据开发经验；2、使用过JanusGraph / ArangoDB／Neo4j／TigerGraph 等图数据库中的一种或者多种，并有性能优化经验者优先；3、有扎实的Java或Scala编程功底，熟练JVM原理及性能调优；4、对Spark、Flink、HBase、Kafka、Hive、Yarn、Elasticsearch等组件原理有深入了解，有PB级数据处理经验及优化经验者优先；5、有Spark Graphx图计算或Spark ML 机器学习项目经验者优先。,"移动互联网,企业服务",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6842342.html,海淀区,15k-30k,汉熵通信有限公司,3-5年,本科,扁平管理，弹性办公，精英团队,岗位职责：（1）负责行业应用的计算平台开发与应用； （2）负责行业应用相关的数据接入、采集、加工、清洗、处理程序的开发； （3）参与大数据平台的搭建、开发、维护、优化； （4）对业务部门的数据分析需求给予实现与支持；（5）不断解决规模增长带来的技术和业务问题，构造高度稳定可用的大数据分布式系统，支撑海量数据分析、数据挖掘、机器学习等场景。任职要求：（1）计算机相关专业，本科及以上学历，3年以上Java或Python开发工作经验，学习能力突出；（2）熟悉Linux/Unix系统环境下的操作，熟悉云计算集群环境，了解分布式任务调度，高可用和网络优化；（3）熟悉Hadoop生态系统内常见项目的使用（HDFS、Hive、HBase、Spark、ZooKeeper、yarn等），熟悉使用Python/Java 进行数据聚合清洗，数据分析ETL等的开发经验，熟悉Kafka/EMQ等消息队列和中间件，熟悉API接口开发，有实际大数据项目经验优先； 熟练掌握高性能数据仓库ClickHouse，内存数据库（Ignite）和其他主流数据库（MySQL/Oracle）的操作，包括数据的导出导入，集群同步，SQL的增删改查和各种查询优化等等；（4）能够独立开发设计数据仓库、ETL设计、Cube建模、OLAP开发、报表开发等；一定的应用系统分析与设计能力，有良好、规范的编程习惯和文档编写习惯； （5）熟练Python进行数据处理，网页爬取；（6）有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术、新理论、新开发实践的学习和实践。,"信息安全,物联网",15-50人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5598058.html,海淀区,15k-25k,新浪网技术（中国）有限公司,3-5年,本科,技术氛围浓厚、大平台、六险一金,岗位职责： 1、负责基于Hadoop、Spark平台的海量数据处理、数据计算、数据开发。 2、负责高并发、高可用性、高可扩展性的线上数据系统开发。 3、负责数据挖掘应用服务开发和数据挖掘算法包研究和应用。 4、负责数据产品和数据项目的相关开发支持。5、负责垂直领域的数据探索，价值数据提取。 任职要求： 1、计算机及相关专业本科及以上学历； 2、精通java开发技术，熟练掌握多进程/多线程开发，熟悉常用设计模式； 3、熟练掌握Hadoop、Spark等大数据开发技术，进行过大数据项目实践； 4、有机器学习、数据挖掘、推荐系统经验者优先； 5、具有分布式计算/搜索引擎/广告引擎等后台开发经验者优先； 6、有/ElasticSearch/hadoop/Spark/storm/kafka/scribe等开源框架经验者优先； 7、对技术有激情、有追求；富于技术创新精神，勇于解决技术难题,文娱丨内容,2000人以上,hadoop,北京
数据开发,https://www.lagou.com/jobs/6353366.html,朝阳区,18k-36k,上海阅文信息技术有限公司,3-5年,本科,大平台、领导nice、福利好,,文娱丨内容,500-2000人,hadoop,北京
前端开发工程师-数据可视化,https://www.lagou.com/jobs/6819286.html,海淀区,18k-30k,乐元素科技（北京）股份有限公司,3-5年,本科,高福利 六险一金 扁平化,岗位职责：1、负责数据平台相关系统(计算调度、开发平台、数据分析、BI报表等)的前端交互设计与开发工作；2、负责数据产品前端用户体验的设计和优化；任职资格：1. 熟练运用 ES6 和原生 ES5，理解 ES6 跨平台（NodeJS 和 浏览器）运用场景和区别2. 熟练使用 CSS3，Flexbox，SASS，BEM 等 css 解决方案，编写简明清晰，组件化，适度抽象，可维护的 css3. 熟悉常见打包工具如 Webpack，Parcel，Rollup 等的核心概念，熟练常见调用方式4. 理解并运用前端工程化思想，可清楚描述和搭建前端工程，根据不同后端特点实现清晰，可操作的前后端分离架构5. 熟悉常见自动化方案，CI，Git，Jenkins 工作流,"移动互联网,游戏",500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7056582.html,朝阳区,20k-30k,北京云保网络科技有限公司,3-5年,不限,移动互联网广告行业，拥有TB级数据,岗位职责：1、负责公司业务系统的数据加工、分析、处理工作；2、按照业务部门的要求加工数据，生成业务需要的分析数据，用于系统使用使用的用户标签数据；3、对业务数据进行优化，提升数据分析处理的效率；要求：1、精通Java或python其中一个语言及相关框架，能熟练掌握常用数据结构和算法；2、有实际的Hadoop生态系统HBbase/Hive/MP开发经验；3、熟悉Spark、Flink、Storm、Impala等计算和数据处理引擎的环境搭建、开发和管理；4、熟悉消息队列的原理，熟练使用Flink、Kafka、Activemq、Rabbitmq等常用的消息队列；5、掌握数据分析的基本流程，擅长数据采集、清洗、分析等环节，；6、具有较强的业务理解能力，并能快速应用于数据分析各阶段；7、能熟练掌握Linux的操作和使用；8、有云计算中心开发经验的优先；9、工作认真，负责，良好的团队合作精神和解决问题分析能力。钻研技术克服困难，勇于挑战；,移动互联网,50-150人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6839321.html,朝阳区,20k-30k,北京拉克沙网络科技有限公司,3-5年,不限,"业务全球化,无限下午茶,扁平化,股权激励","1、负责 HOLLA Group 用户行为的理解和建模，帮助公司各项业务满足用户需求，提升用户覆盖； 2、参与数据治理工作，提升数据易用性及数据质量、准确度； 3、理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作； 职位要求： 1、精通数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景； 2、具备较强的编码能力，熟悉 SQL, Python, Hive, Spark, Kafka, Flink, Druid 中的多项，有至少 TB 以上级大数据处理经验； 3、对数据敏感，认真细致，善于从数据中发现疑点； 4、善于沟通，具备优秀的技术与业务结合能力； 5、加分项：对机器学习有一定了解，有海外项目开发经验；","移动互联网,社交",50-150人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7211887.html,海淀区,16k-30k,度小满科技（北京）有限公司,1-3年,本科,六险一金 班车接驳 健身房 免费水果,"工作职责- 负责度小满金融Growth Hacking团队的亿级别数据的仓储设计和构建；- 负责度小满新一代智能营销系统的设计和实现；- 负责用户增长团队的策略框架的设计和开发，支持模型自动迭代；职责要求-熟悉Hadoop/Kafka/Spark/Hive/Hbase等分布式开源项目及工作原理，并有实际开发经验-数据常见流计算框架如flink，storm等-熟悉常用脚本语言shell,python等-熟悉C/C++，Java编程语言，熟悉linux平台、shell脚本，对数据结构和算法设计有较深刻的理解等-熟悉TCP/IP HTTP等网络协议，有高并发服务开发经验者优先-熟悉Mysql、nosql等数据库-本科及以上相关专业学历，1年及以上工作经验",金融,2000人以上,hadoop,北京
数据仓库开发工程师/专家,https://www.lagou.com/jobs/6829564.html,海淀区,25k-50k,北京百家互联科技有限公司,3-5年,本科,年底双薪,岗位职责：1、参与公司整体数据仓库的建设，包括数据模型、数据仓库设计、实现和维护2、负责重点业务的数据支持，指标体系建设任职要求：1、统招本科或以上学历，计算机相关专业，3年以上工作经验2、熟悉数据仓库建模理论，有数据治理经验3、熟悉hadoop平台，有离线计算或实时计算开发经验4、熟悉hive、spark、flink、kylin、druid等一种或多种技术5、掌握shell、python等一种或多种脚本语言6、有数据治理经验优先，熟悉元数据,"移动互联网,教育",2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6631212.html,海淀区,16k-26k,中科天玑数据科技股份有限公司,3-5年,本科,科学院孵化，福利待遇好，技术牛人多,岗位职责：1、 负责设计、开发、维护大数据分析处理相关的软件产品和模块，开发主要使用语言为JAVA2、 负责对所负责功能模块进行单元测试和集成测试，包括：用例编写、执行测试、编写报告3、 对所负责的产品或项目的功能模块进行需求分析任职要求：1、 本科及以上学历，计算机相关专业；3年年以上工作经验2、 熟悉Java/Scala/Python语言3、 熟悉Linux开发环境；熟练掌握大数据系统后端开发，如多线程、网络等4、 熟悉MongoDB，ElasticSearch，Kafka等组件，有实际数据应用系统开发经验5、 工作态度踏实、认真、积极主动，能承受一定工作压力，有责任心、有团队协作能力6、 有一定的架构设计能力，有很强的分析、解决问题的能力,"移动互联网,数据服务",150-500人,hadoop,北京
高级大数据开发工程师,https://www.lagou.com/jobs/6211364.html,朝阳区,25k-40k,北京易数科技有限公司,3-5年,本科,领导nice 技术大牛 上升空间,工作职责：参与公司数据处理逻辑的设计和优化；参与公司各种数据模型的设计和优化；负责公司大数据基础架构平台的规划、设计。岗位要求：熟悉HDFS、MapReduce和HBase的实现原理；熟悉至少2种分布式计算引擎的实现原理，具备故障定位、以及性能调优能力；熟练使用Java与Scala语言进行开发；具备3年以上的TB级别数据平台开发经验；良好的工作习惯、沟通能力和学习能力。,"企业服务,数据服务",150-500人,hadoop,北京
数据开发工程师/专家-【实时计算】,https://www.lagou.com/jobs/6018085.html,海淀区,20k-40k,北京达佳互联信息技术有限公司,3-5年,本科,"带薪年假,年度体检,免费午餐,弹性工作",工作内容1、根据需求对数据进行实时分析处理；2、负责快手实时数据仓库的建设以及实时指标的开发工作；3、与离线数仓、产品、算法同学一起构建灵活的数据产品。任职要求1、根据需求对数据进行实时分析处理；2、负责快手实时数据仓库的建设以及实时指标的开发工作；3、与离线数仓、产品、算法同学一起构建灵活的数据产品。,文娱丨内容,2000人以上,hadoop,北京
数据开发工程师-【DA应用】,https://www.lagou.com/jobs/6045315.html,海淀区,20k-40k,北京达佳互联信息技术有限公司,3-5年,本科,"牛人多,福利好",,文娱丨内容,2000人以上,hadoop,北京
大数据开发,https://www.lagou.com/jobs/7071526.html,海淀区,28k-50k,昆仑智汇数据科技（北京）有限公司,5-10年,本科,新基建 工业4.0 核心岗位,"职位诱惑：风口行业,大牛带路,扁平化,环境好   职位描述：工作职责：     本岗位将参与昆仑数据全新产品体系的研发工作，以客户价值为导向，为客户构建高效、强大的工业大数据分析产品。你将参与发掘和分析业务需求，系统方案设计和代码编写，确保性能、质量和安全。你将接触到最新的数据分析大师、资深工业领域专家的工业数据分析方法与实践，学到最严谨规范的开发技术与流程，发展你个人的技术能力，领导力和有效的项目管理能力。在这个大家庭里，我们不仅鼓励大家开发出有价值、有影响力的产品给用户，我们同样鼓励大家多学习，多分享，多创新，在工作中找到最大的乐趣！任职资格－计算机相关专业本科及以上，2年以上的系统或应用软件的开发经验。－熟练掌握Java语言和面向对象思想，能写出整洁、高质量的代码。－精通常用关系数据库（PG、MySQL等）和各种NoSQL数据库。－熟悉并实践过Hadoop、Spark、Flink、Kakfa等任意一种大数据分析框架，并理解一定的底层原理。－精通RESTfulAPI开发，具备良好的API设计风格。－熟练使用Linux，理解并熟练使用Docker容器部署方式。－具备良好的软件工程和质量意识，认同并实践过敏捷开发和DevOps方法。优先任职资格－具备在快节奏，敏捷模式下开发新产品的激情。－曾经Lead团队开发复杂的软件产品，并成功地交付给用户。－具备全栈工程能力，掌握多种语言开发，如js，python，golang等。－曾经参与分布式系统开发，熟悉多个大数据产品生态和相关技术。－Linux高手，熟练掌握shell编程。－有指导年轻工程师提高技术能力和开发效率的经验。",数据服务,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7048961.html,西城区,20k-40k,苏州精正信息科技有限公司,5-10年,本科,背景雄厚 技术大牛,"职位描述:1、参与分布式大数据处理系统和数据服务基础设施的架构设计和开发；2、和产品经理一起梳理和完善系统功能需求；3、改进系统性能；任职要求:1、了解分布式、微服务、传统关系型数据库、常用NoSQL开源系统、RESTful、基本的信息安全领域知识2、精通Java代码，其他语言不限制具体要求：1、本科及以上学历，5年以上大型互联网产品或分布式系统开发设计经验；2、丰富的Java研发经验,精通Java, 熟悉Shell或Python等一种或几种脚本语言者优先；3、熟悉常用分布式系统相关理论基础，有一定的分布式系统开发经验，有互联网公司中大型分布式系统经验优先4、具备Spring Cloud等微服务设计和开发经验和能力；5、熟悉大数据技术栈,对Hadoop、Hive、Spark、Hbase、Kafka、ELK等开源组件有使用及优化经验者优先 。","企业服务,金融",少于15人,hadoop,北京
大数据应用开发工程师,https://www.lagou.com/jobs/6979040.html,朝阳区,20k-30k,深圳市赢时胜信息技术股份有限公司,3-5年,本科,优秀团队 办公环境优越 交通便利,岗位职责：1、基于大数据平台的应用系统设计、开发、维护；2、承担公司大数据相关项目的需求分析、开发、实施、现场支持。任职资格：1、计算机或相关专业本科及以上学历；2、3年以上相关工作经验，至少熟练掌握Java，Scala，Python中的一种或多种；3、熟练使用Hadoop、Spark、Storm、SparkStreaming、Hive、HBase进行应用开发；4、熟悉搜索引擎，例如Impala，Presto，Elasticsearch等；5、具备基本的Hadoop运行环境的运维管理经验；6、有实际的大数据应用工程开发经验；7、熟悉金融领域相关知识或有金融系统开发经验的优先。,金融,500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7172364.html,海淀区,20k-30k,秒针信息技术有限公司,3-5年,本科,六险一金，扁平化管理，年终奖丰厚,岗位职责：负责数据中台的汇聚和采集ETL详细设计和开发工作；参与专题库/主题库的模型设计，并负责模型开发；参与数据标准化和数据治理模型的设计，并负责落地开发；负责数据分析需求的模型开发和实现；负责数据中台技术的优化和质量改进；任职要求：1.精通SQL语言，具备存储过程开发能力，能熟练进行SQL查询优化；熟悉Hive数据仓库设计，了解数据仓库模型及思想、维度建模思想，了解数据仓库相关应用；2.熟悉Hadoop、Spark、Sqoop、Hive、Flume、Kafka、 HBase等技术，使用过ETL相关技术进行数据交换工作；3.了解数据调度平台的设计思想，良好的数据批处理 、调度、异常处理等经验，熟悉shell、python、java等语言；4.具备较强的语言表达能力，能与客户顺畅沟通或产品介绍；具有良好的逻辑分析能力、需求理解能力和解决问题的能力；具有一定的文档编写能力；5.具有良好服务意识，工作态度端正，耐心、细致、热情，抗压力强，对工作专注、投入，有很好的职业素养 。6.具有5年及以上数据仓库相关项目工作经验，有电子政务行业项目经验优先；7. 具备一定的组织领导能力，能妥善组织安排并指导组员工作；,"数据服务,广告营销",2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6176433.html,海淀区,20k-40k,北京搜狐新媒体信息技术有限公司,3-5年,本科,广告平台，大数据平台,岗位职责：1.负责广告创意推荐类服务的研发；2.负责广告业务DMP数据平台产品研发；3.负责用户画像后台数据仓库的架构设计与研发；任职要求：1. 计算机相关专业，本科及以上学历，三年以上服务端开发经验；2. 熟练掌握PHP/Python/Golang，编程技术扎实，熟悉Laravel/Lumen等开源框架；3. 熟悉Linux/Unix平台上的开发环境，有较好的Shell脚本编程功底；4. 熟悉业务开发相关技术：常见数据库和协议，架构，存储，缓存，消息队列，API设计理念等；5. 熟悉主流的云计算、大数据技术，包括但不限于hadoop/hive/hbase/spark/kafka/flume/storm等；6. 对数据敏感，具有优秀的团队合作意识及分析问题、解决问题能力。加分项：1. 熟悉数据仓库架构/设计，以及任务调度，在用户行为日志采集、海量数据处理及用户画像方面有相关经验优先；2. 有NLP、机器学习背景，对开源的机器学习框架/模型有线上项目实践经验优先。,"移动互联网,广告营销",2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/4398724.html,朝阳区,15k-25k,拼途（北京）信息技术有限公司,1-3年,本科,"数据产品,离线数据,实时数据","职位描述：1、负责核心数据产品开发； 2、负责离线/实时数据计算的开发，维护；职位要求： 1、本科及以上学历；2、1年及以上JAVA开发经验，了解设计模式、数据结构；3、熟练掌握MySql，Redis等数据库的使用和优化；4、有hive、kylin,、spark、oozie、hue、impala、hbase开发经验者优先；5、严谨的逻辑思维，强烈的技术热情善于合作喜欢有挑战性的工作；",汽车丨出行,150-500人,hadoop,北京
高级大数据开发工程师,https://www.lagou.com/jobs/5316912.html,朝阳区,15k-25k,拼途（北京）信息技术有限公司,3-5年,本科,分布式，开元技术,"工作职责：1.大数据平台实时计算和分布式并行计算的程序开发,以及开源技术组件的二次开发2.大数据集群组件运维调优职责要求：1.熟悉常用的算法和数据结构。 2.熟悉Linux系统，具备java/scala/python/shell等一种或几种语言的开发能力。 3.熟悉常见的开源分布式计算/存储相关技术，包括hdfs、mapreduce、spark、flink、kafka、hive、hbase、elasticsearch等。 4.熟悉Yarn工作原理及深入开发、熟悉linux技术5.有大数据平台实时计算和分布式并行计算的程序开发经验6.有大数据系统项目经验，有海量数据处理和分析经验7.深入了解各种大数据相关框架或组件，对线上大数据集群有运维调优经验(加分项)",汽车丨出行,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6884729.html,海淀区,20k-35k,厦门美图之家科技有限公司,3-5年,本科,有竞争力薪资，餐补交通补等等,工作职责：1、海量商业数据的收集、处理及存储； 2、海量商业数据的查询引擎建设及优化；3、商业数据仓库的建模及多维分析；4、大规模数据平台的建设、治理及优化；任职要求：1、2年以上工作经验；2、计算机科学、工程、数学、统计或相关专业学士、硕士；3、有扎实的java基础、熟悉多线程与JVM相关原理；4、有扎实的数据结构与算法功底；5、熟练使用SQL语言进行数据分析；6、大规模数据的处理相关经验，熟悉Impala、Hadoop、HBase、Flink、Kafka、Hive等分布式系统；具有如下条件之一优先考虑：互联网广告、搜索引擎方向相关背景和工作经验；信息检索、数据挖掘、机器学习、人工智能等相关领域的理论背景或应用实践；,硬件,2000人以上,hadoop,北京
机火研发-Java开发工程师（数据组）,https://www.lagou.com/jobs/7212759.html,朝阳区,20k-40k,北京三快在线科技有限公司,1-3年,本科,团队牛人多，晋升空间大,,消费生活,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7106218.html,朝阳区,20k-35k,元保数科（北京）科技有限公司,3-5年,本科,大厂团队班底 定期分享 技术氛围浓厚,岗位职责：1. 参与大数据系统的设计与研发；2. 负责面向业务的数据平台的研发；3. 负责业务数据采集、传输、清洗、格式化存储、数据分析与数据挖掘的设计和工程实现4. 负责数据产出的稳定性5. 负责数据团队其它数据分析及数据处理工作 职位要求：1. 计算机或相关专业本科以上学历 3年以上开发工作经验；2. 熟练使用hbase hive flume spark mrstorm kafka中的一种以上大数据组件；3. 精通MySQL数据库  熟悉hive SQL优化4. 能使用 Java、scala语言进行相应的开发工作；  5. 熟悉Python、shell中的一种；6. 了解数据分析技术（机器学习）并具有相关项目经验优先7. 有ACM、kaggle比赛经验优先8. 熟悉流式计算框架 如spark、spark streaming、spark SQL等技术优先 9. 对源码有研究优先 10. 熟悉阿里Quick BI的优先11. 热情开朗、善于沟通，工作责任心强，思路敏捷清晰、抗压能力强，良好的学习能力、有较好的创新精神。,"电商,金融",50-150人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6761981.html,朝阳区,18k-25k,北京亿玛创新网络科技有限公司,3-5年,本科,"扁平管理,地铁附近,福利佳",工作职责: 1.负责海量用户行为数据的接入和整合，多维度建设用户画像； 2.负责数据采集、存储、分析、挖掘工作，丰富用户画像； 3.基于数据管理平台指导数据决策并输出解决方案；任职资格: 1.熟悉Linux系统环境，精通Java/Scala/Python等大数据领域常用开发语言的一种或多种；2.熟练掌握主流大数据常用框架，如：Hadoop、Hbase、Hive、Spark、ES、Kafka等; 3.具备使用Spark Streaming实时引擎进行数据流开发和调优的经验; 4.具备海量数据处理经验，有互联网行业数据挖掘经验；5.具备DMP系统建设和机器学习成功应用经验者优先。6.工作严谨负责，较强的学习能力、沟通能力和抗压能力。,"移动互联网,电商",500-2000人,hadoop,北京
美团平台-测试开发（大数据）,https://www.lagou.com/jobs/6790030.html,朝阳区,24k-45k,北京三快在线科技有限公司,3-5年,本科,大牛云集 弹性工作 上市公司,,消费生活,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5184066.html,海淀区,25k-45k,北京字节跳动科技有限公司,3-5年,本科,六险一金，弹性工作，免费三餐，租房补贴,,文娱丨内容,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6388423.html,朝阳区,10k-20k,摩邑盟诚（北京）科技有限公司,1-3年,本科,五险一金 团队Nice 出国旅游,职位诱惑：五险一金 团队Nice 出国旅游职位描述：职位描述：1.设计公司数据流架构，2.开发维护数据流平台3.挖掘数据商业价值-搭建公司整体数据流体系-搭建公司实时、离线报表-搭建流量变现数据模型职位要求：1.本科及以上学历，计算机相关专业。2.拥有良好的代码习惯，代码结构清晰，命名规范，逻辑性强。3. 熟练掌握Hadoop、Spark、Java语言；4.Python、PHP至少掌握一种语言；5.搭建过广告变现的离线流、实时流6.具有较强的学习能力和积极主动性，有责任心，良好的团队合作精神。,广告营销,50-150人,hadoop,北京
大数据开发,https://www.lagou.com/jobs/7176700.html,大兴区,25k-45k,京东数字科技控股有限公司,1-3年,本科,福利待遇丰厚,"工作内容：1. 整合京东商城、京东金融、第三方数据源相关用户行为数据，基于业务需求构建底层数据结构；2. 完成广告、推荐系统产生的业务数据采集、存储等；和算法团队密切合作，完成系统离线、在线的工程化部署；3. 和产品、运营团队合作，完成数据抽取、数据分析相关工作。任职资格：1、计算机、信息、数学等相关专业，硕士及以上学历；2、广告、电商等领域大数据处理3年以上工作经验；有处理TP量级数据的经验，包括离线、实时；3. 熟练使用Kafka、Spark/Flink、Hbase、ES等常用工具；对其中某项框架有深入研究，并有对应的优化经验；4. 逻辑清晰；且有目标导向得高度灵活性；对数据分析相关方法论有熟练应用,，有较强实战能力；良好沟通能力；有数据分析领域较强实战经验；5 .强烈的责任心与主动性，对所负责工作有owner意识，并能自我驱动成长。",金融,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6846945.html,朝阳区,15k-30k,北京热云科技有限公司,3-5年,本科,17薪，午休两小时,"岗位职责:1、参与ADI大数据的开发，实现数据驱动业务；2、根据业务需求进行数据模型的调研、设计、开发及验证工作，并持续进行模型的优化；3、负责数据模型架构的构建，建立数据抽取、清洗、校验等数据加工流程规范及OLAP多维数据分析模型；4、持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。岗位要求：1、统招本科或以上学历，计算机、数据挖掘等相关专业，工作至少3年以上；2、熟悉Java开发，有脚本语言（shell,python)开发经验者优先；3、至少熟悉一种大数据处理技术，如Hadoop、Spark；4、掌握HBase、Redis、Elastic Search等开源大数据存储技术，并能结合不同的业务场景深入使用；5、熟悉常用Java Web开发框架，如：Spring Cloud等；6、熟悉多线程编程，并对Java自带线程池有一定研究；7、对解决具有挑战性的问题充满激情，具有良好的分析问题和解决问题的能力，能够医治各种系统的疑难杂症；8、有营销背景优先考虑。","数据服务,移动互联网",150-500人,hadoop,北京
大数据开发,https://www.lagou.com/jobs/7143637.html,朝阳区,1k-2k,北京云畅游戏科技股份有限公司,3-5年,大专,"年终奖金,五险一金,弹性打卡,房补饭补",岗位职责：1.负责基于spark、sparkSQL、hadoop开发BI分析报表；2.负责参与数据处理、调优等；3.负责数据分析平台功能完善扩展。任职要求：1.本科以上学历，计算机专业优先；2.3年以上JAVA开发经验，熟悉linux环境；3.熟悉hadoop、sparkSQL等，SQL分析能力强者优先；4. 精通java、了解python优先；5. 独立的思维能力，乐于沟通、协作，具备高度的自我约束,"游戏,移动互联网",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6859839.html,朝阳区,12k-18k,广州海鹚网络科技有限公司,1-3年,本科,六险一金 双休 13薪 年终奖,岗位职责：1、参与数据产品后端开发；2、参与底层数据清洗及开发工作。岗位要求:1、本科及以上学历、计算机相关背景 ；2、 2-3年以上数据开发经验 ；3、熟练掌握java或者scala语言 ；4、熟悉Hadoop/hive/spark/kafka等大数据技术优先; 5、有数据仓库项目经验者优先 ；6、有医疗相关数据开发经验者优先。,移动互联网,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6735211.html,朝阳区,12k-20k,弘康人寿保险股份有限公司,1-3年,本科,"五险一金,节日福利",职责描述： 1、负责基于Hadoop、Spark平台的海量数据处理、数据计算、数据开发。2、负责高并发、高可用性、高可扩展性的线上数据系统开发。3、负责数据挖掘应用服务开发和数据挖掘算法研究和应用。4、负责数据产品和数据项目的相关开发支持。5、负责垂直领域的数据探索，价值数据提取。任职要求： 1、计算机及相关专业本科及以上学历；2、精通java和scala开发技术，熟练掌握多进程/多线程开发，熟悉常用设计模式；3、熟练掌握ElasticSearch、Hadoop、Spark、Sqoop、Kafka、HBase、Impala、Kudu等大数据开发技术，进行过大数据项目实践；4、有机器学习、数据挖掘、推荐系统经验者优先；5、具有分布式计算/搜索引擎/广告引擎等后台开发经验者优先；6、对技术有激情、有追求；富于技术创新精神，勇于解决技术难题,金融,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7092105.html,海淀区,25k-35k,北京灵图软件技术有限公司,3-5年,本科,餐补，年度体检,岗位职责：1、海量GIS领域（geomase等）大数据的分析/处理，包括海量数据的存储、计算和检索；2、基于分布式平台（MR/storm/Spark/flink）的业务数据分析和逻辑job的开发；3、开发数据统计系统、数据可视化系统等。任职要求：1、计算机、数学或统计学相关专业本科以上学历；3年以上数据的开发相关经验，特别是(1) 离线领域hadoop的ETL开发经验 或者 (2)实时计算领域包括storm、spark、flink等的开发经验 其中之一经验者；2.、有很好的海量数据开发经验，理解元数据管理。具有一定数据模型和数据架构基础；交通领域大数据工作者更佳；3、 熟悉unix或者linux，具备优秀的编程能力，熟练掌握java或者scala开发，有MR、storm、spark、flink等等语言中的一种或几种经验者优先；4. 对数据敏感、对技术敏感，有研究的意识和直觉者更佳；5. 有良好的团队合作意识，沟通表达能力和综合协调能力,移动互联网,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7175848.html,西城区,20k-40k,建信金融科技有限责任公司,3-5年,本科,六险两金，发展空间大，餐补，带薪休假,岗位职责：1、负责分析和开发政务、金融、交通等领域的大数据应用，实现分析建模、报表汇总、成果展示等功能2、负责搭建或使用基于大数据技术体系的数据仓库，开发数据服务；3、负责项目级和平台级的数据治理工作；    任职条件：1、全日制大学本科及以上学历，信息科学类相关专业；2、熟悉数据仓库理论和技术体系，熟练掌握Hdfs/Hive/Hbase/Spark/Kylin/GreenPlum/Elasticsearch等大数据处理技术；3、至少熟悉（Java/Python/Scala）一门编程语言，能熟练运用SQL进行开发和优化；4、熟练使用常见的ETL工具，使用过Oracle、Mysql、Redis等数据库5、有良好的逻辑思维能力，较强的沟通能力和团队合作精神，能承担工作压力；,"金融,软件开发",2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/4597592.html,海淀区,18k-36k,北京字节跳动科技有限公司,1-3年,本科,弹性工作，免费三餐，租房补贴，休闲下午茶，扁平管理，职业大牛，晋升空间，五险一金,,文娱丨内容,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6997551.html,丰台区,12k-14k,北京先进数通信息技术股份公司成都分公司,3-5年,本科,五险一金；餐补；带薪年假；免费体检；,岗位职责：负责大数据开放式集群的搭建、管理、监控、优化以及相关应用的开发等工作。要求：1.计算机、金融、理工及相关专业本科毕业；2.熟悉HADOOP生态圈，熟悉关系型数据库3.熟练使用SQL、HIVEsql编写4.能够独立搭建HADOOP集群，熟悉HDFS、HIVE、HBASE、SPARK、MAPREDUCE、ZOOKEEPER、KAFKA5.熟悉Linux，能够编写SHELL、PYTHON脚本6.熟悉数据库性能及SQL优化,"软件开发,其他",500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5998503.html,朝阳区,15k-30k,马上消费金融股份有限公司,3-5年,本科,五险一金 丰厚年终奖 持牌金融公司,工作职责负责实时和离线数据交换平台建设。针对海量数据提供实时采集、存储、同步、计算等技术服务，打造易用、稳定、高效的数据交换平台。1. 负责实时和离线数据处理框架的设计、架构、开发。2. 根据需求，从稳定性、功能、性能、可用性等方面，负责设计、实现、改进相关工具。 3. 开发数据交换平台，数据库连接适配、数据同步等工具。4. 支持各种业务相关的数据同步传输处理的需求任职要求1. 有Linux服务端开发经验，有后台分布式系统开发经验。2. 熟悉Java语言，熟悉nio、多线程、高并发处理、jvm内存管理等技术。3. 熟悉HDFS、Kafka、ElasticSearch、Hbase、Impala、Flink等开源存储/计算框架中的至少一种，阅读过源代码更佳。4. 熟悉以上nosql数据库相关工具的开发，包括开发、监控、调优、迁移、同步工具等优先 5. 有数据库迁移和同步的经验，接触过 datax、binlog、ETL 等技术，熟悉全量、增量的数据迁移6. 了解分布式存储和计算系统原理，有相关设计经验尤佳。7. 具备强烈的进取心、求知欲及团队合作精神，具有良好的沟通能力，具有良好的问题分析和解决能力。8. 有互联网产品用户行为研究/日志采集/大数据处理经验优先。,"金融,移动互联网",2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6253377.html,朝阳区,18k-30k,秒针信息技术有限公司,1-3年,本科,行业TOP;团队氛围，晋升空间；福利待遇,"岗位职责：1. 搭建和持续优化基于Lambda架构的大数据处理平台，支持流式和批式的大数据存储以及数据挖掘需求2. 搭建和维护数据仓库，与业务部门密切配合，寻求数据层面的业务价值，利用数据推动产品优化3. 负责数据对接，打通和对外服务的设计、开发和维护，并能保证质量和性能4. 各种算法模型的工程化实施岗位要求:1、计算机及相关专业本科以上学历，具有良好的数学、统计学、计算机相关知识2、精通常见分布式计算框架和技术原理，如Hadoop、Spark等；熟悉常见的分布式存储相关技术，熟练掌握HDFS，HBase等技术；3、熟悉数据仓库维度建模理论，2年以上的离线/实时数据仓库经验；4、熟悉互联网大数据计算领域研发,有TB级及以上大规模数据处理经验者优先，有分布式图数据库经验优先；","数据服务,广告营销",2000人以上,hadoop,北京
高级大数据开发工程师,https://www.lagou.com/jobs/5933871.html,朝阳区,25k-50k,北京闲徕互娱网络科技有限公司,3-5年,本科,发展前景,"职位描述：1、负责公司数据平台的架构设计及实施；2、负责数据仓库的设计与实施；3、负责符合业务的数据工具的抽像及研发；4、负责大数据开发团队小组的工作协调和管理。任职条件1、熟练掌握大数据常用框架，如spark,hive,hbase等；2、熟练开发spark streaming流式分析作业及离线分析作业，熟练应用spark 2.x新特性，掌握flink开发；3、掌握scala开发语言，对底层实现有一定研究，熟练使用Python语言；4、有丰富的数据仓库设计及开发经验，从数据采集到数据报表的整个全链路有比较深刻的理解；5、具有良好的沟通能力和团队合作精神。",移动互联网,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/3397286.html,海淀区,15k-30k,北京芯盾时代科技有限公司,5-10年,本科,"五险一金,工作居住证,节日福利,出国旅游",工作职责：1、参与系统的需求分析和技术方案预研。2、负责大数据产品的研发、设计工作，及大数据平台的完善；3、负责各种生产、测试环境业务系统问题的快速定位和解决；4、负责代码编写、单元测试，确保代码执行性能、质量和安全；5、协助客户参与各种环境业务系统的投产及技术支持。 任职要求：1、思路清晰，善于思考，能独立分析和解决问题，较强的表达和沟通能力，责任心强，具备良好的团队合作精神和承受压力的能力，能接收项目驻场；2、熟练使用Kafka、Redis、Storm、ElasticSearch等大数据组件，并有相关项目开发经验；3、对MySQL、Oracle数据库有一定的了解和使用经验；4、对Tomcat、Weblogic服务器有一定的了解和使用经验；5、有Java开发经验者优先；6、有shell、Python开发经验者优先；7、工作积极主动，具有良好的团队协作精神；8、逻辑清晰，快速的学习能力及良好的沟通能力。,"移动互联网,信息安全",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6347339.html,朝阳区,30k-40k,上海淇毓信息科技有限公司,5-10年,本科,上市公司，免费三餐，0-9个月年终奖,职责描述：1.根据360金融业务和集团的海量数据，为风控、BI提供数据支持；2.对数据处理的需求场景进行抽象，形成自动化工具，提升工作效率；3.基于日常的需求场景，构建安全、高效、稳定的大数据平台，为业务提供更有效的数据支撑。任职要求：1.属性Linux操作系统，熟悉Shell编程语言；2.大数据处理经验丰富，熟悉hadoopmap/reduce编程；有Hbase、Spark、Storm的应用开发经验；3.熟悉其它分布式存储相关技术，包括HDFS，Hive、Redis、mongodb、Flume、Kafaka、Sqoop、Zookeeper、ElasticSearch等。具有以下经验者优先考虑：1.具有海量数据调优、数据倾斜调优经验者优先考虑；2.有大数据平台开发经验者优先考虑；3.具有SQL优化经验优先考虑；4.熟悉REDIS使用的优先考虑。,金融,500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6647090.html,海淀区,12k-24k,上海诺悦智能科技有限公司,1-3年,本科,五险一金 奖金 餐补 通讯补助等,任职要求：1.   精通Scala、java语言，有Scala实际编程经验2.   深入了解分布式系统、大数据平台、消息队列等高可用高弹性架构;3.   对HDFS/Yarn/HBase/Hive/Spark相关组件的性能优化和补丁跟踪等有实际经验4.   在Hadoop、Spark、Storm、Flink等开源社区有过贡献最佳5.   熟悉银行业务，有过银行数据处理、分析经验者优先6.   良好的英语读写能力7.   本科及以上学历，2年以上相关工作经验；,数据服务,50-150人,hadoop,北京
智能硬件-高级大数据开发工程师,https://www.lagou.com/jobs/7118196.html,海淀区,20k-40k,北京搜狗科技发展有限公司,5-10年,本科,明星业务 团队氛围好,项目背景   搜狗AI硬件致力于以搜狗AI能力延展多场景，落地多终端智能硬件产品。涉及AI能力包括麦克阵列、语音识别、自然语言处理、图像识别、翻译、语音合成、搜索和问答等。横跨场景有个人随身、居家、车载等场景。产品矩阵包括翻译产品线、AI录音产品线、AI耳机产品线、糖猫儿童产品线等。随着AI技术的日趋智能化和产品场景的深挖拓展，AI+硬件将推出更多有价值，让获取和表达信息更简单的产品。岗位职责1、负责AI硬件事业部相关业务线内数据需求评估、技术方案和架构设计2、相关业务建模与业务数据支撑，包括但不限于数据清洗、数据仓库构建、数据模型建立，数据报表等工作3、负责相关算法、用户画像等方面研究和实现4、关注业内技术动态，解决实际场景中的问题，优化技术方案任职资格1、统招本科及以上学历，计算机相关专业，4年以上大数据开发经验2、熟悉hadoop\hive\spark\flume\ES等相关大数据技术或组件3、熟悉java、python、sql、shell、scala等编程语言4、有大数据数据开发、数据分析相关项目经验5、有责任心和上进心，且比较细心6、有数据挖掘、算法、统计分析相关经验优先,工具,2000人以上,hadoop,北京
地图数据系统高级开发工程师,https://www.lagou.com/jobs/6977113.html,海淀区,15k-30k,腾讯科技（深圳）有限公司,3-5年,本科,大平台；公司重点业务；氛围好。,岗位要求：1、计算机或者gis相关专业毕业，熟悉常见的数据结构和算法设计，至少会c、c++、python、java中的一种编程语言，优秀的工程能力；2、对网络编程、数据库编程、数据库存储优化、操作系统、常见的分布化redis、postgres/mysql有较多的经验积累和理解，参与过大型业务系统的设计开发；3、具备较强的业务问题理解分析能力和学习能力， 能够应用新技术、提出新想法解决业务问题；有以下条件优先：1、有微服务、缓存&数据库中间件、数据流系统等工作经验者优先；2、有storm/hadoop/spark/kafka/hbase等开源框架经验优先；同时有相关机器学习学习和实践背景更佳；3、具备地图数据方向的相关后台研发经验优先。岗位职责：1、参与地图数据全业务子系统的系统建设、架构设计、功能开发和优化等工作；2、负责地图数据业务后台的系统架构设计和模块开发， 为地图数据业务开发高性能、低延迟的数据存储、访问系统和数据流系统；3、负责腾讯LBS数据生产平台后端的系统功能和模块研发， 为作业编辑提供高效、自动化的平台后端支持。4、负责道路数据编辑平台建设，支撑百万级任务的高速稳定流转，提供稳定的后台系统； 5、负责千万级海量数据的高效读取、精确校验、快速处理,社交,2000人以上,hadoop,北京
腾讯云大数据开发平台研发工程师（北京）,https://www.lagou.com/jobs/6995767.html,海淀区,20k-40k,腾讯科技（深圳）有限公司,3-5年,本科,加入腾讯云，创造下一个里程碑,岗位职责：负责腾讯云公有云数据平台的建设岗位要求：1、统招本科及以上学历，计算机相关专业，3年及以上相关工作经验，有扎实的计算机理论基础；2、精通Java程序开发，熟悉Linux/Unix开发环境；3、对分布式系统以及资源竞争场景有实践经验，具有高扩展性、高性能和分布式系统的实践经验；4、深入理解和熟练使用Hadoop生态，并有源码阅读经验的优先；5、具有大数据平台开发和使用经验优先； 6、具有数据分析经验优先。,社交,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5523279.html,西城区,20k-30k,联洋国融（北京）科技有限公司,3-5年,硕士,发展前景好，五险一金，团队旅游,岗位职责：1.     负责分布式存储平台的设计及研发；2.     负责大数据接入系统的设计和研发；3.     持续对系统进行性能优化、功能改善以及稳定性提升；岗位要求：1.     计算机相关专业，硕士及以上学历，背景特别优秀者可考虑本科学历；2.     有5年以上的大数据平台开发经验，有分布式系统开发经验，参与过大型集群的建设工作；3.     熟悉Java的基础技术体系，包括JVM、线程、并发、IO资源管理、网络等；4.     熟悉HDFS、Hive、Kafka、Flink等开源存储系统中的至少一种，有源代码阅读及修改经验。5.     熟悉分布式存储系统原理，有相关设计经验优先；6.     对Paxos/Raft算法、高可用、高可靠架构等有深入理解，并有一定的实践经验。有压缩算法设计、存储结构设计等经验者优先考虑；,数据服务,50-150人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5714825.html,西城区,18k-28k,联洋国融（北京）科技有限公司,3-5年,本科,海量数据、每天上百亿条数据、数据量50T,岗位职责：1.     负责大数据基础平台、数据分析产品的系统设计及开发；2.     负责大数据平台的搭建、监控、性能调优； 岗位要求：1.     计算机相关专业，本科及以上学历，3年左右大数据或者Java开发工作经验；2.     有较强的开发能力，包括设计，编码，调试能力；3.     熟悉主流的开源大数据技术，Hadoop、Spark、Kafka、Flink、hive等至少一种，在开源社区活跃者优先；4.     对高稳定、高可用、高性能、大数据处理有过实际项目者优先考虑；5.    35岁以下，身体健康，可适应一定的工作压力。,数据服务,50-150人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6976796.html,海淀区,13k-20k,北京世纪高通科技有限公司,1-3年,硕士,一年多薪 免费班车 公司出游,岗位职责：1.负责位置大数据应用系统的开发；2.负责海量位置数据的接入、清洗、处理和发布；3.负责位置数据处理逻辑与处理性能的优化；4.负责现有位置大数据工程的维护和迭代；岗位要求：1.有较强的英语或德语写作和沟通能力；2.有丰富的Scala和/或Java实践开发经验；3.有批处理（如Apache Spark）和流处理（如Apache Flink、Kafka）实战经验；4.能够熟练使用IntelliJ/Eclipse、Maven、Jenkins、Git、Jira、Confluence或类似工具的经验；5.了解AWS批/流处理以及监控组件；6.了解敏捷方法，如SCRUM、LESS等；7.善于团队合作并有较强的解决问题和决策能力；8.有地理空间分析以及空间数据使用经验者优先,"移动互联网,其他",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7141734.html,朝阳区,18k-25k,北京妙医佳健康科技集团有限公司,3-5年,本科,福利健全，准上市公司，平台发展前景好,岗位职责：1.大数据平台建设和维护；2.数据仓库建模和开发；3.实时数据仓库开发；4.研究大数据前沿技术，提升系统效率。任职要求：1. 计算机相关专业，3年以上大数据开发经验； 2. 熟悉Hadoop/Hive/Sqoop/Spark/Storm/Flink/Elasticsearch等当前主流的开源大数据组件并具有相关开发经验；3. 参与过数据仓库（实时、离线）设计和搭建，有数据治理相关经验；4. 熟悉superset/tableau等报表工具；5. 有良好的逻辑思维能力、做事积极主动、有较强的执行能力和较好的沟通能力；6. 2年以上java开发经验，熟悉微架构Dubbo、Spring Boot。,移动互联网,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7184022.html,朝阳区,20k-25k,奇虎360科技有限公司,1-3年,本科,"平台大,免费三餐,健身房,班车",,信息安全,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6992911.html,海淀区,20k-40k,混沌时代（北京）教育科技有限公司,3-5年,本科,"弹性工作,六险一金,年度体检,学习氛围",职位描述：1. 负责大数据系统的数据清洗、建模、监控及治理2. 负责相关开源组件的性能、稳定性、可靠性等方面的深度研究和优化3. 解决生产环境的各种实际问题，保障大数据系统的平稳运行任职要求：1. 计算机相关专业本科及以上学历， 3 年以上工作经验2. 熟悉Python/Java，熟悉常见的数据结构和算法3. 对大数据生态体系中的一项或多项有深入了解，如 HDFS、MapReduce、HBase、Hive、Spark、Kafka等；4. 熟悉整个大数据平台的处理流程和大规模分布式集群的环境搭建5. 有Python web开发经验并熟悉主流开发框架者优先6. 良好的团队协作及沟通能力,"移动互联网,教育",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5968823.html,海淀区,25k-50k,北京世纪好未来教育科技有限公司,3-5年,本科,"上市公司,福利好",任职资格：1、3年以上相关工作经验，计算机相关专业本科以上学历 2、熟悉Hadoop、Hive、Hase、Spark等大数据处理工具，熟悉Hadoop、Spark原理和机制 3、熟悉Python语言编程，有基于Hive、Spark等开发经验，熟悉scala、java语言优先 4、熟悉数据仓库设计与实现，有过相关实践经验者优先 5、有良好而逻辑思维，喜欢底层数据开发，对业务数据敏感 6、做事积极主动、有良好的沟通和合作能力  工作职责：1、负责新项目中数据开发相关工作，具体如下： （1）业务数据仓库建设中数据提取、清洗等 （2）业务数据BI指标开发 （3）业务分析的数据开发支持,教育,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6690555.html,朝阳区,15k-30k,中商惠民（北京）电子商务有限公司,3-5年,本科,"五险一金,餐补,生日福利,员工旅游","技能要求：java岗位职责：1、负责大数据平台的架构和开发；2、负责海量数据处理分布式平台以及数据分析系统；3、参与数据工具、ETL程序开发工作；4、参与大数据处理，算法实施等工作；5、参与数据分析平台的数据开发和调优工作。职位要求：1、此岗位必须具备flink实际项目工作经验，熟悉主流的云计算、大数据产品（hadoop、spark、flume等）和数据分析技术（机器学习)并具有相关项目经验2、四年以上数据仓库设计和ETL开发经验，熟悉数据仓库建模设计，元数据管理，数据质量监控等3、四年以上的离线，实时，OLAP数据分析处理项目经验4、三年年以上MapReduce开发经验5、精通Java，Hive SQL，Linux shell；具备较丰富的Scala，Kafka 开发经验；6、有较强的性能优化及问题排查，解决能力；对开源技术非常感兴趣并具有一定的研究能力,有良好的沟通协调能力。7、有数据挖掘、机器学习、推荐算法、人工智能、数学建模项目经验者优先。任职地点：北京集团总部",电商,2000人以上,hadoop,北京
前端开发工程师（数据可视化）,https://www.lagou.com/jobs/6284953.html,海淀区,20k-38k,北京微聚未来科技有限公司,3-5年,本科,技术大牛 扁平管理 七险一金 16薪考核,"【工作职责】1.负责数据可视化产品的系统开发，包括数据分析平台、用户画像等数据可视化；2.理解主要数据可视化展现形式，结合业务和数据场景，提出专业、合理的可视化方案建议；【职位要求】1.对视觉、交互有着深刻理解，有能力精确还原设计、实现交互，对数据产品有深入理解2.扎实的前端基本功，包括但不限于HTML/CSS/JavaScript,至少熟练一种前端js框架(Angular/Vue/React)3.熟悉常用数据可视化库，如ECharts/D3.js/HighCharts/G2,至少熟练使用任一种4.熟悉java后端开发技术5.对前端性能优化有自己的理解并能编写高性能和可维护性强的模块代码6.有用户画像、运营分析、OLAP等相关数据可视化产品开发经验7.能与团队成员保持良好沟通，能快速理解、消化各种需求，并落实为具体的开发工作","移动互联网,金融",500-2000人,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/6734016.html,海淀区,15k-30k,华为技术有限公司,3-5年,本科,知名企业、待遇优厚、从事核心技术开发,"工作职责：1.负责数据库领域的需求分析、设计、开发、运维等工作;2.负责业界领先的云端到终端各层次内核数据库研发,基于操作系统内核技术构建数据库高性能、高可用等核心竞争力;3.负责数据库内核相关领域的新技术探索；业务技能要求：1.了解国内外数据库产业及行业市场分布情况、了解数据库领域技术趋势变化优先；2.熟悉中小型企业IT系统建设情况，具备主流数据库、数据仓库系统架构和方案设计经验者优先；3.具有良好的沟通能力，刻苦、敬业、有上进心，有良好的团队合作精神。对技术有激情，喜欢钻研，能快速接受和掌握新技术，有较强的独立、主动的学习能力。专业知识要求：1、熟悉C/C++/ python；2、熟悉Linux操作系统、数据库应用，熟悉代码优化的规则与技巧；3、熟悉分布式技术理论，并实践经验者优先；",通讯电子,2000人以上,hadoop,北京
数据库内核开发高级工程师,https://www.lagou.com/jobs/6812399.html,海淀区,25k-50k,华为技术有限公司,5-10年,本科,知名企业、待遇优厚、从事核心技术开发,业务技能要求：1.了解国内外数据库产业及行业市场分布情况、了解数据库领域技术趋势变化优先；2.熟悉中小型企业IT系统建设情况，具备主流数据库、数据仓库系统架构和方案设计经验者优先；3.具有良好的沟通能力，刻苦、敬业、有上进心，有良好的团队合作精神。对技术有激情，喜欢钻研，能快速接受和掌握新技术，有较强的独立、主动的学习能力。专业知识要求：1、熟悉C/C++/ python；2、熟悉Linux操作系统、数据库应用，熟悉代码优化的规则与技巧；3、熟悉分布式技术理论，并实践经验者优先；,通讯电子,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6979640.html,海淀区,20k-40k,北京金山云网络技术有限公司,3-5年,本科,免费三餐 周末双休 弹性工作,岗位职责1、负责数据分析体系的建设、开发与维护，包括平台搭建，大数据开发与处理，数据模型的工程化实现与优化等；2、深入了解业务，并能结合业务特性，对数据进行深度分析与挖掘，探索并构建分析主题3、挖掘业务痛点与问题，提出业务策略建议，制定相应解决方案，并能强力推动实施岗位要求1、有大数据开发与分析相关经验，本科及以上学历，计算机、统计、数学等相关专业毕业2、精通sql，精通java、scala、python一种或多种，熟悉spring，shell3、熟悉hadoop、spark等分布式框架并熟练使用，熟练使用大数据分析相关工具hive/mysql/es等4、扎实的数据结构和算法功底，对数据敏感，要求超强的数据分析和问题解决能力5、逻辑缜密，有强烈的责任心和良好的组织协调能力，对工作充满热情,"移动互联网,数据服务",2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5380005.html,朝阳区,15k-30k,北京数美时代科技有限公司,应届毕业生,本科,"快速发展,待遇好,氛围好,六险一金",你将要负责1、负责构建大数据分析平台以及数据分析和挖掘工作2、负责数据的离线和实时流分析3、参与支撑业务的数据模型建设及数据指标的计算和分析4、参与海量数据的存储、查询和运营数据分析体系搭建5、运用Hadoop、Spark、ES等分布式计算和存储平台希望你1、计算机相关专业应届毕业生2、对Spark及Hadoop技术有深入了解3、熟悉Python/Java/Scala/Php等编程语言，熟练使用SQL，有良好的编码习惯，对分布式有深刻理解4、了解Windows、Unix、Linux等主流操作系统原理，熟练运用系统层支持应用开发5、技术视野开阔，有强烈的上进心和求知欲，善于学习和运用新知识，勇于解决难题 6、善于沟通和逻辑表达，拥有优秀的分析问题和解决问题的能力，良好的团队合作精神和积极主动的沟通意识 7、有激情，具有自我驱动力，追求卓越【关于数美】www.ishumei.com数美科技成立于2015年6月，致力于为全球客户提供专业的AI业务风控服务，由国内知名VC机构腾讯、襄禾资本、顺为资本、清流资本、BV百度风投联合投资，为互联网、互联网+、以及产业互联网客户提供全栈式、可信赖的业务风控解决方案。团队核心成员均来自百度、阿里、腾讯、360、小米等知名互联网企业，拥有10余年搜索、安全、语音等互联网在线产品研发经验。4年探索深耕，数美科技基于先进的人工智能技术，构建了全场景、全流程、全维度业务风控产品矩阵与秒级迭代全球SaaS AI风控服务网络，承载海量风险识别请求，以业务、模型、数据驱动的产品实现快速进化。数美科技结合多年黑产对抗经验打造全栈式实时智能风控引擎-天网，旨在为客户解决营销欺诈、支付风控、数据盗爬、欺诈广告等风险问题；同时，结合人工智能技术打造全栈式智能内容识别引擎-天净，为客户提供一站式的智能内容安全解决方案，帮助客户识别文本、图片、音频、视频、网页中出现的涉黄、涉政、低俗、色情、导流广告等问题，规避业务风险，提升运营效率。数美科技的业务风控服务已成功覆盖游戏、直播、新零售、地产、电商、视频、金融、媒体、旅游、出行、教育等行业。截至目前，数美科技已服务华润置地、苏宁、云闪付、酷狗、爱奇艺、映客、探探、vipkid、B站、汽车之家、游族、小红书、keep等上千家知名企业。…………………………………………………………………………了解更多：www.ishumei.com,"企业服务,数据服务",150-500人,hadoop,北京
数据开发,https://www.lagou.com/jobs/6854370.html,朝阳区,20k-40k,北京数美时代科技有限公司,1-3年,本科,"大佬领投,五险一金,补充医疗,免费下午茶",你将要负责1、负责构建大数据分析平台以及数据分析和挖掘工作2、负责数据的离线和实时流分析3、参与支撑业务的数据模型建设及数据指标的计算和分析4、参与海量数据的存储、查询和运营数据分析体系搭建5、运用Hadoop、Spark、ES等分布式计算和存储平台希望你1、计算机相关专业应届毕业生2、对Spark及Hadoop技术有深入了解3、熟悉Python/Java/Scala/Php等编程语言，熟练使用SQL，有良好的编码习惯，对分布式有深刻理解4、了解Windows、Unix、Linux等主流操作系统原理，熟练运用系统层支持应用开发5、技术视野开阔，有强烈的上进心和求知欲，善于学习和运用新知识，勇于解决难题 6、善于沟通和逻辑表达，拥有优秀的分析问题和解决问题的能力，良好的团队合作精神和积极主动的沟通意识 7、有激情，具有自我驱动力，追求卓越 【关于数美】www.ishumei.com 数美科技成立于2015年6月，致力于为全球客户提供专业的AI业务风控服务，由国内知名VC机构腾讯、襄禾资本、顺为资本、清流资本、BV百度风投联合投资，为互联网、互联网+、以及产业互联网客户提供全栈式、可信赖的业务风控解决方案。团队核心成员均来自百度、阿里、腾讯、360、小米等知名互联网企业，拥有10余年搜索、安全、语音等互联网在线产品研发经验。4年探索深耕，数美科技基于先进的人工智能技术，构建了全场景、全流程、全维度业务风控产品矩阵与秒级迭代全球SaaS AI风控服务网络，承载海量风险识别请求，以业务、模型、数据驱动的产品实现快速进化。数美科技结合多年黑产对抗经验打造全栈式实时智能风控引擎-天网，旨在为客户解决营销欺诈、支付风控、数据盗爬、欺诈广告等风险问题；同时，结合人工智能技术打造全栈式智能内容识别引擎-天净，为客户提供一站式的智能内容安全解决方案，帮助客户识别文本、图片、音频、视频、网页中出现的涉黄、涉政、低俗、色情、导流广告等问题，规避业务风险，提升运营效率。数美科技的业务风控服务已成功覆盖游戏、直播、新零售、地产、电商、视频、金融、媒体、旅游、出行、教育等行业。截至目前，数美科技已服务华润置地、苏宁、云闪付、酷狗、爱奇艺、映客、探探、vipkid、B站、汽车之家、游族、小红书、keep等上千家知名企业。…………………………………………………………………………了解更多：www.ishumei.com,"企业服务,数据服务",150-500人,hadoop,北京
高级/资深大数据开发工程师,https://www.lagou.com/jobs/7029691.html,朝阳区,20k-40k,雪球（北京）技术开发有限公司,3-5年,本科,金融科技 年轻有活力 扁平化管理,1.大数据中台实时能力加强。2.大数据中台用户画像能力加强。3.大数据中台对外输出模型丰富，如漏斗，留存，多维数据集等。4.应用hadoop分布式技术解决性能，存储，计算等问题，具备通用能力抽取，设计和实现的技能。5.具备机器学习能力，能够沉淀简单的机器学习模型到数据中台，对外输出通用模型的分析数据，以供社区头条等提供二次机器学习加工的能力，简化机器学习里最为繁锁的数据清洗和基础特征挖掘的重复劳动，极大提高算法工程师效率。任职要求1.本科以上学历（211/985优先），计算机或数学相关专业，至少具备三年以上的工作经验。2.熟悉Java和python语言。3.熟悉Hadoop/HBase/Spark/Storm/Hive/flink/HDFS/presto/kafka等相关技术。4.聪明，积极，善于发现问题，并有独立解决问题的能力。5.精通数据结构和常用的算法，有很强的编程能力。6.对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先.。7.具备机器学习能力，数据平台，数据仓库经验优先。8.拥有实战大数据处理技术者优先。,金融,150-500人,hadoop,北京
高级大数据开发讲师,https://www.lagou.com/jobs/6790496.html,海淀区,25k-50k,北京拉勾网络技术有限公司,不限,本科,高薪、试用期全薪、六险一金、领导nice,岗位职责：1、参与设计开发具有前瞻性与实用性的 高级大数据开发 课程；2、完成课程一体化设计方案，包括教学内容、教学大纲、教学指南、教学活动等；3、按照教学计划要求，完成在线课程录制与直播，优化改进；4、完善培训教辅材料、案例体系，制定课程考核标准，并建立题库；5、指导助教开展网上学习辅导活动，帮助助教提高专业教学能力。任职要求：1、热爱教育行业，本科以上学历；2、具有大数据开发2年以上一线项目研发经验，2年以上讲师经验；3、对Spark生态体系、Hadoop生态体系有深度研究与实践者优先；4、语言表达流利，思路清晰，有独特的授课风格及表现力，注重理论联系实际，深入浅出；5、能独立完成教学资料的开发（题库、案例库）；具有较高的技术水平和丰富的项目开发经验; 懂在线学习用户心理，善于沟通；6、擅于学习，工作态度积极主动，对学员有极强的责任心；具有创新的思维和意识；具有一定的抗压能力；,企业服务,500-2000人,hadoop,北京
资深大数据开发（数仓搭建）,https://www.lagou.com/jobs/6499838.html,海淀区,20k-35k,北京拉勾网络技术有限公司,5-10年,不限,周末双休，提供午餐和晚餐，下午茶,职位诱惑：福利待遇优，发展前景好职位描述：工作职责 :1.参与大数据平台和大数据处理框架的架构规划设计。2.根据业务需求进行数据处理和统计分析挖掘。职位要求 :1.五年以上大型互联网产品或分布式系统开发设计经验2.熟练掌握Java或者Scala或Python任意一种语言3.熟练SQL开发，掌握Mysql等关系型数据库中的一种或几种4.熟练掌握Hadoop及Map-Reduce应用开发，5.熟练掌握Spark、Kafka、HBase、Hive、Storm、Impala等大数据开发工具中一种或几种6.熟悉Linux系统，具备Shell、Python等脚本开发能力者优先7.有大数据或数据仓库项目经验，了解数据仓库相关理论知识者优先8.有大规模集群开发运维经验，具备源码级问题解决和集群优化改造能力者优先9.学习能力强，喜欢研究开源新技术，有团队观念，具备独立解决问题的能力你将加入这样一群人：追求自由、平等，提倡简单、透明和分享；对新事物充满好奇，对技术充满热情；热爱生活、热爱运动，爱户外、爱篮球、爱羽毛球还有爱二次元的工作地址北京 - 海淀区 - 中关村创业大街海置创投大厦4层,企业服务,500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7071414.html,海淀区,3k-5k,联通云数据有限公司,应届毕业生,硕士,央企、高薪酬、高福利,岗位职责：1、协助进行大数据开发工作；2、协助大数据平台建设和运维。任职要求：1、至少熟悉Java、Python、Scala中一种；2、熟悉hadoop、Spark、Kafka数据处理框架；3、熟悉mysql、redis、mongodb、ElasticSearch等数据库中间件。,硬件,500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7073988.html,海淀区,15k-30k,联通云数据有限公司,3-5年,本科,央企、高薪酬、高福利,岗位职责：1、云警-数据中台建设、维护及优化；2、云警数据类相关功能开发及性能优化。任职要求：1、3年大数据研发相关从业经验，熟练掌握Java或Scala语言开发基本技能；2、熟悉Hadoop、Spark、Flink等大数据开源框架及其生态；3、熟练使用Kafka、Mongodb、ElasticSearch、Redis、Hbase等开源工具，熟练掌握常用中间件调优技巧；4、具备DataOps、AIops、机器学习、运维自动化相关从业经验者优先；5、具有云业务运维监控系统相关开发经验者优先。,硬件,500-2000人,hadoop,北京
高级大数据开发工程师,https://www.lagou.com/jobs/6508784.html,海淀区,25k-50k,脸球（北京）科技有限公司,5-10年,本科,"大牛多,福利多,氛围轻松,**VC","岗位描述：1、负责大数据的日常开发,包括架构和日常的业务；2、与业务方沟通日常的需求,梳理需求文档,产出技术方案;3、支撑用户行为分析,用户画像,智能推荐系统的开发和建设。技能要求: 1. 能够熟练运用java语言和scala语言实现编程; 2. 深刻理解HDFS分布式文件系统存储结构和高可用原理; 3. 能运用scala进行spark RDD，spark streaming编程; 4. 熟练掌握hadoop mapreduce计算框架编程，对yarn的资源调度，作业监控了解; 5. 深刻了解Spark运行机制,掌握spark streaming编程，对定时批量任务处理; 6. 熟悉flume，kafka等日志收集以及kafkaconnect实时多系统导入导出工具等分发框架的使用，能够将他们和storm、spark进行整合,进行数据的实时处理; 7. 能够熟练运用hive数据仓库工具，对日志数据进行查询，统计等数据操作，并且有一定的数据优化经验; 8. 能将hive和spark sql进行整合，进行数据查询等相关操作; 9. 熟悉hbase数据库的使用及其编程; 10. 熟悉redis内存数据库，能搭建redis高可用集群及其编程; 11. 熟悉ELK技术栈，了解ElasticSearch，Logstash的整合使用; 12. 掌握Sqoop数据迁移工具的使用，能熟练的将数据从不同的存储介质进行迁移; 13. 了解linux系统，熟悉常用的linux的shell命令，能在linux系统下搭建开发环境; 14. 熟练掌握JavaSE，深刻理解面向对象设计思想，熟练使用IO流操作、集合框架、网络编程等JavaSE主流技术及ssm框架的使用; 16. 能熟练使用Oracle，MySql主流数据库技术，擅长SQL语句的编写 17. 熟悉大数据环境的搭建,集成,运维工作,擅长调优最好加分项:   有过从0-1搭建大数据的环境,产出大数据上线项目的,优先考虑   有过社交领域用户行为分析,用户画像,智能推荐系统经验的优先考虑","移动互联网,社交",15-50人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7215079.html,海淀区,40k-55k,青岛德谦智行企业管理有限公司,5-10年,本科,独栋办公，独角兽,工作职责：1、负责海量数据的采集，离线和实时计算平台的设计，开发，维护与优化；2、参与计算平台的架构设计，开发，运维等相关工作，并能够进行自动化平台建设；任职资格：必要条件：1、3年以上工作经验;2、掌握hadoop、spark、storm、flink等大数据相关组件，理解底层运行原理，并运用开发3、精通数据采集，离线计算、实时计算4、3年以上的Java或scala开发经验(熟练使用java、scala、python等开发语言);5、了解数据结构及算法（基本算法即可）加分项1、有过参与大数据计算平台的系统规划，并落地的经验优先2、熟悉Kubernetes者优先,企业服务,少于15人,hadoop,北京
高级大数据开发工程师,https://www.lagou.com/jobs/6428452.html,海淀区,18k-24k,亚信科技（中国）有限公司,5-10年,本科,13薪，年终奖，不打卡,"岗位职责：1、参与Hadoop、Spark相关的大数据产品的设计和研发工作;2、 针对公司大数据业务需求，负责数据采集、数据处理、数据分析、储存等工作3、管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；4、 具备良好的沟通能力、业务需求分解能力，能够和业务人员有效进行需求及技术沟通交流任职要求：1、本科及以上学历，计算机等相关专业2、熟悉java语言，会scala或python加分2、熟悉linux系统、Shell等脚本语言；3、 掌握大数据处理及分布式管理相关技术（包括Hadoop、HDFS、Spark、HBase、Hive、ZooKeeper等开源框架）,并具有实际开发经验；4、熟悉Map/Reduce编程，熟悉Storm、Spark streaming等大数据实时处理框架的一种或多种；5、熟练常用的消息中间件kafka，rabbitmq；6、熟悉大数据集群环境的搭建、部署；具有集群性能调优、扩展等实际经验者优先；7、具有智能检索、语义分析、用户画像等实践经验者优先；其他：1、具备较强的沟通交流、良好的文字表达能力、团队合作能力；2、具有通信行业系统开发经验者优先考虑。","企业服务,移动互联网",2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6933273.html,朝阳区,10k-20k,深圳市华云中盛科技股份有限公司,3-5年,大专,福利待遇好、团队氛围好、年终奖,岗位职责：,"数据服务,移动互联网",500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6551648.html,海淀区,10k-15k,北京国双科技有限公司,应届毕业生,本科,大数据人工智能企业、发展前景可观,岗位职责：1.基于国双大数据平台，负责大数据清洗、存储、处理、分析等场景的开发，完成高质量的代码编写；2.完成项目和产品文档设计文档撰写；3.培养并带领初级工程师，进行技术设计、代码编写的指导和评审；4.视项目需要需要在客户办公场所驻场设计和开发。任职要求：1. 扎实的Java开发功底，熟悉scala编程，有丰富的并发编程经验，2. 熟悉Hadoop、Spark、Flink、Kafka、Presto、ES、Hive、Flume等三门以上，熟悉原理源码、有二次开发优先。3. 有参与构建海量数据存储、离线/实时计算、实时查询，大数据平台、BI平台的经验优先；4. 擅于沟通和解决问题，乐于总结分享，有想法，有冲劲，有团队精神和主人翁意识和责任感。,"数据服务,企业服务",500-2000人,hadoop,北京
大数据开发工程师-流式计算,https://www.lagou.com/jobs/7107922.html,海淀区,22k-44k,北京小米科技有限责任公司,3-5年,本科,"六险一金,周末双休,餐补,弹性工作制",职位描述：负责广告平台数据的设计与实现；负责业务数据平台相关数据的存储、查询、挖掘等的功能开发；任职要求：1、计算机、数学相关专业本科及以上学历，4年以上互联网研发工作经验2、具有扎实的计算机科学功底，扎实的编程基础和数据结构算法基础，良好的工程素养，极强的问题解决能力3、精通Unix/Linux操作系统下Java或Scala开发，有良好的编码习惯，有扎实的计算机理论基础4、有基于hadoop体系的数据仓库开发经验，了解 Hive，Hbase，Spark等大数据处理工具和技术，有较强的调优能力5、对数据敏感，有较强的逻辑分析能力，对大数据处理和分析技术有丰富的经验和强烈热情6、善于交流，有良好的团队合作精神和协调沟通能力,硬件,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6766656.html,西城区,20k-40k,苏州精正信息科技有限公司,不限,本科,福利待遇好,"工作职责1、参与分布式大数据处理系统和数据服务基础设施的架构设计和开发。2、和产品经理一起梳理和完善系统功能需求。3、改进系统性能。职位要求1、了解分布式、微服务、传统关系型数据库、常用NoSQL开源系统、RESTful、基本的信息安全领域知识 2、精通Java代码，其他语言不限制 具体要求： 1、本科及以上学历，3年以上大型互联网产品或分布式系统开发设计经验。2、丰富的Java研发经验,精通Java, 熟悉Shell或Python等一种或几种脚本语言者优先。3、熟悉常用分布式系统相关理论基础，有一定的分布式系统开发经验，有互联网公司中大型分布式系统经验优先 4、具备Spring Cloud等微服务设计和开发经验和能力。5、熟悉大数据技术栈,对Hadoop、Hive、Spark、Hbase、Kafka、ELK等开源组件有使用及优化经验者优先 。","企业服务,金融",少于15人,hadoop,北京
hadoop,https://www.lagou.com/jobs/7071618.html,海淀区,18k-36k,昆仑智汇数据科技（北京）有限公司,5-10年,不限,新基建 工业4.0 核心岗位,"职位诱惑：风口行业,大牛带路,扁平化,环境好   职位描述：工作职责：     本岗位将参与昆仑数据全新产品体系的研发工作，以客户价值为导向，为客户构建高效、强大的工业大数据分析产品。你将参与发掘和分析业务需求，系统方案设计和代码编写，确保性能、质量和安全。你将接触到最新的数据分析大师、资深工业领域专家的工业数据分析方法与实践，学到最严谨规范的开发技术与流程，发展你个人的技术能力，领导力和有效的项目管理能力。在这个大家庭里，我们不仅鼓励大家开发出有价值、有影响力的产品给用户，我们同样鼓励大家多学习，多分享，多创新，在工作中找到最大的乐趣！任职资格－计算机相关专业本科及以上，2年以上的系统或应用软件的开发经验。－熟练掌握Java语言和面向对象思想，能写出整洁、高质量的代码。－精通常用关系数据库（PG、MySQL等）和各种NoSQL数据库。－熟悉并实践过Hadoop、Spark、Flink、Kakfa等任意一种大数据分析框架，并理解一定的底层原理。－精通RESTfulAPI开发，具备良好的API设计风格。－熟练使用Linux，理解并熟练使用Docker容器部署方式。－具备良好的软件工程和质量意识，认同并实践过敏捷开发和DevOps方法。优先任职资格－具备在快节奏，敏捷模式下开发新产品的激情。－曾经Lead团队开发复杂的软件产品，并成功地交付给用户。－具备全栈工程能力，掌握多种语言开发，如js，python，golang等。－曾经参与分布式系统开发，熟悉多个大数据产品生态和相关技术。－Linux高手，熟练掌握shell编程。－有指导年轻工程师提高技术能力和开发效率的经验。",数据服务,150-500人,hadoop,北京
大数据开发,https://www.lagou.com/jobs/6831306.html,朝阳区,15k-30k,北京多氪信息科技有限公司,3-5年,本科,上市公司 公司业务稳定,岗位职责：1.负责大数据产品代码开发和架构设计2.负责数据清洗、处理、转换3.数据赋能业务，提升数据价值发现的能力和效率任职要求：1.3年及以上大数据开发经验，丰富的实时或离线数据体系建设经验2.熟悉Hadoop、HBase、Spark、Storm、Flume、ES等大数据生态技术栈3.熟悉Java、Python等开发语言中的一种或几种4.拥有良好的学习能力、团队协作能力和沟通能力。,"移动互联网,电商",500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7172740.html,海淀区,15k-25k,北京一览群智数据科技有限责任公司,3-5年,本科,前景广阔，团队不错,1. 负责大数据平台规划、部署、优化和维护，保证平台稳定可靠高效运行、熟练掌握并使用cdh、hdp、华为云等大数据管理平台2. 熟练掌握hadoop、hive、hbase、spark、kafka、es、oozie、azkaban、flink等分布式组件的工作原理及应用场景，能够独立应用相关组件独立开发项目3. 深入理解大数据平台架构以及适用场景，有较强的自主分析解决问题的能力4. 熟练使用java、python、scala、shell等开发语言5. 深入理解mysql、oracle任一数据库存储原理、有较强的sql能力6. 熟悉linux环境，有过服务器运维经验者优先7. 从事过spark mlib、spark graphx、neo4j、tigergraph、kudu、impala、Phoenix、tez相关项目开发者优先8.  有过真实日增TB级数据量项目开发经验者优先9.  有过两年以上后端开发经验者优先,移动互联网,150-500人,hadoop,北京
数据仓库开发工程师,https://www.lagou.com/jobs/7174463.html,昌平区,20k-38k,北京世纪好未来教育科技有限公司,不限,本科,大平台、好福利、大牛云集,"职位职责：1、负责数据仓库建模和etl开发，构建可扩展的数据仓库和分析解决方案2、负责建立某个业务方向的数据分析模型，为业务赋能。职位要求1、3年以上数据开发经验2、良好的业务理解能力，对数据敏感。3、具备强悍的编程能力，熟练使用sql,熟悉java或python语言。4、精通至少2项分布式计算平台，例如hadoop,spark,hive,flink,kafka等。5、熟悉数据仓库建模方法论。",教育,2000人以上,hadoop,北京
大数据开发工程师—基础研发 (MJ004565),https://www.lagou.com/jobs/7218199.html,海淀区,20k-35k,北京趣拿软件科技有限公司,3-5年,本科,十天年假、十天全薪病假,职位详情1. 负责去哪儿网大数据处理pipeline的开发和维护2. 负责业务实时数据的接入和数据服务的开发、多维度分析和展现任职要求1. 本科或以上，计算机或相关专业毕业2. 扎实的编程能力，熟悉算法和数据结构，熟悉计算机的基础理论3. 熟练使用Java，熟悉python、shell4. 熟练使用大数据处理组件，包括但不限于Flink，Spark，Kafka，Kylin，ES，Presto，Impala，Hadoop，Hive等组件5. 有实时大数据处理经验，并有深刻了解的优先6. 能有良好的产品思路，从技术角度解决产品问题,旅游,2000人以上,hadoop,北京
数据开发工程师—公共产研部 (MJ004463),https://www.lagou.com/jobs/7070780.html,海淀区,20k-35k,北京趣拿软件科技有限公司,3-5年,本科,十天年假、十天全薪病假,"工作职责：1.参与海量数据的运营数据分析体系搭建, 数据量化运营效果,支持产品快速迭代；2.开发各种数据分析工具, 支持产品效果优化；3.探索和研究有效的数据分析模型，为业务提供决策支持和商业智能。任职资格：1.全日制统招本科及以上学历，有3年以上大数据相关开发或运维经验；2.熟练掌握 java、python 等任意一门编程语言；3.熟练掌握 Hadoop/Hive/Hbase/Kylin/Es/Kafka 大数据处理框架，有源码经优先；4.熟练掌握 sql ， 能够编写复杂语句查询，具备sql 调优能力；5.熟练掌握 数据仓库ETL过程，具备维度建模的能力；6.熟悉数据分析、统计学基本概念；7.熟悉回归、决策树等机器学习算法优先；",旅游,2000人以上,hadoop,北京
搜狗金融—大数据开发工程师（spark方向）,https://www.lagou.com/jobs/4931677.html,海淀区,25k-40k,北京搜狗科技发展有限公司,5-10年,本科,"平台大,人脉广,技术牛,氛围好",项目介绍：搜狗金融，这是一款定位于服务平台互联网用户的金融产品，由搜狗公司内部孵化，深度挖掘搜狗在互联网端的用户规模优势以及多年的大数据能力积累。在当下大热的互联网金融领域，搜狗将发挥用户服务和智能算法优势，并结合平台的综合运营实力。如果你认同互联网金融、智能风控，大数据模型等概念，欢迎加入我们共同创造事业。岗位职责：1、负责数据平台开发及维护；2、 以flink为主建设实时数据仓库；3、 负责Hive相关离线数据仓库的ETL设计、开发、维护与优化；4、 对接并支撑相关的数据需求；5、 参与公司大数据处理理方向的技术拓展。任职条件：1、 统招本科及以上学历， 5年年以上工作经验；2、 熟悉python、 Java，熟练使用shell编写数据处理脚本；3、 熟练使用Hadoop、 Kafka、 Hive、 Flink、 Hbase、 ES、 Kylin等，熟悉hive、 mysql的SQL编写及优化；4、 熟悉数据仓库建模理理论，具备大中型数据仓库架构设计、模型设计、 ETL设计的相关经验；5、性格积极乐观、诚信、有较强的语言表达能力，具备强烈的进取心、求知欲及团队合作精神；6、 具备海量数据处理、有性能调优经验、金融、电商、电信、互联网行业数据模型经验者优先。,工具,2000人以上,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/7218647.html,朝阳区,20k-30k,北京健康之家科技有限公司,3-5年,本科,千人规模、产品知名、定期体检、六险一金,"岗位职责：1. 负责大数据数仓工具建设：调度系统,元数据管理，数据质量2. 负责大数据基础设施建设：kafka管理工具，hbase管理工具，flink管理工具等3. 优化平台架构,提升平台稳定性任职资格：1. 统招本科以上，计算机相关专业，Java 基础扎实，强大的写码能力2. 精通面向对象设计开发，对部分 Java 技术有深入研究，研究过优秀开源软件的源码并有心得者优先3. 熟悉常见设计模式，精通 SpringBoot框架、熟练使用至少一种 ORM 框架如 Hibernate、MyBatis4. 了解Elasticsearch、Zookeeper、Hadoop、Hbase、Hive、kafka,hdfs原理及使用，有基于Zookeeper的分布式系统开发经验优先5. 有spark相关开发经验，有基于spark实现数据同步开发经验优先6. 3年以上数据开发经验，学习能力强，较好的沟通能力","移动互联网,医疗丨健康",2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5042492.html,东城区,25k-40k,北京轻松筹网络科技有限公司,3-5年,本科,"技术大咖,扁平管理,交通便利,绩效奖金",职位描述：1、负责流计算平台的开发与优化工作2、负责流式计算平台开发结合业务的应用、处理实时数据、实时应用场景的开发3、负责实时计算系统的运维，保证系统的高可用性和稳定性4、负责设计，开发，优化数据接入、数据存储、数据计算服务框架5、负责对业务的数据接口开发6、负责优化分布式框架，解决大并发下的各种问题任职要求：1、3年以上相关工作经验，本科或以上学历；2、具备扎实的Java语言基础;3、熟悉并行计算或者分布式计算原理，熟悉高并发、高稳定性、可线性扩展、海量数据的系统特点和技术方案；4、有Spark/Storm等数据平台的开发和使用经验；5、对性能调优，算法效率和分布式计算的资源管理策略有较深的理解；6、熟悉Spring、Spring MVC、ibatis等使用框架，深入原理者优先；7、熟悉ZooKeeper/kafka/Hadoop/HBase/Flume/Redis等平台者优先；8、具备良好的沟通能力和自我学习能力。,"移动互联网,金融",500-2000人,hadoop,北京
Java开发工程师（数据系统方向）,https://www.lagou.com/jobs/4675605.html,西城区,20k-40k,北京多来点信息技术有限公司,3-5年,本科,"带薪年假,年终奖金,五险一金,技术大牛",职责描述：1.    负责 HBI 系统核心代码开发2.    参与系统性能优化的方案设计职位要求：1.    统招本科及以上学历，具备扎实的编程基础和数据结构算法基础，优秀的编程能力和问题解决能力；2.    5年以上互联网行业研发经验，具备业务核心系统或高并发系统项目开发经验； 3.    精通Java及面向对象设计开发，精通java web开发4.    优秀的模块设计、抽象能力，能独立的进行系统设计与思考；5.    有大数据相关的开发经验（加分项）6.    善于交流，具备良好的团队合作精神和协调沟通能力； 7.    自我驱动，善于钻研，勤于思考总结，结果导向。行业标杆，高速成长， 团队活跃，平台广阔，交通便利！前景，专注于本地生活的广泛领域&mdash;&mdash;餐饮O2O；晋升，广阔的职业发展空间，越努力你就越幸运；氛围，那是年轻人的世界，公司营造各种交流机会；环境，舒适高大上的办公环境，西直门地标建筑，没有雾霾还可看见西山落日。哗啦啦（www.hualala.com）期待你的加入！,"移动互联网,消费生活",500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6506282.html,海淀区,15k-30k,北京金堤科技有限公司,3-5年,本科,公司发展好,"我们需要你1.主导数据仓库基础架构的建设，以满足数据仓库对时效性、正确性、可扩展性和易用性的要求；2.通过分析相关系统，梳理潜在的数据源和日志清洗需求，并设计合适的、可扩展的数据模型；3.开发并维护数据流水线，挖掘数据中的有价值信息，发挥大数据价值，帮助各个部门用数据驱动决策。我们希望你1.熟练掌握以下一种或多种语言：Java/Scala/Python；2.计算机等相关专业本科及以上学位；3.熟悉Hadoop生态相关技术，包括Hadoop, Hbase, Spark等；4.熟悉数据仓库建设方法，了解数据仓库层次模型，并有完整的数仓建设经验；5.较好的业务理解能力和数据洞察能力，有用户行为分析经验优先。",数据服务,500-2000人,hadoop,北京
高级数据开发工程师,https://www.lagou.com/jobs/7125894.html,西城区,25k-35k,北京多来点信息技术有限公司,5-10年,本科,带薪年假 专业培训 五险 双休,职位描述1、负责服务运营侧数据开发框架和数据指标研发。2、开发并实现优秀的数据流、数据架构、数据工具/产品，提供高可用的数据产出，发挥数据价值。3、构建满足业务方数据需求的多元化数据服务体系，取数、智能模型、数据产品；4、负责数据开发平台中数据资产管理、数据质量管理、数据模型设计等功能的实现；任职资格：1、计算机或相关专业本科及以上学历，5年以上大数据开发经验，对数据和业务敏感，具备复杂业务需求梳理能力;2、熟练使用java/scala，对jvm，多线程，IO等有深入理解。熟悉Linux/Unix开发环境，具备Shell、Python等脚本开发能力;3、熟悉常用开源分布式系统，熟悉Hadoop/Hive/Spark/ElasticSearch一种或几种;5、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计;6、学习能力强，拥有优秀的逻辑思维能力，工作认真负责，谨慎，敬业，沟通能力好。行业标杆，高速成长， 团队活跃，平台广阔，交通便利！前景，专注于本地生活的广泛领域——餐饮O2O；晋升，广阔的职业发展空间，越努力你就越幸运；氛围，那是年轻人的世界，公司营造各种交流机会；环境，舒适高大上的办公环境，西直门地标建筑，没有雾霾还可看见西山落日。哗啦啦期待你的加入！,"移动互联网,消费生活",500-2000人,hadoop,北京
大数据开发,https://www.lagou.com/jobs/7174025.html,海淀区,15k-30k,北京鼎普科技股份有限公司,3-5年,本科,七险一金、餐补交通补贴、周末双休等,岗位职责：1、负责数据应用产品的研发及架构相关工作。2、和产品经理一起推进项目需求落地，将业务和产品需求转变成为技术实现方案。3、深入理解产品的需求、场景、后续发展方向，参与核心模块代码开发。4、作为关键技术攻坚人员，解决重大项目的技术疑难问题。任职要求：1. 统招一本（或者二本且英语6级）及以上学历，5年以上大数据相关开发设计经验；2. 编程能力扎实，熟悉JAVA/PYTHON/SCALA中至少一种，具有良好的数据结构、算法、操作系统、计算机网络等基本知识；3. 对大数据主流技术如Hadoop、HBase、Phoenix、Kafka、Flink、Spark、Elasticsearch等有深入理解和丰富的使用经验，有平台建设经验优先；4. 有网络安全、数据安全相关产品开发经验优先；5. 学习能力强，善于独立思考，思维活跃，对技术有强烈渴望；6. 较好的沟通和团队配合能力，以及对工作的强烈责任。,"移动互联网,信息安全",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5971895.html,海淀区,25k-40k,北京小米科技有限责任公司,5-10年,本科,发展空间、年终奖金、技术氛围浓厚,职位描述：负责全球新零售数据平台的设计与实现；负责全球新零售2B业务数据平台相关数据的存储、查询、挖掘等的功能开发；任职要求：计算机、数学相关专业本科及以上学历，4年以上互联网研发工作经验具有扎实的计算机科学功底，扎实的编程基础和数据结构算法基础，良好的工程素养，极强的问题解决能力精通Unix/Linux操作系统下Java或Scala开发，有良好的编码习惯，有扎实的计算机理论基础有基于hadoop体系的数据仓库开发经验，了解 Hive，Hbase，Spark等大数据处理工具和技术，有较强的调优能力对数据敏感，有较强的逻辑分析能力，对大数据处理和分析技术有丰富的经验和强烈热情善于交流，有良好的团队合作精神和协调沟通能力,硬件,2000人以上,hadoop,北京
大数据应用系统开发,https://www.lagou.com/jobs/7158525.html,海淀区,20k-40k,北京车之家信息技术有限公司,5-10年,本科,平台大 氛围好 福利优,"岗位职责：1、负责商业数据产品的相关数据指标的抽取、转换、加载，数据维护相关工作；2、负责商业数据产品的后端设计与开发；3、深入理解分析师及业务需求，建设完善的数据体系；为业务方和分析师提供；各种工具化解决方案和数据产品；4、大数据技术难点攻关及新技术调研；任职要求：1、本科及以上学历，两年以上数据开发经验；2、3年以上工作经验，熟悉java开发，计算机相关专业优先；3、熟悉Hadoop/Spark/Storm/Kafka/Hive/HBase等大数据相关技术,具有大数；据处理经验；4、熟悉linux平台，熟悉MySQL、Redis等常用的存储组件；5、熟悉Druid、Kylin、Elasticsearch等引擎系统者优先；6、善于对复杂问题和数据进行抽象，善于通用化的设计功能和解决问题；7、良好的团队意识和较强的抗压能力；",汽车丨出行,2000人以上,hadoop,北京
资深数据开发工程师,https://www.lagou.com/jobs/7215762.html,海淀区,60k-100k,北京氦图科技有限公司,5-10年,本科,硅谷团队 涨薪快,"【职位描述】1. 负责 7.5 亿份简历的存储和更新 (ElasticSearch, Canssandra, Redis)2. 支持 40+ 不同渠道的数据爬取和清洗(Python, Scrapy, Selenium)3. 为100TB+数据建立即时通道和线下通道4. 为产品研发提供数据策略支持5. 进行开源数据，文档及pdf的特征值提取，建立知识图谱及数据标签6. 与AI工程师和机器学习工程师合作，建立最大人才数据库和人工智能模型，实现数据渠道管理的自动化和智能化7. 为产品研发提供量化结果，实现数据驱动下的产品研发智能化 【任职资格】1. 非常熟练使用Python语言。2. 非常熟悉使用Linux的操作系统以及文件系统。3. 非常熟悉数据结构和基本算法，熟练运用队列，搜索策略，负载均衡等手段解决具体问题。4. 有核心产品数据研发工作经验。","企业服务,软件开发",50-150人,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/7215799.html,海淀区,23k-45k,北京氦图科技有限公司,1-3年,不限,硅谷团队 涨薪快,"【职位描述】1. 负责 7.5 亿份简历的存储和更新 (ElasticSearch, Canssandra, Redis)2. 支持 40+ 不同渠道的数据爬取和清洗(Python, Scrapy, Selenium)3. 为100TB+数据建立即时通道和线下通道4. 为产品研发提供数据策略支持5. 进行开源数据，文档及pdf的特征值提取，建立知识图谱及数据标签6. 与AI工程师和机器学习工程师合作，建立最大人才数据库和人工智能模型，实现数据渠道管理的自动化和智能化7. 为产品研发提供量化结果，实现数据驱动下的产品研发智能化 【任职资格】1. 非常熟练使用Python语言。2. 非常熟悉使用Linux的操作系统以及文件系统。3. 非常熟悉数据结构和基本算法，熟练运用队列，搜索策略，负载均衡等手段解决具体问题。4. 非常熟练使用某一种 db: MySQL, Mongodb, Redis, Cassandra。并了解不同数据库的优缺点以及应用场景。5. 对数据处理，特别是文本的处理有经验。6. 加分项：有数据抓取，写爬虫的经历。熟悉框架 例如scrapy, beautiful soup, selenium，会解析html/xpath。7. 加分项：有大数据处理的相关经验。了解bulk operation，multiprocessing programming，map/reduce, spark。8. 加分项: 有elasticsearch使用经历，理解index mapping，熟练运用接口。9. 加分项：有理解以及优化data pipeline/ETL的能力。10. 加分项：能使用Python，Java，Php中某一种语言写接口，为其他团队获取数据提供便利。11. 能够适应英语工作环境","企业服务,软件开发",50-150人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7204348.html,海淀区,10k-20k,杭州安恒信息技术股份有限公司,3-5年,本科,上市公司 五险一金,岗位职责：1、负责各项目海量日志信息收集、分析/查询、分布式存储、的代码实现；2、协助建立并完善数据的分析挖掘流程及体系。任职资格：1. 精通多线程，精通微服务开发，有较强的源码研究理解能力；2、熟练使用Spring Boot、Spring Cloud、MyBatis等常用框架;3、具备一定的数据仓库ETL设计及开发经验，精通数据仓库逻辑架构、元数据管理、数据质量监控等数据仓库主要环节，有BI经验者优先4. 精通Spark、Flink、Hive、Hbase、Storm等大数据平台和开源软件的设计和使用；5、熟练使用HiveQL、SparkSQL6、能够熟练应用一种或多种主流数据库（如：Teradata、Greenplum、Oracle、MySQL等）7、熟练使用一种或多种大数据产品CDH，HDP，以及cloudmanager，ambari；8、有k8s设置及管理开发经验者优先。,"信息安全,数据服务",500-2000人,hadoop,北京
数据开发工程师（技术） (MJ000042),https://www.lagou.com/jobs/6629352.html,朝阳区,15k-30k,上海一起作业信息科技有限公司,3-5年,本科,薪资福利,"职位描述：能够快速理解数据分析和统计的相关需求，且参与平台的报表设计开发工作；负责优化公司相关业务下代码逻辑；负责数据平台下的业务开发设计工作；负责数据平台的功能开发与维护任职资格：1.计算机,数学,统计学等理工背景相关专业毕业,本科及以上学历；2.三年以上数据开发工作经验,掌握数据仓库(DW)/ 商业智能(BI)/ 数据统计理论，并灵活的应用，熟练掌握SQL技能，有较好的SQL性能调优经验，理解Hive/Mysql/Oracle 基本原理和调优策略；3.熟悉使用大数据处理相关技术.对 Hadoop/Spark/HIVE/HBase应用有一定的掌握理解；4.具备linux 下开发经验；5.具备数据仓库集市下数据统计开发经验，对java或者python其中一门精通（优先考虑）；6.具备良好的编码习惯，较好的数据敏感度和数据质量把控意识 7.高度的学习能力及适应力，能够快因工作内容的变化而拥抱变化。","移动互联网,教育",2000人以上,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/6857346.html,朝阳区,25k-40k,珐菲琦(上海)电子商务有限公司,3-5年,本科,"弹性工作,股票期权,精英团队,工作氛围好","About the role:As a Data Engineer, you will have the opportunity to apply your strong technical experience on building data models and ETL processes to provide data for business use and building systems including tracking, attribution, data integration, analytics tools, experimentation platform, etc.You will be partnering with other tech teams, business teams, analytical teams, and data scientists across various initiatives. We hope you are motivated to solve challenging problems and willing to learn new technologies. You are able to take vague requirements and transform them into solid solutions.What you'll do:• Data extraction, preparation, and loading from a variety of sources using technology such as SQL, Hadoop and Spark.• Create and maintain optimal data pipeline architecture for large-scale data processing.• Implement data and analytics tools that will offer deeper insight.• Manage individual projects priorities, deadlines and deliverables with technical expertise.Who you are:• With a BS/MS degree in Computer Science or related.• Experienced with big data (batch or streaming): Hadoop, Spark, Kafka, Flink, etc.• Experienced writing SQL.• Experienced with data warehouse, OLAP or reporting systems.• A developer with strong programming skills in one or more of Java, Scala, Python or Pig.• Experienced with Elasticsearch or other indexing systems.• Experienced in information retrieval, data mining, machine learning.• Experienced in marketing, advertising, recommendation or search.*We do appreciate all applicants, but only selected candidates will be contacted by us. And all information provided will be kept confidential.",电商,150-500人,hadoop,北京
大数据开发工程师（北京）,https://www.lagou.com/jobs/4250492.html,朝阳区,20k-40k,上海倾听信息技术有限公司,3-5年,硕士,弹性工作,工作职责：负责蜻蜓大数据平台的研发，包含数据基础平台的搭建，业务数据ETL处理，批量数据报表，实时数据的开发。工作要求：1、计算机或相关专业；2、3年以上数据平台开发工作；3、熟悉Hadoop、Spark、Storm等大数据平台相关技术；4、熟练使用MapReduce、Hive、HDFS、Hbase、Redis、Kafka；5、精通Java、Python、Scala。,移动互联网,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7147035.html,朝阳区,15k-25k,北京睿至大数据科技有限公司,5-10年,本科,五险一金，弹性工作，带薪年假，节日福利,"岗位职责:1、管理、优化并维护集群,解决各种线上问题;2、参与ETL开发，数仓设计与搭建，平台工具开发、数据治理;3、为海量数据及其上的大规模数据挖掘、数据分析、机器学习业务系统提供可靠、高效的支持；4、研究业界最新的大数据技术，提供有通用性的大数据解决方案；5、乐于挑战技术难点，快速理解业务场景，从具体问题中抽象出通用的解决方案。任职资格:1、计算机或相关专业本科以上，5年以上工作经验，不少于4年大数据开发经验；2、具备扎实的Scala语言编程基础，具备良好的编程习惯，较强独立解决问题的能力；3、精通Spark架构，对社区有贡献者加分;4、熟练掌握hadoop生态的大数据开发工具，包括Flink，Kafka，Hbase，Hive,ES等，拥有海量数据处理经验者优先；5、参与过大型复杂分布式系统的设计、数仓架构者优先；6、熟悉多线程编程和JVM性能调优，有高并发、高吞吐量服务开发经验者优先；7、做事严谨踏实，责任心强，具有良好的沟通能力和团队意识；8、有华为大数据服务平台开发经验者优先；9、思维活跃、理解能力强，具有良好的沟通协作能力者优先；","数据服务,信息安全",150-500人,hadoop,北京
数据仓库开发工程师,https://www.lagou.com/jobs/6291491.html,海淀区,15k-25k,新浪网技术（中国）有限公司,3-5年,本科,技术氛围浓厚、大平台、六险一金,岗位职责：1、负责基于Hadoop平台的海量数据处理、数据计算、数据开发。2、负责数据可视化工具系统的开发，包括报表系统、自助工具系统。3、负责数据仓库的建设，包括业务对接、需求梳理及ETL开发和任务优化。4、负责数据产品和数据项目的相关开发支持。5、负责垂直领域的数据探索，价值数据提取。任职要求： 1、必备技能：JAVA、Hive、MR、spark、shell、awk、perl、Linux下的基本命令；对大数据 处理、数据仓库结构有一定认知； 2、至少精通一种关系型数据库，如MSSQL、MySQL、Oracle等； 3、熟悉互联网环境，了解互联网数据的基本概念； 4、工作态度端正，有较强的责任心及执行力，紧急工作能够快速响应；有较强的抗压 能力，能够适当加班； 5、至少2年实际工作经验，不含实习期。 6、以上要求与实际工作内容紧密相关，为岗位最低要求。,文娱丨内容,2000人以上,hadoop,北京
数据分析（BI开发）,https://www.lagou.com/jobs/6151398.html,朝阳区,20k-40k,上海阅文信息技术有限公司,3-5年,本科,大平台，福利好，领导nice,,文娱丨内容,500-2000人,hadoop,北京
高级大数据开发-学信网可查统招,https://www.lagou.com/jobs/6211736.html,海淀区,22k-32k,北京广通信达软件股份有限公司杭州分公司,5-10年,本科,五险一金季度调薪年终奖团建节日礼品体检,岗位职责：1、基于Java相关技术的软件设计与开发；2、独立进行系统功能模块的分析设计和核心功能的开发；3. 参与大数据存储系统、分布式计算系统、数据集成等的设计、研发、维护、优化工作；4、定期向上级主管汇报工作情况。任职要求：1、统招统考全日制本科及以上学历，计算机相关专业，5年以上大数据相关工作经验；2、熟练的Java编程，熟练使用spring、mybatis等框架；3、熟悉Hadoop系列、Hbase、Sparkstreaming、Kafka等主流大数据处理工具4、熟练使用kafka编程并有相关研发经验；5、熟练简单的Linux shell命令和shell脚本编写；6、熟练掌握ElasticSearch集群的配置优化、运维；负责ElasticSearch上层应用开发；根据产品的特性设计搜索规则，提升搜索效率；对搜索算法进行优化，提高处理的准确性和性能7、有分布式系统、大规模线上系统开发或者大规模数据处理经验；8、有实时数据处理经验，对开源组件源码有研究和了解；,"移动互联网,数据服务",500-2000人,hadoop,北京
中级大数据开发-学信网可查统招,https://www.lagou.com/jobs/6211732.html,海淀区,15k-22k,北京广通信达软件股份有限公司杭州分公司,3-5年,本科,五险一金季度调薪年终奖团建节日礼品体检,职位描述：岗位职责：1、基于Java相关技术的软件设计与开发；2、独立进行系统功能模块的分析设计和核心功能的开发；3、参与大数据存储系统、分布式计算系统、数据集成等的设计、研发、维护、优化工作；4、定期向上级主管汇报工作情况。任职要求：1、熟练的Java编程，熟练使用spring、mybatis等框架；2、熟悉Hadoop系列、Hbase、Sparkstreaming、Kafka等主流大数据处理工具3、可对Elasticsearch进行安装维护，即基本的日志排查、restful api查询，分析；4、熟练使用kafka编程并有相关研发经验；5、熟练简单的Linux shell命令和shell脚本编写；6、统招统考全日制本科及以上学历，计算机相关专业，3年以上大数据相关工作经验；,"移动互联网,数据服务",500-2000人,hadoop,北京
高级数据开发工程师,https://www.lagou.com/jobs/6233394.html,朝阳区,30k-50k,瑞庭网络技术（上海）有限公司,3-5年,本科,有竞争力的薪酬，可爱的同事,工作地：集团总部（base 北京）工作内容/职位描述：1、数据仓库和数据集市建设，数据治理相关工作；2、数据模型设计，指标库的建设；3、数据分析需求设计与开发，产品决策支持；4、参与元数据建设、优化数据开发流程；5、前沿技术调研与引进。任职资格：1、熟悉数据仓库常用的建模思想，对数据处理、数据建模、数据分析等有深刻认识和实战经验；2、熟悉Hadoop生态圈 以及大数据环境的 OLAP 框架；3、对BI系统的建设有深刻的理解；4、熟悉数据仓库、多维分析、即时查询等工具原理与技术架构者优先。,移动互联网,500-2000人,hadoop,北京
高级/资深大数据开发工程师,https://www.lagou.com/jobs/7081281.html,海淀区,20k-35k,北京嘀嘀无限科技发展有限公司,3-5年,本科,上升空间,"岗位职责：1.负责信控产品大数据实时离线计算，数据服务需求开发2.负责多源数据融合平台，数据分析和数据指标体系的开发和建设3.支撑项目中数据端定制化需求开发，如数据接入，多源指标计算开发等4.大数据ETL、计算任务等需求分析、设计、开发、维护，调优任职要求1. 计算机、数学，电子，通信，软件工程等相关专业，扎实的计算机基础知识，3年以上工作经验。2. 熟悉Java，Scala，Python,理解Java集合，IO等基础知识，对JVM原理有一定的了解；可以使用Scala完成Spark/Flink任务开发;日常可以使用Python或者SQL完成数据分析工作。3. 熟悉Kafka，Hive/HiveSQL/Hive UDF，HBase，Spark，Flink，ElasticSearch等，有一定的数据分析能力。4. 有ETL，数据仓库建模实战经验，熟悉数据仓库维度建模理论。有离线大规模数据计算经验，熟悉实时计算框架及理论Flink/JStorm/Spark Structured Streaming等实时计算框架。5. 熟悉Spring/Spring Boot，Mybatis框架，并有实战经验优先。6.     有城市计算相关经验，包括：轨迹数据和地图数据分析经验优先。",汽车丨出行,2000人以上,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/6912637.html,海淀区,10k-20k,中科天玑数据科技股份有限公司,1-3年,大专,科学院孵化 五险一金 福利待遇好,任职要求：1、良好的数据库理论基础，精通SQL及数据库优化2、有mysql、oracle等多种数据开发经验3、 精通ETL开发实施流程及原理，做过相关数据库优化4、精通表空间、索引等优化，精通数据库编程5、有很强的自学和自律能力、有良好的沟通能力6、大专及以上学历，计算机相关专业。7、具有2年以上工作经验 主要负责：1、负责主流数据库平台的高可用性部署、配置管理及性能调优，保障系统健康稳定运行2、负责数据库应用系统的运营及监控，及时对故障进行处理，并分析故障原因3、根据业务需要设计、优化数据库结构4、数据仓库系统的ETL设计开发，与业务系统的接口设计5、参与业务数据的统计分析6、接受外派形式,"移动互联网,数据服务",150-500人,hadoop,北京
数据仓库开发工程师,https://www.lagou.com/jobs/6691003.html,朝阳区,25k-40k,北京小唱科技有限公司,5-10年,本科,年终奖 福利好 弹性工作时间,岗位职责： 1. 关注数据变化，负责数据仓库ETL开发，参与团队ETL流程的优化以及相关技术问题的解决； 2. 理解业务需求，建设面向主题的数据集市，支持公司的BI指标； 3. 参与唱吧实时/离线数据平台相关数据开发和管理工作； 4. 跟进数仓技术的演进，推动相关应用落地。  职位要求 1. 计算机/通信/电子/数学/物理等相关专业本科及以上学历 2. 具备数据仓库理论基础，在数据仓库相关领域有3年以上工作经验，在数据治理方面有一定产品化经历； 3. 熟悉数据仓库模型设计方法论，了解数据仓库数据分层架构，精通3NF和多维数据模型设计; 4. 熟悉仓库建设相关的技术栈，包括且不限于：SQL，Hive，Hadoop/Spark，Flume，Kafka，HBase等，精通HiveSQL优先； 5. 至少掌握一门开发语言，包括且不限于：JAVA、Python、Scala、PHP等，掌握UDF和Map-Reduce开发； 6. 具备数据挖掘和机器学习算法应用经验优先； 7. 具备良好的语言沟通、表达能力和学习能力；,"移动互联网,游戏",150-500人,hadoop,北京
大数据高级开发经理,https://www.lagou.com/jobs/6839935.html,朝阳区,35k-45k,北京拉克沙网络科技有限公司,5-10年,不限,"业务全球化,无限下午茶,扁平化,股权激励","职位职责： 1、负责 HOLLA Group 用户行为的理解和建模，帮助公司各项业务满足用户需求，提升用户覆盖； 2、带领团队搭建数据治理、数据质量和元数据等规范体系，提升数据易用性及数据质量、准确度； 3、优秀的业务理解和抽象能力，发挥数据价值，与业务团队紧密合作； 4、能够根据公司和业务需要，有效规划技术选型和落实、团队建设与维护； 职位要求： 1、精通数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景； 2、拥有扎实的数学基础，具备较强的编码和架构能力，熟悉 SQL, Python, Hive, Spark, Kafka, Flink, Druid 中的多项，有至少 TB 以上级大数据处理经验； 3、对数据敏感，认真细致，善于从数据中发现疑点； 4、有成熟的团队管理和业务分配经验，具备优秀的技术与业务结合能力； 5、加分项：对机器学习有一定了解，有海外项目开发经验；","移动互联网,社交",50-150人,hadoop,北京
高级数据仓库开发工程师,https://www.lagou.com/jobs/7149462.html,朝阳区,30k-55k,北京好赞移动科技有限公司,5-10年,本科,弹性工作 租房 交通 午餐 通讯补贴,岗位职责：1、负责核心数据仓库开发工作（业务梳理、宽表建模、数据治理），实现高质量数据的互通与共享；2、负责商业智能数据报表，参与数据产品与应用的数据研发，发掘数据商业价值。任职要求：1、重点本科或本科以上学历，计算机相关专业，有3年以上的数据开发工作经验；2、扎实的数据仓库理论基础，熟悉数据仓库模型设计，对各建模方法有深入的了解；3、深入理解数据仓库理论、体系架构、数据架构、模型设计、元数据管理及数据质量控制；4、熟悉java/scala/python等一种或多种语言，精通SQL；5、有互联网电商数据仓库经验，熟悉Hadoop生态系统者优先；6、具备较好沟通协调能力，主动建立与业务的紧密合作，推动业务升级。,"移动互联网,社交",150-500人,hadoop,北京
大数据计算与调度平台开发工程师,https://www.lagou.com/jobs/6996549.html,朝阳区,30k-50k,北京自如生活企业管理有限公司,3-5年,本科,1 六险一金 2 建立业界领先大数据平台,岗位职责：1. 负责自如大数据计算与调度平台的运维、开发、监控2. 负责大数据管理平台的运维、开发、监控，包括元数据管理、权限管控、血缘分析等任职要求：1. 本科以上学历，计算机相关专业优先，5年以上⼯作经验2. 精通主流大数据批和流处理技术，如Hive、Spark、Flink、Tez、MapReduce等3. 精通主流大数据管理与调度处理技术，如Ambari、Yarn、Atlas、Ranger、Hue、Airflow、Jenkins等4. 熟悉基于Springboot的Java后端开发5. 扎实的计算机基础和算法数据结构功底，掌握Java或Scala，具备并发编程和JVM调优能力6. 良好的团队沟通协调能力和英文阅读能力加分项：1. 对主流大数据处理组件做过二次开发，参与过某些大数据组件的社区开发，附上Github地址或者Blog地址2. 熟悉k8s,房产家居,2000人以上,hadoop,北京
JAVA开发（大数据）,https://www.lagou.com/jobs/6910986.html,昌平区,15k-20k,泰康在线财产保险股份有限公司,3-5年,本科,七险一金、年终奖、过节福利、定期团建,,"移动互联网,金融",500-2000人,hadoop,北京
高级数据开发/仓库专家,https://www.lagou.com/jobs/7131819.html,朝阳区,35k-60k,北京圣达龙翔科技有限责任公司,5-10年,本科,年底双薪，股票期权，大牛多,岗位职责：1、搭建并优化数据体系，负责数据仓库方向、数据应用方向开发和管理工作；2、带领小伙伴构建金融及其各个业务线（包括但不限于：金融生态、支付平台、保险业务等）数据仓库（分层建设、主题模型、元数据管理、性能和效率优化）；3、参与/负责相关 BI 系统建设及其解决方案落地，规划并带领小伙伴试错、成长；4、负责数据仓库 OLAP 体系搭建，建设 PB 级高效、灵活的在线分析应用；5、受理数据日常需求开发，与分析师、PM、OP 一起感知变化，实现高效的数据运营；6、与团队一起调研和实践热门数据仓库组件和技术（kylin、spark、doris、storm、实时数仓......）。任职要求：1、4 年以上数据仓库(DW) / 商业智能(BI) / 数据统计相关工作经验；2、3 年以上数据团队管理经验优先考虑，有成功的案例和项目管理经验，能规划技术路线；3、有支付、金融、风控等系统数据建设经验优先；4、熟悉数据仓库建设方法论：a：熟悉 etl 分层（ODS、CWD、DWD、AWD）建设方法；b：熟悉主题建设方法，能独立抽象主题、建设模型、物理化并调整效率和性能；c：熟悉常用的 BI 系统建设方法，熟练使用主流 BI 工具，理解其实现原理、使用什么技术解决什么问题；5、熟练掌握 SQL，理解 Hive/MySQL/Oracle 原理和调优方法，有独立处理大规模数据/日志的经历；6、熟练掌握 Java / Python / PHP 中至少一种编程语言。,"硬件,数据服务",150-500人,hadoop,北京
大数据开发工程师（北京） (MJ000346),https://www.lagou.com/jobs/7116707.html,朝阳区,10k-20k,杭州玳数科技有限公司,1-3年,本科,阿里系创业、云计算生态、餐补、双休,1、负责数据整合以及数据模型的建立、维护、优化； 2、负责大数据项目的开发、测试和运维工作； 3、负责数据报表的开发、维护工作；4、项目交付过程中的开发文档编写；5、其它安排的事项。职业要求：1、计算机、软件工程、电子信息相关专业背景，1至3年左右工作经验（优秀的应届生也可考虑）；2、熟悉Oracle/MySQL/SQL Server(至少其中一种)等数据库，掌握SQL语言；3、熟悉Hadoop/Hive/Spark/Flink（至少其中之一）等大数据平台/工具，有Flink开发经验可优先考虑；4、了解常见的数据模型，有较好的开发习惯和编程规范；5、有Java或Python开发经验，会使用常用的开发框架；6、有很强的主动学习能力，理解能力，有大数据项目经验优先；7、较好的沟通能力，做事踏实，服从工作安排，接受出差。,数据服务,150-500人,hadoop,北京
高级数据开发工程师,https://www.lagou.com/jobs/6378332.html,海淀区,20k-30k,北京大生在线科技有限公司,3-5年,本科,超Nice的领导同事,工作职责1. 负责数据仓库架构设计、建模和 ETL 开发，构建可扩展的数据仓库和分析解决方案；2. 面向内部用户的 BI 产品的需求梳理和落地；3. 负责针对用户行为的数据监控和数据仓库建模，支持面向用户的数据应用系统。职位要求1. 本科以上学历；2. 有数据仓库理论和实践经验，熟悉数据仓库相关技术；3. 分布式计算工具（Map/Reduce，Hadoop，Hive等）工作经验优先；4. 有 Java 或 Python 的使用经验；5. 开放的心态，勇于挑战过去的自我；善于思考，有独立分析问题并推动解决问题的能力。,"移动互联网,教育",2000人以上,hadoop,北京
资深数据开发工程师,https://www.lagou.com/jobs/7017249.html,海淀区,30k-50k,贝壳找房（北京）科技有限公司,3-5年,本科,六险一金、16薪、十 天 年假,,房产家居,2000人以上,hadoop,北京
数据BP中心-数据开发,https://www.lagou.com/jobs/6625556.html,朝阳区,25k-40k,北京三快在线科技有限公司,3-5年,本科,大牛云集 核心部门 上市公司,,消费生活,2000人以上,hadoop,北京
数据开发,https://www.lagou.com/jobs/6457587.html,朝阳区,25k-50k,北京三快在线科技有限公司,5-10年,本科,技术氛围好 ；平台大；,职责：1 承担数据BP中心的数仓设计和开发工作2 承担业务方应用层数据的搭建和开发工作3 优化数据模型和ETL性能，参与数据治理，确保数据质量4 业务方数据问题的统一接口人与综合解决方案提供方，对外提供一站式服务5 跨团队沟通、推动数据生产链路上的问题改进1）岗位基本要求：1 具有扎实的计算机专业知识，极强的问题解决能力2 掌握数据仓库的经典建模方法，熟悉不同建模方法的优劣，三年以上的数仓开发经验3 掌握大数据生态技术栈，具备较丰富的Hadoop、Hive、HBase等大数据工具应用和开发经验4 扎实的SQL功底，了解不同框架下SQL执行的原理，有过性能优化的实际经验5 优秀的业务理解能力和良好的沟通协调能力2）具备以下者优先：1 了解或有一定系统开发经验，能够使用java、python等语言进行编程2 有数据敏感度、能够从数据分析的视角看待问题或有一定数据分析经验3 了解或参与过数据挖掘项目,消费生活,2000人以上,hadoop,北京
新闻用户增长数据平台开发工程师,https://www.lagou.com/jobs/6641338.html,海淀区,25k-50k,腾讯科技（深圳）有限公司,3-5年,本科,大厂,岗位职责：1.负责用户增长相关的数据业务平台开发工作，运营管理系统、实验系统等后台开发工作；2.开发，维护数据业务平台相关系统；3.参与新业务核心功能开发。岗位要求：1.3年以上互联网工作经验，有大中型互联网开发经验者优先；2.熟练掌握PHP/Go/Java/Scala 中至少1～2种语言；3.熟练使用 Mysql、Redis等数据库，并有相应的项目开发经验；4.熟悉linux操作系统，了解常用的算法，数据结构；5.有大数据、数据分析、数据模型相关经验者优先,社交,2000人以上,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/6592024.html,海淀区,25k-50k,腾讯科技（深圳）有限公司,3-5年,硕士,大厂,"岗位职责：主要负责腾讯新闻以下数据平台的开发与维护： 基础数据仓库，投放与运营分析平台，BI与报表系统，实时数据监控系统，AB实验平台，用户画像平台。岗位要求：1. 全日制大学计算机相关专业硕士及以上学历，3年以上互联网或大数据相关工作经验； 2. 扎实的计算机基础知识，良好的算法和编程功底，认真细致，对数据敏感，有团队合作精神； 3. 熟悉hadoop生态，熟练掌握hive, spark, kafka，有多维分析工具如druid等应用经验者优先； 4. 熟悉java，熟练使用python, shell等脚本语言，熟悉mysql, redis等DB，有BI系统开发经验者优先； 5. 良好的数学和统计学基础，了解机器学习常用算法，具备特征分析等方面的基础知识，有用户画像开发经验者优先。",社交,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5971487.html,海淀区,30k-60k,北京字节跳动科技有限公司,3-5年,本科,六险一金，弹性工作，免费三餐,,文娱丨内容,2000人以上,hadoop,北京
DMP数据开发工程师-【商业化研发】,https://www.lagou.com/jobs/7184157.html,海淀区,30k-40k,北京达佳互联信息技术有限公司,5-10年,本科,发展前景 福利好 氛围好,"职位描述：1、负责数据管理平台（DMP）技术架构搭建、设计、开发与维护；2、负责广告投放中的用户行为日志采集、大数据建模分析、业务系统数据展示工作；3、为公司运营部门提供数据分析支持。任职要求：1、2年以上大数据相关开发经验；2、了解HDFS, Hbase, Strom, Kafka等原理, 熟练使用 MR/streamming/hive/spark 完成业务问题；3、熟悉Linux下开发, 熟练使用shell/php/golang/python等脚本语言；4、有数据分析相关经验, 了解基本数据分析工具；5、针对业务系统数据需求, 能够设计合理的数据收集, 处理方案。加分项：1、有大规模数据收集,日志处理经验；2、有实时日志数据收集处理经验；3、对关系型数据库, 数据建模有经验；4、了解机器学习算法；5、深入研究过大数据框架的运行机制、实现原理、源码者。",文娱丨内容,2000人以上,hadoop,北京
数据开发工程师-【电商】,https://www.lagou.com/jobs/7199625.html,海淀区,25k-50k,北京达佳互联信息技术有限公司,3-5年,本科,空间大 技术牛 氛围好 福利优,"职位描述：1、负责快手电商数据仓库的建设，构建各垂直应用的数据集市；2、负责快手电商新产品数据统计、报表产出、效果监测、归因分析和商务支持； 3、定义并开发业务核心指标数据，负责垂直业务数据建模；4、根据业务需求，提供大数据计算应用服务，并持续优化改进； 5、参与埋点设计、数据生产全流程等技术体系建设和保障工作； 任职要求：1、本科以上学历，两年以上大数据相关开发经验； 2、熟悉Linux平台，熟练使用Java、Python编程语言，编码基本功扎实；3、有Hive、Kafka、Spark、Flink、HBase等两种以上两年以上使用经验；4、熟悉数据仓库理论方法，并有实际模型设计及ETL开发经验，对于数据的架构和设计有一定的思考，具备良好的数学思维和建模思维； 5、熟悉分布式计算框架，掌握分布式计算的设计与优化能力，对Hadoop生态其他组件有一定了解，比如 HBase，Hadoop, Hive, Druid等6、了解流式计算，熟悉至少一种实时计算引擎：Storm, Spark, Flink；7、有很强的学习、分析和解决问题的能力，良好的团队合作意识，较强的沟通能力。加分项：有电商数据开发经验优先。",文娱丨内容,2000人以上,hadoop,北京
质量数据中台后端开发-新业务,https://www.lagou.com/jobs/7066990.html,海淀区,30k-50k,北京字节跳动科技有限公司,3-5年,本科,"六险一金,弹性工作,免费三餐,租房补贴",,文娱丨内容,2000人以上,hadoop,北京
高级大数据开发工程师(J10330),https://www.lagou.com/jobs/6853231.html,朝阳区,20k-35k,秒针信息技术有限公司,3-5年,本科,"年终奖金,福利多多,氛围轻松,爱心假日",工作职责：1. 负责公司数据存储相关产品的架构设计和系统调优；2. 完善和优化现有存储系统，编写核心系统代码；3. 善于发现系统的性能瓶颈、设计缺陷，提出改进方案并实施；4. 对现有系统进行宏观的思考，规划形成统一的框架、平台或组件；5. 能够与管理团队进行良好的沟通合作，按时保质保量完成开发任务。岗位要求：1. 计算机科学或相关技术学科的学士、硕士学位（或同等学历），扎实的数据结构和算法知识；2. Java相关开发经验2年以上，熟悉并理解缓存、消息、RPC调用框架、jvm 调优、序列化、nio等原理，深刻理解面向对象、设计原则、封装抽象等；3. 精通分布式数据处理底层技术，熟悉常用开源数据库系统，包括但不限于：hbase/elasticsearch/greenplum/kylin/druid.io等，可对其进行二次开发和重新编译；4. 具有强烈的责任心，良好的沟通、学习能力，良好的团队合作意识，勇于接受技术挑战；5. 熟悉go/c/c++语言优先；6. (GitHub上)有自己开源项目优先；7. 性格活泼，对技术充满热情。,"数据服务,广告营销",2000人以上,hadoop,北京
资深大数据开发工程师(J10330),https://www.lagou.com/jobs/7135366.html,朝阳区,25k-35k,秒针信息技术有限公司,5-10年,本科,"年终奖金,福利多多,氛围轻松,爱心假日",,"数据服务,广告营销",2000人以上,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/6227546.html,海淀区,30k-40k,北京小米科技有限责任公司,5-10年,本科,年底双薪、股票期权、弹性工作、扁平管理,岗位描述：1、负责或参与数据统计分析相关平台的设计和研发。2、负责对用户行为、产品和运营方面的数据进行分析和挖掘，为产品优化和业务决策提供数据支持。3、数据ETL、数据仓库模型设计和研发。岗位要求：1、掌握Java和Scala语言之一，熟悉常见数据结构、算法和设计模式。2、熟悉hadoop生态系统内常见项目的使用(如Hadoop，Spark，Hive，Kafka，Hbase等)， 对其架构有一定理解。3、掌握数据仓库、ETL开发相关技术。4、熟悉分布式系统的设计和应用，有实际大数据分析处理项目经验。5、较强的分析解决问题能力，沟通协调及团队精神。6、3年以上工作经验。,硬件,2000人以上,hadoop,北京
资深Java开发工程师（财务/主数据）,https://www.lagou.com/jobs/7025328.html,海淀区,30k-50k,贝壳找房（北京）科技有限公司,3-5年,本科,六险一金、16薪、十 天 年假,,房产家居,2000人以上,hadoop,北京
数据开发工程师(J10017),https://www.lagou.com/jobs/6783536.html,朝阳区,15k-25k,北京创业光荣信息科技有限责任公司,3-5年,本科,领导好 发展空间大 六险一金,"职位描述：工作职责:· 负责鲸准数据仓库设计、建模和ETL开发，构建灵活的数据解决方案；· 与各业务线及数据运营团队沟通需求；· 了解旧数据系统，与团队一起制定迁移方案；· 优化数据平台，构建公司级别的数据服务体系；任职资格:· 2年以上DW/ETL项目经验;· 熟悉大数据技术栈，熟悉hadoop/spark生态圈；· 熟悉Hive等分布式数据库，熟练编写SQL脚本并具备一定的SQL性能调优经验；· 熟练使用Python，Shell，java或其他语言进行过复杂业务逻辑的数据处理工作；· 具备海量数据处理以及性能优化的能力；· 具备大型数据仓库架构设计、模型设计、数据治理、数据资产管理等相关经验者优先；· 优秀的沟通理解能力，能快速理解业务，用数据解读业务· 熟悉阿里云大数据开发服务优先(Maxcompute, DataWorks)· 熟悉用过elasticsearch，neo4j等优先考虑","数据服务,企业服务",150-500人,hadoop,北京
数据库开发（西城区）,https://www.lagou.com/jobs/6911890.html,西城区,9k-18k,广州德惟科技有限公司,1-3年,大专,技术牛人多，年终丰厚，环境舒适，周末双休,"任职要求：
   大专及以上学历，计算机相关专业。
    具有2年以上工作经验
   良好的数据库理论基础，精通SQL及数据库优化
    有mysql、oracle等多种数据开发经验
    精通ETL开发实施流程及原理，做过相关数据库优化
    精通表空间、索引等优化，精通数据库编程
    有很强的自学和自律能力、有良好的沟通能力
  工作职责：
    负责主流数据库平台的高可用性部署、配置管理及性能调优，保障系统健康稳定运行
    负责数据库应用系统的运营及监控，及时对故障进行处理，并分析故障原因
   根据业务需要设计、优化数据库结构
    数据仓库系统的ETL设计开发，与业务系统的接口设计
  参与业务数据的统计分析","金融,移动互联网",150-500人,hadoop,北京
数据开发工程师（数仓方向）,https://www.lagou.com/jobs/6928983.html,东城区,25k-50k,紫梧桐（北京）资产管理有限公司,3-5年,本科,知名平台，上市公司，个人发展空间大,工作职责： 1、蛋壳公寓数据仓库和业务数据集市建设；2、业务模型抽象、数据模型设计开发；3、支持业务的数据需求，跟PM及业务方一起完善业务的数据分析体系和工具；4、ETL、数据应用和服务的设计开发； 5、积累数据生产、分析工具，不断提高数据生产效率； 6、实时数据仓库设计、开发与服务；岗位要求： 1、国家统招本科及以上学历，计算机相关专业背景，4年以上互联网背景数据开发、数据仓库相关从业经验；2、快速的业务学习和理解能力，有良好的自驱能力，对工作充满热情；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，熟悉3NF和多维数据模型设计；4、具备大型数据仓库架构设计、模型设计、ETL设计的相关经验；5、熟悉MySQL、Oracle、Greenplum等主流数据库技术，有较好的SQL能力；6、具备Hadoop、Hive、HBase，Spark等大数据技术背景，并具有开发经验者优先。,消费生活,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7151028.html,海淀区,13k-25k,上海塔罗信息技术有限公司,3-5年,大专,周末双休,职位要求：1、3年以上工作经验，计算机、数学统计学等相关专业；2、SQL基础知识掌握牢固；3、熟悉视频行业大数据产品构建，包括数据采集、数据分析、需求分析和产品交付；4、掌握Hadoop、Flink、Machine learning等相关开发技术，理解Mapreduce模型，对Hadoop、Flink、storm等大规模数据存储运算平台有实践经验，有实时和离线大数据处理开发经验；5、熟悉阿里大数据开发工具优先；6、掌握数据验证、数据清洗和数据治理相关体系；熟悉视频行业应用层数据分析和算法；7、熟悉聚类、分类、回归、图模型等机器学习算法，对常见核心算法有透彻理解；8、有视频行业、播放器播放质量数据分析经验者优先。,数据服务,15-50人,hadoop,北京
大数据平台开发/专家,https://www.lagou.com/jobs/6832962.html,东城区,30k-50k,北京睿企信息科技有限公司,3-5年,本科,五险一金,大数据平台研发工程师/专家/负责人 职位描述：研发高可靠、高可扩展、易用的公司统一的大数据平台．包括大规模工作流调度、异构数据交换和同步、数据服务化、统一指标模型管理和服务等核心大数据平台和工具链的研发和性能优化。任职要求：1.有Hive、Clickhouse、Presto、Impala、Airflow、Kafka、Sqoop、MapReduce、Spark、Flink 等两种以上1年以上使用和优化经验；2.参与或主导过大型数据平台建设项目．对大数据平台有一定的整体感知和把控能力； 3.熟悉分布式基本原理．对高可靠．高并发．高吞吐系统特性有一定理解： 4.精通Java、具备较强的分布式架构和研发实现能力； 5．本科及以上学历，计算机相关专业，三年以上工作经验。 符合以下条件优先： 研究过开源代码并有代码贡献。,"移动互联网,信息安全",50-150人,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/6827999.html,海淀区,19k-25k,北京趣加科技有限公司,1-3年,本科,发展前景好 待遇好 平台大,岗位职责：负责BI的建设以及相关数据模型的设计开发；负责数据采集、清洗、接入工作；开发有效的数据应用工具；任职要求：本科以上学历，计算机相关专业，1到3年相关工作经验，游戏行业优先；熟悉superset可视化报表开发工具；有BI平台的数据模型设计开发经验；熟悉常用的大数据处理和分析平台；良好的学习、沟通、团队协作、分析解决问题的能力，有责任心，和主动性；,游戏,500-2000人,hadoop,北京
数据开发工程师（数据仓库方向）,https://www.lagou.com/jobs/7089283.html,海淀区,20k-40k,北京搜狐新媒体信息技术有限公司,3-5年,本科,大平台、团队优秀、发展空间大,工作职责：1.负责数据接入、清洗、底层重构，业务主题建模工作；2.围绕数据分析搭建完善的数据服务，驱动业务的发展；3.参与工具、平台建设，维护数据仓库的稳定、高效、安全运行。岗位要求：1.统招本科及以上学历，计算机相关专业，至少3年数仓开发经验；2.精通Hive、MySQL，有一定的SQL调优经验，熟悉Hadoop、Spark、Kafka、Storm、Flink等一项或多项大数据处理技术；3.熟悉Java、Python、Scala至少一门开发语言，熟悉Shell、Perl等脚本语言；4.熟悉数据仓库建模理论，有ETL、建模或数据分析相关经验；5.善于沟通，喜欢挑战性的工作，有责任心，有较强的学习能力、执行力和问题解决能力。       加分项：1.有OLAP系统（Greenplum，Druid，Kylin，Kudu，Presto，Impala等）开发和运维经验优先；2.对开源数据类产品有源码级研究优先。,"移动互联网,广告营销",2000人以上,hadoop,北京
大数据平台开发工程师,https://www.lagou.com/jobs/4989370.html,朝阳区,15k-30k,阳光保险集团股份有限公司,5-10年,本科,"五险一金,节日福利,绩效奖金,医疗保险","岗位职责：1、参与数据平台相关业务的设计和大数据平台开发 2、保障和提升数据平台业务支撑能力3、负责相关模块的研发，保证系统性能、稳定和安全4、基于Hadoop生态系统相关开源技术的开发和优化等工作5、完成领导交办的其他工作职位要求：  1. 互联网或金融行业5年以上java/scala项目开发经验，JVM内存模型、对gc性能调优有一定经验  2. 熟悉常用设计模式、IO编程、多线程开发、常用算法、数据结构等，熟悉http/https、tcp/ip等通讯协议  3.  熟悉分布式工作原理，其中3~4年以上大数据平台或项目开发经验。。有金融类项目经验者优先4. 熟练掌握hadoop/zookeeper/kafka/hive/flume/es/spark/spark streaming/flink等大数据生态圈开源技术5. 熟练掌握mysql或oracle, 至少掌握以下主流nosql中的1种:　redis/mongodb/hbase 6.  有Linux下开发、部署和调试能力。熟练掌握常用Linux命令，具备shell编程能力 7.  熟练掌握git/svn 版本管理工具, maven构建工具。Eclipse、IDEA等开发工具8.  有较强的责任心和良好的沟通能力，有独立解决问题的能力和排查分析定位问题的能力9.  关注大数据生态圈和开源论坛社区，有开源代码贡献者优先岗位任职条件：1、学历与专业：计算机相关专业2、年龄与性别：35以内3、工作经验：5年以上java/scala等项目开发经验，其中需包含3~4年以上大数据4、行业背景：互联网、金融、IT等5、计算机使用技能：java hadoop spark Kafka es等6、素质能力及性格特征：有团队意识 积极主动 热爱钻研技术7、其他：英语良好",金融,2000人以上,hadoop,北京
数据平台开发工程师,https://www.lagou.com/jobs/7134274.html,海淀区,18k-26k,北京环球兴学科技发展有限公司,3-5年,本科,五险一金、平台大、行业前景好,岗位职责：1. 负责大数据平台的搭建、完成数据平台各功能组件设计和开发工作，解决数据平台搭建过程中遇到的技术难题。2. 负责数据采集、处理、存储、应用过程中技术方案的选型和实施。3. 负责数据产品相关的开发工作。4. 对大数据平台相关组件的进行持续运维和优化。任职要求：1 熟练掌握Java语言，具备扎实的程序设计基本功及编码能力。2. 有过Web项目的开发经验，熟悉Spring、 mybatis等框架。3. 具备大数据平台的开发经验，熟悉至少一种大数据相关组件，例如Hadoop、Spark、Flink、Hbase、Clickhouse、Druid、Kafka等。4. 熟悉Linux环境，具备在linux下定位、调试、优化平台组件运行过程中遇到的问题的能力5. 主动性强，具有良好的沟通、协调能力6. 具备良好的文档编写能力，能够准确理解业务需求，并转化成系统设计文档。,"移动互联网,教育",500-2000人,hadoop,北京
高级数据开发工程师,https://www.lagou.com/jobs/7216540.html,昌平区,20k-38k,北京世纪好未来教育科技有限公司,3-5年,本科,大平台、好福利、大牛云集,"岗位职责：1.负责AB测平台、埋点平台等研发工作；2.负责数据清洗、数据模型开发、查询引擎优化工作。任职要求：1.熟练掌握JAVA开发，熟悉掌握分布式应用开发原理，熟练掌握设计模式；2.熟悉jvm，有线上调优经验；3.熟悉常用的大数据分析框架，如hive、spark、flink、Impala等，并熟悉运行原理,有源码改造经验优先；4.熟悉列式存储，精通presto、clickhouse、有源码开发经验优先；5.良好的计算机编程素养；6统招本科学历，三年以上相关工作经验。",教育,2000人以上,hadoop,北京
大数据开发高级工程师（后台序列),https://www.lagou.com/jobs/6997456.html,朝阳区,20k-35k,北京三快在线科技有限公司,3-5年,本科,核心业务,,消费生活,2000人以上,hadoop,北京
大数据开发工程师-无人车配送中心,https://www.lagou.com/jobs/6940204.html,朝阳区,25k-40k,北京三快在线科技有限公司,3-5年,本科,五险一金，大厂经验,,消费生活,2000人以上,hadoop,北京
腾讯广告大数据开发工程师（北京）,https://www.lagou.com/jobs/6494021.html,海淀区,25k-35k,腾讯科技（深圳）有限公司,3-5年,本科,大平台；发展前景；福利待遇,岗位职责：1、负责广告在线预估服务的架构设计和开发，支持高并发，高可用，低延迟； 2、负责广告平台用户画像线上系统的开发和维护； 3、负责高可用的任务调度系统开发，支持各种离线任务的分发和调度。岗位要求：1、大学本科以上学历，计算机相关专业； 2、两年以上相关工作经验，精通算法与数据结构，精通c++编程语言； 3、有扎实的编程功底和编码习惯，以及良好的分析解决问题能力； 4、熟悉机器学习框架和分布式系统，熟悉tensorflow等机器学习框架者优先； 5、积极主动，有责任心，勇于接受挑战。,社交,2000人以上,hadoop,北京
腾讯云大数据开发平台研发工程师,https://www.lagou.com/jobs/6531939.html,海淀区,30k-60k,腾讯科技（深圳）有限公司,5-10年,本科,平台,"岗位职责1.负责调研并设计大数据开发平台的系统架构，并能持续优化，保障系统稳定性；2.负责与客户进行持续需求沟通，通过完善产品功能服务好企业客户；3.通过梳理和抽象，沉淀通用性的平台或服务能力。岗位要求1 计算机、通信等相关专业，本科及以上学历，3年以上大型互联网产品或分布式系统开发设计经验；2 扎实的java技术基础，对linux，分布式系统，高并发等技术经验丰富；3 对hadoop生态相关组件如spark, airflow等精通；4 有企业级大数据开发平台研发经验，对云厂商大数据开发平台如dataworks等架构熟悉者优先；",社交,2000人以上,hadoop,北京
流媒体大数据开发工程师,https://www.lagou.com/jobs/7203152.html,海淀区,20k-40k,北京达佳互联信息技术有限公司,3-5年,本科,待遇好，前景广阔，团队nice,岗位职责：1、 建设流媒体实时OLAP分析平台，提供监测和持续优化能力，不断优化快手直播、点播视频播放体验；2.通过数据分析指导工程化落地方案的实施，包括海量实时数据处理、边缘计算等等，实现精细化流量调度策略，不断推进质量优化，节省流量和资源成本。任职资格： 1、精通Java/C++，具备较强的分布式架构和研发实现能力； 2、有Kafka、Rocketmq、Storm、Spark Streaming、Flink等流式处理相关开源系统使用经验，有Flink海量数据处理经验者优先； 3、熟悉基本的分布式计算原理，对高可靠，高并发，高吞吐系统特性有一定理解； 4、了解大数据处理的Lambda架构，了解流媒体相关协议，有互联网络拓扑优化经验者优先； 5、有责任心，乐于挑战，沟通能力强。,文娱丨内容,2000人以上,hadoop,北京
数据开发Leader,https://www.lagou.com/jobs/7036816.html,海淀区,35k-55k,北京字节跳动科技有限公司,不限,本科,"六险一金,带薪休假,免费三餐,弹性工作",,文娱丨内容,2000人以上,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/6988031.html,海淀区,25k-50k,北京字节跳动科技有限公司,3-5年,本科,"弹性工作,免费三餐,租房补贴,带薪休假",,文娱丨内容,2000人以上,hadoop,北京
数据开发工程师-【电商生态】,https://www.lagou.com/jobs/7214658.html,海淀区,30k-60k,北京达佳互联信息技术有限公司,不限,本科,"空间大,待遇优,大牛多,氛围好",,文娱丨内容,2000人以上,hadoop,北京
高级数据开发工程师-小米视频,https://www.lagou.com/jobs/6718085.html,海淀区,21k-40k,北京小米科技有限责任公司,3-5年,本科,六险一金 年底奖金 弹性工作双休,岗位职责1.负责小米视频业务中台数据平台的设计与实现；2.负责小米视频业务中台数据平台相关数据的存储、查询、挖掘等的功能开发； 任职要求1.计算机、数学相关专业本科及以上学历，4年以上互联网研发工作经验；2.具有扎实的计算机科学功底，扎实的编程基础和数据结构算法基础，良好的工程素养，极强的问题解决能力；3.精通Unix/Linux操作系统下Java或Scala开发，有良好的编码习惯，有扎实的计算机理论基础；4.有基于hadoop体系的数据仓库开发经验，了解 Hive，Hbase，Spark等大数据处理工具和技术，有较强的调优能力；5.对数据敏感，有较强的逻辑分析能力，对大数据处理和分析技术有丰富的经验和强烈热情；6.善于交流，有良好的团队合作精神和协调沟通能力。,硬件,2000人以上,hadoop,北京
数据应用开发工程师,https://www.lagou.com/jobs/5907294.html,朝阳区,15k-20k,狮桥融资租赁（中国）有限公司,3-5年,本科,"绩效奖金,节日福利,团队建设,生活补贴",【岗位职责】 1. 负责所属模块的代码开发、调试与维护工作；2. 参与公司数据中台功能规划、需求分析设计、技术实现；3. 参与公司平台的架构优化，性能优化并辅助其他模块进行技术实现；4. 快速响应产品需求并进行开发和交付；5. 协助并完成其他各类技术开发任务。【任职要求】1. 必须具备条件：SpringBoot两年或以上，Java基础扎实；熟悉Neo4j优先，有GPS相关项目优先。2. 3年以上的Java开发及应用经验；了解J2EE规范和常用的设计模式，熟练掌握Web的开发和应用；3. 熟练掌握目前主流的开源框架（Spring／SpringBoot／MyBatis/SpringCloud/Dubbo等），并对其核心思想和实现原理有一定的了解；熟悉SpringCloud优先；4. 熟悉微服务架构思想，并有相关项目经验；5. 熟练掌握MySql、Oracle关系型数据库，具备一定的SQL编写能力；了解、熟悉Hive、Hbase优先；6. 熟悉Linux操作系统，掌握常用的Linux命令；7. 如果你有产品意识、善于沟通、积极主动、有良好的快速学习能力和团队协作能力；能够以目标为导向理解工作中相关任务的处理优先级关系。我们更加欢迎。【还有……】1. 你将全程参与、开发、实施公司数据中台的搭建从0到1，并持续优化的过程；2. 你将有机会将好的技术实施在生产环境;CICD、Docker、K8S、Neo4j，你敢想并且评审可实施我们就敢干；3. 你将有机会学习 Hadoop 生态圈、图数据库（Neo4j）技术，并实施到生产。,"金融,物流丨运输",2000人以上,hadoop,北京
商业化-数据开发Leader,https://www.lagou.com/jobs/5763319.html,朝阳区,30k-60k,行吟信息科技（上海）有限公司,3-5年,本科,良好的发展前景,工作职责：1、负责广告产品核心业务模块数据仓库的构建；2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；任职要求：1、计算机、数学相关专业，本科及以上学历，三年以上大数据开发工作经验，数据挖掘和BI分析领域优先；2、熟练掌握Hive/SQL，熟悉Spark/Map-Reduce/MPI分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；3、有产品sense，主动思考基于业务场景下的数据体系建设，而不单单只会做执行；4、工作认真，负责，良好的团队合作精神和解决问题分析能力，钻研技术克服困难，勇于挑战；5、有数据分析经验优先。,消费生活,500-2000人,hadoop,北京
大数据开发工程师 （数据分析方向）(J10262),https://www.lagou.com/jobs/6892635.html,朝阳区,15k-25k,包头市包银消费金融股份有限公司,3-5年,本科,六险一金；节日福利；年终奖,,金融,150-500人,hadoop,北京
数据开发工程师(J10363),https://www.lagou.com/jobs/6785316.html,海淀区,20k-40k,北京读我科技有限公司,3-5年,本科,业务发展清晰、车补房补、地铁周边、年终奖,,移动互联网,500-2000人,hadoop,北京
EI数据中心java开发工程师,https://www.lagou.com/jobs/6766429.html,朝阳区,15k-30k,北京区块节点科技有限公司,3-5年,本科,上市企业平台，接受应届生、实习生,岗位职责（接受应届生、实习生）1、基于产品、项目需求，完成模块开发、单元测试工作2、协助工程实施人员做好项目的后期维护工作任职要求1、统招本科以上学历，计算机、数学相关专业，1-3年实际Java开发经验；2、JAVA基础扎实，对JVM原理有一定的了解；3、掌握常用的数据结构和基本算法，面向对象的思想和设计模式；4、熟练使用SpringBoot、SpringMVC、MyBatis、JPA等开源框架，了解原理和机制；5、熟悉mysql/Oracle 数据库，并有一定的SQL优化经验；6、有hadoop、spark使用经验；8、工作习惯良好，自驱动，擅于合作，代码清晰整洁,移动互联网,50-150人,hadoop,北京
C/C++开发工程师（数据库内核）,https://www.lagou.com/jobs/3369758.html,朝阳区,20k-36k,北京人大金仓信息技术股份有限公司,5-10年,本科,"国有企业,六险一金,发展好,团队好",1、作为数据库内核研发团队成员，参与或主导数据库内核相关领域的新技术探索，含算法、分布式架构等；2、参与或主导某类数据库领域的客户场景分析、需求定义、架构设计和特性交付；3、进行相关部分或全部算法设计、数据库系统方案设计以及软件架构设计；4、独立或协同负责内核或数据库工具特性的研发。任职要求：1、本科及以上学历，5年以上工作经验；2、熟练掌握Linux环境下C/C++编程，熟悉进程间通信、内存管理、网络通信等相关知识；3、熟悉数据库理论基础和主要算法，并且具有数据库内核相关开发经验者优先；4、熟悉Oracle、DB2、SQL Server、Sybase、Greenplum、MySQL、PostgreSQL等主流数据库架构中一种或多种者优先；5、熟悉数据库查询引擎（如查询代价估算算法，分布式查询计划产生算法等）、缓存管理、并行处理、I/O 访问相关知识，并有实践经验者优先；6、 有广阔的技术视野，优秀的团队合作能力和沟通能力。7、 喜钻研，有很强的学习能力和分享精神。,数据服务,150-500人,hadoop,北京
中级数据库内核开发工程师,https://www.lagou.com/jobs/3394664.html,朝阳区,18k-35k,北京人大金仓信息技术股份有限公司,3-5年,本科,"六险一金,带薪年假,国有企业,团队氛围好",职位描述：1、负责数据库产品内核的需求分析、系统设计、编码、单元测试、BUG修改等研发工作；2、负责为技术支持人员提供答疑和研发级的技术支持；3、负责配合产品经理，进行竞品的功能、实现分析；职位要求：1、计算机相关专业，本科及以上学历，3年以上研发经验; 2、熟悉掌握linux下C/C++编程，熟悉进程间通信，内存管理，网络通信等3、算法能力强，能够设计合理的算法对程序进行优化；4、熟悉研发项目过程，具有基本的项目管理能力；5、良好的沟通能力和技巧，和良好的文档编写能力；6、有数据库、操作系统基础软件开发经验者优先；7、对工作充满热情，责任心强，能够承受压力；有良好的团队协作意识和能力。,数据服务,150-500人,hadoop,北京
研究开发所-大数据研发岗,https://www.lagou.com/jobs/6102352.html,海淀区,13k-26k,中国移动通信集团设计院有限公司黑龙江分公司,不限,硕士,服务待遇完善,学历要求：硕士及以上毕业院校要求 ： 211学校专业要求(含研究方向)：计算机、通信工程或相关专业其他需求条件：1、掌握 Java、Hadoop、Hive、HBase、Zookeeper、Spark、Storm 的安装配置，具有 MapReduce 开发经验，有实际大数据项目经验者优先选择。2、掌握 hadoop 生态系统内常见项目（hdfs、hive、hbase、spark、zookeeper、yarn），有系统架构、核心算法与开发测试者优先选择。3、掌握Linux/Unix 系统环境下的操作；4、掌握Tomcat 等应用服务器的配置和优化。5、掌握Oracle、MySql 等主流数据库。6、具有较强的学习能力，具有一定的英语阅读能力，能积极主动跟踪与研究业界主流技术和热点问题；7、具有良好的沟通和团队协作能力及解决问题的能力，良好的职业道德及敬业精神，具有责任心，踏实稳重，吃苦耐劳；,通讯电子,2000人以上,hadoop,北京
中高级大数据开发工程师,https://www.lagou.com/jobs/7217699.html,海淀区,15k-25k,神州数码（中国）有限公司,5-10年,本科,发展空间大 七险一金,工作职责负责构建信创生态的核心软件能力，研发面向信创领域的创新应用软件产品的大数据方向软件开发任职要求1、本科以上学历2、5年以上开发经验，3年以上大数据软件开发经验，熟练掌握java或python等大数据产品开发语言中的一种，熟悉hadoop、spark、storm、elasticSearch等框架组件3. 有大数据领域的应用规划，设计和开发经历者优先考虑4. 有良好的沟通能力，有较强的独立工作能力和解决问题的能力，工作认真负责，积极主动，能够承担工作压力,"硬件,数据服务",2000人以上,hadoop,北京
数据库内核高级开发工程师(存储引擎),https://www.lagou.com/jobs/6493073.html,海淀区,25k-50k,北京聚云位智信息科技有限公司,3-5年,本科,不打卡、周末双休、领导nice、带薪年假,岗位职责：负责分布式数据库存储引擎的设计，开发和性能优化。 任职要求：1. 精通C/C++，具备问题分析， 概念抽象和设计，以及工程编码的能力；2. 熟悉数据库查询引擎与存储引擎工作原理，熟悉至少一种列式存储引擎的设计和实现；3. 优秀的发现和解决问题能力，良好的沟通能力；4. 有数据库系统底层开发经验，熟悉LevelDB/RocksDB的优先。,数据服务,50-150人,hadoop,北京
大数据高级开发工程师,https://www.lagou.com/jobs/7013578.html,朝阳区,25k-50k,北京孔网时代科技有限公司,5-10年,本科,团队靠谱 餐饮免费、人性化工作、水果,职位描述：1、负责大数据平台的开发，完成关键数据报告；2、基于产品与业务需求，在产品端设计埋点方案、推动技术开发上线；3、理解产品业务逻辑，利用数据分析手段，发现产品体验问题并推动改进；4、负责建立用户画像及用户分层的数据。任职资格：1、计算机、数学、统计等专业，5年以上大数据相关工作经验；2、良好的Java基础，熟悉JVM原理，熟悉java主流框架，如：Spring，Spring mvc，mybatis等；3、熟悉并使用过各种大数据相关技术，如elk、Hadoop、Spark、Hive等；4、熟悉并使用过mysql等关系型数据库进行数据开发；5、熟悉埋点、插码、数据采集等工作；6、有从0到1的构建数据平台经验者优先；7、有互联网电商领域数据工作经验，熟悉电商业务者优先。,电商,50-150人,hadoop,北京
大数据开发工程师-ETL,https://www.lagou.com/jobs/7089193.html,西城区,20k-30k,上海任意门科技有限公司,3-5年,本科,"高薪资,上升空间,扁平管理,期权股权",岗位职责： 1、负责soul推荐算法的数据体系的建设，通过数据+工程化能力，处理和萃取数据，满足算法生产和产品分析； 2、参与算法阶段的数仓的基础架构和技术体系的规划建设，包括且不限于流式日志、特征工程、数据报表、数 据监控等。 3、为产出的数据准确性负责，参与数据管控和数据治理； 岗位要求： 1、3年以上ETL开发经验； 2、熟悉数据仓库架构，熟悉数据建模理论和方法，并具有1年以上数据仓库/数据集市建设经验； 3、掌握基于Hadoop、Hive、Spark等大数据组件的ETL开发方法； 4、具有娴熟的沟通技巧，执行力强，具有优秀的团队合作精神、敬业精神； 加分项： 熟悉推荐流程及基本推荐算法，有特征工程或模型训练日志相关经验；,"社交,文娱丨内容",150-500人,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/7044243.html,朝阳区,15k-30k,贝天姆网络科技（杭州）有限公司,3-5年,本科,发展前景 大牛团队 福利待遇,职责描述：1. 参与数据仓库架构设计与数据开发2. 负责数据平台相关数据管理工作，如研发规范、质量规范、保障规范的制定与推动实施落地3. 负责来自业务团队数据需求的研发支撑任职要求：1. 从事数据仓库领域工作至少3年以上，熟悉数据仓库模型设计方法论，并有实际模型设计及ETL开发经验2. 掌握大型数据库开发技术，必须熟练掌握Mysql，灵活运用SQL实现海量数据ETL加工处理，熟悉MongoDB者优先3. 至少掌握一门编程语言，如Java、Python、Perl、shell等4. 熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、性能调优等5. 有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先6. 良好的语言沟通与表达能力和自我驱动动力，英文能作为工作语言者优先。,"电商,移动互联网",2000人以上,hadoop,北京
大数据高级开发工程师,https://www.lagou.com/jobs/6785774.html,东城区,20k-30k,北京酷云互动科技有限公司,5-10年,本科,福利好 领导棒 周末双休 六险一金,工作职责：                        1. 根据业务项目需求，参与大数据项目的设计开发工作2. 开发维护数据仓库，保证数据的准确性、可靠性3. 保证大数据相关服务的稳定性、高可用性，不断优化服务性能                                                         任职资格的具体描述：                                                1、5年以上工作经验，3年以上大数据相关经验，参与过多个大数据项目的开发，熟练掌握java、scala编程语言。                        2、熟练使用Spark、Hadoop、Hbase、Hive，具有数据仓库相关经验者优先。 3、熟悉Zookeeper、Redis、Kafka、elasticsearch、Flink等大数据组件，有相关的使用经验。   4、熟悉Spring开发，有SpringBoot使用经验者优先。             5、熟练使用Linux系统，熟悉python语言者优先。                        6、具有较强的沟通能力，工作协作能力，学习能力，执行力，组织能力。                                         7、工作态度积极主动、细致、有全局观，有一定的抗压能力，善于与他人合作，良好的团队合作意识。,"数据服务,广告营销",150-500人,hadoop,北京
数据平台开发工程师 (MJ000700),https://www.lagou.com/jobs/6974404.html,海淀区,30k-60k,北京智者天下科技有限公司,3-5年,本科,带薪年假 补充医疗 弹性办公,"负责公司大数据平台建设，设计有层次、灵活可扩展的平台架构
 负责数据可视化平台的设计与优化，满足灵活的多维分析需求和稳定的报表需求
 搭建公司统一的数据服务层，高效开放数仓生产的数据
 设计和搭建公司通用数据集成服务建设，负责数据的落地和交换
职位要求
 有数据服务或者数据集成经验者优先
 精通 Java 语言，熟悉 Java Web 开发框架
 有至少 TB 以上级大数据处理经验，支撑过实际业务场景
 编码能力强悍，熟悉 Flume，Spark，Kylin，Druid，Storm，Flink 等应用开发经验优先
 善于沟通，具备优秀的产品嗅觉，优秀的技术与业务结合能力
 3年以上相关工作经验",社交,500-2000人,hadoop,北京
中级大数据开发工程师,https://www.lagou.com/jobs/6850958.html,朝阳区,17k-22k,北京亿和博嘉教育科技有限公司,3-5年,本科,互联网医疗行业 节日福利 有挑战,岗位职责：1、参与大数据平台的通用功能设计和开发、单元测试、文档编写等工作；2、负责大数据平台的数据整合、数据挖掘、画像推荐等方面的技术研究工作；3、使用SparkML、TensorFlow等常用机器学习库，实现并调优常用的机器学习算法；任职要求：1、精通Java或scala语言；2、本科以上学历，计算机、应用数学、统计学相关专业;3、熟悉大数据技术包括Hadoop、Spark、Flink、Kafka、Hive、ElasticSearch、HBase、kylin、Zookeeper等，并具备2年以上实际的大数据开发经验，对分布式数据处理和数据存储设计有很强的理解和优化能力，具备实时流数据处理的项目经验；4. 熟悉常用机器学习算法，包括但不限于决策树，线性回归，聚类，支持向量机，关联规则，线性规划等；5. 熟悉深度学习领域的基础理论，熟悉TensorFlow常用的神经网络模型如：DNN、CNN、LSTM等；6、熟悉Linux操作系统，熟练使用Shell或Python完成相关工作；7、优秀的分析问题和解决问题的能力，对解决具有挑战性的问题充满激情，良好的沟通能力和团队合作能力；,"教育,医疗丨健康",50-150人,hadoop,北京
python数据开发工程师,https://www.lagou.com/jobs/6836537.html,海淀区,15k-25k,北京能量盒科技有限公司上海分公司,1-3年,本科,福利待遇、扁平管理，无打卡制，加班补助,岗位职责：负责BI的建设以及相关数据模型的设计开发；负责数据采集、清洗、接入工作；开发有效的数据应用工具；任职要求：本科以上学历，计算机相关专业，1到3年相关工作经验，游戏行业优先；熟悉superset可视化报表开发工具；有BI平台的数据模型设计开发经验；熟悉常用的大数据处理和分析平台；良好的学习、沟通、团队协作、分析解决问题的能力，有责任心，和主动性；,游戏,500-2000人,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/6288114.html,朝阳区,17k-30k,北京心更远科技发展有限公司,3-5年,本科,七险一金,职位描述：工作内容： 1.为业务部门、运营部门提供数据处理支持 ；2.Review及评估数据库表设计的合理性 ；3.负责公司的数据清洗、加工、处理入库等工作 ；4.大数据系统建设及开发 。岗位要求： 1.计算机，数学、统计学等专业，本科及以上学历，数据相关工作经验3年以上； 2.熟练使用mysql数据库，精通SQL语句，有丰富的ETL经验；能够快速根据数据的状况决定采用技术、保证数据入库的正确性 3.熟悉shell及python脚本语言，能够快速高效的使用脚本完成简单的数据处理任务； 4.熟悉java开发语言，能够基于java完成map/reduce等功能开发 5.对常用机器学习算法熟悉，能够基于场景完成相应相应算法的开发和实现 6.对数据敏感，能够从数据中寻找到规律，同时能够保障数据输出的正确性和完备性 7.具备大数据处理经验、自然语言处理、机器学习等背景者优先；,"移动互联网,教育",2000人以上,hadoop,北京
Java数据开发实习生,https://www.lagou.com/jobs/3414613.html,朝阳区,3k-5k,北京豆果信息技术有限公司,不限,本科,"专业培训,完善福利,良好氛围,快速成长","岗位职责：1. 负责豆果网数据统计系统的开发。2. 负责公司各部门对电商&网站相关数据的统计。任职要求：1. 有数据展示系统及服务器端系统开发经验者优先。2. 熟悉常用设计模式，对代码的美观和优化有想法和追求。3. Java功底扎实，熟悉JavaEE架构，练掌握Struts，Hibernate，Spring等常用开发框架。4. 熟悉Linux操作系统及常用Shell命令。5. 熟练掌握SQL,有使用过Mysql等数据库的经验，懂得常用的SQL语句优化方法者优先。6. 熟悉hadoop、hive、sqoop等开源系统。综合素质：1. 具有开放的心态，具备快速接受新技术和新知识的能力，对前沿技术有浓厚的兴趣。2. 具有较强的独立工作能力、工作积极主动和富有团队协作精神。3. 具有优秀的自我管理、自我学习能力、富有创造力。","移动互联网,社交",50-150人,hadoop,北京
Java开发工程师/专家(数据平台）,https://www.lagou.com/jobs/6791852.html,朝阳区,25k-40k,北京三快在线科技有限公司,不限,本科,技术前沿，大落地场景，复杂业务逻辑,,消费生活,2000人以上,hadoop,北京
机火研发-数据开发工程师,https://www.lagou.com/jobs/6854845.html,朝阳区,20k-40k,北京三快在线科技有限公司,不限,本科,团队牛人多，晋升空间大,,消费生活,2000人以上,hadoop,北京
云大数据开发平台研发工程师（北京）,https://www.lagou.com/jobs/6434282.html,海淀区,30k-60k,腾讯科技（深圳）有限公司,5-10年,本科,发展机会大、待遇优、团队优秀,"岗位职责1.负责调研并设计大数据开发平台的系统架构，并能持续优化，保障系统稳定性；2.负责与客户进行持续需求沟通，通过完善产品功能服务好企业客户；2.通过梳理和抽象，沉淀通用性的平台或服务能力。岗位要求1 计算机、通信等相关专业，本科及以上学历，3年以上大型互联网产品或分布式系统开发设计经验；2 扎实的java技术基础，对linux，分布式系统，高并发等技术经验丰富；3 对hadoop生态相关组件如spark, airflow等精通；4 有企业级大数据开发平台研发经验，对云厂商大数据开发平台如dataworks等架构熟悉者优先；",社交,2000人以上,hadoop,北京
大数据开发实习生-智能营销方向,https://www.lagou.com/jobs/6951693.html,海淀区,8k-10k,北京字节跳动科技有限公司,不限,本科,"弹性工作,免费三餐,租房补贴",,文娱丨内容,2000人以上,hadoop,北京
高级测试开发工程师-大数据方向,https://www.lagou.com/jobs/5811836.html,海淀区,20k-40k,北京字节跳动科技有限公司,3-5年,本科,六险一金，弹性工作，免费三餐，租房补贴,,文娱丨内容,2000人以上,hadoop,北京
数据开发实习生,https://www.lagou.com/jobs/6978586.html,朝阳区,4k-8k,北京思维造物信息科技有限公司,应届毕业生,本科,"弹性工作,氛围轻松,学习机会多",职位职责：1.参与得到大数据平台建设，参与海量数据的离线和实时计算工程开发；2.支撑数据产品研发，提升数据产品性能和稳定性。职位要求：1.具备大数据思想，希望在大数据领域深入发展；2.了解业界主流的大数据生态组件和解决方案，至少熟悉三个以上技术点，如 HDFS，MapReduce，Spark，ES，Flink等；3.具有扎实的Java基础，掌握J2EE体系结构；4.熟练使用SpringBoot，对设计模式有深入理解为加分项；5.热爱技术，思维清晰，性格open，自我驱动；6.本科及以上学历，计算机相关专业，可确保每周最低4天到岗，2021年毕业生优先。,"移动互联网,文娱丨内容",150-500人,hadoop,北京
大数据开发工程师-商业数据,https://www.lagou.com/jobs/7051371.html,海淀区,30k-60k,北京小米科技有限责任公司,5-10年,本科,业务空间大 海量数据 集团战略,"岗位职责：1、 负责整个公司的数据收集、清洗工作，进行相关数据产品的开发工作；2、 建设、完善公司级用户画像,建设数据质量体系；3、 利用技术手段赋能新零售、广告、金融、小爱同学、手机等业务。任职要求：1、 精通至少一门编程语言(Java/Scala/Python/C/C++)，透彻理解常见的核心算法；2、 熟练掌握概率统计、数据挖掘、机器学习相关理论知识；3、 对Hadoop、Spark等工具拥有实践经验；4、 大数据新技术探索,技术攻坚。",硬件,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7138315.html,海淀区,12k-20k,浙江邦盛科技有限公司,3-5年,本科,年底双薪 绩效奖金 管理规范 五险一金,"岗位职责：1、负责项目实施过程中的数据源分析、需求分析工作。2、独立完成项目中数据模型设计、数据开发、调度工作。3、负责数据仓库ETL流程的优化及解决ETL相关技术问题。4、配合完成项目测试工作，负责所开发内容的高质量交付。5、对数据仓库的日常监控，确保整个数据流程数据的完整性、一致性以及准确性。6、参与大数据平台系统建设和调优。任职资格：1、两年及以上大型数据库或数据仓库系统的设计和开发经验。2、熟悉Hive、MySql、Oracle数据库, 熟练掌握SQL,PL/SQL, SQL优化。3、熟悉Linux/Uinx，熟练掌握Shell、JAVA、SCALA等其中一门语言。4、熟悉大数据生态圈相关技术，有2年以上Hadoop和Spark相关开发和调优经验。5、具有数据分析相关工作经历优先。6、工作积极主动、责任心强，具有良好的沟通表达能力和敬业精神。",信息安全,150-500人,hadoop,北京
资深软件开发工程师（引擎数据 Go）,https://www.lagou.com/jobs/7115098.html,海淀区,30k-60k,北京嘀嘀无限科技发展有限公司,5-10年,本科,负责一个或多个核心模块的开发工作,工作内容滴滴外卖配送服务的分单引擎是外卖业务中最具有技术挑战的业务方向之一，其技术架构脱胎于滴滴多年以来在出行业务上的积累，针对外卖场景做了非常深度的定制改造，当前已经可以支持远大于拼车复杂度的拼单计算，并且还在持续优化中。分单引擎涉及到复杂的VRP算法优化、流式计算框架、资源调度平台研发等，需要对各种C++/Go实现的工程和算法代码进行性能和稳定性优化，不断提升引擎的计算能力。同时分单引擎还需要特征工程相关开发，以及为分单策略和预估模型等提供策略工具开发，提高研发和策略落地效率。职责：1、为滴滴外卖业务研发最为核心的配送策略引擎架构，设计和实现配送场景下的分布式计算架构，确保在高并发、大数据量、复杂模型计算的场景下保持系统稳定和高性能；2、负责大数据的特征工程建设，并提供高性能的特征存取服务；3、为分单策略，预估模型提供体系化策略效率工具，提高策略验证能力。4、在充分理解外卖业务的前提下，对配送业务进行持续的抽象和建模，并持续优化架构以适应业务的不断演进。任职要求：1、本科及以上学历，计算机相关专业；2、有扎实的代码能力，精通C++或Golang之一，熟悉Linux环境开发；3、有扎实的数据结构、算法功底；4、有分布式存储或计算经验，精通Hadoop、SparkStreaming，Flink/Redis、HBase、LevelDB等系统优先；5、有至少3年以上一线互联网服务的项目经验，有大规模高并发系统负责人经历优先；6、有搜索、推荐、机器学习等领域经验者优先；7、积极主动，敢于挑战，善于沟通合作。,汽车丨出行,2000人以上,hadoop,北京
C++开发工程师-分布式数据库,https://www.lagou.com/jobs/7202774.html,朝阳区,18k-35k,北京万里开源软件有限公司,3-5年,本科,牛人多 工资多 假期多 弹性工作多,岗位职责：1、参与公司分布式集群数据库产品的bug修复、产品化开发以及性能优化开发；2、针对MySQL新版本新特性进行分布式集群数据库产品的适配开发；3、负责公司分布式集群数据库产品的安全产品方向的开发以及数据库产品Oracle适配的开发；4、负责公司分布式集群数据库产品功能和可靠性测例的编写。岗位要求：1、本科及以上学历，3年以上工作经验，英文读写熟练；2、熟练掌握linux下C++开发调试；3、熟练掌握mysql基本原理以及相关主从复制管理操作；4、熟悉python语言优先；5、有分布式系统研发经验优先。,数据服务,150-500人,hadoop,北京
分布式数据库引擎开发工程师,https://www.lagou.com/jobs/6831317.html,朝阳区,20k-35k,北京万里开源软件有限公司,3-5年,本科,牛人多 工资多 假期多 弹性工作多,岗位职责：1、 负责开发MySQL独立引擎；2、 负责开发全局事务管理模块；3、负责维护全局元数据模块。岗位要求：1、熟练掌握C/C++语言，良好的编程习惯、数据结构、算法等基础知识；2、熟悉MySQL的代码框架，对MySQL进行过二次开发者优先；3、对MySQL存储引擎接口开发有经验者优先，对分布式事务有深入研究优先；4、有数据库底层系统研发经验优先。,数据服务,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5687971.html,海淀区,10k-20k,北京锐安科技有限公司,应届毕业生,硕士,发展空间大、福利多,"岗位职责：1.负责公司的大数据处理框架的研发工作，设计与开发，基于Hadoop平台的海量日志的分布式存储与数据分析架构。2.负责Hadoop集群配置管理，性能调优；Hadoop集群日常维护，提供稳定的系统服务。3.负责数据采集及预处理程序开发、维护，优化。4.负责项目相关设计、开发、测试文档的撰写。岗位要求：1. 本科及以上学历，计算机相关专业，2020届应届毕业生；2. 了解Java开发工具和调试工具的使用；3. 了解大数据分析处理（Hadoop，HDFS, MapReduce，Hbase，Pig，Hive）等技术内部机制；4. 熟悉Linux系统，能使用一种shell/perl/python脚本处理问题；5. 具有较强的团队意识与良好的沟通能力，高度的责任感，对工作积极严谨，勇于承担压力，较强的学习能力以及快速解决问题的能力。","信息安全,数据服务",500-2000人,hadoop,北京
大数据事业部项目开发部咨询顾问,https://www.lagou.com/jobs/6956042.html,朝阳区,16k-25k,西藏嗨球科技有限公司,3-5年,本科,14薪；五险一金；带薪年假；餐补,岗位职责：1、快速、深入的理解大数据事业部整体战略及规划；2、定期评估事业部战略规划实施情况，编写战略实施报告，提出改进方案并持续跟进；3、研究外部战略合作企业特点、分析内外部资源，将各方资源特点与事业部及公司的战略发展有效结合，提出合作落地方案建议，编制战略合作实施报告；4、结合集团企业特点及事业部业务发展需要，以整体战略为指导，为企业提供必要的战略规划服务。岗位要求：1、大学本科以上学历，计算机及相关专业毕业，3年以上战略咨询、或战略规划项目经验；2、逻辑严谨、思维清晰、擅于快速掌握需求形成整体解决方案；3、有较高的市场敏感度，对于市场环境及变化有快速的判断及积极的反应；4、文档编写能力出色，兼具优秀的表达及学习能力；5、熟悉战略咨询方法论，有大数据行业战略咨询顾问经验优先考虑；6、能力出众者薪酬可谈。,移动互联网,50-150人,hadoop,北京
高级Angular前端开发工程师 （医学数据产品）,https://www.lagou.com/jobs/7106059.html,海淀区,20k-25k,艾迪泰科科技（北京）有限公司,3-5年,本科,六险一金 节日福利 餐补 带薪年假,"技能要求：angular岗位职责1、 负责公司医学数据产品Web前端开发和功能自测；2、 参与产品设计，与产品经理共同讨论制定产品的需求方案；3、 根据产品需求，独立分析并给出最优的页面前端结构解决方案；4、 编写和优化核心模块和前台的UI,配合后端工程师一起实现前端页面效果和功能；5、 提供培训，提升前端团队水平任职要求1、 计算机及相关专业本科及以上学历，3年以上JS开发经验2、 两年以上熟练使用Angular框架的经验，深入理解其设计原理3、 另有Vue/ Jquery经验者优先4、 熟悉HTML/CSS/JavaScript相关框架和工具,熟练使用JSON。有针对不同浏览器编写前端的经验。5、 有大规模前端应用、大型网站优化经验者优先6、 有复杂医药IT产品前端经验者优先7、 英语读写能力优秀，英语听说能力良好，需和海外团队沟通8、 一定程度了解后端开发技术（Java、NodeJS等）",其他,50-150人,hadoop,北京
广告大数据开发工程师,https://www.lagou.com/jobs/6566256.html,朝阳区,20k-40k,北京快看世界信息技术有限公司,3-5年,本科,"双休,七险一金,免费晚餐,重点业务","职位描述1、参与公司广告BI、DMP系统的架构设计和系统实现；2、支撑DMP人群包计算、标签挖掘等需求以及大规模数据的计算和分析。3、发现系统的性能瓶颈、设计缺陷，提出改进方案并实施，解决海量数据服务面临的挑战。职位要求1、本科及以上学历，计算机、通信等相关专业，3年及以上相关工作经验；2、有良好的数据结构、算法基础和扎实的编程能力；3、精通java、python、scala 等任意一门语言，熟悉MapReduce编程；4、熟悉大数据生态相关技术，具有hadoop,hive,spark,hbase,es,OLAP,flink等开发经验；5、具有良好的团队沟通意识和快速学习能力;6、加分项: 熟悉广告系统或者DMP业务。",文娱丨内容,500-2000人,hadoop,北京
大数据开发工程师-用户画像/推荐方向,https://www.lagou.com/jobs/6339535.html,朝阳区,25k-50k,北京快看世界信息技术有限公司,3-5年,本科,七险一金，工作环境好，双休，免费晚餐,岗位职责：（用户画像）1、参与企业级亿级用户画像体系的开发搭建；2、参与画像源数据的ETL清洗开发，参与画像标签体系的技术规划；3、开发挖掘用户各级标签，提升用户画像标签体系的覆盖度和准确性；（推荐方向）1、参与亿级用户个性化推荐业务的数据需求开发工作；2、为用户计算生成漫画业务、社区业务的精准画像、精准推荐提供数据支持；3、参与需求开发文档撰写；任职要求：1、本科及以上学历，计算机相关专业毕业，有3年以上的数据开发经验；2、熟悉大数据开发的工作流程和规范；3、理解Hadoop及其子项目的体系架构、工作原理，掌握Spark开发；4、编程基础扎实；5、有用户画像体系开发、搭建经验者优先；6、有个性化推荐数据开发经验者优先；7、拥有良好的团队协作及沟通能力。,文娱丨内容,500-2000人,hadoop,北京
数据开发专家（实时计算方向）,https://www.lagou.com/jobs/7190880.html,东城区,30k-45k,北京轻松筹网络科技有限公司,5-10年,本科,福利待遇 发展前景,岗位职责：1.   负责流计算平台的开发与优化工作2.   负责流式计算平台开发结合业务的应用、处理实时数据、实时应用场景的开发3.   负责实时计算系统的运维，保证系统的高可用性和稳定性4.   负责设计，开发，优化数据接入、数据存储、数据计算服务框架5.   负责对业务的数据接口开发6.   负责优化分布式框架，解决大并发下的各种问题 任职要求： 1.   5年以上相关工作经验，本科或以上学历；2.   具备扎实的Java语言基础;3.   熟悉并行计算或者分布式计算原理，熟悉高并发、高稳定性、可线性扩展、海量数据的系统特点和技术方案；4.   有Spark/Storm等数据平台的开发和使用经验；5.   对性能调优，算法效率和分布式计算的资源管理策略有较深的理解；6.   熟悉Spring、Spring MVC、ibatis等使用框架，深入原理者优先；7.   熟悉ZooKeeper/kafka/Hadoop/HBase/Flume/Redis等平台者优先；8.   具备良好的沟通能力和自我学习能力。,"移动互联网,金融",500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6898159.html,朝阳区,25k-50k,行吟信息科技（上海）有限公司,3-5年,本科,年底双薪、绩效奖金、租房补贴、带薪年假,"工作职责：1. 负责数据分布式存储、计算系统；2. 高水平团队，有 Ownership 的推动数据系统迭代；3. 从架构到业务，支持公司快速发展；4. 支持 CRM、搜索、机器学习平台等应用的底层数据架构。职位要求：1. 掌握分布式系统原理，对存储、离线计算、实时计算中的一项或多项有深入的理解和认识；2. 很强的系统设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；3. 思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原因；4. 对 HDFS, RocksDB, LevelDB, Memcache, Redis, MySQL, HBase, Kafka 的一项或多项有开发经验；5. 了解 Kafka、 MQ 等消息系统；6. 对 Spark, Druid, Flink, OLAP 的一项或多项有经验者优先；7. 拥抱新技术，有很强的学习能力。",消费生活,500-2000人,hadoop,北京
大数据测试开发工程师(J200210006),https://www.lagou.com/jobs/6803585.html,海淀区,20k-35k,北京嘀嘀无限科技发展有限公司,3-5年,本科,广阔的发展空间、前景行业、技术大牛汇聚,,汽车丨出行,2000人以上,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/3524278.html,海淀区,10k-20k,北京金山办公软件股份有限公司,1-3年,本科,"免费三餐,免费健身房,六险一金,各种团建",岗位职责：1、负责公司内大数据平台的开发需求；2、对接第三方业务系统，完成数据回流入仓；3、与外部公司数据接口、交互等的开发、沟通等； 任职资格：1、3年以上数据开发经验，熟悉大数据生态圈，尤其是实时计算部分；2、熟练使用hadoop、spark、storm、hive、python等；3、掌握Linux基本操作 ；4、具有金融背景或是有从0到1搭建数据平台经验优先,移动互联网,2000人以上,hadoop,北京
数据仓库开发工程师,https://www.lagou.com/jobs/7194152.html,朝阳区,20k-40k,一点网聚科技有限公司,1-3年,本科,七险一金，带薪年假，带薪病假，福利待遇好,"工作职责：1、负责数据仓库、用户标签、业务指标的构建；2、负责数据任务的调度编排、数据质量管控；3、负责数据异常检测机制、数据修复机制的构建4、数据采集、数据加工、数据同步相关工具的研发5、保障服务的稳定性，准确性，可用性；岗位要求：1、熟练掌握hive、Impala、Redis、Hbase、Mysql等常规数据库的使用, 掌握相关计算引擎查询优化方法；2、精通SQL，Python,掌握数据仓库建模相关方法，熟悉数据重构相关理论；3、熟悉Linux平台，熟练掌握Java/Python等至少一种编程语言，对数据结构和算法设计有较为深刻的理解；4、从事过数据异常检测机制、数据修复机制建设经验者优先考虑；5、良好的团队合作，较强的沟通能力，对解决挑战型问题充满激情。",文娱丨内容,500-2000人,hadoop,北京
高级数据挖掘开发工程师,https://www.lagou.com/jobs/6753296.html,海淀区,15k-30k,北京金山办公软件股份有限公司,3-5年,本科,带薪年假，各种团建，六险一金,【职位描述】1.对产品用户行为数据的分析挖掘，协助构建用户数据模型，研究互联网产品，用户变化，用以支持各项决策。2. 因项目研发需要而赋予的其他工作职责。【任职资格】1、具备扎实的数学和计算机科学功底，以及坚实的数据挖掘和机器学习理论基础2、具有扎实的数据结构和算法功底，掌握C/C++/Java/Python等至少一门高级编程语言3、具备良好的逻辑分析能力和解决实际问题的能力4、3年以上数据挖掘工作经验,移动互联网,2000人以上,hadoop,北京
资深大数据开发工程师,https://www.lagou.com/jobs/7211459.html,海淀区,25k-40k,北京国双科技有限公司,5-10年,本科,上市大数据公司、发展前景可观,工作内容：- 参与分布式数据库引擎子系统的技术预研和功能开发；- 根据真实业务场景的数据反馈，持续优化平台的各项技术指标；任职要求：- 本科及以上学历，计算机专业背景优先；- 具有5年以上服务端分布式软件编程经验，以及高并发、海量数据处理、性能调优等经验；- 精通至少一种开源分布式数据库引擎，对分布式系统的技术原理和难点有系统化的认识；- 熟练掌握传统关系型数据库如Oracle、SQLServer、MySQL等的SQL查询及常见调优技巧；- 热爱技术，逻辑思维较强，能编写高质量代码，喜欢探寻技术原理和问题本质；- 擅于沟通和解决问题，乐于总结分享，有想法，具有较强的自驱力；,"数据服务,企业服务",500-2000人,hadoop,北京
高级数据仓库开发工程师,https://www.lagou.com/jobs/5708856.html,海淀区,20k-40k,厦门美图之家科技有限公司,3-5年,不限,"大数据平台,千万级用户,福利待遇好",1、负责美图系各产品线核心业务模块数据仓库的构建；2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；3、负责全产品线数据字典维护，提升数据资产质量。职位要求：1、计算机、数学相关专业本科及以上学历，三年以上大数据开发工作经验；2、 深入理解常用的数据建模理论，可独立把控数据仓库的各层级设计；有数据挖掘，机器学习，推荐相关经验优先；有熟悉java或php语言、后台服务开发经验优先3、熟练掌握Hive/SQL，熟悉Spark/Map-Reduce/MPI分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；4、有数据和产品意识，主动思考基于业务场景下的数据体系建设5、工作认真，负责，良好的团队合作精神和解决问题分析能力，钻研技术克服困难，勇于挑战。,硬件,2000人以上,hadoop,北京
数据库高级开发工程师,https://www.lagou.com/jobs/6806010.html,东城区,20k-30k,北京数码易知科技发展有限责任公司,5-10年,本科,七险一金、年终奖金、定期体检、公司食堂,岗位职责：     1.负责工程软件底层数据库的设计、开发     2.负责数据库维护、调优     3.负责技术文档编制     4.负责技术培训岗位技术要求：     1.本科及以上学历，计算机相关专业     2.熟悉关系型、非关系型、图等多种数据库开发     3.熟悉常用算法及数据结构     4.有工程类软件方面开发经验者优先,"移动互联网,企业服务",150-500人,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/7176646.html,西城区,12k-15k,南通东华软件有限公司,3-5年,本科,上市公司,负责数据仓库的存储过程开发及维护要求：1、 计算机类相关专业背景，本科或以上学历；2、熟练掌握Oracle数据库存储过程编程，有SQL优化经验3、掌握ETL工具开发，熟悉Informatica优先4、有金融行业软件开发项目经验者优先5、熟悉金融行业业务知识者优先6、有过风控系统指标开发者优先7、3年大型项目开发经验,"信息安全,数据服务",150-500人,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/7162508.html,海淀区,20k-25k,海致网络技术（北京）有限公司,5-10年,本科,金融大数据 独角兽 固定奖金+项目奖金,岗位职责：1、负责大数据、BI系统相关模块的实施和项目管理工作，包括但不限于需求管理、项目规划、过程实施、上线验收、交付运营等；2、依据业务场景，分析需求提供技术、业务解决方案并加以实现；3、与技术部门对接，解决数据建模、报表和报告在系统开发中遇到的问题；4、协助项目经理进行项目交付或协助商务开展售前支持或POC工作。  任职要求：1、本科及以上学历，计算机、统计学、应用数学等相关专业；2、4年以上相关工作经验，有银行或金融数据仓库，数据管理、数据建模经验优先；3、熟悉Hadoop平台和Hive相关语法及性能优化，熟悉Spark，有一定的Spark SQL或Core开发经验；4、熟悉Linux开发环境和Shell脚本，熟悉Sed或Awk优先，熟悉Python脚本加分；5、优秀的业务理解能力、逻辑性和沟通能力，能跨部门沟通协作。,"移动互联网,企业服务",150-500人,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/7036045.html,朝阳区,20k-40k,北京嘟嘟一下科技有限公司,1-3年,本科,租房补助,岗位描述： 1、根据不同的业务场景，构建业务指标体系，建立和完善日常业务报表，提供决策数据支持，包括但不限于：基于Hive离线数据仓库分层模型设计，报表的开发，专题分析，业务洞察以及AB实验评估等;2、为线上服务提供数据接口； 3、分析挖掘业务 ； 4、数据异常预警开发；5、基于流计算实现实时数据统计；6、基于BI数据报表可视化；7、AB test以及埋点系统开发设计；8、用户画像建设等小打卡良好的数仓分层体系对齐BAT等一线互联网企业架构，基于阿里云Dataworks+odps实现数千个离线任务调度，业务增长迅猛，拥有丰富的数据应用场景，期待你的加入，和我们一起迎接更大的挑战~岗位要求： 1、本科以上学历，3-5年大数据相关工作经验； 2、熟练掌握大型数据库开发技术，能灵活运用Hive SQL实现海量数据ETL加工处理与查询性能调优； 3、掌握数据仓库维度建模设计方法论以及基本数据结构和算法，并有实际基于Hive的离线数仓模型设计及ETL开发经验 （硬性条件）；4、熟悉Hadoop  / Hive / Mysql / Hbase / ES / Redis / kafka 等优先， 有相关源码有研究更佳;5、熟悉常用的数据分析的工具和方法优先；有java(spring boot)接口开发经验优先；熟悉flink流计算优先；熟悉linux平台，精通shell/python等脚本语言的一种或多种，编码基本功扎实优先； 6、具备快速学习能力、沟通协调能力及团队精神，有较强的责任心和抗压性。,"移动互联网,数据服务",50-150人,hadoop,北京
大数据开发高级工程师,https://www.lagou.com/jobs/7116794.html,朝阳区,18k-24k,玄吉（上海）信息技术有限公司,3-5年,本科,优秀的研发团队，良好的工作环境,岗位职责：1. 参与大数据平台架构建设2. 参与数据仓库的搭建和分层设计3. 负责大数据在线、离线分析，数据挖掘模型的建立、应用、监控和优化任职要求：1. 本科3年以上相关工作经验2. 熟悉Hadoop/Spark生态圈及环境搭建3. 熟悉ETL开发及流程4. 熟悉数据仓库的建设和大数据分析5. 熟悉Hive-SQL，Spark-SQL，Spark-Streaming，Scala语言6. 熟悉Hbase和Elasticsearch优先7. 能够独立产出数据报告，熟悉数据采集到报表展示的全流程,移动互联网,15-50人,hadoop,北京
java开发工程师（大数据）,https://www.lagou.com/jobs/7060928.html,朝阳区,20k-30k,北京高域海汇科技有限公司,3-5年,本科,"核心业务,行业大牛,上升空间",岗位职责：1、负责服务端接口设计与开发；2、需求分析，系统设计，模块设计及核心代码实现；3、技术文档编写。任职资格：1、3年以上工作经验，具有Java语言服务端开发经验，具有大型系统完整开发经验者优先；2、Java基础扎实，熟悉io、多线程、集合、消息队列机制等基础框架；3、对J2EE有较清晰的认识，熟悉主流Java Web框架，熟悉常用设计模式，熟悉MVC编程思想；4、熟悉MySQL等RDBS，在数据库设计和性能调优方面具备实战经验；5、熟悉主流Key-Value存储系统，能够进行系统性能调优；6、熟悉maven/Spring MVC/Mybatis；7、熟悉Java大数据开发者优先，熟悉Python/PHP/C++/GoLang等语言者优先；8、具有良好的编码风格，有较强的独立工作能力和团队合作精神。,移动互联网,150-500人,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/7176328.html,朝阳区,25k-35k,北京酷克数据科技有限公司,3-5年,本科,期权激励 五险一金 弹性工作 节假日福利,岗位职责：1、分布式数据库功能组件开发、测试及技术支持。2、与合作伙伴协同工作，推进产品的迭代。3、参与到开源数据库项目中，增强公司在开源社区中的声誉。4、参加大数据技术会议和发表技术文章。岗位要求：1、本科及以上学历。三年以上工作经验。具有数据库、分布式系统开发工作经验。2、熟练使用 C/C++ 在 Linux 环境下开发。有开源项目经验优先。,企业服务,15-50人,hadoop,北京
高级数据开发工程师--3234,https://www.lagou.com/jobs/7054829.html,海淀区,25k-40k,北京奇艺世纪科技有限公司,3-5年,本科,"核心团队,精英文化,职业发展","1、负责爱奇艺推荐基础数据架构的优化和开发工作； 2、负责爱奇艺推荐基础数据平台报表系统开发工作； 3、负责实时和离线等分布式系统的性能优化，可用性和可扩展性的改造工作。 1、全日制统招本科及以上学历,3年以上大数据研发相关工作经验； 2、具备计算机科学基础知识，掌握数据库基本原理，扎实的SQL基本功及调优能力； 3、熟悉Hadoop生态圈上的各种应用两种以上，如Hive、Spark 、Kylin、Hbase、Flink等，具备较强的海量数据开发及调优能力； 4、优秀的问题解决能力，对数据有敏锐度，能够挖掘问题的本质，并提供解决方案； 5、良好的沟通交流能力、团队合作与协调沟通能力，具有与产品，系统，BI等等多方密切配合的经验和意识； 6、用Hive进行数据统计经验丰富者优先； 7、有实时计算相关经验者优先。 温馨提示：如果7天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可。",文娱丨内容,2000人以上,hadoop,北京
海外-高级JAVA开发工程师（大数据方向）--3215,https://www.lagou.com/jobs/6996903.html,海淀区,30k-60k,北京奇艺世纪科技有限公司,3-5年,本科,"海外业务,管理扁平,饭补,加班补助",岗位职责:1、负责推荐系统特征仓库建设，规范底层数据存储，结构化查询逻辑，方便快捷获取数据；  2、负责行为数据统计任务（离线、实时）的实现；  3、负责算法相关训练数据的预处理工作。任职要求:1、精通Java，编程基础良好；本科或以上学历，计算机专业，3年以上大数据项目开发经验；  2、具有Hadoop/Spark开发与应用经验，有较大规模的项目经历并能应用在生产环境；  3、熟悉hbase、hive、YARN、Storm、zookeeper等大数据相关工具，并有处理TB级以上数据的项目经验；  4、熟悉Linux，掌握Python/Shell等脚本工具优先；  5、有实时流架构经验，熟悉常用的数据挖掘算法，有数据平台建设经验；  6、熟悉docker/impala/elasticsearch/mongodb等技术的优先。温馨提醒： 如果 7 天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可。,文娱丨内容,2000人以上,hadoop,北京
高级测试开发工程师（大数据）,https://www.lagou.com/jobs/7192627.html,海淀区,25k-50k,北京金山云网络技术有限公司,3-5年,本科,免费三餐 周末双休 弹性工作,工作职责：1.参与大数据业务质量保证全流程，包括不限于参与需求分析、设计评审、制定测试计划、设计和执行测试用例、进行缺陷跟踪能力、协助开发工程师定位和解决问题；2.保证被测系统的质量，具备风险识别能力，并通过测试流程和方法的创新，努力提升研发的质量和效率；3.参与CI/CD体系的搭建及落地，合理制定自动化测试策略，编写、维护自动化测试脚本，提升交付效率；4.收集并解决业务测试效率的痛点，并有效改进5.了解一种或多种自动化测试工具职位要求：1.掌握基本的测试理论和开发技能2.良好的沟通表达和团队合作能力3.熟练掌握git、maven常用工具的使用以及Linux常用操作，具备shell脚本编写能力4.熟练掌握Java/Python开发语言的一种，能够编写和维护自动化测试用例5.了解ELK、Kafka、Hadoop、flume、Prometheus、Nginx等相关组件6.对工作认真负责，自我驱动能力强，工作积极主动，对新知识、新技术有不断的学习和探索能力7.本科及以上学历，3年以上自动化、测试开发经验，计算机相关专业具备以下条件优先：1.有过大数据相关业务测试经验的优先2.具备丰富的自动化测试、实践经验的优先3.具备快速学习能力的优先,"移动互联网,数据服务",2000人以上,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/6487884.html,朝阳区,20k-30k,北京美住美宿科技有限公司,5-10年,本科,扁平化管理 五险一金 优质行业,岗位职责：    1、承担公司的数仓设计和数据开发工作    2、承担数据产品的搭建，支持数据应用和数据存储的开发工作    3、优化数据模型和ETL性能，参与数据治理，确保数据质量    4、解决业务的所有数据需求，为业务提供一站式数据服务    5、跨团队沟通，推动数据生产链路上的问题改进任职要求：    1、计算机相关专业，5年以上工作经验，2年以上大数据开发经验    2、熟悉数据仓库建模方法，如范式建模、维度建模等    3、有较强的SQL开发与优化能力    4、掌握大数据生态技术栈，理解OLAP与OLTP数据库的管理和常用架构；    5、具备良好的学习能力、团队合作意识和责任心强    6、热爱数据，对数据有较好的敏感度。    7、有互联网行业数据开发经验。,"消费生活,电商",500-2000人,hadoop,北京
大数据开发工程师（spark）(J10392),https://www.lagou.com/jobs/7179929.html,东城区,20k-30k,北京腾云天下科技有限公司,3-5年,本科,"大数据,行业领先,领导靠谱,学习氛围",任职资格:,移动互联网,500-2000人,hadoop,北京
用户数据中心_数据平台php开发工程师,https://www.lagou.com/jobs/6814200.html,海淀区,17k-34k,百度在线网络技术（北京）有限公司,1-3年,本科,福利好 工作弹性 平台大 机会多,工作职责-负责百度集团级大数据分析平台功能设计和开发 -调研前沿技术，提升平台数据分析的通用化、智能化及平台化水平 -参与大数据平台底层分布式数据系统的调研与应用，提升平台性能 -因岗位赋予的其他工作内容任职资格-本科及以上学历优先，计算机相关专业优先，2年以上数据平台工作经验 -丰富的BI报表开发经验，具备大型通用、自助式数据分析产品的开发能力 -精通PHP、MySQL，熟悉开源架构和分布式数据库 -良好的沟通和学习能力，有大型互联网公司相关经验者优先,工具,2000人以上,hadoop,北京
大数据开发实习生（21届） (MJ000358),https://www.lagou.com/jobs/7042872.html,朝阳区,3k-4k,杭州玳数科技有限公司,应届毕业生,不限,大数据；云计算；双休；餐补,"1、根据客户的需求，能基于大数据平台完成相应的场景需求开发；2、能在项目技术leader带领下完成数据加工、清洗、处理程序的开发技术要求：1、21届计算机、软件或相关专业，本科及以上学历，基础扎实2、熟悉java/scala/python至少一门语言，有大数据开发经验优先；3、熟悉hadoop/hbase/flink/spark等分布式大数据技术体系；4、了解myql,es,hbase,redis等存储引擎的数据存储及使用方法；5、使用spark streaming和spark sql进行数据处理的经验，有flink实时处理经验者优先；6、对数据敏感，有良好的沟通表达能力和跨团队协调能力，乐于寻求挑战和突破自我。",数据服务,150-500人,hadoop,北京
数据平台开发工程师（Java）,https://www.lagou.com/jobs/7070375.html,朝阳区,20k-35k,瑞达环球市场咨询（北京）有限公司,3-5年,本科,核心部门，发展空间，大牛多，氛围nice,岗位职责；负责互联网金融相关产品的后端数据平台建设、开发、维护工作。任职资格：1.对 java基础技术体系（JVM、多线程编程，REST API，IO）有一定的掌握和运用；2. 对面向对象有深刻的理解，深刻理解设计模式以及应用场景；3. 熟悉VIM，linux基本操作；熟悉一两种数据库、redis、nginx等尤佳。4. 熟悉git各种操作；5. 英语四级及以上。6.表达能力强、逻辑清晰、责任心强。7.工作四年以上。PS： 有金融行情、交易、金融、账户、清结算业务经验加分。,"移动互联网,金融",50-150人,hadoop,北京
资深数据开发工程师,https://www.lagou.com/jobs/7035125.html,海淀区,25k-50k,北京火币天下网络技术有限公司,5-10年,本科,五险一金、补充医疗、节日福利、免费健身,"岗位职责：1. 负责数据的信息抽象，数据仓库建设；2. 主持和参与实时架构设计并实现；3. 基于开源系统大数据系统进行二次开发；4. 基于金融风控的模型训练的机器学习。任职资格：1. 本科及以上学历，计算机相关专业，5年以上数据平台开发经验；2. 熟悉Java/Python，熟练掌握SQL，对大数据平台有深入的了解；例如 Hadoop生态系统，MongoDB, Elastic Search， Spark,Flink和图数据库，能够按照业务需求选择底层技术；3. 熟练使用Javaweb，Spring-boot， Redis 等web开发；4. 有大型数据仓库实施经验,应对复杂业务数据建模,经过大型应用场景的考验；5. 有金融风控系统，征信系统经验，金融衍生品知识的优先；6. 有用户画像，消费行为分析经验的优先；7. 有团队管理经验者优先。8. 有监督学习，非监督学习的线上工作经验。9. 向往区块链行业。",金融,2000人以上,hadoop,北京
2020校园招聘-大数据开发工程师,https://www.lagou.com/jobs/6404539.html,朝阳区,10k-16k,北京深演智能科技股份有限公司,应届毕业生,本科,升职加薪快 扁平管理,任职资格:,"移动互联网,广告营销",150-500人,hadoop,北京
大数据开发工程师(J11109),https://www.lagou.com/jobs/6841596.html,朝阳区,8k-12k,朗新科技股份有限公司,应届毕业生,本科,节日福利五险一金交通补助带薪年假弹性工作,,"移动互联网,企业服务",2000人以上,hadoop,北京
数据集成工程师/软件开发工程师,https://www.lagou.com/jobs/7149107.html,东城区,15k-30k,宝石花医疗信息技术有限公司,3-5年,本科,医疗集团、国企控股、平台规模大、项目稳定,"岗位职责:1.参与集团数据集成平台项目需求沟通及平台架构的整体规划设计2.负责搭建平台的研发构架并协助完成平台核心功能开发3.负责数据平台数据库的管理及优化4.参与平台建设过程中的数据集成、数据存储、数据清洗、数据挖掘、数据展现功能实现  任职要求:1.计算机或相关专业本科以上学历,熟悉目前市场主流医院信息系统及其数据结构，有2年以上医疗大数据集成及平台开发相关经验2.熟练使用Java/Python等语言进行开发（至少熟练掌握一种），有高效、高可靠代码开发经验3. 熟悉主流的ETL工具，如DataPipeline，Kettle，Talend或 Datax等。4.精通主流数据（如Oracle、MySQL、PostgreSQL等）5.有较强的学习能力和问题解决能力，良好沟通能力团队协作能力。","医疗丨健康,人工智能",50-150人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6604151.html,东城区,20k-35k,北京百观科技有限公司,5-10年,本科,"高成长空间,有挑战性,福利待遇好","岗位职责】1. 根据数据源及业务的需求，制定ETL方案。2. 负责数据仓库运维工作，保障数据的稳定性。3.负责大数据相关产品的设计和开发工作。【任职要求】本科及以上学历、计算机相关专业；至少熟悉一门编程语言，Java/Python；有分布式系统的设计、开发、调优实战经验，熟练掌握Hadoop、Spark、MongoDB、HBase、Hive、ElasticSearch、Redis等大数据组件和工具；具有丰富的数据加工处理经验，对数据处理、数据清洗，数据建模、数据分析等有深刻认识和实战经验具备良好的学习能力，善于沟通，具备较强的业务推动能力和执行力。# 关于我们百观科技（BigOne Lab）是一家国际化的金融数据技术公司，致力于为全球投资机构挖掘、分析互联网时代所产生的大数据，提供可视化投资决策数据产品。百观正在打造新一代的投资研究产品，目前我们已经为二级市场机构投资者开发出监测多家上市公司运营和财务指标的数据产品，促成了大数据在金融领域的领先应用。百观于2016年获得了真格基金天使轮融资，2017年获得了华创资本Pre A轮融资，2019年获得标普全球（S&P Global）在中国的**笔战略投资。 我们位于北京，是一个快速成长的国际化创业团队，成员来自JP.Morgan，Amazon, Bloomberg, IBM, MUFG, Yipit Data, iResearch等国际一流技术、数据、与金融公司，团队有1/3成员拥有海外学习与工作经历。团队成员毕业于清华大学、北京大学、香港大学，新加坡国立大学，哥伦比亚大学，华盛顿大学、约翰.霍普金斯大学，达特茅斯学院等海内外知名院校。","数据服务,金融",15-50人,hadoop,北京
大数据开发工程师（数据仓库开发工程师）,https://www.lagou.com/jobs/7050190.html,海淀区,30k-50k,贝壳找房（北京）科技有限公司,5-10年,本科,16薪,工作职责：1.负责与数据pm对接，开发业务数据需求；2.负责业务需求梳理以及报表体系的规划设计；3.负责数据应用层的开发以及报表的开发；4.负责对城市数据开发者进行培训，以及数据开发能力的赋能；5.负责将业务分析的通用模块进行沉淀与归纳，规划设计自动化的分析报告体系。岗位要求：1.熟悉SQL开发；2.快速的业务学习能力和良好的逻辑分析能力，具有良好的数据理解能力和数据敏感性；3.熟练掌握报表开发工具，比如奥丁、tableau者优先；4.熟悉python脚本开发者优先。,房产家居,2000人以上,hadoop,北京
无人机配送中心-数据可视化软件开发工程师/专家,https://www.lagou.com/jobs/6790211.html,朝阳区,25k-40k,北京三快在线科技有限公司,5-10年,本科,自动驾驶前瞻技术，创新应用，大落地场景,,消费生活,2000人以上,hadoop,北京
视觉智能中心-数据平台java开发专家,https://www.lagou.com/jobs/6876413.html,朝阳区,25k-50k,北京三快在线科技有限公司,5-10年,本科,"AI前瞻技术,创新应用,大落地场景",,消费生活,2000人以上,hadoop,北京
大数据开发实习生-有转正机会,https://www.lagou.com/jobs/5533364.html,海淀区,8k-10k,北京字节跳动科技有限公司,应届毕业生,本科,弹性工作，免费三餐，租房补贴，休闲下午茶,,文娱丨内容,2000人以上,hadoop,北京
数据仓库开发（高级）工程师,https://www.lagou.com/jobs/5119651.html,海淀区,20k-40k,北京字节跳动科技有限公司,1-3年,本科,弹性工作，免费三餐，租房补贴，休闲下午茶,,文娱丨内容,2000人以上,hadoop,北京
资深数据仓库开发工程师(J200420012),https://www.lagou.com/jobs/7043888.html,海淀区,30k-45k,北京嘀嘀无限科技发展有限公司,3-5年,本科,平台广阔,,汽车丨出行,2000人以上,hadoop,北京
资深数据仓库开发工程师(J200325010),https://www.lagou.com/jobs/6956571.html,海淀区,30k-40k,北京嘀嘀无限科技发展有限公司,3-5年,本科,广阔平台；急速成长；诱人福利,,汽车丨出行,2000人以上,hadoop,北京
大数据开发工程师(J10019),https://www.lagou.com/jobs/7177029.html,东城区,25k-30k,塞纳德（北京）信息技术有限公司,5-10年,不限,六险一金 带薪病假 年假 工作氛围好,,"移动互联网,社交",500-2000人,hadoop,北京
Java数据开发实习生,https://www.lagou.com/jobs/6204339.html,朝阳区,3k-4k,北京豆果信息技术有限公司,应届毕业生,本科,"晋升机会,职业发展,良好氛围,薪资待遇","职位职责：1. 负责豆果网数据统计系统的开发。2. 负责公司各部门对电商&网站相关数据的统计。任职要求：1. 有数据展示系统及服务器端系统开发经验者优先。2. 熟悉常用设计模式，对代码的美观和优化有想法和追求。3. Java功底扎实，熟练使用SpringBoot，掌握常用前端开发框架。4. 熟悉Linux操作系统及常用Shell命令。5. 熟练掌握SQL,有使用过Mysql等数据库的经验，懂得常用的SQL语句优化方法者优先。6. 熟悉hadoop、hive、sqoop等开源系统。综合素质：1. 具有开放的心态，具备快速接受新技术和新知识的能力，对前沿技术有浓厚的兴趣。2. 具有较强的独立工作能力、工作积极主动和富有团队协作精神。3. 具有优秀的自我管理、自我学习能力、富有创造力。","移动互联网,社交",50-150人,hadoop,北京
数据开发实习生,https://www.lagou.com/jobs/7145151.html,朝阳区,5k-6k,上海蔚来汽车有限公司,应届毕业生,硕士,成熟平台 福利好 上升期,岗位职责：1、参与蔚来汽车电池相关数据的处理，在分布式计算平台基础上建立高效、实时的数据 pipeline；2、参与检索系统/推荐系统的数据分析，发现模式与规律，为实验解释、系统改进提供数据支持；3、参与Hadoop，Spark 等大数据基础设施和平台的改进，解决大规模生产环境集群可用性和性能化问题；岗位描述：1、本科及以上学历，计算机相关专业，每周可实习4天以上，持续3个月以上；2、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具；3、对数据敏感，掌握量化分析方法，善于从数据中发现问题，提出假设并使用数据进行验证；4、对至少一项分布式计算平台有使用经验，例如 Hadoop，Spark，Hive，Storm，Kafka 等；5、有参与开源项目对社区有贡献的经历，有互联网公司实习经历，有大数据处理或用户行为数据分析经验者优先；6、有机器学习算法经验者优先。,"移动互联网,硬件",2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6267366.html,海淀区,20k-40k,北京小米科技有限责任公司,1-3年,本科,"大牛云集,各种福利",大数据工程师 职责描述：- 负责海量数据处理分布式平台以及大数据分析系统的架构设计和搭建；- 负责海量数据交互式查询引擎的改进和研发；- 探索和研究有效的数据分析模型，为广告业务提供决策支持和商业智能；岗位要求：- 计算机、统计学、数学 相关专业本科及以上学历- 精通 Java / C++ / Python / Scala 其中的一种或几种编程语言- 精通 Hadoop / Hive / Spark / Hbase / Druid / Impala 其中的一种或几种，有分布式系统的实际开发经验者优先- 对数据敏感，能熟练预估数据量，善于从数据中发现问题，有广告数据处理经验者优先- 很强的学习、分析问题能力，良好的团队意识和协作精神,硬件,2000人以上,hadoop,北京
大数据开发工程师-天津,https://www.lagou.com/jobs/7111229.html,朝阳区,15k-30k,捷信消费金融有限公司,5-10年,本科,六险一金，带薪年假,"工作内容：1. 负责大型数据平台的离线和实时计算编码及代码优化。2. 基于Spark技术参与海量数据的处理，分析，统计和挖掘。3. 参与Kafka的开发与优化。4. 负责构建或维护搜寻器系统，并为Web数据开发自动搜寻器脚本。5. 最新社区技术的实时跟进，可应用于实际生产。6. 具有金融行业大数据平台离线实时场景登陆经验者优先。任职资格：1.  3年以上Spark 或 Spark Streaming开发经验，有良好的编程基础2.  熟悉Hadoop架构，熟练掌握Spark框架和Scala语言 3.  熟悉Linux/Unix操作系统，使用过Kafka、Redis、ES、Hbase等组件中的一种以上（或类似组件）4.  熟悉Spark Streaming, Structured streaming和Spark SQL, RDD、DataFrame编程 5.  具备良好的沟通能力和表达能力，有较强的数据敏感度，能承受一定的工作压力6.  对新技术感兴趣，较强的学习能力，有优良的Trouble Shooting能力",金融,2000人以上,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/6752087.html,海淀区,15k-25k,珠海盈米基金销售有限公司,3-5年,本科,"团队大牛多,工作弹性,免费午餐",岗位职责：1、数据驱动业务：深入理解且慢业务，为评估业务价值、进行业务决策等提供数据支持；2、数据统计：参与数据产品建设，完善多维数据统计与分析；3、数据挖掘：理解投资策略与用户行为，建立投顾服务模型；4、金融数据处理、分析与计算；5、金融数据服务的设计、开发与维护。任职要求：1、计算机相关专业本科以上学历；2、熟悉 Python，精通 SQL，具有3年以上数据研发经验； 3、熟悉数据系统架构优先，熟悉大数据平台架构优先；  4、有数据分析、挖掘、清洗和建模经验优先；   5、熟悉 pandas/numpy/scipy/matplotlib 优先。加分项：具有证券、基金等投资理财相关经历。,"移动互联网,金融",50-150人,hadoop,北京
数据仓库开发工程师,https://www.lagou.com/jobs/7055244.html,朝阳区,20k-25k,深圳市华云中盛科技股份有限公司,3-5年,本科,福利待遇好、团队氛围好、年终奖,,"数据服务,移动互联网",500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7184222.html,朝阳区,20k-35k,北京京东尚科信息技术有限公司,3-5年,本科,数据量大、实时性高、技术栈丰富,"工作内容和方向：1、基于Hive/Hadoop/Storm/Spark/Flink等计算框架，进行离线/实时业务数据开发。2、基于Hive/Presto/Impala/Clickhouse/ES/Kylin/Hbase等技术进行智能运营实时OLAP引擎核心能力建设。3、具备较强Java功底,熟练使用Redis。4、具备较强业务理解沟通能力，并能主导业务开发快速迭代。任职要求：1、本科及以上学历，计算机相关专业；2、熟练Java语言，有三年以上Java开发经验，对分布式有深刻理解。3、熟悉Hadoop/Storm/Hive/Hbase/Spark/Flink等分布式开源项目及其工作原理，并有实际开发经验。4、熟悉常用脚本语言Shell,Python等。5、有互联网或移动互联网公司背景优先。",电商,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7201391.html,海淀区,15k-30k,海致网络技术（北京）有限公司,1-3年,本科,氛围好，领导nice，弹性上班，丰厚年终,岗位职责：1.基于Hive，Spark，Hadoop的计算架构，进行大数据开发工作；2.对业务场景进行分析，通过Hive和Spark数据开发完成业务处理需求；3.能够定位数据计算任务的瓶颈并进行性能优化；4.能够针对具体的业务场景，实现基于大数据平台的服务开发。任职要求：1.计算机相关本科及以上学历，具备3年以上的工作经历；2.熟练掌握Java、Scala、Kotlin等java系编程语言，了解Python；3.熟练掌握Linux、git、maven等开发相关工具的使用；4.熟悉数据库，SQL语法，了解数据仓库建模方法论；5.精通Hadoop、Hive、Spark、Hbase等相关组件，包括组件的使用和实现原理，有相关源码阅读经验优先；6.有ETL性能调优经验者优先；7.有强烈的责任心和团队合作精神，具备良好的沟通能力以及快速学习的能力。,"移动互联网,企业服务",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5797781.html,朝阳区,15k-25k,北京人民在线网络有限公司,3-5年,不限,"五险一金,补充医疗,带薪年假,大牛团队","岗位描述1. 参与人民在线众云大数据产品线相关大数据平台和大数据处理框架的架构规划设计； 2. 参与数据治理工作，提升数据易用性及数据质量； 3. 理解并合理抽象业务需求，发挥数据价值，主动思考不断优化，与业务团队紧密合作； 4. 管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定。岗位要求1. 两年以上相关工作经验；2. 熟练掌握java语言，Scala和python至少掌握一种，熟练使用linux,强悍的编码和 troubleshooting能力； 3. 熟悉大数据开源栈spark/hadoop、Hive、Hbase、ElasticSearch、kafka、redis, strom/spark-streaming/flink，有至少TB以上级大数据处理经验；4. 有SparkStreaming的实时统计或实时规则引擎整体架构开发经验优先；有SparkML开发经验优先； 5. 对数据敏感，认真细致，善于从数据中发现疑点； 6. 善于沟通，具备优秀的技术与业务结合能力； 7. 有风控研发经验者优先，对风控行业有自己思考的优先；8. 学习能力强，喜欢研究开源新技术，有团队观念，具备独立解决问题的能力。","数据服务,移动互联网",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5559855.html,海淀区,20k-27k,随行付（北京）金融信息服务有限公司,3-5年,不限,空间大福利好六险一金+绩效奖金+补助,岗位职责：1、研究大数据技术在金融风控领域的应用；2、参与大数据产品平台架构设计和研发维护工作；3、解决项目中的技术难题，关键技术难点攻关；任职要求：1、计算机或相关专业本科及以上学历，扎实java基础，3年以上大数据开发经验；2、熟悉Linux/Unix开发环境，精通java/python/shell，扎实的数据结构和算法功底，熟悉JVM原理，做过JVM调优者优先；3、具有丰富的数据加工处理经验，对数据处理、数据清洗，数据建模、数据分析等有深刻认识和实战经验；4、熟悉基于图数据库（Neo4j、Titan/JanusGraph）的系统开发者优先；5、有分布式系统的设计、开发、调优实战经验，熟练掌握Hadoop、Spark、MongoDB、HBase、Hive、ElasticSearch、Redis、Storm等技术；,"移动互联网,金融",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6905569.html,海淀区,24k-45k,北京奇艺世纪科技有限公司,3-5年,本科,海外业务 大平台 扁平化管理 发展空间大,岗位职责：1、负责爱奇艺海外视频业务数据仓库的构建； 2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决； 3、深入理解常用的数据建模理论，可独立把控数据仓库的各层级设计； 4、大数据的离线和实时处理，可以进行海量数据模型的设计、开发。任职要求：1、本科及以上学历，计算机或数理统计相关专业；2、3年以上企业级数据仓库建模经验，有数据挖掘，机器学习，推荐相关经验优先；3、熟练掌握Hive/SQL，熟练掌握Hadoop及Map-Reduce应用开发，熟悉Hive、Spark、Flink等大数据开发工具中一种或几种；4、熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖掘和数据可视化；5、具有较好的逻辑思维能力和创新能力，对未知领域有浓厚的好奇心。温馨提醒：如果 7 天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可。,文娱丨内容,2000人以上,hadoop,北京
大企平-数据开发（实时计算方向）,https://www.lagou.com/jobs/7073589.html,朝阳区,20k-30k,北京三快在线科技有限公司,3-5年,本科,大厂，氛围好,,消费生活,2000人以上,hadoop,北京
数据平台-机器学习平台系统开发,https://www.lagou.com/jobs/5890528.html,朝阳区,30k-55k,北京三快在线科技有限公司,5-10年,本科,上市公司 大牛云集 核心部门,,消费生活,2000人以上,hadoop,北京
数据平台-大数据开发套件服务端高级工程师,https://www.lagou.com/jobs/5121042.html,海淀区,20k-40k,北京字节跳动科技有限公司,1-3年,本科,六险一金，弹性工作，免费三餐，餐补,,文娱丨内容,2000人以上,hadoop,北京
数据开发实习生-飞书,https://www.lagou.com/jobs/6539367.html,海淀区,8k-10k,北京字节跳动科技有限公司,不限,本科,免费三餐，租房补贴，休闲下午茶，健身瑜伽,,文娱丨内容,2000人以上,hadoop,北京
数据服务开发工程师(J190710004),https://www.lagou.com/jobs/7106475.html,海淀区,30k-40k,北京嘀嘀无限科技发展有限公司,3-5年,本科,平台和业务方向,,汽车丨出行,2000人以上,hadoop,北京
数据库开发,https://www.lagou.com/jobs/6479514.html,西城区,13k-15k,中钞信用卡产业发展有限公司,应届毕业生,硕士,五险二金,1.硕士及以上学历；2.软件工程及相关专业3.有技术研发、项目管理经验优先；4.党员、学生干部优先；,"移动互联网,金融",150-500人,hadoop,北京
数据分析开发工程师,https://www.lagou.com/jobs/6479609.html,西城区,13k-15k,中钞信用卡产业发展有限公司,应届毕业生,不限,五险二金,1.本科及以上学历；2.软件工程及相关专业3.有技术研发、项目管理经验优先；4.党员、学生干部优先；5.强烈的求知欲，卓越的学习能力；6.专业知识深厚，具备一定的抗压能力；7.责任意识强，勇于创新和担当。,"移动互联网,金融",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5498937.html,海淀区,25k-50k,北京奇艺世纪科技有限公司,5-10年,本科,工作氛围好，发展空间大,工作内容/职位描述： 1、参与爱奇艺财务大数据平台的架构设计和开发； 2、基于业务需求和应用场景，设计和实现爱奇艺财务大数据相关产品； 3、为爱奇艺提供财务相关数据支持和服务。任职资格： 1、本科或以上学历，计算机专业，5年以上大数据项目开发经验； 2、具有Hadoop/Spark开发与应用经验，有较大规模的项目经历并应用在生产环境； 3、熟悉hbase、hive、YARN、Storm、Pig、zookeeper等大数据相关工具，并有处理TB级以上数据的项目经验； 4、具有独立完成从方案选型设计到原型系统开发实现的能力； 5、具有Java后端开发经验，熟悉ssm（spring+spring MVC+MyBatis）开发框架； 6、熟悉spring cloud等微服务框架； 7、熟悉docker/impala/elasticsearch/mongodb/mysql等； 8、有较强的沟通表达能力，善于学习，能迅速理解产品需求；有较强的责任心和事业心，能够自我驱动； 9、有财务大数据相关项目开发经验的优先考虑。温馨提醒：如果 7 天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可。,文娱丨内容,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6858873.html,朝阳区,20k-40k,北京每日优鲜电子商务有限公司,3-5年,本科,五险一金、补充医疗、不打卡、发展空间大,大数据开发职位描述：1、跟进业内前沿技术、持续优化数据基础架构，更加稳定、可靠、高效。2、完善数据链路平台，及时响应用户数据需求，保障链路的稳定、高效。3、查询引擎、画像标签、实验平台等应用支撑方面数据开发工作。岗位要求：1、深入了解hadoop，spark生态组件，熟练使用并深入了解其原理，包括但不限于yarn，hdfs，hive，spark，hbase，kylin，presto，druid，flink。2、丰富的hive，spark，hbase调优经验，对olap引擎有比较深入的了解。3、熟悉java与scala编程，具备良好的源码阅读能力。4、具备组件二次开发能力，尤其是yarn，hbase，spark，kylin等。5、具备良好的沟通合作意识和能力，乐于分享。,"移动互联网,电商",2000人以上,hadoop,北京
Hadoop平台工程师,https://www.lagou.com/jobs/7172082.html,海淀区,20k-40k,北京转转精神科技有限责任公司,1-3年,本科,"六险一金,牛人共事,弹性工作,成长空间大",岗位要求： 1、计算机或相关专业本科以上学历，2~3年及以上hadoop生态开发/运维工作经验。 2、精通Java/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境。 3、基于Hadoop的大数据体系有深入认识，具备相关产品（Hadoop、Hive、HBase、Spark、Flink、 Flume、Kafka、ES等）项目应用研发经验，有Hadoop集群搭建和管理经验，读过hadoop/spark/Flink源码，有 Patch 或二次开发经验优先。4、具有扎实的大数据和数据仓库的理论功底，负责过大数据平台或数据仓库设计。工作职责： 1、负责公司大数据底层框架的整体架构设计，结合公司实际业务情况进行技术选型及大数据战略规划；2、负责统一数据平台项目的整体评估、设计、架构及关键模块的开发与优化，协助团队解决开发过程中的技术难题； 3、负责新技术的调研，并能在团队内进行推广应用； 4、参与数据平台开发规范制定，数据建模及核心框架开发；5、负责对 hadoop 相关组件优化、二次开发、Patch Merge、Bug Fix，保障集群高可用、高性能。,"移动互联网,消费生活",500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7193971.html,海淀区,6k-10k,北京东方国信科技股份有限公司,不限,本科,大数据，hadoop，电信行业,北京东方国信科技股份有限公司诚招数据库开发人员，要求如下，欢迎你的加入。1，熟悉hive，oracle，mysql，hbase等常用数据库。2，熟悉基于hadoop生态圈的各种大数据技术。3，熟悉linux常用主机命令以及简单的shell编程。4，要求一本以及以上计算机相关专业，熟悉电信行业者优先。5，能适应项目加班攻坚，能适应中短期出差。,数据服务,2000人以上,hadoop,北京
数仓开发（大数据）,https://www.lagou.com/jobs/7177583.html,石景山区,13k-25k,深圳索信达数据技术有限公司,3-5年,本科,七险一金，不加班；晋升快速，涨知识；,经验要求及优先条件：1.计算机及相关专业本科及以上学历;2.有数据仓库项目开发工作经验、熟练运用automation等主流ETL工具专业技能及其它要求：1.熟悉linux平台，熟练掌握shell操作及编程。2.掌握实时流计算技术，有sparkstreaming、flink、storm等开发经验者优先3.熟悉hadoop，熟练掌握基于hive、hbase和spark等组件的ETL开发。4.精通SQL，有较强的SQL优化及编写能力5.精通linux操作系统，熟练掌握shell操作及编程；6.熟悉perl或python等脚本语言7.熟悉数据质量管理、元数据管理及数据标准管理，理解数据管控的意义,人工智能,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6126306.html,海淀区,20k-40k,中寰卫星导航通信有限公司,5-10年,本科,"弹性工作,试用期全薪,福利待遇好",岗位职责:1、负责公司Hadoop相关产品的架构设计和系统调优；2、完善和优化现有实时流计算系统和存储系统，编写核心开发框架；3、善于发现系统的性能瓶颈、设计缺陷，提出改进方案并实施。任职资格:1、计算机科学或相关技术学科的学士、硕士学位（或同等学历）；2、Java或python相关开发经验2年以上，熟悉并理解缓存、消息、RPC调用框架、序列化等原理，熟悉http等相关通信协议；3、精通分布式数据处理底层技术，包括但不限于：hadoop/elasticsearch/hive/spark/hbase/kafka/flume等，用过mysql，redis，hbase等开源存储；4、具有强烈的责任心，良好的沟通、学习能力，良好的团队合作意识，勇于接受技术挑战；5、有车联网行业经验优先。,移动互联网,500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7209423.html,海淀区,15k-25k,中国电信股份有限公司云计算分公司,3-5年,本科,13薪，6险一金,职责描述：1、负责对交易相关数据的清洗、提取、结构化等工作；2、重点对促销和优惠活动等数据做数据探查、数据分析、模型构建等；3、探索深度学习等前沿技术在电商领域的应用；4、深入研究NLP技术在电商领域的内容分析、舆情分析等方面的应用；5、将数据模型在Hadoop、Hive、Spark、Storm等框架上进行工程化；任职要求：1、计算机或相关专业本科及以上学历；2、熟悉java或python语言编程，对数据结构和算法设计有较为深刻的理解；3、熟悉大规模数据挖掘、机器学习、深度学习、分布式计算等相关技术；4、对技术有热情，动手能力强，参加过各类竞赛并取得较好成绩优先；5、有高并发情况下的系统设计及实现经验优先；6、有3年以上互联网大数据算法、工程化架构经验优先。,"其他,数据服务",500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6995312.html,海淀区,25k-50k,北京小米科技有限责任公司,3-5年,本科,上升空间大，年底奖金丰厚,岗位职责：1.负责小米视频业务中台数据平台的设计与实现；2.负责小米视频业务中台数据平台相关数据的存储、查询、挖掘等的功能开发； 任职要求1.计算机、数学相关专业本科及以上学历，4年以上互联网研发工作经验；2.具有扎实的计算机科学功底，扎实的编程基础和数据结构算法基础，良好的工程素养，极强的问题解决能力；3.精通Unix/Linux操作系统下Java或Scala开发，有良好的编码习惯，有扎实的计算机理论基础；4.有基于hadoop体系的数据仓库开发经验，了解 Hive，Hbase，Spark等大数据处理工具和技术，有较强的调优能力；5.对数据敏感，有较强的逻辑分析能力，对大数据处理和分析技术有丰富的经验和强烈热情；6.善于交流，有良好的团队合作精神和协调沟通能力。,硬件,2000人以上,hadoop,北京
高级数据开发工程师 (MJ003983),https://www.lagou.com/jobs/6881867.html,海淀区,25k-50k,小船出海教育科技（北京）有限公司,3-5年,本科,发展前景不错,岗位职责： 1、负责服务运营侧数据开发框架和数据指标研发。2、开发并实现优秀的数据流、数据架构、数据工具/产品，提供高可用的数据产出，发挥数据价值。3、持续优化系统性能，保证系统稳定性，攻克技术难题。岗位要求：1、计算机或相关专业本科及以上学历，三年以上大数据开发经验，对数据和业务敏感;2、熟练使用java/scala，对jvm，多线程，IO等有深入理解。熟悉Linux/Unix开发环境;3、熟悉常用开源分布式系统，熟悉Hadoop/Hive/Spark/ElasticSearch一种或几种;4、有阅读过ElasticSearch源码经验优先，有在线教育行业数据开发背景优先;5、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计;6、学习能力强，拥有优秀的逻辑思维能力，工作认真负责，谨慎，敬业，沟通能力好;,工具,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6635147.html,海淀区,25k-50k,武汉立民电子商务有限公司,3-5年,本科,待遇好,岗位描述：1、基于海量数据，支持业务对数据的分析和使用；   2、支持业务处理数据的流式处理、分析客户行为等。岗位要求：1、精通至少一门编程语言，熟练运用各种常用算法和数据结构，有独立的实现能力 ；   2、熟悉常用的开源组件：Hadoop/Hive/Spark/Storm，并了解其特性和使用场景优先；3、熟悉机器学习、数据挖掘、数据分析、分布式计算至少某一方面，有较深的理论研究和实践经验优先； 4、数据分析、推荐、机器学习、数据挖掘相关的开发工作优先。,"移动互联网,电商",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6636907.html,海淀区,20k-40k,北京众信利民信息技术有限公司,3-5年,本科,福利待遇、发展前景等,岗位职责：1 负责大数据工具平台和业务系统设计与功能开发及维护； 2 参与技术架构和产品规划讨论，支撑业务的快速迭代； 3 参与项目质量审核，提升团队开发质量和效率； 4 对现有系统的不足进行分析，改进优化系统性能。任职要求：1.大学本科及以上学历，计算机相关专业；2.精通Java技术，熟悉框架开发，有中间件，DB，缓存，消息方面的开发经验;3.对大数据相关技术栈，如：hive、spark、hbase、flink及OLAP引擎等有一定的了解;4.有数据平台开发经验者，如：有调度系统、元数据管理系统、有doris、clickhouse、kylin等一种或者多种olap开发使用经验者优先；5.有强烈的技术热情，工作责任感，对代码和设计质量有严格要求;6.能够主动独立跟踪问题，解决问题，有良好的自驱力；7.能够对国内外同类产品进行架构设计调研，给出可落地的架构设计方案。,"金融,数据服务",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6959289.html,海淀区,30k-45k,上海基分文化传播有限公司,5-10年,本科,上市公司 大牛多 16薪,职位描述1、负责趣头条数据中台，全公司各类业务数据仓库的构建；2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；3、负责构建用户主题、各业务线主题、推荐主题、广告主题、数据门户系统；4、负责各产品线数据维护，提升数据资产质量。职位要求1、计算机、数学相关专业本科及以上学历，2年以上大数据开发工作经验；2、 深入理解常用的数据建模理论，可独立把控数据仓库的各层级设计；有数据挖掘，机器学习，推荐相关经验优先；3、熟练掌握Hive/SQL，熟悉Spark/Map-Reduce分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；4、有产品sense，主动思考基于业务场景下的数据体系建设，而不单单只会做执行；5、工作认真，负责，良好的团队合作精神和解决问题分析能力，钻研技术克服困难，勇于挑战。,文娱丨内容,500-2000人,hadoop,北京
公共数据-数据系统开发,https://www.lagou.com/jobs/5890353.html,朝阳区,28k-45k,北京三快在线科技有限公司,5-10年,本科,上市公司 大牛云集 核心部门,,消费生活,2000人以上,hadoop,北京
数据平台Java开发-视觉智能中心,https://www.lagou.com/jobs/6768148.html,朝阳区,25k-45k,北京三快在线科技有限公司,3-5年,本科,场景丰富，技术大牛,,消费生活,2000人以上,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/6965460.html,海淀区,20k-40k,北京字节跳动科技有限公司,3-5年,本科,"六险一金,免费三餐,租房补贴,带薪休假",,文娱丨内容,2000人以上,hadoop,北京
高级测试开发工程师-大数据方向,https://www.lagou.com/jobs/5811836.html,海淀区,20k-40k,北京字节跳动科技有限公司,3-5年,本科,六险一金，弹性工作，免费三餐，租房补贴,,文娱丨内容,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6550004.html,朝阳区,15k-30k,龙盈智达（深圳）科技有限公司,3-5年,本科,带薪年假 五险一金 通讯补助 周末双休,"岗位职责:1.参与大数据平台建设，结合应用需求，发现潜在的特征，规划应用场景，挖掘现有数据的价值，驱动业务发展。2.从场景和问题出发，运用内外部数据，对业务数据进行场景识别，发现和挖掘大数据价值。3.负责业务数据分析，包括数据建模、算法实现、分析应用、结果评估等。   岗位要求：1． 计算机、经济/金融、数学相关专业本科或以上学历，有3年以上的数据分析经验，熟练常用数据结构及算法，对其中一个领域或几种算法有深入研究，年龄原则上不超过35周岁。2． 熟悉Python、R或C++，有较强的数据敏感性，在经济/金融领域大规模数据处理及挖掘有经验，熟悉元数据管理和数据安全管理方法。3． 深入大数据生态体系，对Hadoop，spark，hive等分布式框架有深刻理解，通读主要源码，有大数据项目构建经验。4． 熟练人工智能项目构建流程，熟悉目前业界使用的机器学习算法；熟悉深度学习常用算法，熟练TensorFlow,Pytorch,Caffe其中一种深度学习框架；对图像识别，语音识别，自然语言处理，推荐系统，知识图谱有项目经验者优先。5． 具有良好的沟通协调能力和团队合作意识，为人诚实正直、严谨细心，具有较强的学习能力，一定抗压能力和高度责任心。","移动互联网,金融",150-500人,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/6979288.html,海淀区,15k-30k,北京金堤科技有限公司,1-3年,本科,"精湛的团队,超牛的技术,超棒的领导",岗位职责：1、根据产品需求，完成数据的清洗与转化工作，交付符合业务质量要求的数据2、负责维度数据的存储设计、清洗算法设计3、负责多源数据的比对和融合工作。4、负责维护线上数据的正确性、一致性、时效性。岗位要求：1、熟练掌握一门编程语言，有较强的数据研发能力；2、熟练掌握MySQL，熟悉任意一种非关系数据库，如MongoDB、HBase等；3、能够使用Kafka、MQ等中间件；4、良好的沟通能力和独立工作能力，积极主动及良好的团队合作意识与责任心；5、有数据清洗、ETL经验、统计学背景者优先,数据服务,500-2000人,hadoop,北京
高级数据仓库开发工程师,https://www.lagou.com/jobs/7160087.html,海淀区,30k-60k,北京百家互联科技有限公司,3-5年,本科,上市公司 大牛团队 发展快速,1. 负责用户增长领域基础数据体系建设。包括：PB级数据仓库（离线、实时）的数据模型规划设计、数据ETL开发。2. 负责全链路数据处理和数据建模，包括但不限于：投放日志、人群标签数据，媒体画像、销售链路数据体系，人群画像数据体系，效果计算和投放策略多维分析评估。3. 负责业务／产品需求的数据需求理解、数据探查分析，及数据产品化项目推进职位要求1. 熟悉数据仓库各类建模理论、数据仓库数据层级关系、3NF和多维数据模型设计。2. 熟悉数据仓库开发流程，至少熟悉Hive/Hadoop/Spark/Storm/Flink分布式计算框架中的一种。3. 灵活运用SQL实现海量数据ETL加工处理 ，有较好的SQL性能调优经验。4. 优秀的数据敏感性和业务理解能力，可以对复杂业务逻辑快速抽象建模；期望通过对业务的深入理解，发挥数据价值，并反哺数据体系的建设。5. 良好的沟通表达和团队协作能力，自我驱动，学习能力强。,"移动互联网,教育",2000人以上,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/6995159.html,海淀区,18k-30k,度小满科技（北京）有限公司,1-3年,本科,福利待遇好 弹性工作制 免费早餐、夜宵,职位要求：1.计算机或相关专业本科及以上学历;2.熟练使用至少一门编程语言（Python、Java、scala等）;3.良好的逻辑思维能力，能够从海量数据中发现有价值的规律;4.优秀的分析和解决问题的能力，对挑战性问题充满激情;5.良好的团队合作精神，较强的沟通能力和学习能力;6.熟悉数据挖掘、数据分析、机器学习至少某一方面，有一定的理论研究和实践经验;7.有互联网金融工作经验优先;职责范围：1.支付风控模型的开发与优化;2.支付风控数据平台建设，包括数据交互、特征提取、数据挖掘、用户画像等;3.支付风控数据和模型监控系统建设;,金融,2000人以上,hadoop,北京
java开发工程师-数据平台,https://www.lagou.com/jobs/6164833.html,海淀区,20k-35k,北京小米科技有限责任公司,1-3年,本科,发展空间、年终奖金、技术氛围浓厚,工作职责：        1、负责智能硬件数据采集、加工和统计的相关工作        2、负责数据仓库和数据平台的设计、开发和优化工作        3、保证数据流程的稳定性、及时性、高性能                任职要求：        1、计算机、通信、数学、统计相关专业本科以上学历，一年以上Java开发经验        2、精通JSP、Spring，对Linux下的开发环境有较深厚的开发经验        3、熟练MySQL，对数据库有较强的设计能力，同时熟悉大数据相关技术        4、熟悉JavaScript、HTML、CSS等Web前端常用开发技术        5、熟练使用git，熟悉Maven，熟悉Nginx等应用服务器，熟悉高并发处下的性能优化        6、熟悉网络编程，具有设计和开发对外API接口经验和能力        7、具有良好的沟通，团队协作、计划和创新的能力        8、熟悉Hadoop(HDFS/MapReduce/Hive)、Spark、HBase、Storm、Kafka等类框架技术，大数据产品开发、报表平台研发、数据仓库建设经验者优先。,硬件,2000人以上,hadoop,北京
大数据系统工程师（Hadoop方向）,https://www.lagou.com/jobs/7143209.html,海淀区,30k-40k,贝壳找房（北京）科技有限公司,3-5年,本科,"16薪,大平台",,房产家居,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6998240.html,海淀区,15k-30k,微梦创科网络科技（中国）有限公司,1-3年,本科,大平台,大数据开发工程师职位描述：    职位要求：    1、全日制大学本科及以上学历，计算机相关专业    2、两年以上大数据平台开发经验    3、熟练使用Hadoop、Hive、Storm、Kafka、Spark等    4、熟练掌握至少一种语言，JAVA/C++/PHP    5、熟悉Python者优先    6、熟悉机器学习/数据挖掘者优先    7、具有较强的逻辑思维能力，分析和解决问题的能力，沟通能力，学习能力，具备良好的团队合作精神和服务意识    8、社招优先，应届生可以先实习。,文娱丨内容,2000人以上,hadoop,北京
高级数据开发工程师,https://www.lagou.com/jobs/7084682.html,海淀区,20k-30k,启迪公交（北京）科技股份有限公司,3-5年,本科,补充医疗,"工作职责：1.        负责公司业务系统的服务端数据和应用的开发2.        负责搭建业务系统微服务平台，解决数据对接和开发过程中的各种问题，进行系统优化；3.        深入理解业务需求，负责数据产品需求分析，根据数据建模完成相关设计及编码；4.        配合产品团队，完成对外包项目的技术管控。 任职要求：1.        计算机相关专业本科及以上学历，2年以上工作经验，有数据挖掘/BI开发经验；2.        熟悉HIVE开发，熟练使用HQL，有阿里云MaxCompute使用经验优先,至少熟悉一种关系型数据库如MySQL、Oracle等；3.        熟悉Hadoop、MapReduce、Spark、Flink等分布式计算框架，进行海量数据模型设计、数据ETL开发；4.        有Java开发经验，有一定的分布式开发经验，对消息服务、负载均衡、高可用等机制经验；5.        思维灵活,逻辑缜密,能快速理解业务；6.        具备数仓或BI模型设计能力优先；7.        具备良好的编码习惯和技术文档编写能力，具有很强的沟通和协调能力，能够承受较强的工作压力和强度，有工作责任心。","移动互联网,消费生活",15-50人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6550212.html,西城区,25k-40k,网联清算有限公司,5-10年,本科,监管视野 平台稳定 发展空间,工作职责：1、 负责大数据集群建设、运维、管理，大数据系统集成研发，公司数据运营、数据运维、数据风控产品的设计开发等工作。 2、 使用数据挖掘工具，对支付业务数据进行分析，挖掘用户行为特征，构建用户精准行为的体系模型。 3、 深入理解支付业务的方向和战略、针对具体的业务问题，规划、设计基于数据挖掘的解决方案。任职资格：全日制数学、统计、计算机等相关专业本科以上学历 3 年以上大数据分析挖掘相关经验，互联网金融行业背景优先 工作经验 1、数据挖掘项目经验丰富，在挖掘模型应用上有成功案例。 2、对数据挖掘方法论有深刻理解，能深入分析、定位业务问题，并利用挖掘模型解决。 3、熟悉常见的概率统计、数据挖掘、机器学习算法，包括聚类、回归、关联规则、决策树、朴素贝叶斯等常用算法的适用场景。 4、熟练掌握 Hadoop、Hive、Spark、流式计算、实时计算等大数据相关技术。 5、熟练掌握 java、shell、python 等编程语言，精通 sql。,金融,150-500人,hadoop,北京
高级大数据开发工程师,https://www.lagou.com/jobs/6812651.html,海淀区,20k-40k,北京中经惠众科技有限公司,5-10年,本科,福利好，发现前景好,"高级大数据开发工程师职位描述:1、	参与公司大数据平台的架构设计；2、	参与开发面向大数据套件产品；3、	参与需求调研与用户技术支持；4、	追求**，构建业内领先的数据平台产品。职位要求:1、	计算机相关专业，本科及以上学历，5年以上相关工作经验；2、	精通Java/Scala/Python语言；3、	参与过数据分析平台的设计与搭建；4、	良好的数据敏感度，能从数据中提炼核心结果，具备数据清洗、分析和建模经验；5、	熟悉Spring架构和微服务架构；6、	熟悉Hadoop中HBase、Hive、Yarn、Spark等，能够解决数据分析过程中遇到的问题；7、	熟悉ElasticSearch平台者优先；8、	有图数据库开发经验者优先；9、	扎实的计算机基础，对技术有热情，愿意不断尝试新技术和业务挑战。","金融,企业服务",50-150人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6640630.html,朝阳区,10k-15k,博易智讯（北京）信息技术有限公司,应届毕业生,本科,五险一金定期旅游不加班,岗位职责1.能独立担任SAP PP模块实施，精通PP模块的标准业务流程、系统操作和后台配置； 2.能独立与客户进行业务沟通、有效整理客户需求、定制行业方案、编制业务蓝图并在系统中加以实现； 3.能独立组织和开展用户培训； 4.能承担项目经理工作经验和能力者优先。 任职要求： 1.本科及以上学历，计算机、财经等相关专业，有良好的英文水平，英语口语流利者优先；有PMP或相关项目管理类证书者优先； 2.3年以上SAP项目实施经验，参与过3个以上完整的SAP项目实施，熟悉相关业务流程； 3.能独立完成PP模块，能兼顾2个或2个以上模块者优先； 4.要求较强的学习能力和沟通表达能力，清晰的思路和分析判断能力，工作主动性强，创新，具有良好的团队合作精神，能够承受一定的工作压力; 5.精通SAP BO 报表开发，和精通Sap Hana计算平台；’6.善于学习，具有分析、解决应用问题的能力。,"数据服务,移动互联网",15-50人,hadoop,北京
数据开发,https://www.lagou.com/jobs/7156157.html,昌平区,8k-16k,北京东方国信科技股份有限公司,3-5年,本科,十三薪加年终奖，体检福利,1负责存储过程编写2负责数据etl流程开发3负责报表数据稽核有电信运营商行业经验优先,数据服务,2000人以上,hadoop,北京
企平-Java资深开发工程师（大数据方向）,https://www.lagou.com/jobs/7072911.html,朝阳区,20k-30k,北京三快在线科技有限公司,3-5年,本科,大厂，Java,,消费生活,2000人以上,hadoop,北京
数据仓库开发-技术专家,https://www.lagou.com/jobs/6409026.html,朝阳区,30k-60k,北京三快在线科技有限公司,5-10年,本科,新零售业务 空间大 良好的晋升机制,,消费生活,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6640630.html,朝阳区,10k-15k,博易智讯（北京）信息技术有限公司,应届毕业生,本科,五险一金定期旅游不加班,岗位职责1.能独立担任SAP PP模块实施，精通PP模块的标准业务流程、系统操作和后台配置； 2.能独立与客户进行业务沟通、有效整理客户需求、定制行业方案、编制业务蓝图并在系统中加以实现； 3.能独立组织和开展用户培训； 4.能承担项目经理工作经验和能力者优先。 任职要求： 1.本科及以上学历，计算机、财经等相关专业，有良好的英文水平，英语口语流利者优先；有PMP或相关项目管理类证书者优先； 2.3年以上SAP项目实施经验，参与过3个以上完整的SAP项目实施，熟悉相关业务流程； 3.能独立完成PP模块，能兼顾2个或2个以上模块者优先； 4.要求较强的学习能力和沟通表达能力，清晰的思路和分析判断能力，工作主动性强，创新，具有良好的团队合作精神，能够承受一定的工作压力; 5.精通SAP BO 报表开发，和精通Sap Hana计算平台；’6.善于学习，具有分析、解决应用问题的能力。,"数据服务,移动互联网",15-50人,hadoop,北京
数据开发,https://www.lagou.com/jobs/7156157.html,昌平区,8k-16k,北京东方国信科技股份有限公司,3-5年,本科,十三薪加年终奖，体检福利,1负责存储过程编写2负责数据etl流程开发3负责报表数据稽核有电信运营商行业经验优先,数据服务,2000人以上,hadoop,北京
大数据开发工程师（校招）,https://www.lagou.com/jobs/6934772.html,朝阳区,10k-20k,在线途游（北京）科技有限公司,应届毕业生,不限,五险一金，年底双薪，餐补下午茶 近地铁站,1，负责公司大数据平台相关组件的研发设计；2，负责业务系统数据收集、处理、存储方案的设计开发；3，持续关注大数据前沿技术，优化公司平台相关架构。任职要求：1：2020年应届毕业，本科及以上学历，计算机相关专业；2：丰富的编码实战经验，热爱大数据； 3：有激情，有创造力，也有强悍的逻辑性，喜欢研究新技术。,"移动互联网,游戏",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6006103.html,朝阳区,30k-60k,北京三快在线科技有限公司,应届毕业生,本科,福利好，待遇好，氛围好,"职位描述岗位职责： 1、负责数据仓库的架构设计, 开发和实施；2、负责数据ETL流程的建设，优化以及解决ETL相关技术问题；3、负责机器学习流水线的架构设计, 开发和实施；4、负责数据任务调度系统、数据监控系统的设计，开发和实施；5、负责数据schema管理系统的设计，开发和实施。任职要求：1、本科及以上学历，计算机相关专业;两年以上互联网行业大数据相关工作经验；2、了解并行和分布式计算的基本原理；熟练掌握Hadoop,hdfs, hive, Spark,Storm,flink，cassandra, hbase、ElasticSearch等常用的大数据系统或式计算框架；熟悉MySQL, postgres, MongoDB等数据库；3、具备优秀的数据敏感性；4、优秀的分析问题和解决问题的能力，勇于解决难题；强烈的上进心和求知欲，较强的沟通表达能力与协作推进能力； 5、热爱互联网，对互联网产品和技术有浓厚的兴趣，热衷于追求技术**与创新；6、有开源社区贡献经验的开发者优先考虑。",消费生活,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7053966.html,西城区,7k-11k,北京先进数通信息技术股份公司成都分公司,1-3年,本科,1-3个月年终奖 、每年调薪、上市公司,1、有java/Scala/Python/C中一种或多种开发经验2、有SQLSERVER、MYSQL、DB2、Oracle等SQL开发经验；3、有大数据开发组件如hive、hbase、kafka、hdfs、ES、spark等开发经验4、有ETL开发经验，不限DataStage、Sap DataServices、Informatic或存储过程经验；5、有数据仓库开发经验者优先6、学历要求本科以上，计算机相关专业7、至少2年以上工作经验；8、有银行或金融机构工作经验者优先；,"软件开发,其他",500-2000人,hadoop,北京
Hadoop专家,https://www.lagou.com/jobs/7091675.html,海淀区,40k-60k,度小满科技（北京）有限公司,5-10年,本科,免费双餐，免费班车，领导nice,岗位职责：1、为度小满研发基础架构服务组件，包括分布式存储、计算引擎2、调研新技术，推动适合的技术落地满足业务需求任职要求1、本科及以上学历，计算机、通信等相关专业； 2、熟练掌握Linux环境下的Java/Go/C/C++/Python等1至2种以上语言； 3、具有linux服务器端软件开发经验；4、熟悉Hadoop生态、Spark生态优先；5、善于沟通及主动思考总结、倡导创新与持续优化、思路周密、代码严谨、对待技术有强烈兴趣；6、 具备一定架构能力、有大容量、高性能、分布式系统的设计开发经验优先。7、有社区贡献者优先；有阿里云、百度云离线架构解决方案经验者优先；,金融,2000人以上,hadoop,北京
大数据系统工程师（Hadoop方向）,https://www.lagou.com/jobs/6601334.html,海淀区,30k-50k,贝壳找房（北京）科技有限公司,3-5年,本科,产业互联网，高速成长期，领导nice,"工作职责：
 负责公司大数据平台底层技术架构的规划、设计、实施和优化。
 负责公司大数据平台资源调度系统的规划、设计、实施和优化。
 负责结合软硬件持续对公司大数据平台基础架构层进行优化和整合。
职位要求：
 具有扎实的大数据和分布式系统的理论知识，对大数据基础组件有深入的研究。
 熟悉 Java、C/C++语言，熟悉 Linux 操作系统。
 参与过大型分布式系统架构设计和实施，有具体的实践经验。
 参与过大型调度系统的研发，并在线上实际运行并取得较好的效果。
 基于Hadoop的大数据体系有深入认识，具备相关产品（Hadoop、Hive、HBase、Spark、Storm、 Flume、Kafka、ES、flink等）项目应用研发经验
 具有良好的问题分析和追踪能力，具有正确的团队合作意识和良好的沟通能力。
 3年工作经验以上，硕士学历者优先",房产家居,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6831903.html,海淀区,15k-20k,北京人人云图信息技术有限公司,3-5年,本科,六险一金、双休，人性化企业文化，弹性工作,职责:  1、依据客户需求完成大数据项目的数据分析及建模;  2、进行大数据核心算法的编写;  3、参与项目的需求分析、系统设计、编码工作;  4、参与开发过程中相关新技术的研究和验证。  5. 协助承担架构性的体系设计和改造工作，配合制定技术实施方案，按照总体设计组织子系统的设计和开发。  任职要求:  1、精通数据建模、数据体系建设，具备数据仓库架构设计、模型设计和处理性能调优等相关经验;  2、具有丰富的基于hadoop体系的数据平台、数据仓库建设经验，精通基于hadoop源码的开发、优化改造及成功应用案例;  3、精通hadoop生态体系各项技术，如kafka、flume、hive、impala、hbase、spark、mlib等，具有100+节点hadoop集群的开发、运维经验;  4、具有对大型hadoop集群的硬件规划能力;  5、熟悉python优先,"移动互联网,数据服务",15-50人,hadoop,北京
数据开发工程师-【电商】,https://www.lagou.com/jobs/7059893.html,海淀区,20k-40k,北京达佳互联信息技术有限公司,3-5年,本科,福利待遇好,职位描述1、为快手电商新产品构建业务指标体系，建立和完善日常业务报告体系，能够及时、准确、完整的披露业务方向的运作情况； 2、负责快手电商新产品数据统计、报表产出、效果监测、归因分析和商务支持； 3、通过专项分析，输出专项分析报告，为快手电商的业务决策和产品方向提供数据支持和指导； 4、参与埋点设计、数据生产全流程等技术体系建设和保障工作； 5、参与数据集市建模与数据开发，建设共享数据集市。任职要求1、本科以上学历，两年以上数据开发经验； 2、灵活运用Hive实现海量数据ETL加工处理，Hive查询优化； 3、熟悉数据集市模型设计方法论，并有实际模型设计及ETL开发经验； 4、熟悉常用的数据挖掘、分析工具和方法，有数据挖掘工作经验；熟悉Linux平台，精通Shell/C、C++/Java/Python 等脚本语言的一种或多种，编码基本功扎实； 5、具备快速学习能力，跨团队沟通协作能力，团队精神。加分项：1、有较强产品Sense优先； 2、有数据洁癖和代码洁癖者优先。,文娱丨内容,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7134860.html,朝阳区,16k-22k,人民日报媒体技术股份有限公司,3-5年,本科,"六险一金,年终奖，绩效奖,定期体检","岗位职责：1、负责基于Hadoop/Flink等生态系统建设小赢大数据基础平台，包括但不限于基础集群的搭建与维护、离线计算平台、实时流计算平台、模型算法平台的架构与研发；2、深入了解业务背景，能抽象业务需求，对数据应用提供数据存储、数据服务、查询引擎、元数据管理的架构设计3、系统核心部分代码编写、指导和培训工程师、不断进行系统优化；4、跨团队/部门协作，系统分析并解决各类大数据平台相关的运行或数据问题；5、打造有行业竞争力的系统，能够支撑快速发展的数据业务。任职资格：1、本科及以上学历，3~8年或以上的大数据从业经验。2、有大型分布式系统设计经验，负责过海量数据平台上高可用、高性能分布式系统的架构设计。3、精通任意一门编程语言，对大数据基础架构和平台底层原理有深度理解和丰富开发经验, 对复杂系统的性能优化和稳定性提升有一线实战经验，具备相关产品（Hadoop、Hive、HBase、Kafka、Flink、Kylin等）项目应用研发经验；对开源社区有贡献者优先；4、熟悉分布式存储和NoSQL数据库技术（如HBase、Cassandra、Redis等），有实际生产项目应用经验；5、具有一定的项目规划和决策能力，善于捕捉业务需求、架构设计存在的问题，并给出有效的解决措施和方法；6. 工作有计划性，责任心和执行能力强，具备高度的责任心、诚信的工作作风、优秀沟通能力及团队精神。",移动互联网,150-500人,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/6673499.html,海淀区,15k-30k,北京偶数科技有限公司,1-3年,本科,年底双薪 平台好 发展空间大,"根据用户需求分析使用产品，设计相应的数据库特性与功能,确定数据库产品和规范；
 高性能数据库内核的开发以及测试；
 企业客户问题支持并提供相应解决方案。
职位要求：1.统招211院校、本科及以上学历，计算机相关专业；2.熟练掌握任意一门开发语言：C/C++/Java/Python；3.有一定数据库系统开发经验；4.熟悉以下领域：Linux系统内核、虚拟化、容器、分布式系统者优先，HADOOP系统基础者优先；5.工作细致认真，善于团队合作；6.勇于创新，热衷学习新技术，接受挑战。",数据服务,50-150人,hadoop,北京
数据仓库开发工程师/技术专家,https://www.lagou.com/jobs/7215744.html,朝阳区,25k-50k,北京三快在线科技有限公司,3-5年,本科,新业务机会好，大平发展好,,消费生活,2000人以上,hadoop,北京
美团打车-数据开发,https://www.lagou.com/jobs/5899739.html,朝阳区,35k-45k,北京三快在线科技有限公司,5-10年,本科,平台大、氛围好,,消费生活,2000人以上,hadoop,北京
高级/资深数据开发工程师 - Data&amp;AILab,https://www.lagou.com/jobs/7141366.html,海淀区,25k-50k,北京字节跳动科技有限公司,3-5年,本科,"六险一金,免费三餐,租房补贴,健身瑜伽",,文娱丨内容,2000人以上,hadoop,北京
数据仓库开发工程师,https://www.lagou.com/jobs/5988705.html,海淀区,25k-50k,北京字节跳动科技有限公司,3-5年,本科,六险一金，高薪期权，弹性工作，免费三餐,,文娱丨内容,2000人以上,hadoop,北京
数据开发高级经理,https://www.lagou.com/jobs/6950534.html,海淀区,50k-80k,北京奇艺世纪科技有限公司,5-10年,本科,五险一金，带薪年假，绩效薪资，交通补贴,岗位职责:1、负责爱奇艺多条业务线的数据仓库建设、数据规划设计工作；2、提升数据质量、生产效率，提高数据易用性、完备性；3、优化数据计算的监控告警流程、提升数据快速修复能力。任职要求:1、计算机相关专业，本科及以上学历，5年以上大数据开发工作经验；2、熟悉数据仓库理论，具备企业级数据仓库开发经验；3、深入了解Hadoop生态，熟练掌握Spark、Flink 等开发工具；4、具备良好的沟通能力、项目驱动能力和团队管理能力；5、思维活跃、学习能力强，关注前沿大数据技术。温馨提醒：如果 7 天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可。,文娱丨内容,2000人以上,hadoop,北京
大数据平台开发工程师（golang）,https://www.lagou.com/jobs/6797234.html,朝阳区,25k-35k,奇虎360科技有限公司,3-5年,本科,核心业务 前沿技术,工作职责：1.为分析人员打造自动化分析和发现安全事件的平台2.结合docker/k8s等容器技术设计部署和运维方案3.深入理解安全业务， 设计安全数据存储和分析流程，构建核心流程引擎工作要求：1.统招985/211院校，计算机或相关专业本科毕业2.深入理解golang3.熟悉Linux环境以及对应的编程技术4.熟悉容器技术者优先5.熟悉python，有数学建模/机器学习背景者优先6.熟悉Hadoop/Hive/Spark者优先7.熟悉olap/tp存储引擎者优先8.对开源项目有贡献者优先,信息安全,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6111897.html,朝阳区,25k-50k,北京闲徕互娱网络科技有限公司,5-10年,本科,"团队和谐,薪资优厚,免费零食,健身房","职位描述：1、负责公司数据平台的架构设计及实施；2、负责数据仓库的设计与实施；3、负责符合业务的数据工具的抽像及研发；4、负责大数据开发团队小组的工作协调和管理。任职条件：1、熟练掌握大数据常用框架，如spark,hive,hbase等；2、熟练开发spark streaming流式分析作业及离线分析作业，熟练应用spark 2.x新特性，掌握flink开发；3、掌握scala开发语言，对底层实现有一定研究，熟练使用Python语言；4、有丰富的数据仓库设计及开发经验，从数据采集到数据报表的整个全链路有比较深刻的理解；5、具有良好的沟通能力和团队合作精神。",移动互联网,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7060006.html,西城区,40k-80k,北京宏博未来信息技术有限公司,3-5年,本科,六险一金，14薪，奖金，弹性,岗位职责：1. Hadoop数据分析平台建设、开发、测试、部署和优化；2. 基于Hadoop的存储平台架构设计与性能优化；3. 设计和开发海量数据的管理系统；4. 基于现有数据统计平台，开发数据统计报表；5. 结合当前大数据平台技术，设计和实现数据收集模型、数据分析处理模型和数据汇总展现模型；6. 实现各运营组织要求的相关数据的统计报表。任职要求：1. 精通计算机算法，及大数据相关算法；2. 精通SQL语句，可以快速编写复杂查询；3. 懂得 Hadoop、GFS 一类分布式存储原理；4. 熟练编写 Java 和 Linux shell 程序；5. 有大数据工作经验者优先。,"旅游,消费生活",15-50人,hadoop,北京
大数据高级开发工程师,https://www.lagou.com/jobs/6565064.html,东城区,16k-30k,上海客鹭信息技术有限公司,5-10年,本科,领导好 发展空间大 五险一金 带薪年假,岗位职责：1.   负责大数据应用的架构设计、核心代码开发等任务；2.   根据项目要求编写相关技术文档；3.   负责大数据应用的架构评审，代码评审，上线评审；4.   参与数据应用需求、设计、审核和评审；5.   负责大数据平台的搭建，完成系统调试、集成与实施；6.   负责建立和维护大数据平台技术标准规范，指导开发人员编写代码。任职要求：1. 国家正规全日制大学本科以上学历；2. 具有5年以上相关工作经验；有2年以上实际大规模数据开发经验优先；3. 熟练使用JAVA，熟悉JVM调优；4. 精通离线和实时数据处理流程，掌握离线数据处理框架，掌握实时数据处理常用技术等；5. 熟悉大数据技术生态圈，精通大数据技术架构，有大数据平台构建经验；6. 掌握常见数据流接入工具；7. 熟练掌握基本的Linux操作系统和某种脚本语言编程（如Shell、Python等）；如满足下列一条或多条，优先录用1. 精通MySQL/Redis/MongoDB数据库，具备性能优化经验；2. 精通Hadoop、HDFS、Hive、Yarn，MapReduce、、Elastic Search体系搭建及开发；3. 精通Flink或Storm或Spark中的一种或多种；4. 熟悉RabbitMQ/Kafka中的一种或多种消息队列服务；5. 熟悉ETL及数据仓库搭建方案及海量数据实际落地经验；6.  熟悉K8S，docker,"信息安全,其他",50-150人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7198590.html,海淀区,20k-35k,海致网络技术（北京）有限公司,3-5年,本科,公司氛围好，发展空间大,岗位职责：1. 基于Hive， Spark，Hadoop的计算架构，进行大数据开发工作； 2. 对业务场景进行分析，通过Hive和Spark数据开发完成业务处理需求； 3. 能够定位数据计算任务的瓶颈并进行性能优化； 4. 能够针对具体的业务场景，实现基于大数据平台的服务开发。 任职要求： 1. 计算机相关本科及以上学历，具备3年以上的工作经历； 2. 熟练掌握Java、Scala、Kotlin等java系编程语言，了解Python； 3. 熟练掌握Linux、git、maven等开发相关工具的使用； 4. 熟悉数据库，SQL语法，了解数据仓库建模方法论； 5. 精通Hadoop、Hive、Spark、Hbase等相关组件，包括组件的使用和实现原理，有相关源码阅读经验优先； 6. 有ETL性能调优经验者优先； 7. 有强烈的责任心和团队合作精神，具备良好的沟通能力以及快速学习的能力。,"移动互联网,企业服务",150-500人,hadoop,北京
内推阿里云数据智能java开发专家,https://www.lagou.com/jobs/7095578.html,朝阳区,35k-65k,阿里云计算有限公司,5-10年,硕士,平台大，成长快，福利不错,"我们团队是“城市大脑”中的负责交通出行行业的产品研发团队，基于阿里云计算和大数据基础平台，通过机器学习的手段，整合客户多元数据，在诸如交通、航空、物流、环境和港口等领域，构建行业应用模型，帮助客户解决特定的业务问题，并进行数字化转型升级，过程中沉淀打造城市大脑开放人工智能平台，为政府提供城市建设的基础设施。加入我们，共创产业AI, 让各行各业拥有智慧的大脑！岗位职责：1. 负责阿里云平台类和行业类数据产品的研发、系统架构演进，驱动产品迭代开发；2. 深入行业需求与痛点，引导客户发现问题，并通过算法和模型解决；职位描述1. 五年以上JAVA开发经验，精通JAVA语言，熟悉shell、python等脚本语言；2. 精通各种主流JAVA框架，包括spring、netty、hibernate、mybatis等，对JVM原理有深层次的理解；3. 具备系统架构能力，熟悉分布式容错、分布式缓存、高并发等主流技术；4. 有分布式系统经验者优先。5. 具备2B的交付类的经验者优先。通过“阿里巴巴编码规范” 认证的同学优先录取，认证地址：https://edu.aliyun.com/certification/cldt02","电商,企业服务",2000人以上,hadoop,北京
大数据开发工程师-实时计算,https://www.lagou.com/jobs/6911874.html,朝阳区,18k-35k,慧科讯业（北京）网络科技有限公司,3-5年,本科,优秀团队，五险一金，带薪年假，年终奖,"职位描述:• 搭建公司的实时计算平台• 参与海量数据的运营数据分析体系搭建• 负责数据接入, 数据处理, 业务数据建模等工作     职位要求:• 扎实的编程能力，熟练掌握Java/Scala/Python编程• 深入理解主流的大数据和流式数据处理技术MapReduce，Storm，Spark，Flink等• 熟练运用运用数据库 如Solr, ElasticSearch, Mysql，MongoDB，Hive，HBase，Neo4j 等• 工作细致、责任心强，具备较强的学习能力及理解能力，有良好的沟通能力和团队协作能力• 有NLP相关开发经验优先• 有分布式系统、大规模线上系统开发或者大规模数据处理经验的优先",文娱丨内容,500-2000人,hadoop,北京
大数据开发工程师-AWS方向,https://www.lagou.com/jobs/7141357.html,朝阳区,25k-50k,慧科讯业（北京）网络科技有限公司,3-5年,本科,五险一金，年底双薪，优秀团队,"岗位职责:• 搭建公司的实时计算平台与作业管理平台• 参与海量数据的运营数据分析体系搭建• 负责数据接入, 数据处理, 业务数据建模等工作     • 负责作业管理平台相关开发，任职要求:• 扎实的编程能力，熟练掌握Java/Scala/Python编程• 深入理解主流的大数据和流式数据处理技术MapReduce，Storm，Spark，Flink等• 理解AWS服务（EC2, S3, RDS等）及相关概念（IAM, 区域，可用区等）• 有基于公有云开发资源调度平台的经验。• 工作细致、责任心强，具备较强的学习能力及理解能力，有良好的沟通能力和团队协作能力• 持有AWS相关认证优先• 基于AWS开发过相关平台或公司使用AWS运行工作负载优先• 有NLP相关开发经验优先• 有分布式系统、大规模线上系统开发或者大规模数据处理经验的优先",文娱丨内容,500-2000人,hadoop,北京
高级Java开发工程师（大数据抓取平台方向）,https://www.lagou.com/jobs/5967055.html,东城区,15k-30k,北京猫眼文化传媒有限公司,3-5年,本科,发展空间大、领导nice,工作职责 1、负责开发维护大规模分布式的数据抓取系统，设计底层架构，解决系统的吞吐瓶颈问题，提高系统的可用性。2、为舆情系统，影视剧数据分析提供高效、可靠的大数据支持。  职位要求1、熟悉爬虫系统的工作原理，掌握HTTP等互联网基础通讯协议，了解Web页面解析的基本技术，具有hacker钻研精神。 2、3年以上Java开发经验，编程基础扎实。对数据库，Kafka消息队列，redis缓存系统有一定了解。3、对海量数据存储，高并发、高吞吐系统有一定的架构设计能力。分析问题能力强，能解决分布式系统中遇到的性能瓶颈问题。4、具备985/211名校背景者优先，对大数据分析有一定了解者优先。,文娱丨内容,500-2000人,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/6572339.html,东城区,15k-30k,北京猫眼文化传媒有限公司,3-5年,本科,高成长,团队介绍：负责猫眼大数据应用平台建设，探索数据平台驱动数据运营，支撑公司数据精细化运营发展。岗位描述：参与大数据应用服务数据全生命周期平台研发工作，包括用户标签体系，精准攻防体系，计算引擎，用户触达(push、短信等)，数据接口编排引擎等核心功能等设计与实现。岗位要求：1、本科及以上学历，熟悉LINUX，JAVA/Python基础扎实，五年以上工作经验，三年以上大数据系统分析、设计和实施经验；2、熟悉Hadoop生态圈主流技术及产品，深入了解Kafka、Storm、Spark、Hive、HBase、Kylin等有实际应用、维护和优化经验；3、具备丰富的大型互联网日志采集处理系统设计或架构经验，具备较扎实的理论基础和工程能力，熟悉HTTP、HTTPS、RPC等协议，熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息、队列等机制，能对分布式常用技术进行合理应用，解决实际架构问题；4、有大中型大数据项目实战经验，熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析和挖掘；5、有用户画像服务系统搭建相关经验者优先；6、较强的责任心，良好的敬业精神和团队协作精神，较强的沟通协调能力和学习能力，能够承受较大的工作强度和工作压力。,文娱丨内容,500-2000人,hadoop,北京
数据库运维开发工程师,https://www.lagou.com/jobs/6663500.html,海淀区,30k-50k,北京金山云网络技术有限公司,3-5年,本科,绩效奖金免费三餐健身房员弹性时间,工作职责1.负责数据库服务的架构设计、性能优化、故障处理等2.制定并实施数据库运维管理规范，为业务提供数据库的解决方案与技术支持3.负责数据库运维平台的开发工作，包括服务健康度监控、自动故障处理、集群扩缩容等任职要求：1.2年以上DBA相关工作经验，熟悉MySQL/PostgreSQL/Oracle/SQLServer等主流数据库的体系结构和工作原理2.熟悉常见存储引擎的原理、特点，以及高可用方案的实践3.熟悉常用中间件的解决方案，如Mycat、Atlas等4.有一定的开发能力，熟悉Shell、Python、Php等脚本编程语言5.良好的沟通、协调能力，善于解决和分析问题，富有想象力和学习能力,"移动互联网,数据服务",2000人以上,hadoop,北京
金融-大数据开发工程师,https://www.lagou.com/jobs/6753958.html,海淀区,20k-40k,北京小米科技有限责任公司,不限,本科,上升空间大，年底奖金丰厚,1、负责小米金融大数据处理pipeline的开发与维护；2、负责小米金融业务数据的接入、清洗、转换、统计、多维分析和展现；3、把数据挖掘，机器学习等算法运用在金融大数据上。 任职资格：1、本科或以上，计算机软件或相关专业毕业；2、扎实的编程能力，熟悉算法和数据结构，熟悉计算机的基础理论；3、熟练使用 Java，熟悉SQL，熟悉Python或Scala；4、熟悉大数据处理相关技术，包括但不限于 Hadoop、Hive 、Hbase、Impala、Spark 、Kafka、Flume、Sqoop 、Storm等；5、熟悉推荐系统和数据挖掘算法者优先。,硬件,2000人以上,hadoop,北京
时序数据库开发工程师（FBS1wc）,https://www.lagou.com/jobs/7149221.html,朝阳区,10k-20k,北京东方国信科技股份有限公司,1-3年,本科,13薪、六险一金、节日福利、定期体检,工作职责:1. 负责分布式时序数据库存储和计算相关功能的研究和开发；2. 负责时序数据查询性能的优化工作；任职资格:1. 本科及以上学历；2. 熟练掌握至少一种下列编程语言 java、C++、golang；3. 良好的团队协作能力、沟通表达能力和文档编写能力；4. 熟练掌握多线程、异步编程、网络编程技术；5. 熟悉分布式系统理论，对分布式协议、时序索引结构、近似查询索引、一致性协议、存储引擎、查询优化等分布式数据库相关技术的优先；6. 对时序数据库引擎和系统OpenTSDB、InfluxDB等有深入研究和相关经验的优先；7. 有IoT系统相关数据处理经验的优先。8. 有存储系统设计研发工作经验的优先。待遇：月薪12k-20k，14月薪希望你：1. 可以没有时序数据库相关研发设计经验，但是要有积极向上，努力学习的心；可以非计算机背景，但是至少需要有足够的逻辑思维能力和基本的编程能力；2. 拥有钻研技术的耐心，拥有坦诚沟通和团队合作的同理心，拥有hold住分内工作的责任心。在这里：1. 导师制度，一对一辅导培训，让你尽快融入工作中，也能帮忙解决生活种种小麻烦2. 宽敞的工位，独立食堂，不定期团建千里之行，始于投简历，wait for you!,数据服务,2000人以上,hadoop,北京
流数据库高级开发工程师（lx）,https://www.lagou.com/jobs/6475502.html,朝阳区,20k-40k,北京东方国信科技股份有限公司,1-3年,本科,十三薪、年终奖、节日礼品、定期体检,"工作职责:1、负责流数据库的设计&开发； 2、参与流数据库需求对接、支持以及落地工作；3、制定合理切实可行产品研发计划；4、建设统一的SQL平台，为业务提供高效便捷的数据查询和计算服务。任职资格:1、本科及以上学历，计算机相关专业，3年以上工作经验；2、熟悉Java，Scala以及多种编程语言，优秀的编程能力及良好的开发习惯，能够快速的阅读开源项目源代码，具备独立沟通需求，设计，开发、重构的能力；3、熟悉一门以上的大数据实时计算引擎。如: Flink, Spark等，熟悉核心部分代码；4、扎实的文档功底具备需求规格说明、概要设计及市场宣讲文档编写能力。加分项：1、熟悉Flink计算引擎，有参与Flink开源社区。",数据服务,2000人以上,hadoop,北京
Java高级开发工程师/专家-数据智能部-金融风控,https://www.lagou.com/jobs/6458960.html,朝阳区,25k-45k,高德软件有限公司,3-5年,本科,优厚的福利待遇，大平台，发展前景广阔,职位描述                                                                                       1. 负责高德金融风控相关引擎开发 2. 持续优化系统架构设计，提出问题解决方案 职位要求 1、3年及以上Java开发经验，熟悉基本的数据结构、面向对象设计，熟悉Java网络编程、多线程编程，对JVM原理有扎实的理解； 2、熟练掌握SpringMVC（SpringBoot）、MyBatis等主流的开发框架，并有深入了解和实践经验； 3、熟悉分布式计算和存储，消息队列和流式计算，掌握容器相关的基本知识； 4、有大数据处理经验，熟练使用mysql、hbase、mongodb、redis等各类存储的常用方法，并能给出合适的存储解决方案； 5、熟练使用Linux环境，能进行shell编程，及对Python有一定的基础； 6、熟悉软件技术文档的编写，具备良好的文档编制习惯和代码书写规范； 7、思路清晰，有良好的需求理解、分析、抽象能力和系统设计能力； 8、较强的沟通表达能力；工作主动积极、认真严谨，对系统质量有近乎苛刻的要求意识； 9、有机器学习模型线上部署运维经验者优先,工具,2000人以上,hadoop,北京
数据库内核开发工程师,https://www.lagou.com/jobs/6884387.html,海淀区,35k-70k,华为技术有限公司,3-5年,本科,能力优秀者薪酬待遇上不封顶。,"【部门介绍】    高斯实验室是华为数据库核心研发部门，研发团队扛鼎华为云端的数据治理和使能。团队分布于中国（深圳、北京、上海、西安）、加拿大、德国、印度、以色列等地，你可以和全球的**Fellow专家并肩作战，快速提升自身的职场竞争力。团队同时和世界**高校、研究机构开展广泛的合作，结合云化和大数据、人工智能发展趋势，通过持续不断的技术创新，构建新一代世界领先数据库平台。【岗位要求】1、计算机相关专业，本科及以上学历，工作两年以上；2、熟练掌握C/C++，Python语言之一；3、了解常用的软件架构模式、基本的编程编译工具；4、熟悉Linux操作系统、数据库应用，熟悉代码优化的规则与技巧；5、拥有数据库领域编码经验，熟悉SQL和存储引擎的优先。6、具备3年以上工作经验。【岗位职责】1、负责数据库领域的需求分析、设计、开发等工作;2、负责业界领先的云端到终端各层次内核数据库研发,基于操作系统内核技术构建数据库高性能、高可用等核心竞争力;3、负责数据库内核相关领域的新技术探索。【工作地点】北京/上海/深圳【注意事项】接受校招和实习",通讯电子,2000人以上,hadoop,北京
高级大数据开发,https://www.lagou.com/jobs/5910618.html,海淀区,25k-40k,秒针信息技术有限公司,5-10年,本科,六险一金，补助，团建，双休,"工作职责：- 负责知识图谱产品核心功能的设计和开发- 带领中初级开发完成开发目标任职要求：- 能接受短期非频繁出差- 工程技术基础熟练的数据结构和算法编程能力Linux操作经验MySQL/SQL关系型数据库使用经历Maven，Java开发调试能力、JVM基础- 大数据基础熟悉HDFS&Yarn，MapReduce原理 或 Spark执行原理熟悉Hbase存储和查询原理，对Hbase适用场景和关键问题有认识对索引，并行计算，存储原理有独到的见解熟悉常用的图算法- 大数据开发项目面向大数据平台组件做过相关开发工作，比如数据接入治理：flume, kafka, hive, spark streaming等数据存储和查询：hbase，sparksql等有分布式系统开发经历在项目中承担了重要的开发角色，有一定的方案设计能力- 加分项有知识图谱、图数据库相关工作经历开源项目贡献","数据服务,广告营销",2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7184091.html,朝阳区,26k-52k,北京京东尚科信息技术有限公司,3-5年,本科,注重人才培养，办公地点朝阳。,"工作内容和方向：1、基于hive/hadoop/storm/spark/flink等计算框架，进行离线/实时业务推荐开发。2、基于Hive/Presto/Impala/Clickhouse/ES/Kylin/Hbase/clickhouse等引擎进行实时数据分析平台建设。3、具备较强Java功底，结合大数据技术进行数据管理和监控平台建设。4、具备一定的机器学习算法知识并具备运用到线上业务经验。任职要求：1、本科及以上学历，计算机相关专业；2、熟练Java语言，有四年以上java开发经验，对分布式有深刻理解。3、熟悉Hadoop/Storm/HIVE/Hbase/spark/Flink等分布式开源项目及其工作原理，并有实际开发经验。4、了解常用的机器学习算法。5、熟悉常用脚本语言shell,python等。6、有互联网或移动互联网公司背景优先。",电商,2000人以上,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/7151933.html,西城区,18k-35k,建信金融科技有限责任公司,5-10年,本科,五险一金,,"金融,软件开发",2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7047649.html,海淀区,30k-55k,北京达佳互联信息技术有限公司,3-5年,本科,五险一金，三餐免费，下午茶等,"1、负责数据管理平台（DMP）技术架构搭建、设计、开发与维护；2、负责广告投放中的用户行为日志采集、大数据建模分析、业务系统数据展示工作；3、为公司运营部门提供数据分析支持。任职要求1、2年以上大数据相关开发经验；2、了解HDFS, Hbase, Strom, Kafka等原理, 熟练使用 MR/streamming/hive/spark 完成业务问题；3、熟悉Linux下开发, 熟练使用shell/php/golang/python等脚本语言；4、有数据分析相关经验, 了解基本数据分析工具；5、针对业务系统数据需求, 能够设计合理的数据收集, 处理方案。加分项：1、有大规模数据收集,日志处理经验；2、有实时日志数据收集处理经验；3、对关系型数据库, 数据建模有经验；4、了解机器学习算法；5、深入研究过大数据框架的运行机制、实现原理、源码者。",文娱丨内容,2000人以上,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/5355843.html,海淀区,8k-10k,福建顶点软件股份有限公司,1-3年,本科,六险一金、员工旅游、节日福利、生日福利,岗位职责：证券行业数据类应用开发与实施；岗位要求:1.计算机相关专业，大学本科及以上学历；2.两年以上软件开发经验，一年以上数据库开发经验；3.熟悉ORACLE数据库开发；4.积极，主动，敬业，对开发有浓厚兴趣、有良好的自学能力和沟通能力。,"移动互联网,企业服务",500-2000人,hadoop,北京
大数据安全产品开发工程师,https://www.lagou.com/jobs/3777505.html,东城区,15k-25k,联通大数据有限公司,3-5年,本科,"岗位提升,能力提升,技术提升,市场化薪酬",岗位职责:1.负责公司对外大数据安全产品的设计和开发；2.负责公司对外大数据产品和方案中安全相关的技术支撑。 岗位要求：1.计算机、软件工程、通信相关专业全日制本科以上学历；2.3年以上安全产品研发经验，有1年以上数据加密解密、数据追踪溯源、大数据流通和共享的安全基础设施、大数据态势感知方面产品研发经验。3.了解信息安全基本原理，了解主流安全技术；4.具有良好的沟通能力，具备较强的新知识学习能力，具有强烈的进取意识及责任心，诚实敬业；5.有较强的Java独立编程能力优先，有实际开发的系统案例者优先；6.有linux下开发部署经验者优先，有主流安全厂商研发工作经验者优先。,数据服务,150-500人,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/7211392.html,朝阳区,14k-16k,北京瑞友科技股份有限公司,3-5年,本科,有加班费 缴纳五险一金 早九晚六 双休,学历 学历 本科专业 计算机、信息技术相关专业技术 精通 SQL（基于Oracle的SQL脚本及存储过程的开发及调优）熟练掌握 至少熟悉一种主流ETL工具熟练掌握 同时有Java应用开发经验者优先人员 工作经验 3年（含）以上项目经验 有数据平台、数据仓库、报表开发项目经验者优先行业经验 有金融行业项目经验者优先,电商,2000人以上,hadoop,北京
大数据开发实习生,https://www.lagou.com/jobs/6657890.html,朝阳区,10k-15k,包子科技（北京）有限公司,应届毕业生,本科,团队氛围好 扁平管理 五险一金 绩效奖金,岗位职责：1、参与数据平台开发与建设，包括但不限于数据ETL、数仓建设、数据BI产品；2、参与推荐系统业务和电商业务系统的数据化探索和数据价值挖掘。任职资格：1、本科及以上学历在读，每周能保证5天，优秀者可转正；2、熟悉数据仓库产品，对数据处理、维度建模、数据分析等有了解，如Hadoop/Hive，Storm/Spark，Flink等；3、对大数据平台的构建和实现机制有深刻的理解，有大数据平台开发经验优先；4、对大数据、云计算、开源软件、数据仓库类产品有一定的深度和广度；5、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python其中一门编程语言，有较强的分布式计算基础和算法工程能力；6、具备较好沟通协调能力，主动建立与业务的紧密合作，推动业务升级,"移动互联网,电商",150-500人,hadoop,北京
高级JAVA开发工程师-大数据平台(J11605),https://www.lagou.com/jobs/7176234.html,海淀区,13k-18k,北京天融信网络安全技术有限公司,3-5年,本科,上市企业、网络安全、分布式、大数据平台,,信息安全,2000人以上,hadoop,北京
高级JAVA开发工程师（大数据方向）,https://www.lagou.com/jobs/6966391.html,海淀区,30k-60k,北京奇艺世纪科技有限公司,3-5年,本科,海外业务 大平台 扁平化管理 发展空间大,职位描述： 1、负责推荐系统特征仓库建设，规范底层数据存储，结构化查询逻辑，方便快捷获取数据； 2、负责行为数据统计任务（离线、实时）的实现； 3、负责算法相关训练数据的预处理工作 。任职资格： 1、精通Java，编程基础良好；本科或以上学历，计算机专业，3年以上大数据项目开发经验； 2、具有Hadoop/Spark开发与应用经验，有较大规模的项目经历并能应用在生产环境； 3、熟悉hbase、hive、YARN、Storm、zookeeper等大数据相关工具，并有处理TB级以上数据的项目经验； 4、熟悉Linux，掌握Python/Shell等脚本工具优先； 5、有实时流架构经验，熟悉常用的数据挖掘算法，有数据平台建设经验； 6、熟悉docker/impala/elasticsearch/mongodb等技术的优先。温馨提醒：如果 7 天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可。,文娱丨内容,2000人以上,hadoop,北京
大数据开发工程师，架构师,https://www.lagou.com/jobs/7165357.html,海淀区,35k-65k,百度时代网络技术（北京）有限公司,不限,本科,大数据，架构师,1、架构师工作职责:-负责集团大数据计算技术体系的整体规划和架构设计，持续提升算力，支撑日均数百E级别数据量的计算需求-负责大数据计算方向的难点攻关、前瞻研究、指导审核团队技术方案和解决方案-领导大数据计算产品，使其具备市场竞争力职位要求:-本科及以上学历，具备10年以上大数据计算引擎领域的工作经验，有FLAG、BATJ等企业的架构师工作经历优先-精通Spark和Flink，熟悉3个以上大数据框架包括不限于hadoop/hive/Kfk/druid等-具备丰富的大数据引擎开发经验，commiter优先-具有宽广的技术视野，精深的技术功底，良好的工程素养，优秀的分析和解决问题能力-为人正直，良好的团队合作能力和沟通能力，抗压能力强，具有较强的自我驱动力2、大数据计算引擎开发工作职责:-研发大规模分布式计算系统，包括高吞吐的批量计算、高时效的流式计算、高效能的OLAP等-为全百度提供高性能、高可用、低成本的计算服务-探索新架构、新技术、新硬件，设计下一代分布式计算系统职位要求:-本科及以上学历，计算机专业优先-熟悉Hadoop/Spark/Flink/Hive/Druid/Yarn等任一项主流开源技术，具备类似技术的引擎研发经验-有5年以上大规模系统软件的研发经验，如操作系统、存储系统、数据库系统、计算系统等，熟悉网络编程、多线程编程、操作系统原理-对分布式数据计算或数据分析的原理、架构及使用调优有一定经验和深入见解者优先，精通Spark优先-具备扎实的编程能力，良好的工程素养，团队合作能力和沟通能力强，抗压能力强，具有较强的自我驱动力3、大数据开发olap方向工作职责:-研发大规模分布式计算系统，包括高吞吐的批量计算、高时效的流式计算、高效能的OLAP等-为全百度提供高性能、高可用、低成本的计算服务-探索新架构、新技术、新硬件，设计下一代分布式计算系统-构建高性能Olap数据平台，提供多种在线服务职位要求:-本科及以上学历，计算机专业优先-对常见的olap引擎有深入研究及优化经验-熟悉多维分析和数据建模，具备基于海量数据的olap实战经验-熟悉云数据库的构架，有核心模块涉及和开发经验-熟悉机器学习，有数据挖掘和深度数据分析者优先-有前沿数据库技术的敏锐度，并能够持续跟踪关注相关技术,工具,2000人以上,hadoop,北京
Java开发工程师-数据中间件方向,https://www.lagou.com/jobs/6741522.html,朝阳区,12k-18k,深圳市金蝶天燕中间件股份有限公司,3-5年,本科,发展空间大 平台大 福利好,"岗位职责：1.参与软件产品的需求调研和需求分析，撰写相关技术文档 ；2.负责数据中间件产品研发、优化工作；3.参与数据中间件产品测试、部署和集成；4.负责解决开发过程中的技术攻关问题；5.参与团队技术研讨交流和分享活动，促进团队进步和个人能力提升。 任职要求：1. Java基础扎实，精通多线程、并发、集合、网络、IO等基础知识，熟悉JVM；2. 熟练掌握各类算法、常用数据结构、设计模式；3. 理解SpringMVC，SpringBoot, Mybatis, Dubbo, Zookeeper等领域的框架或产品的机制与代码；4. 熟悉 SQL、NoSQL、缓存、Kafka、队列、异步框架等技术；5. 熟悉高性能、高并发系统设计方案，如分布式缓存、ElasticSearch、消息队列等；6. 思路清晰，优秀的分析与沟通能力；7. 3年以上工作经验，大学本科以上，熟练阅读英文技术文献.",企业服务,150-500人,hadoop,北京
数据开发,https://www.lagou.com/jobs/6143353.html,朝阳区,20k-40k,北京猿力未来科技有限公司,不限,硕士,五一9天假、旅游津贴、餐补、双休,岗位职责：1、负责设计与实现数据仓库；2、确保数据指标完备性和正确性;3、根据具体的业务需求构建业务分析模型，对海量数据进行分析，利用数据分析模型对产品与运营做出指导；4、负责业务建模和数据分析方向前沿技术的调研。岗位要求：1、计算机、数学或其他相关专业，硕士及以上学历，同样欢迎2020年毕业的应届生；2、熟悉Hadoop，熟悉Hive，Pig的使用，有数据仓库的开发经验；3、熟悉Linux开发环境，具有良好的编程基础，掌握C/C++/Java/Python/PHP等至少一门高级编程语言；4、熟悉常用的数据结构和算法，了解各种建模方法，熟悉MySQL等关系型数据库；5、有大数据分析工作经验优先；6、对数据敏感，具有较强的逻辑思维能力和分析解决问题能力；7、具备良好沟通能力和团队合作精神，工作认真细致，责任心强。,"移动互联网,教育",2000人以上,hadoop,北京
高级数据开发/仓库,https://www.lagou.com/jobs/7019468.html,朝阳区,30k-50k,上海丁酉网络信息服务有限公司,5-10年,本科,福利待遇好,岗位职责： 1、搭建并优化数据体系，负责数据仓库方向、数据应用方向开发和管理工作；2、带领小伙伴构建金融及其各个业务线数据仓库（分层建设、主题模型、元数据管理、性能和效率优化）； 3、参与/负责相关 BI 系统建设及其解决方案落地，规划并带领小伙伴试错、成长；4、负责数据仓库 OLAP 体系搭建，建设 PB 级高效、灵活的在线分析应用； 5、受理数据日常需求开发，与分析师、PM、OP 一起感知变化，实现高效的数据运营； 6、与团队一起调研和实践热门数据仓库组件和技术（kylin、spark、doris、storm、实时数仓......）。 任职要求： 1、4 年以上数据仓库(DW) / 商业智能(BI) / 数据统计相关工作经验； 2、3 年以上数据团队管理经验优先考虑，有成功的案例和项目管理经验，能规划技术路线； 3、有支付、金融、风控等系统数据建设经验优先； 4、熟悉数据仓库建设方法论： a：熟悉 etl 分层（ODS、CWD、DWD、AWD）建设方法；b：熟悉主题建设方法，能独立抽象主题、建设模型、物理化并调整效率和性能； c：熟悉常用的 BI 系统建设方法，熟练使用主流 BI 工具，理解其实现原理、使用什么技术解决什么问题； 5、熟练掌握 SQL，理解 Hive/MySQL/Oracle 原理和调优方法，有独立处理大规模数据/日志的经历；6、熟练掌握 Java / Python / PHP 中至少一种编程语言。,金融,15-50人,hadoop,北京
数据库运维开发工程师,https://www.lagou.com/jobs/6429247.html,海淀区,25k-50k,作业帮教育科技（北京）有限公司,3-5年,本科,高速发展期，大厂班底，成长快，氛围好,岗位职责： 1、负责RDS运维平台的研发，实现数据库运维的自动化、标准化、服务化； 2、构建、优化线上数据库的监控、高可用、容灾体系，确保数据库7*24稳定运行； 3、参与作业帮所有数据库集群的运维和管理，优化运维流程； 4、自动化运维脚本的编写和优化； 5、协助并支持团队其他小伙伴解决疑难问题。 任职资格： 1、精通Python、Shell开发，熟悉Django等常用Web框架； 2、熟悉Linux操作系统原理，TCP/IP以及常用的网络协议； 3、有设计和开发自动化运维平台的能力和经验； 4、了解数据库基本原理，具有一定的MySQL、Redis运维经验； 5、为人诚实正直，具有良好的逻辑分析和沟通协作能力，做事认真，有责任心，有主动性。    6、有大型互联网公司数据库平台及运维平台开发经验优先； 7、本科以上学历，计算机相关专业。,工具,2000人以上,hadoop,北京
资深大数据开发工程师,https://www.lagou.com/jobs/7108202.html,海淀区,20k-40k,北京新意互动数字技术有限公司,5-10年,本科,上市公司，扁平化管理。福利齐全,工作职责：1、负责公司产品平台的架构设计与构建，技术改进与性能优化；2、负责面向海量数据查询、数据计算、数据存储以及数据模型与管理的基础架构搭建；3、负责规划技术发展方向，新技术领域的探索，将新技术应用到项目中，并回馈开源社区；4、参与技术团队建设和学习成长，为团队整体的知识积累，技能提升做贡献。任职资格：1、熟练掌握java/scala/python开发语言以及相关框架，有大型项目经验优先；2、负责过大型数据平台或者数据仓库设计，具有扎实的大数据和数据仓库的理论功底；3、对Hadoop的大数据体系有深入认识，对Hadoop/Kafka/Spark/Druid/clickhouse等有实际应用研发经验，读过关键源码为佳；4、具备良好的问题分析能力、沟通能力和团队合作能力，具备很强的学习和钻研能力；5、本科以上学历，5年以上相关工作经验；6、关注技术发展趋势，热爱开源，为开源项目贡献过代码优先。,广告营销,500-2000人,hadoop,北京
​腾讯广告大数据开发工程师（北京）,https://www.lagou.com/jobs/7001130.html,海淀区,20k-40k,腾讯,3-5年,本科,大平台,工作职责负责广告转化链路服务的架构设计和开发，支持高并发，高可用，低延迟；负责高可用的任务调度系统开发，支持各种离线任务的分发和调度；工作要求重点大学本科以上学历，计算机相关专业，两年以上相关工作经验，精通算法与数据结构，精通java或c++编程语言；有海量后台服务支撑经验，熟悉spark等大规模数据计算引擎，有扎实的编程功底和编码习惯，以及良好的分析解决问题能力;积极主动，有责任心，勇于接受挑战。,"移动互联网,游戏",2000人以上,hadoop,北京
Hive离线数据仓库开发工程师,https://www.lagou.com/jobs/7110393.html,朝阳区,20k-40k,北京嘟嘟一下科技有限公司,3-5年,本科,不打卡，弹性工作,欢迎通过如下链接快速了解我们：https://www.baidu.com/s?rtt=1&bsst=1&cl=2&tn=news&rsv_dl=ns_pc&word=%E5%B0%8F%E6%89%93%E5%8D%A1岗位描述： 1、根据不同的业务场景，构建业务指标体系，建立和完善日常业务报表，提供决策数据支持，包括但不限于：基于Hive离线数据仓库分层模型设计，报表的开发，专题分析，业务洞察以及AB实验评估等;2、为线上服务提供数据接口； 3、分析挖掘业务 ； 4、数据异常预警开发；5、基于流计算实现实时数据统计；6、基于BI数据报表可视化；7、AB test以及埋点系统开发设计；8、用户画像建设等小打卡良好的数仓分层体系对齐BAT等一线互联网企业架构，基于阿里云Dataworks+odps实现数千个离线任务调度，业务增长迅猛，拥有丰富的数据应用场景，期待你的加入，和我们一起迎接更大的挑战~岗位要求： 1、本科以上学历，1-5年大数据相关工作经验； 2、熟练掌握大型数据库开发技术，能灵活运用Hive SQL实现海量数据ETL加工处理与查询性能调优； 3、掌握数据仓库维度建模设计方法论以及基本数据结构和算法，并有实际基于Hive的离线数仓模型设计及ETL开发经验 （硬性条件）；4、熟悉Hadoop  / Hive / Mysql / Hbase / ES / Redis / kafka 等优先， 有相关源码有研究更佳;5、熟悉常用的数据分析的工具和方法优先；有java(spring boot)接口开发经验优先；熟悉flink流计算优先；熟悉linux平台，精通shell/python等脚本语言的一种或多种，编码基本功扎实优先； 6、具备快速学习能力、沟通协调能力及团队精神，有较强的责任心和抗压性。,"移动互联网,数据服务",50-150人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5825616.html,朝阳区,9k-15k,中国科学院信息工程研究所,不限,本科,平台大、百TB级数据、团队氛围好,职位描述1.主导数据仓库基础架构的建设，以满足数据仓库对时效性、正确性、可扩展性和易用性的要求；2.通过分析相关系统，梳理潜在的数据源和日志清洗需求，并设计合适的、可扩展的数据模型；3.开发并维护数据流水线，挖掘数据中的有价值信息，发挥大数据价值，帮助各个部门用数据驱动决策。4.参与流数据引擎的开发任职要求：熟悉java语言，熟悉基本的数据结构、算法，基础扎实；熟悉Hadoop大数据生态相关组件，包括但不局限于hive、hbase、kafka、spark、elasticsearch、flink和yarn等；熟悉linux系统基本操作，会shell脚本更好；,通讯电子,500-2000人,hadoop,北京
云粒智慧-大数据开发工程师/专家,https://www.lagou.com/jobs/5691560.html,西城区,20k-40k,云粒智慧科技有限公司,5-10年,本科,"技术大牛,不打卡，人工智能","岗位职责：1、参与分布式大数据处理系统和数据服务基础设施的架构设计和开发；2、和产品经理一起梳理和完善系统功能需求；3、改进系统性能；任职要求：1、了解分布式、微服务、传统关系型数据库、常用NoSQL开源系统、RESTful、基本的信息安全领域知识2、精通Java代码，其他语言不限制具体要求：1、本科及以上学历，3年以上大型互联网产品或分布式系统开发设计经验；2、丰富的Java研发经验,精通Java, 熟悉Shell或Python等一种或几种脚本语言者优先；3、熟悉常用分布式系统相关理论基础，有一定的分布式系统开发经验，有互联网公司中大型分布式系统经验优先4、具备Spring Cloud等微服务设计和开发经验和能力；5、熟悉大数据技术栈,对Hadoop、Hive、Spark、Hbase、Kafka、ELK等开源组件有使用及优化经验者优先","移动互联网,企业服务",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7089157.html,西城区,15k-30k,维恩贝特科技有限公司,3-5年,大专,六险一金；定期体检,"岗位要求：1、精通SQL语句，同时具备JAVA、Python等语言开发能力2、 熟悉阿里大数据组件开发流程；3、能够熟练使用DataWorksMaxCompute, DataWorks, StreamCompute，ECS， RDS等工具,能够基于该工具开展数据分析；4、能够熟练使用DataHub、DTS、Blink、Spark等阿里相关组件进行数据集成或开发，熟练使用OGG、Informatica ETL配置及开发；5、具有一定技术方案规划能力及文档编写能力6、具有4年以上阿里云大数据开发工作经验；7. 较好的沟通理解能力，性格乐观，态度踏实，积极上进；8、具备ACP大数据者优先。",电商,500-2000人,hadoop,北京
数据产品经理-【数据开发管理】,https://www.lagou.com/jobs/7092610.html,海淀区,20k-40k,北京快手科技有限公司,不限,不限,免费三餐，丰富下午茶、健身房,职位描述：1、负责设计一站式数据开发管理工具，提供数据集成、数据开发、数据管理、数据质量和数据服务等全面产品服务；2、优秀的跨团队项目管理、沟通管理能力，提升团队的产品意识及能力，用数据说话，提升团队的整体影响力；3、全面参与数据产品的需求分析、产品规划、方案设计、项目管理以及线上产品运营等工作，对产品最终结果负责；4、组织数据开发工具对外使用培训，跟用户良好互动，根据反馈分析持续优化产品；任职要求：1、3年以上数据产品经验，设计过数据开发相关工具或者有过数据开发相关经验优先；2、对于Hadoop生态相关的技术有一定的了解，了解离线数据开发以及流式数据开发；3、具备清晰的逻辑分析能力，并能够把复杂场景的分类分析并能抽象成解决的方案；4、具备良好的用户思维，能够从用户角度出发思考问题；5、良好的沟通能力，系统思考能力，以及产品设计能力,移动互联网,2000人以上,hadoop,北京
美团打车-数据开发（风控）,https://www.lagou.com/jobs/7141610.html,朝阳区,30k-50k,北京三快在线科技有限公司,3-5年,本科,平台大，氛围好,,消费生活,2000人以上,hadoop,北京
数据仓库开发高级工程师,https://www.lagou.com/jobs/6770935.html,海淀区,20k-40k,北京字节跳动科技有限公司,3-5年,本科,六险一金,,文娱丨内容,2000人以上,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/7147918.html,海淀区,20k-40k,北京字节跳动科技有限公司,3-5年,本科,扁平管理，用户过亿，大牛带队,"职位描述1、负责安全数据中台模型设计，ETL设计与开发流程优化；2、负责数据仓库整体架构改进与流程优化；3、负责整理并分析相关的数据需求，运用BI技术为运营、管理提供决策依据；4、推动团队内成员技术经验分享，关注相关前沿技术研究，通过新技术服务团队和业务。职位要求1、本科及以上学历，计算机、软件工程等相关专业优先；2、3年以上数据仓库工作经验，3年以上数据仓库建模经验，主导过大型数据仓库类项目的模型设计与开发工作；  3、精通hadoop/hive/hbase/kylin；4、精通spark/flink等实时计算 ,了解spark mllib/python sklearn等机器学习优先；5、掌握主流bi工具如tableau等。      福利：下午茶，健身瑜伽，六险一金，团队氛围好，晋升空间大，带薪休假，扁平管理，用户过亿，大牛带队，免费三餐，租房补贴",文娱丨内容,2000人以上,hadoop,北京
数据开发/数据仓库,https://www.lagou.com/jobs/7138381.html,朝阳区,30k-60k,北京三快在线科技有限公司,5-10年,本科,发展空间大 技术氛围好,,消费生活,2000人以上,hadoop,北京
广告数据开发工程师（实时数据）,https://www.lagou.com/jobs/6885653.html,海淀区,30k-50k,北京奇艺世纪科技有限公司,3-5年,硕士,六险一金、发展空间,岗位职责：1、海量广告日志数据的收集、处理、报表计算及自动化任务管理及监控平台开发；2、广告数据实时/流计算平台设计、开发与调优，要求低延迟，高并发，精确一次，支持品牌，效果，RTB等多种业务 ；3、负责实时/流计算平台线上运维、保障系统稳定和高可用，解决大并发下的各种问题。任职要求:1、较强的学习和动手能力，对大数据领域有兴趣；2、两年流计算应用开发或流计算平台开发相关经验；3、精通Flink、Spark Streaming任意一项，熟悉Kafka、kudu底层机制；4、精通Java，熟悉Scala语言；5、本科或本科以上学历，计算机/电子／通信／统计／数学相关专业优先，有广告相关背景优先。温馨提醒： 如果 7 天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可,文娱丨内容,2000人以上,hadoop,北京
Python数据处理开发工程师-0301,https://www.lagou.com/jobs/7126363.html,海淀区,10k-15k,北京视野金融信息服务有限公司,3-5年,本科,五险一金 定期团建,岗位职责：1、负责各类数据的爬取、接口调用接入，清洗、转换、融合入库以及数据处理性能调优等工作；2、根据业务、产品和项目相关需求，负责数据验证、数据管理、数据服务接口、数据分析等功能的开发维护工作； 岗位要求：1、计算机、数学或统计等相关专业本科及以上学历，2年以上相关工作经验；2、熟悉linux平台，熟练掌握Python、SQL、ETL数据处理开发工作；3、能够熟练使用Redis、MySQL、Mongo、ES等数据库工具进行数据处理开发和维护工作；4、熟练掌握数据处理性能调优、数据管理和维护等工作;5、具备大数据处理开发（Hadoop/Hive，Storm/Spark等）相关工作经验者优先考虑；6、具备良好的编程习惯和逻辑思维能力；7、具备创业心态，善于学习，热爱技术开发，善于团队协作，能积极主动地参与公司产品研发等相关工作。,"移动互联网,金融",50-150人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7016845.html,海淀区,15k-30k,北京酷划在线网络技术有限公司,5-10年,本科,舒适工作环境 诱惑薪酬福利 良好文化氛围,大数据研发工程师工作职责:- 负责实时数据平台的数据流研发和优化工作- 建设数据分析平台以及相关模块，满足业务需求- 管理维护ETL任务 为各业务线提供数据支持职位要求:- 本科及以上学历，计算机科学、数学等相关专业- 熟悉Linux，熟练掌握shell、Python语言- 熟悉Hadoop、Hive、Impala、Flink，拥有海量数据处理经验- 熟悉Hive Sql，能分析和定位数据异常，有强烈的责任心- 积极、主动，具备良好的学习能力、抗压能力和团队协作能力,移动互联网,150-500人,hadoop,北京
大数据平台高级开发,https://www.lagou.com/jobs/6974653.html,朝阳区,16k-32k,深圳市赢时胜信息技术股份有限公司,5-10年,不限,上市公司，薪酬体系具有竞争力，福利多样化,"岗位职责：1、建设大数据平台；2、基于大数据平台的应用系统设计、开发、维护。任职资格：1、统招二本以上，计算机专业；2、精通Java或Scala语言；3年以上大数据应用开发经验；有实际的大数据应用工程开发经验；熟练实施安装部署运维大数据环境；3、基于SpringBoot微服务开发；对新技术有强烈的学习热情，有想法、有毅力和韧性；参与过开源项目，并做出过一定的贡献的优先；有实际的大数据平台建设经验；深入研究过大数据框架的运行机制、实现原理、源代码的优先，熟练使用大数据相关组件，比如hbase、hadoop、yarn,spark、storm、flink，kafka、presto。",金融,500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6600076.html,朝阳区,11k-16k,中国科学院信息工程研究所,不限,本科,海量数据，多种类大数据生态组件应用,1.熟练掌握Java语言开发，2年以上开发经验，精通网络编程、多线程调度处理、分布式环境问题处理、JVM优化等；     2.熟练掌握Linux操作系统常用命令，掌握Shell编程，有实际Linux环境下的开发和bug跟踪、处理经验；     3.熟练掌握常见大数据组件的原理，具备丰富的大数据平台组件使用经验，对大数据组件的源码有深入了解，并有过实际二次开发、优化经验，包括不限于Spark、HDFS、Hbase、Hive、ES等；     4.了解大数据软件在服务器硬件基础上的优化方法，有相关国产化服务器优化经验者优先；     5.具备较强的学习能力和团队合作意识，沟通能力好；     6.具备较强抗压能力；     7.毕业于211、985等国内知名高校者优先；,通讯电子,500-2000人,hadoop,北京
高级大数据研发工程师/高级JAVA开发工程师,https://www.lagou.com/jobs/6722723.html,海淀区,15k-30k,北京中经惠众科技有限公司,5-10年,本科,发展前景好,岗位：高级大数据研发工程师/高级JAVA开发工程师主要职责：1.面向大数据开发套件产品设计与研发，包括大数据数据分析平台、大数据共享平台、知识图谱平台等；2.复杂指标、图计算指标、复杂模型开发；3.追求**，构建业内领先平台；岗位要求:1.精通Java/Scala语言，5年以上Java开发经验；2.扎实的计算机基础，对技术有热情，愿意不断尝试新技术和业务挑战；3.精通Spring架构和微服务架构；4.熟悉前端技术的全栈开发工程师优先；5.熟悉Hadoop常用开源框架者优先；。6.熟悉ElasticSearch平台者优先；。7.有图数据库开发经验者优先考虑；8.有高并发经验优先；,"金融,企业服务",50-150人,hadoop,北京
高级数据开发工程师,https://www.lagou.com/jobs/6904758.html,海淀区,25k-35k,北京希瑞亚斯科技有限公司,5-10年,本科,八险一金 提升空间大 团队氛围好,"高级数据开发工程师：1、参与分布式大数据处理系统和数据服务基础设施的架构设计和开发；2、和产品经理一起梳理和完善系统功能需求；3、改进系统性能；任职要求:1、了解分布式、微服务、传统关系型数据库、常用NoSQL开源系统、RESTful、基本的信息安全领域知识2、精通Java代码，其他语言不限制具体要求：1、本科及以上学历，5年以上大型互联网产品或分布式系统开发设计经验；2、丰富的Java研发经验,精通Java, 熟悉Shell或Python等一种或几种脚本语言者优先；3、熟悉常用分布式系统相关理论基础，有一定的分布式系统开发经验，有互联网公司中大型分布式系统经验优先4、具备Spring Cloud等微服务设计和开发经验和能力；5、熟悉大数据技术栈,对Hadoop、Hive、Spark、Hbase、Kafka、Flink、Spark等开源组件有使用及优化经验者优先 。6、熟悉数仓建模理论，有数仓建模经验",企业服务,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6852016.html,海淀区,23k-46k,华为技术有限公司,不限,本科,大数据平台开发，分布式技术架构,华为od：大数据解决方案平台的开发、设计和交付，以及大数据解决方案的竞争力分析和架构研进,通讯电子,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6307067.html,朝阳区,15k-25k,奇虎360科技有限公司,3-5年,本科,薪资福利，学习环境，平台资源，团队氛围,职位描述：1、负责商业数据仓库设计、ETL开发、数据治理、流程优化和数据质量保障2、负责基础日志方案和合理性评估3、深入理解各业务方需求，规划设计数据仓库模型4、为业务方提供快速、准确、灵活的数据仓库主题支持5、满足上层数据运营体系、OLAP、数据挖掘等需求职位要求：1、本科及以上学历，计算机、通信等相关专业；3年以上互联网数据仓库设计和开发经验2、精通数据仓库实施理论，具备大型数据仓库设计，模型设计优化能力3、深入理解Hadoop系统中Hive、MapReduce、Spark原理，有实际使用Hive/MR/Spark处理大数据相关问题的经验，具备丰富的性能调优经验4、掌握基本的数据结构、算法，依据实际的数据问题具备一定的算法调优能力5、熟悉Linux环境开发，精通Java开发，掌握Shell/Python等脚本语言至少一6、对商业化业务感兴趣，对数据敏感，逻辑性强，认同技术驱动业务发展的价值观，有良好的逻辑思维与沟通能力,信息安全,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6222550.html,朝阳区,20k-30k,一点网聚科技有限公司,1-3年,本科,弹性管理，移动互联网，钱途无量，前景好,职责描述：1.负责一点商业化广告数据建设，建立完善的底层存储，数据计算，数据仓库，OLAP分析，实时计算，业务建模等。任职要求：1. 计算机或相关专业本科以上学历，大数据开发相关工作经验；2. 精通JAVA/Python任意一门；3. 熟悉Hadoop/Hive/HBase/Spark/Storm/Kafka等；4. 熟悉某一大数据源码优先；5. 相关互联网公司工作经验优先。,文娱丨内容,500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6626472.html,朝阳区,20k-40k,车主邦（北京）科技有限公司,3-5年,本科,五险一金,岗位职责:1. 参与数据中台产品的开发；2. 完善及优化现有软件产品；3. 负责相关软件模块需求、设计、编码及测试工作。任职要求:1、熟悉java或者python语言2、熟悉redis、mysql、elasticsearch等技术，熟悉mysql binlog优先3、熟悉Linux服务器的操作及基本shell编程4、熟悉大数据相关技术比如spark、hive、hbase、clickhouse5、了解docker、k8s技术的优先考虑6、良好的沟通技能，团队合作能力,"移动互联网,电商",500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7036337.html,海淀区,25k-50k,北京快手科技有限公司,3-5年,硕士,海量数据，用户画像，大数据建模分析,1、负责快手商业化数据管理平台（DMP）技术架构搭建、设计、开发与维护；2、负责广告投放中的用户行为日志采集、大数据建模分析、业务系统数据展示工作；3、为公司运营部门提供数据分析支持。,移动互联网,2000人以上,hadoop,北京
外卖配送-数据开发高级经理（管理岗）,https://www.lagou.com/jobs/6756949.html,朝阳区,60k-90k,北京三快在线科技有限公司,5-10年,本科,团队nice,,消费生活,2000人以上,hadoop,北京
外卖配送-资深数据仓库开发工程师,https://www.lagou.com/jobs/6640714.html,朝阳区,30k-40k,北京三快在线科技有限公司,3-5年,本科,六险一金，弹性工作,工作职责：1.负责数据仓库体系化建设和数据建模及架构的持续优化； 2.负责画像数据体系的建设和标准制定； 3.负责业务需求的开发，并将业务或产品的需求和智能数据化运营相结合进行落地； 4.负责相关项目的管理、代码review，参与团队规范的制定与优化； 5.负责数据治理相关工作； 6.面向业务运营的统计分析工作。 任职要求：1.深入理解数据仓库建设和业务建模理论，熟练掌握ETL研发流程； 2.熟悉分布式计算框架和工作原理，精通MapReduce编程；精通Hive、spark，有代码优化经验； 3.掌握数据结构与算法，有java/python、SQL研发经验；理解基本的设计模式，能将业务需求快速理解成技术需求； 4.熟练使用至少一种RDBMS，并熟悉其原理； 5.有其他大数据生态技术经验优先，例如HBase、ES、Tair/Redis； 6.有统计学基础和相关项目经验优先； 7.具备良好的沟通协调能力，有较好的抽象思维和解决问题的能力； 8.有团队管理经验优先。,消费生活,2000人以上,hadoop,北京
用户增长数据开发工程师,https://www.lagou.com/jobs/6501651.html,海淀区,25k-50k,北京字节跳动科技有限公司,3-5年,本科,六险一金，弹性工作，免费三餐，租房补贴,,文娱丨内容,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6941628.html,海淀区,20k-40k,北京字节跳动科技有限公司,3-5年,本科,python 大数据开发,职位名称：后端开发工程师（大数据方向）职位描述1、参与公司企业级产品后端的研发，确保系统的安全、高可用性和可靠性；2、参与业务需求讨论，评审产品设计，驱动研发团队一起按时、高质量完成产品交付；3、负责公司企业应用平台的开发和架构设计，保证设计和编码的质量，承担重点、难点的技术攻坚，主要开发语言为Python/Java。职位要求1、本科及以上学历，计算机及相关专业 ，4年以上工作经验；2、熟悉Python/Java，熟悉网络编程和多线程编程技术，熟悉常见的数据结构和算法；3、熟悉大规模数据处理、分布式计算等相关技术，如Hadoop 、Spark、Hive、MapReduce；4、熟悉linux平台 ， 熟悉至少一种脚本语言（shell/python）；5、有Java Web开发经验，熟悉主流开发框架者优先；6、有基于大数据平台的数据治理、 作业调度、大数据开发套件等大数据平台应用组件的设计开发经验优先；7、良好的团队合作，较强的沟通能力，对解决具有挑战性问题充满激情。,文娱丨内容,2000人以上,hadoop,北京
数据开发工程师(J15489),https://www.lagou.com/jobs/7157294.html,朝阳区,18k-26k,瑞庭网络技术（上海）有限公司,3-5年,本科,六险一金，免费班车，餐补，绩效奖金,,移动互联网,500-2000人,hadoop,北京
资深数据开发工程师(J15011),https://www.lagou.com/jobs/6825203.html,朝阳区,25k-35k,瑞庭网络技术（上海）有限公司,5-10年,本科,六险一金，免费班车，餐补，绩效奖金,,移动互联网,500-2000人,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/7133080.html,朝阳区,15k-20k,世纪互联集团有限公司,3-5年,本科,公司文化、福利待遇,工作职责:1.通过电话，邮件和在线会议和客户沟通复杂的Azure大数据，数据库，机器学习等相关的问题2. 分析客户程序中的问题，通过开发代码和提供解决方案以符合客户的期望。期间，需要调试、排错、编写代码，并对问题负责，直到问题全部解决3. 持续性的学习和掌握Azure中国现有的服务以及新上线的服务4. 识别客户反馈的产品问题，并提交给产品组5. 负责数据建模，数据开发，数据生产流程优化及相关技术问题的解决6.深入理解公司业务，负责业务相关的个数据统计平台，日常报表及数据可视化的设计开发工作，提供高可用的数据服务，发挥数据价值任职资格:1.了解大数据常用技术，Hadoop/Spark/Flink/Kafka/Hive等2. 具有离线，实时数据处理相关经验优先3.了解机器学习者优先4.具备问题排错和解决能力、代码调试能力5.精通SQL，有SQL性能调优经验，理解MySQL基本原理6.良好的沟通技巧7.良好的英语读、写、说的能力8.至少5年及以上开发经验,"移动互联网,数据服务",2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7032787.html,朝阳区,15k-20k,微岚星空（北京）信息技术有限公司,3-5年,本科,班车接送，薪资待遇好,职位描述：1.    负责360政企集团数据建模、算法设计和研发工作，通过海量数据分析，选择合理的指标，设计和改进安全数据挖掘和算法;2.    负责大数据平台架构设计和性能调优，构建数据平台，支持海量数据的离线和实时分析，对数据敏感；3.    熟悉实时数据计算和离线数据计算相关技术；4.    参与大数据平台的开发和维护，保证数据平台的稳定和可靠。任职资格：1．计算机、数学和统计学先关专业，本科及以上学历；2．熟悉linux开发环境，熟悉基础命令操作和shell脚本的编写；3．熟悉java、scala、python等任一开发语言，有2年及以上开发经验；4．熟悉Hadoop、Hive、Saprk等，有spark、flink、Es、Storm等开源框架优先；5．熟悉数据结构，对常用算法有所了解，有良好的数据思维；6．熟悉大规模数据挖掘、机器学习等相关技术，并有相应实践经验者优先；7．对数据敏感，有良好的沟通能力和团队合作能力，善于沟通，工作自主驱动，具备良好的问题定位分析能力。,广告营销,150-500人,hadoop,北京
高级大数据开发工程师（商业化）,https://www.lagou.com/jobs/7108415.html,海淀区,30k-60k,北京快乐茄信息技术有限公司,不限,本科,大牛云集 16薪奖金多 下午茶 不打卡,职位职责：1、负责公司海量用户行为数据的处理，在分布式计算平台基础上建立高效、实时的数据 pipeline、处理实时数据、实时应用场景的开发； 2、负责广告系统的数据分析，发现模式与规律，为实验解释、系统改进提供数据支持； 3、负责 Hadoop，Spark 等大数据基础设施和平台的改进，解决大规模生产环境集群可用性和性能优化问题；4、特征工程工程系统建设，为模型方提供特征数据流和特征离线调研、评估平台，并保证模型训练和预测阶段的特征线上与线下一致性；5、广告后台海量日志数据处理平台，为投放引擎提供实时的询量控量数据服务，为运营和广告主提供实时的数据报表服务。职位要求：1、211/985硕士及以上学历，计算机相关专业，大数据方向3年以上工作经验；2、熟练使用 Java，go，C/C++， Python中的一种或者几种；3、对数据敏感，掌握量化分析方法，善于从数据中发现问题，提出假设并使用数据进行验证；4、熟悉Hadoop/Spark生态环境体系的搭建和管理掌握Hadoop、Spark、MapReduce、HDFS、Hive、druid、clickhouseSpark Streaming等开源项目的原理和使用方法，有实际的集群搭建和调优经验者优先；5、有较强学习能力和逻辑思维能力，具备良好的问题分析与解决能力；6、有参与开源项目对社区有贡献的经历，有主流互联网公司工作经验优先。,工具,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6958201.html,海淀区,7k-14k,北京先进数通信息技术股份公司成都分公司,1-3年,本科,年终奖、生日婚育礼金、餐补、季度团建,岗位职责：1、对项目个人数据、企业数据进行处理分析，构建个人画像与企业画像；2、通过日志分析、数据提炼等方法归纳企业属性、行为等信息，构建企业分类标签；3、根据个人和企业的相关数据，生成企业经营分析报告；4、负责项目中数据的整理、基础数据的梳理和数据模型的构建；5、抽象并建立项目通用的数据抽取、清洗、校验等数据加工流程、规范；并完成数据分析任务。任职要求：1、有java/Scala/Python/C中一种或多种开发经验2、有SQLSERVER、MYSQL、DB2、Oracle等SQL开发经验；3、有大数据开发组件如hive、hbase、kafka、hdfs、ES、spark等开发经验4、有ETL开发经验，不限DataStage、Sap DataServices、Informatic或存储过程经验；5、有数据仓库开发经验者优先6、学历要求本科以上，计算机相关专业7、至少2年以上工作经验；8、有银行或金融机构工作经验者优先。,"软件开发,其他",500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6958226.html,西城区,7k-14k,北京先进数通信息技术股份公司成都分公司,1-3年,本科,年终奖、生日婚育礼金、餐补、季度团建,岗位职责：1、对项目个人数据、企业数据进行处理分析，构建个人画像与企业画像；2、通过日志分析、数据提炼等方法归纳企业属性、行为等信息，构建企业分类标签；3、根据个人和企业的相关数据，生成企业经营分析报告；4、负责项目中数据的整理、基础数据的梳理和数据模型的构建；5、抽象并建立项目通用的数据抽取、清洗、校验等数据加工流程、规范；并完成数据分析任务。任职要求：1、有java/Scala/Python/C中一种或多种开发经验2、有SQLSERVER、MYSQL、DB2、Oracle等SQL开发经验；3、有大数据开发组件如hive、hbase、kafka、hdfs、ES、spark等开发经验4、有ETL开发经验，不限DataStage、Sap DataServices、Informatic或存储过程经验；5、有数据仓库开发经验者优先6、学历要求本科以上，计算机相关专业7、至少2年以上工作经验；8、有银行或金融机构工作经验者优先。,"软件开发,其他",500-2000人,hadoop,北京
数据库开发及数据分析岗,https://www.lagou.com/jobs/6523902.html,海淀区,4k-7k,联想（北京）有限公司,应届毕业生,不限,优秀团队，发展机会多，周末双休,Linux运维/大数据运维 实习生岗职位描述：1.计算机相关专业，熟练掌握Python/Sql2.Linux系统基本原理、熟练掌握Linux常用命令、熟悉shell编程3.熟悉Windows Server服务器的日常维护管理，包括检查状态、报错信息检查、用户管理、参数配置管理等4.有Hadoop/Spark/Hive等大数据相关组件经验优先,"移动互联网,数据服务",2000人以上,hadoop,北京
数据产品开发工程师,https://www.lagou.com/jobs/6832103.html,海淀区,4k-6k,联想（北京）有限公司,不限,本科,优秀团队，发展机会多，周末双休,"职位职责： 实习天数：5 天 / 周任职要求：1. 精通 python, sqlMSSQL, MySQL, Hive SQL；2. 熟练掌握至少一种ELT工具；3. 熟悉UML，原型法，建模等需求抽取技术；4. 有跨不同类型数据库处理及数据自动化经验；5. 良好的需求沟通能力；6. 较强的逻辑思维能力；7. 英语良好；8. 加分项：熟悉数据挖掘算法；9. 985，211优先。","移动互联网,数据服务",2000人以上,hadoop,北京
Java开发工程师（数据分析方向）,https://www.lagou.com/jobs/6621846.html,朝阳区,6k-10k,北京华热科技发展有限公司,应届毕业生,硕士,七险一金 双休 免费食堂 晋升通道,岗位职责：1、负责基于Hadoop/Spark生态体系建设大数据平台，包括架构设计、搭建、开发、运维、监控和性能调优等；2、负责数据上报、数据存储、数据查询、数据计算等平台基础能力的设计和开发工作；3、制定并落实大数据平台各项高可用容灾降级策略、技术运营，保证集群高效稳定运行；4、负责分析定位、解决大数据平台各类运行问题；5、协助打造有行业竞争力的大数据平台产品，以支撑快速发展的海量数据业务；6、负责大数据相关前沿技术研究及实践 。任职资格：1、2020年应届毕业生，硕士研究生及以上学历，计算机相关专业，全脱产学习（即学习期间未缴纳过社保）；2、熟悉Java/Scala应用设计开发，有良好的编码习惯，有一定系统架构设计能力；3、熟悉Hadoop/Spark生态体系主要组件(如HBase、Hive、Spark，Kafka，Zookeeper、Yarn等)，对若干技术组件的底层原理有深入了解，并有丰富的开发、调优经验；4、有主人翁精神，善于沟通，有良好的团队合作精神，能承受高压工作；5、对新技术有强烈的求知欲望，有良好的学习和理解能力；6、有大型互联网公司、电商企业相关项目实践经历者优先；7、有Hadoop/Spark大数据平台搭建、运维相关项目经验者优先。,"数据服务,移动互联网",50-150人,hadoop,北京
高级大数据开发工程师,https://www.lagou.com/jobs/6711718.html,朝阳区,15k-20k,北京新聚思信息技术有限公司,3-5年,本科,弹性工作时间、免费饮料,"[鉴于**，可采用远程面试方式，入职时间视情况而定]职责描述：1. 对现有系统的业务流程重构，转变开发模式，参与和实施自动化项目的设计，开发，部署以及运维。 技能要求：Java/Scala/Python(至少一种)DevOps(Slack/hubot/Ansible, CI/CD), 如果有APM经验更好。Data Storage: MySQL/Redis/ActiveMQ/MongoDB2. 参与相关业务数据的数据处理，流处理，以及实时/近实时数据处理分析。HDP/HDF参与构建Synnex Data Lake.技能要求：熟悉大数据平台相关技术,Hadoop/HDFS, Spark, Flink, NiFi, zookeeper, MR, Hive/HBase/HAWQ, Storm, Kafka, Solr, Zeppelin, Atlas, ELK.任职要求：1、计算机、软件相关专业毕业，具有3年以上数据(大数据、数据库，BI)相关工作经验;2、至少1年大数据工作经验，熟练掌握Java/Python/Scala至少一种编程语言；3、具备大数据平台搭建/应用开发/运维的相关实践经验，熟悉HDP优先。4、熟悉Hadoop、Spark、Kafka、Hive等大数据组件开发；5、精通一种以上主流关系型数据库。6、有丰富的数据库开发，SQL性能优化或BI/数据仓库者优先",电商,500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7092164.html,朝阳区,25k-50k,京东世纪贸易有限公司,5-10年,本科,大数据 云计算 广告,岗位职责:1. 从事大数据的挖掘和开发工作；2. 参与开放AI平台的系统功能开发和数据分析；任职要求:1、熟悉java或者python语言，了解内部原理2、熟悉mysql、redis、elasticsearch等技术3、熟悉Linux服务器的操作及基本shell编程；4 、熟悉大数据相关技术比如spark、hive、hbase、hadoop的原理5、良好的沟通技能，团队合作能力6、本科5年、硕士3年以上工作经验,电商,2000人以上,hadoop,北京
高级大数据开发工程师G101332,https://www.lagou.com/jobs/6257880.html,朝阳区,30k-40k,广州汇量信息科技有限公司,1-3年,本科,三餐+下午茶、弹性工作不打卡，16薪,"岗位职责1、负责公司的数据平台的开发建设，有flink实时作业开发部署调优经验。对kafka有较深入研究，对性能调优、故障恢复有一定的处理经验。2、开发基于大数据技术的流式计算平台，OLAP引擎及大数据报表系统；3、设计和研发数据计算平台；4、研究和设计公司的大数据仓库平台，负责数据仓库中的数据计算ETL pipeline的设计和开发，管理和维护。任职资格1. 2年以上的大数据研发经验；2. 熟悉Linux操作环境，有良好的至少一门语言 (Java、Python或者C++) 开发调试经验；3. 熟悉大数据开发相关技术，如hadoop、hive、spark、kafka、 spark streaming、Flink等 ；4. 熟练数据仓库，对多维数据建模有深入理解；5. 有olap引擎相关开发经验优先；5. 熟悉amazon aws, 包括但不限于s3, emr等技术优先；5. 熟悉常用数据挖掘与机器学习算法优先；6. 思维敏捷，有较强的钻研学习能力，较好的沟通能力、团队合作 。",广告营销,500-2000人,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/7148155.html,大兴区,30k-60k,京东数字科技控股有限公司,5-10年,本科,大平台 福利好,岗位职责：1、负责分布式数据库中间件Apache ShardingSphere的设计、开发和维护；2、对Apache ShardingSphere的整体架构、扩展性、可用性和性能进行不断优化；3、解决系统中的关键问题和技术难题，同时满足对内业务和对外金融云使用及产品需求；4、践行Apache Way，积极参与开源推广以及社区运营。任职要求：1、本科以上学历，有数据库开发经验；2、扎实的Java开发功底，有丰富的分布式、IO、并发编程以及数据库使用经验，熟悉Linux操作系统； 3、代码风格优雅，面向意图编程，有代码洁癖，能够践行ShardingSphere的开发规范；（https://shardingsphere.apache.org/community/cn/contribute/code-conduct/）； 4、积极主动，具备良好的自我驱动能力和责任心，具备良好的团队合作精神和承受压力的能力； 5、熟悉Apache ShardingSphere、了解开源风向、拥有GitHub活跃账号、有参与社区与开源经验； 56具有基本的英语沟通与写作能力。,金融,2000人以上,hadoop,北京
大数据开发工程师（金融财务）,https://www.lagou.com/jobs/7125799.html,大兴区,20k-40k,京东数字科技控股有限公司,5-10年,本科,大平台 福利好,工作内容： 1、学习调研京东数科下金融等核心业务和系统知识，根据财务部需求对公司各项业务数据进行计算和分析，出具相关数据及报表； 2、进行数据仓库设计、建立数据中间层模型、提升数据质量和性能； 3、进行数据差异分析，找出统计口径、系统错误、业务错误等造成的差异原因。保障提交给财务部数据的准确性。任职资格： 1、熟悉Hadoop相关技术，深刻理解MapReduce原理和过程； 2、精通Hive SQL，进行数据处理及模型开发； 3、能进行数据查询优化，解决数据计算性能问题。 4、具有良好的编码规范、注释； 5、有较强的学习能力，能快速学习和理解业务知识及数据需求； 6、有Spark\Flink开发经验优先； 7、有Java\Python编程经验者优先； 8、对金融大数据方向有兴趣，能化解压力、积极主动完成学习和工作。,金融,2000人以上,hadoop,北京
高级大数据开发工程师,https://www.lagou.com/jobs/6656530.html,朝阳区,30k-60k,北京比图科技有限公司,5-10年,不限,硅谷文化 一线待遇 优秀团队,Tubi 是一家以数据为中心的公司，从产品路线图决策到为我们的服务提供强大动力的算法，数据都处于中心位置。我们正在寻找热衷于构建可扩展、高吞吐量数据基础架构的工程师。你将与产品、工程师及数据科学家团队紧密协作，解决个性化推荐、内容发现、搜索、广告和内容生产方面的难题。你将遇到的挑战会包括：精简特征工程，帮助数据科学家在生产环境中使用机器学习模型，驱动数据科学研究及分析在整个公司内内的使用。工作职责负责批量、实时任务开发和维护负责推荐系统架构搭建和维护与机器学习和数据科学家密切协作，了解数据需求，包括架构及数据频率通过利用分布式可拓展平台 （databricks）编写 Scala （或者其他语言）脚本以生成丰富的表格与客户端工程师协作讨论需求细节 职位要求五年以上工作经验，至少两年数据开发相关工作经验熟悉掌握 Scala、Python 等语言，深入了解 Apache Spark 原理及应用对于新技术，能快速评估和权衡利弊，迅速完成和交付项目了解推荐系统、数据挖掘、机器学习等常用算法良好的英语听说读写能力加分项：熟悉 Apache Spark 原理及应用加分项：熟悉 AWS、S3、Redshift、Airflow 等如果你天赋异禀且踌躇满志，可以忽略上述要求，直接投简历给我们。我们能提供什么？- 快速成长学习的氛围- 宽松弹性的工作方式，拒绝 996- 极具竞争力的薪资和期权- 免费技术会议、书籍、培训- 每年至少一次硅谷出差机会希望了解我们更多？不妨看下这些文章：- Tubi 中国团队 http://chinateam.tubi.tv/- Tubi 为什么 https://zhuanlan.zhihu.com/p/********- Tubi 技术博客 https://code.tubitv.com/- Tubi 主站 https://tubi.tv,"移动互联网,文娱丨内容",150-500人,hadoop,北京
产险总公司-信息技术部-数据开发工程师岗,https://www.lagou.com/jobs/7048695.html,海淀区,12k-24k,阳光财产保险股份有限公司,1-3年,本科,六险一金 办公环境好 领导NICE,岗位职责：1、负责统信系统的数据报送；2、熟悉保单登记平台数据报送工作；3、对统信数据和保单登记平台数据的完整性核对4、ETL开发和运维。 任职要求：1、本科或以上学历，1年以上相关工作经验；2、精通SQL编程语言；熟练oracle、mysql等数据库开发；3、有保险工作经验优先；特别是有监管报送和登记平台数据报送经验者优先考虑。4、工作踏实、认真细致，态度端正，积极上进，具有良好的沟通能力及团队精神,"企业服务,金融",500-2000人,hadoop,北京
Hadoop开发工程师,https://www.lagou.com/jobs/4738359.html,朝阳区,10k-20k,北京人民在线网络有限公司,3-5年,本科,"五险一金,补充医疗,带薪年假,大牛团队","岗位职责:1、负责Hadoop、HBase、Spark系统运行维护和状态监控；2、负责Hadoop、HBase、Spark等系统的性能优化；3. 基于Hadoop、HBase、Spark系统开发大数据数据相关分析算法任职资格:1、熟悉Hadoop、Hbase、Spark,两年以上Hadoop开发经验；2、理解MapReduce计算框架的思想，熟悉分布式计算模型，有Spark编程开发经验者优先；3、精通JAVA语言；4、至少熟练使用Shell、Python等脚本语言之一；5、热爱技术，工作认真、严谨，有团队精神。","数据服务,移动互联网",150-500人,hadoop,北京
数据库内核开发,https://www.lagou.com/jobs/6021127.html,海淀区,25k-43k,毕威拓科技（北京）有限公司,不限,本科,无996、高薪、硅谷文化,"职位描述：本职位负责世界最先进的 MPP 分布式数据库 Greenplum (GPDB) 内核开发，包括查询优化模块，执行引擎，分布式事物，存储引擎等。如果你有兴趣和PostgreSQL/Greenplum社区大牛一起写代码，如果你天生喜欢极具挑战性的工作，如果你是技术极客，如果你渴望快速成长，请加入我们!岗位要求：- 精通C语言（或者任意一门语言，并且愿意学习C），理解计算机核心知识- 编程功底深厚，具有良好的编程习惯和代码质量- 有其它数据库或SQL引擎工作经验者优先- 熟悉 PostgreSQL者优先- 有开源工作经验者优先- 良好的团队合作精神- 热爱技术，孜孜追求，精益求精Greenplum (GPDB) 是 原Pivotal /现VMware公司自主研发的，目前世界上最先进、性能最优、功能最全的开源分布式数据库，代码超过150万行: https://github.com/greenplum-db/gpdb  ，详细请参考 https://greenplum.cn/  。Greenplum研发团队聚集了众多来自Stanford、CMU、北大、清华、中科院体系等知名高校的数据库杰出人才，以及PostgreSQL社区的committer 和黑客。这是我们北京研发中心的工作风格：用时70天 Greenplum 内核从 PostgreSQL 9.0 升级到 9.1，修改代码约260,000行用时72天 Greenplum 内核升级到 PostgreSQL 9.2，修改代码约380,000行用时16天 Greenplum 内核升级到 PostgreSQL 9.3，修改代码约310,000行用时 3 周 Greenplum 内核升级到 PostgreSQL 9.4，修改代码约270,000行",数据服务,2000人以上,hadoop,北京
高级大数据开发工程师,https://www.lagou.com/jobs/7162332.html,朝阳区,15k-30k,北京亿和博嘉教育科技有限公司,3-5年,本科,平台初期，个人成长空间大,工作职责：1、负责公司大数据离线、实时平台（如Hadoop/Hive/Storm/Spark）的建设、优化；2、负责开发大数据工具，如报表平台、推荐系统、多维度分析工具、ETL平台、调度平台的研发；岗位要求：1、熟悉Hadoop、Hive、Spark、Storm的原理、优化；主导过大型数据平台建设者优先2、熟悉数据仓库理论，对多维数据建模有深入理解和实际经验；3、熟悉开源大数据平台如HBase、ES、Kylin、Druid等，有实际的报表平台、多维度分析工具、etl平台、调度平台中至少一种工具的实际建设经验；多种经验者优先；4、熟练进行Java、Scala的代码编写，良好的代码编写素养，良好的数据结构算法技能；5、思维敏捷，有较强的钻研学习能力；6、较好的沟通能力、团队合作；,"教育,医疗丨健康",50-150人,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/7028988.html,西城区,15k-30k,建信金融科技有限责任公司,不限,本科,五险两金，带薪休假，公司食堂，出游团建,1、参与项目的需求和设计的讨论与分析，进行相应的数据库架构设计与数据库开发；2、数据库方案设计，负责生产及测试数据库的日常维护、管理和优化工作；3、负责撰写并维护工作相关的文档，如数据库的设计、管理和维护文档。要求：1、熟悉关系数据库基本原理与特点，了解NoSql数据库设计思想和基本原理；2、熟悉关系型数据库基本操作，拥有oracle或Mysql数据库开发、管理和维护调优经验；3、熟悉Linux系统的常用命令，熟练使用shell或python等至少一门脚本语言；4、工作态度认真负责，具有良好的逻辑分析和学习能力，良好的沟通能力。5、2年以上数据库及数据库中间件的开发经验，拥有ORACLE DBA证书优先；,"金融,软件开发",2000人以上,hadoop,北京
大数据开发工程师（实时计算方向）,https://www.lagou.com/jobs/7194408.html,海淀区,15k-30k,北银金融科技有限责任公司,3-5年,本科,扁平化、福利待遇高,1、参与大数据方向开发项目，深度理解业务需求，提出解决方案；建立健全大数据平台，保证平台稳定高效，持续迭代优化，提升平台服务能力 2、负责大数据平台开发工作。负责数据收集、清洗和规约，完成数据指标的统计、多维分析和归类，提供面向业务的数据服务；负责非结构化数据的采集、转换、存储，建立数据模型，提供统一使用口径；负责通用协议请求解析、外部数据调用、规则引擎配置、业务场景实现；负责数据可视化开发 3、负责大数据平台业务数据分析、模型的研究和开发实现；持续引入数据维度，挖掘并提取可以特征；利用数据分析工具开展大数据分析挖掘，构建数据分析和挖掘模型，产生数据分析报告1. 本科以上学历，3年以上大数据方向开发工作经验，1年以上金融类大数据项目开发经验；2. 熟练掌握JAVA、Python、Scala中至少一种开发语言，掌握常见的数据结构、算法，了解软件工程、敏捷开发等知识，熟悉常用设计模式；3. 熟悉大数据开发框架，熟悉Hadoop/Spark/Hbase/MPP DB及业界主流的流处理平台，如Storm/Flink/Spark Streaming，熟练使用Kafka等常用分布式发布订阅消息系统；4. 熟练使用常用关系型数据库及NoSQL数据库如Redis，Hbase；5. 熟悉Linux开发环境，能够根据实际需要快速编写shell脚本；6. 有技术经理经验、项目管理经验优先；具有数据分析的基础知识，有机器学习模型研发经验者优先。7. 责任心强；耐心细致且具有条理性；有钻研精神；有快速学习能力；逻辑思维强；具有数学推理能力；具有规范的编程风格及文档编写能力。,金融,150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6861144.html,朝阳区,20k-40k,车主邦（北京）科技有限公司,3-5年,本科,弹性工作制、交通便利、年底奖金、领导好,岗位职责:1. 参与数据中台产品的开发；2. 完善及优化现有软件产品；3. 负责相关软件模块需求、设计、编码及测试工作。任职要求:1、熟悉java或者python语言2、熟悉redis、mysql、elasticsearch等技术，熟悉mysql binlog优先3、熟悉Linux服务器的操作及基本shell编程4、熟悉大数据相关技术比如spark、hive、hbase、clickhouse5、了解docker、k8s技术的优先考虑6、良好的沟通技能，团队合作能力,"移动互联网,电商",500-2000人,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/7195378.html,朝阳区,12k-16k,北京文思海辉金信软件有限公司,3-5年,本科,六险一金 央企控股 双休 加班调休,主要工作：1、保单登记系统、数据仓库系统数据库由原来的TD、oracle迁移至greenplum 数据库；2、由greenplum 数据库支持的保单登记系统和数据仓库系统的后续日常开发；要求：1、全日制统招本科及以上学历，2017年之前毕业，计算机、电子、软件、统计及相关专业； 2、3年以上的数据ODS、数据集市、数据仓库等数据类项目实施开发经验； 3、熟悉Teradata、Oracle数据库相关知识，掌握Teradata、Oracle数据库编程开发技术；熟悉greenplum 数据库相关知识； 4、熟悉数据质量、标准和元数据相关数据管控基本技术和流程 5、熟练使用Shell、Python或Perl等常用脚本开发语言；6、适合通州、燕郊小伙伴,"金融,软件开发",2000人以上,hadoop,北京
数据服务/网络协议开发工程师/Go语言开发工程师,https://www.lagou.com/jobs/4395527.html,昌平区,8k-15k,北京万维盈创科技发展有限公司,1-3年,本科,"晋升空间,员工旅游,免费体检,年底双薪","岗位职责：1.负责环保监测数据接收、解析、报警逻辑判断以及统计处理功能设计和开发；2.负责软件产品的需求分析，并提供软件发展功能性建议；3.负责编写软件相关的设计和技术文档；4.解决工作中的疑难技术问题攻关。 任职要求：1.本科及以上学历，计算机、电子自动化、数学等相关专业；2.二年以上网络协议开发经验优先，知识基础扎实的应届毕业生也可考虑；3.熟悉网络通讯协议和原理应用，对socket处理过连包、断包等情况；4.熟悉Mysql、SQL Server、Oracle，了解掌握C#，winform, go开发；5.具有较强的问题解决能力，思维逻辑严谨；6.具备优秀的学习能力和一定的抗压能力；7.有中型以上项目设计开发经验者优先考虑。 福利待遇：1.底薪+全勤奖+午餐补助+通讯补助+年终奖2.节日慰问礼金+年度体检+年度员工旅游+丰富多彩的员工活动party3.根据实际需要可提供员工宿舍 培养体系：新员工入职培训+入职导师指导+专业技能培训+公司级外派培训 发展空间：1.纵向：高级开发工程师、研发项目经理、系统架构师2.横向：项目管理方向","移动互联网,硬件",150-500人,hadoop,北京
大数据平台开发工程师-Hadoop,https://www.lagou.com/jobs/3497041.html,朝阳区,30k-40k,飞维美地信息技术（北京）有限公司,3-5年,本科,"硅谷文化,美国轮岗,超长年假,全员持股",职责负责FreeWheel数据基础架构系统或组件的调研、开发和维护工作，及时高质量地交付任务对所负责的组件或特性进行持续的优化及改进，建立高效可扩展的数据基础架构指导初级工程师，跨团队沟通协作要求扎实的编程能力，良好的开发习惯，熟悉Java、C++，熟悉Go更佳自我驱动，有很强的解决问题能力，能够快速掌握新的技术对流行的大数据处理平台如Hadoop有深入的了解，并有实际的项目经验，熟悉HBase、Presto、Spark更佳有消息队列，分布式缓存，RPC框架，AWS开发，以及分布式同步等方面的实际的项目经验更佳对Linux内核，包括线程调度，内存管理，磁盘缓存等有一定了解良好的沟通能力与团队合作精神，能顺利进行英语口语交流,"企业服务,数据服务",500-2000人,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/7201856.html,西城区,22k-40k,建信金融科技有限责任公司,5-10年,本科,发展迅速、六险二金、福利好,岗位职责：1、参与项目的需求和设计的讨论与分析，进行相应的数据库架构设计与数据库开发；2、数据库方案设计，负责生产及测试数据库的日常维护、管理和优化工作；3、负责撰写并维护工作相关的文档，如数据库的设计、管理和维护文档。 任职资格：1、熟悉关系数据库基本原理与特点，了解NoSql数据库设计思想和基本原理；2、熟悉关系型数据库基本操作，拥有oracle或Mysql数据库开发、管理和维护调优经验；3、熟悉Linux系统的常用命令，熟练使用shell或python等至少一门脚本语言；4、工作态度认真负责，具有良好的逻辑分析和学习能力，良好的沟通能力。5、2年以上数据库及数据库中间件的开发经验，拥有ORACLE DBA证书优先；ps:基本条件补充说明1、最高学历学校为985或211院校，或计算机类强校（仅限计算机类、软件工程类专业）。2、最高学历为硕士及以上的，本科院校须为全日制一本及以上院校；3、境外大学QS世界排名前500；4、社会招聘近5年跳槽次数少于3次（不含3次）。5、年龄原则上在35周岁及以下，表现特别突出者可酌情适当放宽年龄限制。,"金融,软件开发",2000人以上,hadoop,北京
C/C++开发工程师（5G承载/数据通信协议）,https://www.lagou.com/jobs/6919245.html,海淀区,15k-25k,华为技术有限公司,1-3年,本科,5G,岗位要求：1、计算机、软件工程、通信、电子、仪器、控制、自动化等相关专业本科及以上学历；2、热爱编程，基础扎实，熟悉掌握C/C++等编程语言，有良好的编程习惯；3、具备独立工作能力和解决问题的能力、善于沟通，乐于合作，热衷新技术，善于总结分享，喜欢动手实践；4、对数据结构有一定了解；5、熟悉TCP/IP协议及互联网常见应用和协议的原理；6、有分布式系统经验，有软件开发的实际操作经验者优先；【工作职责】1、负责华为数通协议软件的设计、开发和实现等工作，实现BGP、SR、5G承载等协议的竞争力持续领先；2、负责华为数通协议软件的测试、验证和集成等工作；实现华为数通协议在业界的竞争力领先；3、研究通信行业前沿动态，积极与业界专家交流，参与协议标准的创新和规划；4、掌握业界领先的软件工程技术，实现千万级大型分布式软件的工程管理能力创新，熟悉华为安全编码规范，代码安全可信；,通讯电子,2000人以上,hadoop,北京
大数据平台开发工程师,https://www.lagou.com/jobs/6833434.html,西城区,25k-30k,北京柠檬微趣科技股份有限公司,3-5年,本科,扁平式组织架构，福利好，技术氛围浓厚,岗位职责：1、Hadoop数据分析平台建设、开发、测试、部署和优化；2、基于Hadoop的存储平台架构设计与性能优化；3、设计和开发海量数据的管理系统；4、基于现有数据统计平台，开发数据统计报表；5、结合当前大数据平台技术，设计和实现数据收集模型、数据分析处理模型和数据汇总展现模型；6、实现各运营组织要求的相关数据的统计报表。任职要求：1、 精通计算机算法，及大数据相关算法；2、精通SQL语句，可以快速编写复杂查询；3、 懂得 Hadoop、GFS 一类分布式存储原理；4、 熟练编写 Java 和 Linux shell 程序；5、有大数据工作经验者优先。,"移动互联网,游戏",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6797271.html,海淀区,20k-40k,北京小米科技有限责任公司,不限,本科,明星团队，大牛云集,"岗位职责：1、 负责整个公司的数据收集、清洗工作，进行相关数据产品的开发工作；2、 建设、完善公司级用户画像,建设数据质量体系；3、 利用技术手段赋能新零售、广告、金融、小爱同学、手机等业务。任职要求：1、 精通至少一门编程语言(Java/Scala/Python/C/C++)，透彻理解常见的核心算法；2、 熟练掌握概率统计、数据挖掘、机器学习相关理论知识；3、 对Hadoop、Spark等工具拥有实践经验；4、 大数据新技术探索,技术攻坚。",硬件,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6818552.html,海淀区,20k-40k,北京小米科技有限责任公司,3-5年,本科,明星团队，大牛云集,"岗位职责：1、 负责整个公司的数据收集、清洗工作，进行相关数据产品的开发工作；2、 建设、完善公司级用户画像,建设数据质量体系；3、 利用技术手段赋能新零售、广告、金融、小爱同学、手机等业务。任职要求：1、 精通至少一门编程语言(Java/Scala/Python/C/C++)，透彻理解常见的核心算法；2、 熟练掌握概率统计、数据挖掘、机器学习相关理论知识；3、 对Hadoop、Spark等工具拥有实践经验；4、 大数据新技术探索,技术攻坚。",硬件,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/5681391.html,朝阳区,25k-35k,上海淇毓信息科技有限公司,5-10年,本科,上市公司，发展前景好,岗位描述:1. 根据360金融业务和集团的海量数据，为风控、BI提供数据支持2. 对数据处理的需求场景进行抽象，形成自动化工具，提升工作效率3. 基于日常的需求场景，构建安全、高效、稳定的大数据平台，为业务提供更有效的数据支撑岗位要求:1.属性Linux操作系统，熟悉Shell编程语言2.大数据处理经验丰富，熟悉hadoop map/reduce编程；有Hbase、Spark、Storm的应用开发经验3.熟悉其它分布式存储相关技术，包括HDFS，Hive、Redis、mongodb、 Flume、Kafka、Sqoop、Zookeeper、ElasticSearch等,金融,500-2000人,hadoop,北京
数据开发／挖掘工程师G00123,https://www.lagou.com/jobs/6651019.html,朝阳区,25k-50k,便利蜂商贸有限公司,3-5年,本科,期权激励,,消费生活,2000人以上,hadoop,北京
数据开发(J10056),https://www.lagou.com/jobs/7158627.html,朝阳区,15k-25k,北京小步大成科技有限公司,3-5年,本科,包晚餐 六险一金 年终0-3个月奖金,,"移动互联网,教育",150-500人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/4478725.html,海淀区,20k-40k,秒针信息技术有限公司,不限,本科,"大数据,可视化",基于 Hadoop 系统的分布式大数据处理和分析平台的二次开发与实施；参与项目的需求分析、概要设计、详细设计，技术文档的编写；负责开发框架的搭建、改进；协助完成项目的测试、系统交付工作，对项目实施提供支持。负责跟进软件系统安全、稳定、维护和性能优化等工作;分布式技术研究，及关键技术的开发工作；相关数据平台系统的开发与调试；负责搭建行业产品大数据的存储、计算等框架以及主要代码编写1 3年大数据开发经验，熟悉各个大数据组件，尤其对es，hbase，titan，hive，spark，yarn能够熟练编写代码，对大数据各个组件原理有清晰深刻理解2 熟悉掌握java，web框架，数据库设计等基本web开发工具及技巧3 有处理高并发，高吞吐数据量的经验。4 精通Linux环境，常用指令操作5 能够承担大数据平台运维工作，对大数据平台出问题后的调试有一定经验。6 可以承受阶段性出差的工作节奏,"数据服务,广告营销",2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7007709.html,海淀区,20k-30k,北京新东方迅程网络科技股份有限公司,3-5年,本科,发展空间大，有挑战,"职位描述：1. 负责在线教室的系统稳定性指标（实时、离线）开发、性能优化；直播，消息系统的全链路监控分析工具开发2. 负责搭建数据后台系统，包括数据收集、数据处理、数据存储、数据分析、AB测试等工作。3. 快速的生产数据，让数据产生价值，是我们的目标。任职要求：1.本科以上学历，计算机相关专业，2-5年大数据开发工作经验2.熟练Java/Scala/Python/go等一种或多种编程语言3.熟练Spark Structured Streaming和Flink等流计算引擎，有实际项目经验者优先4.熟悉kafka,hadoop，zk,HBase，elasticsearch,clickhouse，Druid等大数据技术,有实际项目经验者优先5.了解并行计算或者分布式计算原理，了解数据仓库相关知识优先6.了解常见的机器学习算法，了解CNN/RNN/LSTM/GBDT等算法者优先7.有责任心，乐于挑战，善于沟通，学习能力强","移动互联网,教育",2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6599352.html,朝阳区,20k-40k,平安健康保险股份有限公司,5-10年,本科,业务高速发展，成长空间宽阔，福利保障齐全,岗位职责：    1、负责大数据平台的开发工作    2、负责大数据平台架构设计，性能优化调优工作    3、负责大数据技术和业务探索，研究及落地任职要求：    1、本科及以上学历，计算机相关专业    2、熟练掌握JAVA编程语言    3、熟练掌握大数据生态圈工具及开发语言    4、具备良好的分析解决问题的能力及有较强的学习能力。    5、有数仓搭建，数据建模及机器学习等相关经验。,金融,500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7002260.html,海淀区,25k-50k,上海基分文化传播有限公司,3-5年,本科,五险一金、周末双休、餐补、,职位描述1、负责趣头条数据中台，全公司各类业务数据仓库的构建；2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决；3、负责构建用户主题、各业务线主题、推荐主题、广告主题、数据门户系统；4、负责各产品线数据维护，提升数据资产质量。职位要求1、计算机、数学相关专业本科及以上学历，2年以上大数据开发工作经验；2、 深入理解常用的数据建模理论，可独立把控数据仓库的各层级设计；有数据挖掘，机器学习，推荐相关经验优先；3、熟悉Aerospike和Clickhouse的同学优先考虑，熟练掌握Hive/SQL，熟悉Spark/Map-Reduce分布式计算框架，熟悉大数据的离线和实时处理，可以进行海量数据模型的设计、开发；4、有产品sense，主动思考基于业务场景下的数据体系建设，而不单单只会做执行；5、工作认真，负责，良好的团队合作精神和解决问题分析能力，钻研技术克服困难，勇于挑战。,文娱丨内容,500-2000人,hadoop,北京
高级大数据开发工程师,https://www.lagou.com/jobs/3913107.html,朝阳区,35k-50k,飞维美地信息技术（北京）有限公司,5-10年,本科,"硅谷文化,美国轮岗,全员持股,大牛聚集",1 ． 基 于 流 处 理 (Spark Streaming) 的 实 数 据 服 务 。 为 客 户 提 供 实 时 的 投 放 数 据 帮 助 客 户 及 时 了 解 投 放 状 态 ，调整投放方案。 2．基 于 SQL-on-hadoop (Presto) 的 数 据 查 洵 服 务 。 数 据 科学家 和 客 户 可 以 快 速 从 海 量 的 广 告 投 放 数 据 中 找 到 业 务 相 关 的 数 据 统 计 。 3 ． 基 于 商 业 智 能 工 具 (Looker) 的 数 据 分 折 服 务 。 客 户 可 以 灵 活 的 创 建 业 务 报 表 对 广 告 投 放 效 果 、 资 产 利 用 状 态 能 有 非 常 准 确 的 把握。我 们 的 大 数 据 平 台 同 时 建 立 在 自 建 数 据 中 心 和 云 端 （ AWS ） ， 对 数 据 感 兴 趣 的 同 学， 这 里 是 成 为 数 据 工 程 师 (Data Engineer) 的 好 地 方 。,"企业服务,数据服务",500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6672960.html,海淀区,13k-17k,北京世纪高通科技有限公司,1-3年,硕士,一年多薪、节日福利、全员旅游、各类补贴,岗位职责：1. 负责大规模机器学习特征提取；2. 参与用户位置数据分析和挖掘，为算法和业务场景提供支持；3. 应用机器学习、深度学习等技术，针对海量信息建模，挖掘潜在商业价值  任职要求：1. 计算机或相关专业，有至少两年大数据开发工作经验;2. 具备良好的编程能力和代码风格，熟练掌握Java语言，并至少掌握一门脚本语言;3. 熟悉机器学习常用算法，有机器学习应用、数据挖掘相关经验者优先;4. 具有良好的分析问题和解决问题的能力，对解决具有挑战性问题充满激情，有较强的学习能力，并且能够快速实现数学模型;5. 良好的团队合作精神，较强的沟通能力; 6. 熟悉Hadoop、HBase、Hive、Storm、Spark、Kafka分布式大数据处理系统者优先。7. 有位置大数据开发经验（地图、位置、轨迹等）优先,"移动互联网,其他",150-500人,hadoop,北京
大数据开发（hadoop，hive，spark）,https://www.lagou.com/jobs/6891421.html,朝阳区,20k-35k,联储证券有限责任公司,5-10年,本科,五险一金、所有节假日休息、券商总部、,岗位职责：1. 根据需求设计开发大数据相关系统功能；2. 解决开发过程中技术难题；3. 撰写技术文档。岗位要求：1. 6年以上Java开发经验，3年以上Hadoop生态圈开发经验，熟悉TDH大数据平台者优先；2. 精通Java EE开发技术和主流框架，精通ECharts仪表盘开发，熟悉SmartBI开发技术者优先；3. 工作积极主动，做事细致认真，善于沟通，有团队合作精神，能承受较大压力；4. 有金融行业项目经验者优先。,金融,500-2000人,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/7105945.html,朝阳区,10k-15k,北京羽实箫恩信息技术股份有限公司,1-3年,大专,五险一金绩效奖金带薪年假补充医疗节日福利,1、大专及以上学历，计算机等相关专业优先，1年以上工作经验；2、熟悉DB2/Oracle数据库，精通SQL编写技能，存储过程/函数编程，精通SQL优化技术；3、熟悉软件技术文档的编写；具备良好的文档编制习惯和代码书写规范；4、思路清晰，善于思考，能独立分析和解决问题；5、责任心强，具有团队精神以及良好的逻辑思维能力和学习能力，抗压能力强。6、熟悉银行业务、具有银行相关软件开发者优先；工作地址北京市朝阳区朝阳门,"数据服务,金融",50-150人,hadoop,北京
大数据开发实习生,https://www.lagou.com/jobs/5724392.html,朝阳区,3k-4k,中国科学院信息工程研究所,应届毕业生,硕士,毕业有留所机会，有户口,职位描述参与流计算引擎开发任职要求：熟悉java语言，熟悉基本的数据结构、算法；熟悉Hadoop大数据生态相关组件，包括但不局限于hive、hbase、kafka、spark、elasticsearch、flink和yarn等；熟悉linux系统基本操作，会shell脚本更好；支持在所内完成毕业论文，有中科院导师指导。实习至少10个月。,通讯电子,500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6231539.html,海淀区,30k-50k,指尖视野（北京）科技有限公司,5-10年,本科,待遇优厚，发展空间大，气氛活跃,工作职责:1、构建集团的数据管控体系，对数据进行全生命周期管理;2、创建集团的数据治理体系，对数据质量进行探查与提升;3、制定各项的数据建设标准，并确保各项标准落地实施;4、规划业务相关的主题建设，参与其逻辑模型与物理模型设计;任职资格:1. 3年及以上的数据仓库建设经验;2. 熟悉数据仓库各类建模理论，以及数据仓库数据层级关系，具备大型数据仓库逻辑模型和物理模型设计经验；3. 有元数据管理、数据质量管理、主数据管理经验者优先；4. 有Hadoop、Hive等分布式计算平台使用经验者优先；5. 有互联网金融、银行、保险及征信等行业应用经验者优先；6. 具备良好的团队合作精神，良好的分析能力与沟通技巧,"广告营销,企业服务",少于15人,hadoop,北京
Hadoop开发岗,https://www.lagou.com/jobs/6887183.html,通州区,10k-15k,阳光人寿保险股份有限公司,1-3年,本科,五险一金、年终奖、带薪假期、父母赡养津贴,岗位职责：1、依据业务需求文档，完成软件模块的分析、设计、开发、测试，以保证能够按期交付，并稳定运行；2、分析数据及效率问题，并给出解决方案，及时修复；3、参与数据设计、数据抽取、数据加工的开发，并依据环境进行效率调优；4、跟踪了解业界发展、互联网、大数据相关最新技术，参与重点项目新技术研发工作；5、对低阶岗位人员进行技能培训、指导低阶岗位的技术开发工作；6、领导交代的其他任务。 任职资格：1、统招本科及以上学历，计算机相关专业，2年以上开发经验；2、熟练掌握Hadoop框架及技术，如Spark Core、Hbase、Hive、HDFS、Kudu、Impala、Yarn等3、熟悉大数据ETL工具及技术，如Sqoop、Spark Streaming、Kafka、Flink等；4、熟悉大数据常用开发语言，如Java、Scala、Python等；4、良好的团队合作精神、独立解决问题和沟通能力；5、正直诚实、有责任心，能够承受一定压力；6、对Hadoop性能调优有深入了解者优先；7、有大型Hadoop项目开发、实施经验者优先；8、有数据中台经验者优先；,其他,500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6864255.html,朝阳区,15k-18k,阳光保险集团股份有限公司,应届毕业生,硕士,平台大,岗位职责：1.负责大数据清洗、存储、处理、分析等场景的开发，完成高质量的代码编写；2.负责大数据平台开发建设工作，支撑各类业务应用场景的数据采集，加工，建模，分析，实验，可视化的全流程；  3.解决大规模生产环境集群的分布式计算和存储系统的可用性和性能优化问题。 任职要求：1、统招硕士应届毕业生2、计算机、数学、统计相关专业3、沟通能力好，有一定的学习能力和独立思考能力。,金融,2000人以上,hadoop,北京
大数据开发实习生,https://www.lagou.com/jobs/6701822.html,朝阳区,3k-5k,中国科学院信息工程研究所,应届毕业生,硕士,海量数据，多种类大数据生态组件应用,主要职责：        主要从事大数据存储与处理系统的开发和优化操作、大数据挖掘与分析开发； 任职要求：        （1）计算机/软件工程专业，或具有较强编程自学能力学员；     （2）熟悉Linux环境以及对应的编程技术；       （3）精通Java/Python/Scala 或C/C++语言，有扎实编程功底和良好的编码习惯；        （4）熟悉Haoop大数据生态环境及子系统；     （5）熟悉Spark/Flink/Spark-Streaming等数据处理系统者优先。,通讯电子,500-2000人,hadoop,北京
大数据开发,https://www.lagou.com/jobs/6583038.html,海淀区,30k-60k,北京古德莱克国际咨询有限公司,应届毕业生,本科,福利好，发展空间大，有期权,1，参与搜索数据平台架构和规划; 2，参与数据仓库的建模开发，满足业务各应用端对数据的使用需求; 3，参与数据仓库ETL设计，开发和优化工作，保证数据准确，稳定，组织合理; 4，总结与沉淀数据仓库建设的方法，设计和开发数据产品和工具，系统化，自助化地提高业务分析效率。任职要求：1，从事数据仓库领域至少2年以上，熟悉数据仓库模型设计与ETL开发，具备海量数据加工处理（ETL）相关经验 2，具有一定数据模型和数据架构基础，熟悉hadoop \ hive和常用数据库，理解云计算和数据服务; 3，熟练使用脚本语言：如perl，python，shell等任意一种以上优先;  4，有spark，hive，OLAP系统使用经验优先。,电商,少于15人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6969342.html,房山区,15k-30k,同方工业有限公司,3-5年,本科,七险两金，餐补，通讯补贴，年度体检等,岗位职责：1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、依据公司业务开发大数据平台运维、监控、故障处理等相关脚本；4、负责集群服务、业务优化、应急响应、容量规划等；5、根据业务需要，进行平台数据服务功能的开发与测试，并完成相关文档编写。任职资格：1.全国统招全日制高校计算机软件及相关专业研究生学历及以上。3年以上信息技术产品开发经验，2年以上大数据平台和相关产品设计、研发经验；2.两年以上MySql数据库系统管理经验，精通数据库构架设计和性能调优；3.熟悉Linux软硬件环境、系统管理和优化，熟练部署、优化各种常用服务；4.熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验;5.熟悉一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP;6.掌握R或者Matlab，有行业应用背景，有工业大数据处理经验者优先；7.有Hadoop、hive、Hbase、redis、kafka、jstorm等组件相关开发经验；8.精通Java语言以及J2EE平台特性，熟悉常用的设计模式和开源框架，有大型互联网项目经验或工业大数据平台研发经验者优先；9.具备很好的沟通能力和团队精神，具有高度的责任心和主动性，能承受较大的工作压力。,硬件,500-2000人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6797588.html,海淀区,20k-35k,北京天码科技有限责任公司,5-10年,本科,团队稳定，工作时间有弹性,岗位职责1、负责公司大数据项目的需求收集、需求分析、平台整体架构设计、开发及上线全流程相关工作；2、数据管理工作，分析和维护数据标准、参与元数据管理和数据质量管理工作。3、按公司开发规范要求，编写项目相关文档，包括但不限于需求相关、设计相关文档；4、对团队中初、中级开发人员进行代码审查、技术指导，能够带领团队完成开发工作，按时高质量的交付系统。任职要求1、计算机及相关专业，本科及以上学历，熟练掌握Java/Scala/Python等多种语言；2、有多年大数据处理实战经验，熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖掘和数据可视化；3、熟练掌握大数据生态圈相关框架的使用及开发，比如Hadoop/Hive/Flume/Kafka/HBase/Sqoop/Oozie/Spark/Spark Streaming/Flink等；4、熟悉数据仓库和数据集市的框架结构，具备数据仓库与数据集市的架构设计能力；5、熟悉数据管理基本理论，对数据标准管理、数据质量管理、元数据管理有一定理解，并具备实施能力；6、对有挑战性的问题充满激情，具有良好的团队合作精神和较强的沟通能力以及抗压能力。,数据服务,150-500人,hadoop,北京
数据开发工程师(J200204019),https://www.lagou.com/jobs/6789096.html,海淀区,25k-50k,北京嘀嘀无限科技发展有限公司,3-5年,本科,快速成长团队 优秀员工福利,,汽车丨出行,2000人以上,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/6648680.html,朝阳区,15k-25k,北京贵士信息科技有限公司,1-3年,本科,弹性工作 扁平管理 零食供应 宽敞办公,岗位职责：1.        编写存储过程和SQL脚本实现业务数据需求；2.        根据数据产品的指标逻辑完成数据库设计，数据清洗计算，数据结果展示；3.        配合数据运营团队完成日常数据的发布。任职要求：1.        计算机/数学/统计学相关专业，一年及以上SQLServer等关系型数据库开发工作经验；2.        仔细认真负责，良好的逻辑思维能力，业务理解能力，团队沟通协作能力；3.        加分项：海量数据处理经验，数据库运维经验，Hadoop/Hive/Spark经验。,"移动互联网,数据服务",50-150人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6720088.html,海淀区,15k-30k,北京益友会科技有限公司,3-5年,本科,"平台大,团队强、职业成长性好",岗位职责：1、负责大数据平台的设计、开发、维护、升级等工作；2、负责离线/实时海量数据的采集、清洗、存储、加工处理和挖掘等工作，保证数据的高质量；3、负责大数据平台的算法设计和建模等工作，支持上层业务数据需求；4、负责大数据基础设施和平台改进，解决生产环境可用性和性能优化问题；5、配合业务团队进行定量和定性分析，把数据转化成为业务增值的信息。任职要求:1、3年以上大数据开发经验，全日制本科及以上学历，计算机、数学及相关专业；2、精通Java语言，有Scala、Python开发经验者优先；3、具有扎实的数据结构和算法基础，熟悉常用数据挖掘算法，有机器学习和深度学习开发经验者优先；4、精通SQL；熟悉大数据领域开源框架，包括Spark、Hadoop、ClickHouse、Kafka、Zookeeper、Hbase、Hive、Yarn、Elasticsearch、Flume等；5、良好的团队精神和合作意识，强烈的责任心，对工作有激情，良好的沟通能力。,"电商,消费生活",150-500人,hadoop,北京
大数据运维开发工程师,https://www.lagou.com/jobs/7184377.html,海淀区,15k-30k,中科威荣计算机技术有限公司,5-10年,大专,大厂项目 氛围好 工作有挑战,工作职责：1、负责腾讯AI平台TI-ONE产品交付部署工作，完成部署、调试和上线交付；2、负责产品技术咨询和技术支持，及时响应并处理客户问题与咨询；3、负责在项目现场对客户进行AI产品使用/运维培训事宜；4、负责AI平台的运维工作，包括日常巡检、故障处理，保证产品运行顺畅；5、做好集群扩缩容规划与实施，并能够根据现场集群负载情况，对集群做诊断和调优。1、计算机相关专业；2、五年以上运维经验，至少三年以上大数据开发运维经验；3、熟练Linux操作系统的配置、管理及优化，能够独立排查及解决操作系统层面的问题；4、熟练部署Linux环境下各种常见服务；5、熟练使用shell编写运维脚本；6、熟悉Hadoop、Hbase、Hive、Impala、Flume、Zookeeper、kafka、Spark、ELK等开源项目，并有大数据集群部署维护经验；7、熟悉Docker、k8s等容器技术；8、熟练使用批量管理工具，如Ansible、Saltstack；9、熟悉Python开发，有从事AI相关工作优先；10、有大数据/容器相关项目现场实施经验，工作积极主动，有较强抗压能力；,"移动互联网,数据服务",50-150人,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7073634.html,海淀区,15k-25k,百度时代网络技术（北京）有限公司,1-3年,本科,大数据开发，待遇优厚，双休。,大数据开发工程师岗位职责：1、负责大数据基础技术的调研和选型；2、负责数据ETL流程的建设，优化以及解决ETL相关技术问题；任职要求：1、具有扎实的php/java/c++/python（或关系）功底，熟练掌握架构设计原则和实际操作方法；2、掌握分布式、多线程及高性能的设计与编码及性能调优，熟悉使用常用关系型数据库，了解SQL优化方法；3、有大数据Kafka、Storm、Spark Streaming、Flink、hbase、es等使用经验，熟悉主流的大数据计算产品和数据分析技术并具有一定的相关项目经验，有flink、Spark Streaming处理海量数据经验者优先；友情提示：投递简历前可先搜索 百度企业信用 进行体验。,工具,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6824849.html,朝阳区,12k-20k,中国国际金融股份有限公司,应届毕业生,本科,金融数据开发，金融科技方向,工作描述： 1. 负责大数据处理、大数据整合开发；2. 负责大数据挖掘、大数据检索开发； 任职资格：1. 全日制本科及以上学历，计算机、软件工程、金融相关专业优先；2. 熟练掌握SQL语言，熟悉Oracle，sqlserver，mysql等关系型数据库，了解redis，mongo，influxdb等非关系型数据库的使用及优化，了解SQLlite等轻量级数据库；3. 熟练掌握开发语言，java、Python、、C++或go语言，有扎实的编程基础；4. 数据整合、数据校验经验者优先；5. 数据挖掘、信息检索背景者优先；6. 具备较强的主动性及快速学习，对数据敏感，能从数据中自主发现问题，具有良好的沟通协调能力；7. 具备良好的人际沟通能力，有团队意识。,金融,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6906703.html,海淀区,15k-25k,北京千喜鹤餐饮管理有限公司,3-5年,本科,五险一金，各项补助，公司食堂,"1. 计算机相关专业本科及以上学历，3年及以上数据开发经验；2. 熟悉hadoop相关技术，包括Mapreduce、Hive、Storm/Flink、flume、spark、Kafka、Oozie/azkaban等一个或多个技术框架的使用和开发,有平台搭建或维护调优经验者优先；3. 熟悉java，python开发语言的使用，熟练使用Flink或Storm实时计算平台进行计算和开发；4. 熟练掌握mysql数据库的使用；5. 对大数据技术有兴趣和热情，对工作有强烈的责任感，有较强的学习能力和创新精神；",消费生活,2000人以上,hadoop,北京
高级大数据开发工程师,https://www.lagou.com/jobs/6294695.html,朝阳区,15k-25k,龙湾科技（北京）有限公司,5-10年,大专,五险一金、带薪年假、户外拓展,"1、主要关注技能为 flink/blink（实时计算）, 次要关注技能为java  主要关注项目经验为 特征工程、用户画像、实时计算（非日志收集统计类项目）  5年及以上数据研发经验； 2、精通java开发； 3、精通flink等实时分析技术； 4、有特征工程、用户画像、实时计算等项目的开发经验； 5、有较好的逻辑思维能力，较强的抽象、概括、总结能力","移动互联网,企业服务",150-500人,hadoop,北京
高级数据开发工程师,https://www.lagou.com/jobs/7150282.html,东城区,18k-36k,盛银消费金融有限公司,3-5年,本科,"大厂高管，6险2金,餐补,车补",【工作职责】1.参与构建金融业务的数据仓库（分层建设、主题模型、元数据管理、性能和效率优化）2.参与/负责金融相关BI系统建设，做离业务最近的数据BI系统3.参与/负责业务数据仓库OLAP体系搭建，建设高效在线分析应用4.参与/负责业务数据日常需求开发，与分析师、PM、业务方一起感知变化，实现高效的数据运营5.与团队一起调研和实践热门数据仓库组件和技术（kylin、spark、storm、实时数仓......）【职位要求】1.优秀的金融业务理解能力，对金融类数据实践及金融业务目标和指标等有了解；2.具有良好的大数据建设体系化思维，熟悉数据仓库etl分层（ODS、base、fact、topic、cube）等建设方法，能独立抽象主题、建设模型、物理化并调整效率和性能。了解常用的BI系统建设方法，熟练使用主流BI工具，理解其实现原理、使用什么技术解决什么问题；3.熟练掌握 SQL，理解 Hive/MySQL/Oracle 原理和调优方法，有独立处理大规模数据/日志的经历4.有三年以上数据仓库(DW) / 商业智能(BI) / 数据统计相关工作经验5.熟练掌握 Java / Python / PHP 中至少一种编程语言6.优先：有信贷类金融公司同业经验者.,金融,500-2000人,hadoop,北京
大数据开发实习生,https://www.lagou.com/jobs/7135766.html,东城区,8k-15k,北京字节跳动科技有限公司,不限,本科,"下午茶,扁平管理,免费三餐,租房补贴",,文娱丨内容,2000人以上,hadoop,北京
美团App部-测试开发（大数据）,https://www.lagou.com/jobs/6717287.html,朝阳区,24k-45k,北京三快在线科技有限公司,3-5年,本科,大牛云集 弹性工作 上市公司,,消费生活,2000人以上,hadoop,北京
大公交-Java开发工程师（数据策略）,https://www.lagou.com/jobs/6514032.html,朝阳区,20k-40k,北京三快在线科技有限公司,不限,本科,团队牛人多，晋升空间大,,消费生活,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7168829.html,海淀区,30k-60k,北京字节跳动科技有限公司,不限,本科,字节跳动，今日头条,1、负责字节跳动电商相关业务数据仓库的开发与优化，建设电商数据中台；2、基于Hive/Flink等平台建设数据仓库，实时数仓建设，进行ETL开发；3、负责大数据能力在产品功能上的落地，推动产品数据化和智能化，为业务赋能；4、抽象业务逻辑，构建行业领先的大数据中台。职位要求1、熟悉大数据相关技术：Kafka/Flink/Hadoop/Druid/HBase/Hive 等；2、熟练使用 Java、Go、Python语言中的一种或者多种；3、具备数据库系统理论知识，掌握主流数据库管理和应用，精通SQL；4、了解统计以及数据挖掘、机器学习、人工智能技术，会使用关联分析、分类预测、聚类分析等常用分析方法；5、两年以上大数据开发经验，有高性能分布式平台开发经验，有电商行业经验优先。,文娱丨内容,2000人以上,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/7160224.html,西城区,25k-35k,建信金融科技有限责任公司,5-10年,本科,福利好，领导好,岗位职责：1、参与项目的需求和设计的讨论与分析，进行相应的数据库架构设计与数据库开发；2、数据库方案设计，负责生产及测试数据库的日常维护、管理和优化工作；3、负责撰写并维护工作相关的文档，如数据库的设计、管理和维护文档。 任职资格：1、熟悉关系数据库基本原理与特点，了解NoSql数据库设计思想和基本原理；2、熟悉关系型数据库基本操作，拥有oracle或Mysql数据库开发、管理和维护调优经验；3、熟悉Linux系统的常用命令，熟练使用shell或python等至少一门脚本语言；4、工作态度认真负责，具有良好的逻辑分析和学习能力，良好的沟通能力。5、2年以上数据库及数据库中间件的开发经验，拥有ORACLE DBA证书优先；ps:基本条件补充说明1、最高学历学校为985或211院校，或计算机类强校（仅限计算机类、软件工程类专业）。2、最高学历为硕士及以上的，本科院校须为全日制一本及以上院校；3、境外大学QS世界排名前500；4、社会招聘近5年跳槽次数少于3次（不含3次）。5、年龄原则上在35周岁及以下，表现特别突出者可酌情适当放宽年龄限制。,"金融,软件开发",2000人以上,hadoop,北京
大数据java开发,https://www.lagou.com/jobs/6820658.html,东城区,15k-30k,盛银消费金融有限公司,3-5年,本科,"大厂高管，6险2金,餐补,8小时","【工作职责】1.参与构建金融业务的数据中台的java服务开发，能设计可扩展、高可用、高性能、稳定安全的系统；2.参与/负责金融相关BI系统建设，提供java技术中台支撑BI系统,以及其他重要业务模块及核心框架的搭建及编码实现；3.参与/负责业务数据OLAP体系搭建，建设高效在线分析应用4.参与/负责业务数据日常需求开发，与分析师、PM、业务方一起感知变化，实现高效的数据运营5.与团队一起调研和实践热门技术，对新技术快速学习，可以影响提高团队技术能力及战斗力。【职位要求】1.优秀的金融业务理解能力，对金融类数据实践及金融业务目标和指标等有了解；2.对大数据架构及数据中台有较好认识，了解常用的BI系统建设方法，熟练使用主流BI工具，理解其实现原理、使用什么技术解决什么问题；3.熟练掌握 SQL，理解MySQL/Oracle 原理和调优方法，有独立处理大规模数据/日志的经历4.全日制统招本科及以上学历，3年以上互联网或金融类系统Java开发 / 商业智能(BI) / 数据统计相关工作经验5.精通Java及面向对象设计开发， 研究过优秀开源软件源码并有心得；具备很强的沟通能力、组织能力、分析和解决问题的能力以及团队协作精神，有强烈的责任心和使命感。",金融,500-2000人,hadoop,北京
资深广告大数据开发-数据仓库方向01,https://www.lagou.com/jobs/6141496.html,朝阳区,30k-50k,一点网聚科技有限公司,不限,本科,"股票期权,团队大牛多,工作氛围好,技术驱",岗位职责:1、负责广告业务数据仓库建设，构建数据集市，完善各项指标；2、面向PB级超大规模数据处理和查询需求，设计适应业务变化的合理的多维数据分析系统架构，满足多样性的需求；3、构建设计良好的数据流、调度系统、查询引擎、监控系统，保证系统稳定高效运行，以实现数据的最大价值；4、负责广告系统的数据分析，发现模式与规律，为商业化变现、系统改进提供数据支持。任职资格:1、具有丰富的数据仓库建设经验，对数据处理、数据建模、数据分析等有深刻认识，数据仓库/ETL相关开发3年以上工作经验； 2、优秀的数据开发能力，熟悉Hadoop/MapReduce/Hive/Spark/Kylin中的一种或多种技术，对某个技术方向有独到深入的见解，有开源项目代码贡献者优先； 3、数据敏感，逻辑清晰、严谨，理解数据发现价值，数据驱动业务； 4、有互联网大数据平台数据开发，数据仓库实施经验优先； 5、有广告行业相关数据加工经验优先； 6、985/211院校计算机相关专业，硕士优先~。 7、如果你觉得和以上要求不符，但你对这个岗位很感兴趣，并且确认你以往的其他经历或经验能给团队带来自己独特的价值，那么也欢迎投递简历；,文娱丨内容,500-2000人,hadoop,北京
大数据开发实习生,https://www.lagou.com/jobs/6851078.html,东城区,2k-4k,欧普拉软件技术（北京）有限公司,应届毕业生,本科,"上市公司,各种团建,试用期全薪，大牛",岗位职责:1.基于每天几十亿级展现数据，协助搭建大数据处理平台；实现实时流式计算；离线数据清洗，数据仓库创建2.根据业务的需要，协助设计开发合理高效的数据仓库模型，参与数据底层的工具、平台、部署流程等技术体系建设的研发工作3.了解产品业务，进行数据挖掘分析，和各个team合作，基于数据驱动持续地优化产品—该职位有2020/2021校招机会。名校/硕士在校生优先。任职资格:1.本科/研究生在校生，熟悉python， scala/java， golang等一种或多种编程语言，较强的编程能力；有一定的大数据处理技术使用经验；对业内先进的数据架构及技术有较强的学习能力及独立思考能力2.对开源的大数据组件有较好的使用经验，熟悉hadoop/hive/spark，了解elasticsearch/druid加分，精通上述一项或多项者优先3.熟悉数据仓库设计及开发，有大数据ETL等相关处理经验，灵活运用SQL实现海量数据ETL加工处理与查询性能调优4.熟悉基本的数据挖掘算法，常用的数据分析方法及工具，有一定的数据分析经验5.较强的学习能力，沟通协调能力及团队合作精神我们为你提供了：1、学习成长：可以提出自己的解决方法，你的声音可以被听到，没有任何限制；2、餐补：免费三餐，水果、零食、牛奶、面包定时供应；3、休闲：免费健身房、羽毛球、篮球俱乐部等。4、保险：虽然只是短期实习，但是实习期间，公司会为你购买人身意外保险，为你的安全加一分保障,移动互联网,500-2000人,hadoop,北京
大数据开发（实习生）,https://www.lagou.com/jobs/7150206.html,海淀区,8k-10k,第四范式（北京）技术有限公司,应届毕业生,本科,弹性工作 零食下午茶,"【岗位职责】：- 负责研发高效的机器学习计算框架，提升机器学习系统执行效率；- 负责研发面向不同场景的机器学习组件，降低解决方案的实现复杂度；- 负责提升机器学习算法可用性和易用性，降低使用门槛；- 创造更有价值的产品与服务，通过技术创新推动产品提升或客户业务增长。【岗位要求】：- 熟练掌握基于Spark的PySpark或Scala数据处理原理，具有Spark的性能优化或二次开发经验；- 熟练掌握Python，了解C++, Shell；- 了解机器学习建模过程【加分项】：- 熟练掌握一种分布式计算框架原理（如hadoop/spark/flink等），有性能优化或二次开发经验；- 有丰富的工程经验- 参加知名编程比赛如ACM/ICPC并取得优异名次- 熟悉大规模分布式并行计算的原理，有一定的相关研发经验- 熟悉至少一种集群资源与任务管理系统，如Yarn/Mesos/Kubernates- 熟悉常用深度学习的框架，如Pytorch/Tensorflow，有丰富的实践经验【入职后挑战与机遇】- 接触最前沿的自动机器学习算法- 机器学习算法和平台的深度融合",企业服务,500-2000人,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/6684706.html,海淀区,15k-30k,北京易联通达科技有限公司,5-10年,本科,五险一金，带薪年假，领导好,工作职责：1、负责电力大数据仓库的模型设计和优化，参与数据质量规则设计和数据质量评估，构建可扩展的数据仓库和分析解决方案；2、深入理解业务场景，参与数据架构方案规划设计、数据架构实现，参与大数据平台的数据集成，实现高质量的数据互通与共享。任职资格：1、计算机、信息科学、应用数学相关专业，全日制本科及以上学历；2、3年以上工作经验，1年以上数据仓库开发与建模经验，熟悉数据仓库模型设计，掌握常用数据建模方法；3、熟悉 Hadoop 生态相关技术例如 HDFS/MapReduce/Hive/HBase、并且有项目实施经验，对数据处理、建模、分析、数据架构等有一定理解和认识；4、有较好的业务理解能力，有大数据平台架构设计经验，有能源电力数仓建设经验优先。,"移动互联网,信息安全",50-150人,hadoop,北京
大数据高级开发工程师,https://www.lagou.com/jobs/6858982.html,海淀区,25k-35k,北京金山云网络技术有限公司,5-10年,本科,发展迅速 奖励丰厚,"工作职责：1. 负责数据分析平台体系建设，支撑运营及产品的数据需求2. 利用大数据组件对海量业务数据进行处理，搭建需求模型并独立完成数据模型的工程化实现3. 能够深入了解业务，挖掘痛点和问题，制定相应的解决方案 职位要求:1. 本科以上学历，有过大型互联网公司数据开发相关经验者优先2. 扎实的数据结构和算法功底, 具备一定的数据分析经验3. 熟练使用 Java、SQL，熟悉 Shell、Python 等至少一种脚本编程4. 熟悉大数据相关组件，Hadoop\Hive\Spark\MPP 架构等5. 良好的沟通、组织协调能力和强烈的责任心，具备很强的分析和解决问题的能力加分项：熟悉业界数据处理及分析工具，有相关的项目经验","移动互联网,数据服务",2000人以上,hadoop,北京
大数据工程师（数据应用开发方向）,https://www.lagou.com/jobs/7121711.html,朝阳区,25k-30k,新奥阳光易采科技有限公司,5-10年,本科,免费宿舍、餐补、话费补助,,企业服务,2000人以上,hadoop,北京
大数据平台开发工程师,https://www.lagou.com/jobs/7177697.html,海淀区,25k-50k,北京原力棱镜科技有限公司,5-10年,本科,研运发一体、全球性互动的游戏公司,岗位职责：1. 构建可定制化的数据分析平台。2. 负责数据仓库的建设以及维护。3. 负责分析基础数据，挖掘用户特征。4. 分析用户商业意图，挖掘用户行为潜在商业价值，为游戏商业化提供依据。任职要求：1. 统招本科及以上学历，计算机相关专业。2. 五年以上Java开发经验，熟悉 C++ 或 Python 语言优先。3. 熟悉列式存储，并且了解其中原理。4. 熟练使用 Linux，有一定JVM调优经验。5. 熟练使用 Flink、Hive、Kafka、Flume 等Hadoop生态组件。6. 有扎实的数据结构和算法功底，熟悉机器学习、自然语言处理、数据挖掘、分布式计算中一项或多项。7. 了解大数据前沿技术。,游戏,50-150人,hadoop,北京
百度网盘数据开发工程师,https://www.lagou.com/jobs/7183362.html,海淀区,20k-40k,百度在线网络技术（北京）有限公司,1-3年,本科,大平台 福利好,岗位职责1、负责业务板块数据平台建设，包括数据仓库建设、数据模型设计、数据报表开发等；2、负责业务各项数据统计、报表输出、效果分析、用户行为等数据支持工作；3、分析业务场景，输出专题报告，为业务决策和产品方向提供数据支持和指导。任职条件1、重点院校计算机、数学、统计学、经济类相关专业毕业，本科及以上学历；2、2年以上数据分析相关工作经验者；3、熟悉常用的分析方法，熟悉数据仓库方法论及ETL相关技术；4、熟悉SQL，具备ETL处理、SQL优化、海量数据处理的实战经验；5、熟悉Linux/Shell，熟悉Python等开发语言，编码基本功扎实；6、了解大数据平台hadoop技术栈，使用过Hive/HBase/spark等大数据平台组件优先；7、具备很好的业务敏感度，能够深入业务，实施数据驱动业务发展；8、工作积极主动，责任心强，抗压能力强，有较强的学习能力，具备良好的团队合作精神、沟通协调能力和工作推进能力。,工具,2000人以上,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/6552163.html,海淀区,25k-35k,北京搜狐新媒体信息技术有限公司,3-5年,本科,核心业务 团队氛围好,"工作职责：1、负责数据计算平台的架构设计，提升计算效率、提高数据平台的可用性2、实时计算平台、离线计算平台的维护，解决日常的问题3、实时跟进社区最新技术，并能应用到实际生产中4、深入理解广告业务逻辑，完成数据模型设计及优化工作 5、负责数据接入、清洗、底层重构，业务主题建模等工作，参与数据开发流程的优化以及相关技术问题的解决任职要求：1、正规统招本科及以上学历(硬性指标)2、熟悉数据仓库模型建模理论，有数据ETL、建模或数据分析相关经验； 3、精通hive/mysql,有一定的hql/sql性能调优经验，熟悉Hadoop/spark/kafka/storm等一项或多项大数据处理技术；熟练掌握java、shell、scala语言4、对开源分布式项目有较高热情，并能自主学习社区新框架、新技术，并应用到生产中","移动互联网,广告营销",2000人以上,hadoop,北京
etl数据库开发,https://www.lagou.com/jobs/6117013.html,东城区,8k-15k,深圳市长亮科技股份有限公司,不限,本科,职业发展多样化、平台空间大、升职机会多,职责描述：1.参与客户需求调研，熟悉业务逻辑及数据源表结构等；2.对源数据全量或增量进行抽取、清洗、转换、加载等程序开发；3.配置环境及安装数据库，搭建目标数据仓库，进行维度建模；4.按照数据分析模型或可视化需求，编写存储过程对数据进行加工汇总等。任职要求：1.熟练编写存储过程，熟悉Linux/centos系统环境；2.熟悉至少一种常见数据库：Mysql/Postgresql/Oracle/Sqlserver/HBase；3.具备良好的沟通能力，做事认真、仔细，具有团队协作能力；4.愿意分享和承担责任，抗压能力强，接受出差安排；5．具有银行管理会计相关系统实施经验者优先。,企业服务,2000人以上,hadoop,北京
【社招】高级大数据开发工程师,https://www.lagou.com/jobs/5730636.html,朝阳区,32k-42k,北京三快在线科技有限公司,应届毕业生,不限,福利齐全，成长空间大,职位职责： 1、基于海量数据，支持业务对数据的分析和使用； 2、支持业务处理数据的流式处理、分析客户行为等。 职位要求： 1、精通至少一门编程语言，熟练运用各种常用算法和数据结构，有独立的实现能力 ； 2、熟悉常用的开源组件：Hadoop/Hive/Spark/Storm，并了解其特性和使用场景优先； 3、熟悉机器学习、数据挖掘、数据分析、分布式计算至少某一方面，有较深的理论研究和实践经验优先； 4、数据分析、推荐、机器学习、数据挖掘相关的开发工作优先。,消费生活,2000人以上,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/7082657.html,朝阳区,20k-30k,北京三快在线科技有限公司,1-3年,本科,新业务、发展空间大,"数据开发JD工作职责：1.负责O2O业务风控数据仓库建设2.负责离线数据仓库ETL设计、开发和优化工作，保证数据准确、稳定、结构合理3.负责实时计算任务开发，结合业务进行实时应用场景的开发职位要求：1.3年以上大数据相关开发经验，本科及以上学历2.有较强的编程能力、丰富的编程经验，至少熟悉Java/Python/Scala其中一种编程语言3.熟悉数据仓库各类模型建模理论,了解数据仓库数据分层架构，精通多维数据模型、维度建模等数据建模方法4.熟练使用Hadoop、Hive、Mysql，熟悉Spark、Storm、Flink、Kafka等工具及具有相关使用经验5.对数据敏感、较强的逻辑分析能力、良好的团队协作精神，对海量数据处理和分析有热情",消费生活,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/7124297.html,海淀区,20k-30k,北京字节跳动科技有限公司,不限,本科,大牛团队，交流氛围浓厚,职位描述1、负责直播端及服务端海量用户行为数据的加工处理，数据洞察驱动业务优化；2、打造业界领先的大数据平台，支撑数据采集，加工，建模，分析，实验，可视化的全流程；3、打造业界领先的分布式计算，存储系统，解决大规模生产环境集群可用性和性能优化问题。职位要求1、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具；2、对开源大数据系统有相关经验者优先，包括但不限于Hadoop/Spark/Hive/Flink/Kafka/Druid 等；3、对数据敏感，掌握量化分析方法，善于从数据中发现问题者优先。,文娱丨内容,2000人以上,hadoop,北京
大数据开发工程师,https://www.lagou.com/jobs/6816643.html,海淀区,25k-50k,北京字节跳动科技有限公司,1-3年,本科,大厂核心部门,"职位描述1、负责广告业务平台及其相关系统的研发；2、负责现有系统的问题分析和改进，提高系统性能，保证系统稳定性；3、持续改进系统架构、核心算法或者核心技术等，保证系统高性能、高可用性和高可扩展性；4、新技术预研，完成项目的选型和设计，难点公关。职位要求经验1-3年学历本科及以上1、本科及以上学历，一年以上大数据系统开发经验；2、熟悉java/python/c/c++等语言， 熟练使用Linux；3、有大数据集、分布式计算工具(Hadoop，Spark，Hive，Flink, Druid，ES)等应用开发经验优先；4、有良好的团队合作精神，较强的沟通能力；5、愿意深入了解业务知识，并能敏锐的发现业务痛点；6、有A/B测试，数据统计，数据挖掘经验优先；",文娱丨内容,2000人以上,hadoop,北京
大数据安全开发工程师,https://www.lagou.com/jobs/6753411.html,海淀区,20k-30k,北京颐顺太和软件科技有限公司,3-5年,本科,加班少 六险一金 大平台 旅游津贴,"任职要求 ：                     1、本科及以上学历，3年以上大数据安全产品开发相关工作经验；2、熟悉Python/Ruby/Java/PHP/C++等至少一种，擅长Linux/Unix系统操作；3、熟悉Spark, Storm, Kafka, Hadoop, Hbase, Hive，ES等大数据相关技术及开发经验，了解高并发&高可用架构、负载均衡、消息队列、缓存、分布式存储的应用和开发；4、熟悉常见的机器学习算法，具备大数据安全分析和开发经验。职责描述：1、负责基于大数据平台构建企业内部安全产品，主导安全产品的架构设计和开发，包括但不限于安全运营SOC及安全自动化编排和响应SOAR等产品；2、负责安全系统服务接口的集成，以及安全运维自动化和智能化工具开发；3、负责大数据安全分析规则引擎和算法模型的开发和优化。",教育,2000人以上,hadoop,北京
大数据运维&amp;开发工程师,https://www.lagou.com/jobs/5281377.html,东城区,9k-14k,北京智慧空间科技有限责任公司,1-3年,本科,五险一金,1、负责现有风电大数据平台的运维与部分开发工作2、负责整理现有风电大数据平台的技术文档3、与其他公司的技术沟通工作4、有风电大数据领域经验，工业大数据领域经验优先,企业服务,15-50人,hadoop,北京
资深大数据开发,https://www.lagou.com/jobs/7140356.html,海淀区,30k-50k,海致网络技术（北京）有限公司,5-10年,本科,AI与金融结合，走在行业前沿,大数据开发工程师岗位职责：1.基于Hive，Spark，Hadoop的计算架构，进行大数据开发工作；2.对业务场景进行分析，通过Hive和Spark数据开发完成业务处理需求；3.能够定位数据计算任务的瓶颈并进行性能优化；4.能够针对具体的业务场景，实现基于大数据平台的服务开发。任职要求：1.计算机相关本科及以上学历，具备3年以上的工作经历；2.熟练掌握Java、Scala、Kotlin等java系编程语言，了解Python；3.熟练掌握Linux、git、maven等开发相关工具的使用；4.熟悉数据库，SQL语法，了解数据仓库建模方法论；5.精通Hadoop、Hive、Spark、Hbase等相关组件，包括组件的使用和实现原理，有相关源码阅读经验优先；6.有ETL性能调优经验者优先；7.有强烈的责任心和团队合作精神，具备良好的沟通能力以及快速学习的能力。,"移动互联网,企业服务",150-500人,hadoop,北京
数据仓库开发工程师,https://www.lagou.com/jobs/6747879.html,西城区,15k-25k,泰康养老保险股份有限公司,3-5年,本科,朝阳产业、福利好、不加班,职责描述        参与公司数据平台建设，负责整合公司内部各种源数据，对数据进行清洗、建模、整合，设计开发各类数据模型和数据流程，持续优化完善，支持业务分析。任职要求1、有数据仓库需求调研和需求分析经验，能根据业务需求设计数据仓库模型，并对数据仓库数据模型进行管理，保证数据质量，3年以上数据仓库开发实施经验，精通保险领域业务者优先。2、精通SQL开发，熟练掌握至少一种ETL工具，有informatica开发经验者优先。3、熟悉至少一种常用大型数据库，有Oracle、Greenplum开发维护经验优先。4、熟悉C或JAVA开发，至少掌握一种脚本开发语言。5、国家统招本科一批以上学历（211以上优先）。6、工作认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧。,"企业服务,金融",2000人以上,hadoop,北京
大数据平台开发工程师,https://www.lagou.com/jobs/6929180.html,海淀区,28k-40k,北京颐顺太和软件科技有限公司,5-10年,本科,发展前景好,职位描述：1、 负责新东方集团Hadoop生态圈的大数据平台开发，完善优化大数据平台的设计开发。2、 紧密配合产品经理，数据开发团队，理解业务需求。针对不同的业务场景，制定合理的系统架构和实现方式，可以独立完成技术解决方案。3、 周期性产品迭代开发，团队内部协调配合，解决技术难题和性能瓶颈。4、 参与和主导技术难题攻关，持续优化系统，使系统具备更好的灵活性和可扩展性。 任职要求：1、 计算机相关专业本科以上学历，3年以上大数据生态圈工作经验，2年以上数据产品实践经验。2、 对数据产品设计、交互、系统架构有深刻的理解。3、 熟悉Spark/MapReduce/Hbase/Presto/Impala/Flink等开源大数据技术。4、 3年以上的JavaEE开发经验，熟悉SpringMVC、Spring、SpringBoot、Mybatis等。5、 熟练掌握ZooKeeper、Redis、Nginx、Kafka技术。6、 有良好的团队合作精神和学习能力。,教育,2000人以上,hadoop,北京
大数据开发负责人,https://www.lagou.com/jobs/5655480.html,海淀区,50k-70k,贝壳找房（北京）科技有限公司,5-10年,本科,集团层面基础架构 带薪年假,工作职责:1. 带领大数据团队，包括数据建设、数据质量治理、数据应用和数据产品；2. 设计并优化贝壳大数据架构，包括数据建设流、数仓模型、数据集市架构；3. 构建数据质量保障体系，包括全流程监控、预警和数据快速恢复、数据质量评估4. 完善数据应用体系，包括数据产品构建、数据分析需求响应、数据集市5. 数据工程架构迭代，包括实时流、权限管理、调度、应用输出等任职资格:1、5年以上大数据平台开发、搭建相关经验2、具有前沿的大数据技术实践经验3、很强的项目驱动和团队管理能力4、统招本科以上学历,房产家居,2000人以上,hadoop,北京
资深数据开发工程师(偏模型),https://www.lagou.com/jobs/7019757.html,朝阳区,25k-30k,车易拍（北京）汽车技术服务有限公司,3-5年,本科,六险一金 地铁周边 年终奖金,岗位职责：1、负责平台系统的可用性、容量、性能、监控、发布、安全等运维管理工作，确保系统持续稳定、高效运行；2、沉淀分析思路与框架，提炼数据产品需求，提供对重点业务的数据分析&洞见，能够帮助业务给出优化建议和方案；3、参与大数据底层数据基础搭建，包括数据仓库、数据集市的模型设计与开发，ETL数据准确性验证及ETL任务的优化；4、负责数据质量、稳定性等数据管理，数据内部共享融通的数据平台，让数据标准更规范、数据获取更高效；5、承担对大数据架构组件的优化和改造的工作，设计以及开发核心代码，带领并解决项目开发中的技术难点；6、参与产品规划及设计讨论。任职要求：1、2-5年海量数据分布式数据处理和离线数据仓库设计相关工作经验；2、熟练应用并深刻理解大数据相关组件（包括但不限于Kafka、Hadoop、HBase、Yarn、Zookeeper、Spark、Hive、Elasticsearch）；3、熟悉数据仓库、数据集市模型设计方法论，并有实际模型设计及ETL开发经验 ；4、具有较好的数据建模经验，并且能够使用相应的方法论（例如维度建模方法论Kimball）进行较好的数据模型建模经验；5、熟悉Linux平台，熟练使用Shell、Python等脚本语言经验其中一种；6、具备良好的抗压能力、沟通能力和团队精神，有独立开展分析研究项目能力，具备跨部门协调获取资源的能力；7、能根据业务需求进行高效的数据建模和逻辑抽象，输出合理的数据建设解决方案；8、熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、性能调优等 。,电商,500-2000人,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/5582113.html,朝阳区,40k-60k,中信百信银行股份有限公司,5-10年,本科,互联网金融创新，成长型公司，技术挑战大,"资深数据工程师 工作职责：深入了解业务，运用算法支撑和优化金融服务平台的产品和运营方案；调研新的机器学习和统计建模的方法，并用这些方法应用实际业务问题中；清晰简洁的将数据实验结果沟通给公司各个层级的同事；  任职资格：全日制统计学、计算机科学、数学或相关专业本科及以上学历，5年以上数据研发相关工作经验；熟练使用Excel、SQL, 熟悉至少一种数据分析工具hive/impala/presto/R/Python/SAS;具有良好的逻辑思维能力和分析能力，能够基于对业务的深入理解，从数据中探查和解决问题；具备良好的团队协作和沟通合作能力，对新技术有强烈求知欲；",金融,150-500人,hadoop,北京
数据开发工程师,https://www.lagou.com/jobs/6987282.html,朝阳区,20k-40k,北京三快科技有限公司,3-5年,本科,良好的技术氛围，富有挑战性的工作内容。,"岗位职责-深入业务理解，数据模型设计，参与团队数据模型优化-完成数据模型的ETL实施，参与团队ETL流程的优化以及相关技术问题的解决-满足运营方的数据需求，提供面向运营的OLAP、报表、数据提取等数据服务-参与数据产品的设计和开发，助力打车业务增长岗位要求-计算机相关专业本科及以上学历-熟悉数据仓库模型建模理论，有两年以上大数据ETL、建模或数据分析相关经验-精通hive/mysql,有较强的hql/sql性能调优经验，熟悉Hadoop/spark/kafka/storm等大数据处理技术优先-有较好的逻辑思维能力，较强的抽象、概括、总结能力",消费生活,2000人以上,hadoop,北京
数据仓库开发工程师,https://www.lagou.com/jobs/7157190.html,朝阳区,20k-40k,一点网聚科技有限公司,3-5年,本科,大数据 MapReduce 数据仓库,工作职责：1、负责一点资讯大数据仓库平台的开发建设；2、设计并实现大规模分布式计算算法，处理海量数据；3、跨部门协作，协同分析并解决数据问题；4、深入的数据挖掘和数据分析。任职资格：1、熟练使用Java/C/C++/Python 等语言进行开发（至少熟练掌握一种），有高效、高可靠代码开发经验 ；2、有扎实的算法基础，熟悉常见的数据结构，了解分布式算法和分布式系统；3、精通常见的开源分布式计算/存储相关技术，包括YARN，MapReduce，Hive，Pig；4、熟悉常见的数据计算优化策略，有优化MapReduce作业、Hive作业，Pig作业执行效率经验；5、熟悉OLAP引擎者的设计和开发者优先 ；6、熟悉机器学习，有数据挖掘和深度数据分析者优先。,文娱丨内容,500-2000人,hadoop,北京
大数据开发高级工程师,https://www.lagou.com/jobs/4808214.html,海淀区,20K-35K,秒针信息技术有限公司,5-10年,本科,公安，工业物联网，大数据，AI,"1、 从事大数据平台建设开发，数据治理，分析，编码的工作。2、 负责大数据项目的核心业务设计和开发；3、 随着项目发展，不断优化分布式系统架构，提高可用性，扩展性和性能；4、 调研新的大数据技术并进行应用，助力业务成长；任职要求：1、数学、统计、计算机等相关专业，大学本科及以上学历；2、了解统计学、数学、人工智能和数据挖掘理论基础，了解数据仓库、数据挖掘与分析的相关知识，具有良好的数据模型设计能力，熟悉常用统计分析方法、数据挖掘基本算法；3、熟悉Linux/Unix操作系统，熟练掌握java/scala/go/python/php等一种或多种编程语言；4、熟悉 hadoop ecosystem，包括但不限于Hadoop, HBase, Hive, Kafka, Flume，ElasticSearch，Spark，Storm, Druid/Presto/Impala 等，具备2年以上开发和使用经验；5、了解Oracle、MySQL、SQL Server、DB2至少一种数据库软件，熟练使用SQL完成常规取数，使用Linux Shell、Python脚本初步处理数据；6、熟悉联机分析处理(OLAP) 理论与工具，掌握OLAP数据平台，熟悉大数据结构化及非结构化分析工具；7、 学习能力强，适应能力好，主动性强，抗压能力强，团队协作意识强，能适应一定程度的加班；8、 具备良好的沟通能力和表达能力，有较强的数据敏感度，良好的沟通协调能力，能承受一定的工作压力","数据服务,广告营销",2000人以上,hadoop,北京
资深数据开发,https://www.lagou.com/jobs/6769593.html,海淀区,20k-40k,贝壳找房（北京）科技有限公司,3-5年,本科,免费三餐，春节额外假期，购房租房优惠,岗位职责：1.负责人力财务的数据仓库建设(分层建设、主题模型、元数据管理、性能和效率优化)2.负责日常需求开发，实现高效的数据运营3.参与实时数据计算和数据服务的性能优化、稳定性建设任职要求：1. 有优秀的业务理解能力，及足够的主动性和好奇心2. 熟悉数据仓库建设方法论    a：了解etl分层（ODS、DWD、DWS、ADS）建设方法    b：了解主题建设方法，能抽象主题、建设模型、物理化并调整效率和性能    c：了解常用的BI系统建设方法，熟练使用主流BI工具，理解其实现原理、使用什么技术解决什么问题3. 熟练掌握 SQL，理解Hive、MySQL、数据库原理和调优方法，能处理大规模数据4. 熟悉常用的大数据组件，如Hadoop、HDFS、Yarn、Hive、Spark、Kylin等5. 实时数据计算方向：扎实的大数据和分布式系统建设经验，具备丰富的（Storm、Flink、Flume、Kafka等）流式大数据（PB级数据集 ）计算经验6. 熟练掌握 Java、Python、Scala等至少一种编程语言,房产家居,2000人以上,hadoop,北京
阿里大数据团队—java开发,https://www.lagou.com/jobs/6999811.html,朝阳区,25k-40k,阿里巴巴（中国）网络技术有限公司,3-5年,硕士,大中台小前台、氛围好、文娱、大数据,工作内容：负责数据核心产品如文娱数据资产、文娱数据银行等产品的架构设计及核心代码的实现职位描述：1.三年以上Java开发经验，良好的java基础，对高并发、高可用架构系统有深刻的理解，有大型分布式系统设计或开发经验2.熟悉Classloader、JIT、GC、Sandbox等JVM原理并有实战经验3.了解分布式系统原理：CAP、最终一致性、幂等操作等；大型网络应用架构：消息中间件、缓存、负载均衡、集群技术、数据同步；高可用、可容灾分布式系统设计能力3.有微服务架构设计和开发经验，精通RPC网关／服务注册发现 / 服务治理／分布式跟踪监控4. 具备较好的逻辑思维能力、沟通能力、学习能力，工作中积极主动、有责任心、抗压性强,电商,2000人以上,hadoop,北京
数据库开发工程师,https://www.lagou.com/jobs/5704276.html,海淀区,10k-20k,创而新（中国）科技有限公司,不限,本科,餐补、五险一金、绩效奖金,"岗位职责：1、熟练掌握 SQLserver 数据库的日常维护操作；2、负责处理海量数据的对接及数据库存储；3、数据库日志分析；4、可编写高效脚本及任务的监控与优化，应用服务器的体系管理与性能优化；5、数据库安装配置、管理、故障诊断、备份和恢复，搭建稳定的，易扩展的，高可用性的数据服务平台；6、数据库性能监控与优化、数据库安全、数据库空间管理等；7、熟悉并熟练安装维护数据库高可用策略（主从，复制订阅等）任职要求：1、熟悉Visual Studio.Net开发环境，熟练掌握C#.net,ASP.NET ，熟悉MVC3框架开发；2、熟悉软件技术文档的编写，具备良好的文档编制习惯和代码书写规范；3、熟练掌握SQL Server数据库开发及设计；1. 精通SQL Server体系结构、数据库性能调优;2. 精通T-SQL查询优化,能够从业务逻辑端开始对相关数据库应用进行优化;3. 熟悉SQL SERVER数据库复制原理;4. 熟悉SQL SERVER数据库集群及镜像部署,有过大规模部署经验；5. 具有处理千万级数据的高并发处理能力；6. 对 Mysql 或有实际维护经验更佳；","移动互联网,教育",150-500人,hadoop,北京
ETL数据库开发,https://www.lagou.com/jobs/6010811.html,朝阳区,14k-22k,北京宇信科技集团股份有限公司,3-5年,本科,七险一金，完善的晋升渠道,"岗位职责： 负责银行ETL的开发（报表项目，ODS，ECIF系统,风险优化等） 任职要求： 1、熟悉ETL数据加工流程 2、熟练掌握Oracle，DB2数据开发 3、熟悉以下一项或多项技术能力：ETL开发工具DataStage、Informatica、存储过程、SHELL脚本、TD脚本开发",企业服务,2000人以上,hadoop,北京
高级Java开发工程师（数据分析方向）,https://www.lagou.com/jobs/6436004.html,朝阳区,20k-25k,北京运车网网络科技有限公司,5-10年,本科,全额五险一金；补充医疗；年终奖；定期体检,"岗位职责1、负责数据分析平台、可视化及数据统计相关平台的架构设计与实现2、参与系统需求分析与设计，负责完成核心代码编写，接口规范制定。3、参与架构设计，持续重构优化现有系统主框架和业务代码4、主导技术难题攻关，持续提升产品的高处理性能和可维护性，保证系统的安全、稳定、快速运行5、负责开发过程的优化及团队技术能力的提升，包括但不限于开发规范的制定、系统方案的评审，代码Review，技术布道与培训，开源组件选型等；任职要求1、 精通Java编程，理解java运行时工作原理，熟悉jvm性能调优，2、 熟练掌握JS、HTML、CSS、jquery等技术，有使用VUE框架经验者尤佳2、熟练使用springMVC，spring，mybatis等框架，SOA服务框架框架，了解其原理和实现机制，阅读过源码优先3、熟练掌握MySQL数据库，有数据库调优经验，熟悉hadoop/hbase/spark/storm相关技术者优先；4、熟悉1inux/she11编程，能够利用常用的工具对程序进行跟踪诊断；5、6年以上工作经验，本科及以上学历,计算机相关专业；",消费生活,150-500人,hadoop,北京
中级Java开发工程师（数据分析方向）,https://www.lagou.com/jobs/6435985.html,朝阳区,15k-20k,北京运车网网络科技有限公司,5-10年,本科,全额五险一金；补充医疗；年终奖；定期体检,"岗位职责：1、负责数据分析平台、可视化及数据统计相关平台的开发与维护工作2、参与系统需求分析与设计，负责完成核心代码编写，接口规范制定。3、参与解决项目中的技术难题，关键技术难点攻关；4、负责线上系统的日常维护，线上问题分析、排查和处理5、能够学习和掌握完成本职工作所需要的相关知识，并在工作场景中应用和总结；6、根据开发规范编写各种开发文档及项目文档等任职要求：1、精通Java开发语言，熟练掌握JS、HTML、CSS、jquery等技术，有使用VUE框架经验者尤佳2、熟练使用springMVC，spring，mybatis等框架，SOA服务框架框架，了解其原理和实现机制，阅读过源码优先3、熟悉MySql、MongoDB数据库，熟悉复杂sql的处理及优化，有大数据处理经验优先考虑4、熟悉1inux/she11命令，有1inux环境下开发经验与技能优先；5、4-6年工作经验，本科及以上学历,计算机相关专业；",消费生活,150-500人,hadoop,北京
资深软件开发工程师（引擎数据 Go）,https://www.lagou.com/jobs/5877788.html,海淀区,25k-50k,北京嘀嘀无限科技发展有限公司,5-10年,本科,海外市场 复杂系统 大牛指导 快速成长,滴滴外卖配送服务的分单引擎是外卖业务中最具有技术挑战的业务方向之一，其技术架构脱胎于滴滴多年以来在出行业务上的积累，针对外卖场景做了非常深度的定制改造，当前已经可以支持远大于拼车复杂度的拼单计算，并且还在持续优化中。分单引擎涉及到复杂的VRP算法优化、流式计算框架、资源调度平台研发等，需要对各种C++/Go实现的工程和算法代码进行性能和稳定性优化，不断提升引擎的计算能力。同时分单引擎还需要特征工程相关开发，以及为分单策略和预估模型等提供策略工具开发，提高研发和策略落地效率。目前正针对海外市场及国内市场积极开展业务。职责：1、为滴滴外卖业务研发最为核心的配送策略引擎架构，设计和实现配送场景下的分布式计算架构，确保在高并发、大数据量、复杂模型计算的场景下保持系统稳定和高性能；2、负责大数据的特征工程建设，并提供高性能的特征存取服务；3、为分单策略，预估模型提供体系化策略效率工具，提高策略验证能力。4、在充分理解外卖业务的前提下，对配送业务进行持续的抽象和建模，并持续优化架构以适应业务的不断演进。1、本科及以上学历，计算机相关专业；2、有扎实的代码能力，精通C++或Golang之一，熟悉Linux环境开发；3、有扎实的数据结构、算法功底；4、有分布式存储或计算经验，精通Hadoop、SparkStreaming，Flink/Redis、HBase、LevelDB等系统优先；5、有至少3年以上一线互联网服务的项目经验，有大规模高并发系统负责人经历优先；6、有搜索、推荐、机器学习等领域经验者优先；7、积极主动，敢于挑战，善于沟通合作。,汽车丨出行,2000人以上,hadoop,北京
大数据平台开发工程师,https://www.lagou.com/jobs/6391032.html,朝阳区,30k-50k,行吟信息科技（上海）有限公司,3-5年,本科,福利待遇好,"【工作职责】1. 负责数据分布式存储、计算系统；2. 高水平团队，有 Ownership 的推动数据系统迭代；3. 从架构到业务，支持公司快速发展；4. 支持 CRM、搜索、机器学习平台等应用的底层数据架构。 【职位要求】1. 掌握分布式系统原理，对存储、离线计算、实时计算中的一项或多项有深入的理解和认识；2. 很强的系统设计&编码能力，追求优雅的设计和优秀的代码质量，高标准，快速行动；3. 思路清晰，具备生产系统快速 trouble-shooting 的经验和能力，擅长分析更深层次的原因；4. 对 HDFS, RocksDB, LevelDB, Memcache, Redis, MySQL, HBase, Kafka 的一项或多项有开发经验；5. 了解 Kafka、 MQ 等消息系统；6. 对 Spark, Druid, Flink, OLAP 的一项或多项有经验者优先；7. 拥抱新技术，有很强的学习能力。",消费生活,500-2000人,hadoop,北京
大数据开发岗,https://www.lagou.com/jobs/6749416.html,西城区,15k-20k,中国联合网络通信有限公司,1-3年,本科,绩效奖金、带薪年假、五险两金、弹性福利,"主要岗位职责:1．负责基于大数据平台数据处理、开发及性能优化等工作；2．负责异构系统数据的对接与存储工作；3．负责向外部门输出数据的开发与维护工作；4.   完成领导交办的其他任务。   任职资格要求：1．计算机、软件工程、信息通信等相关专业本科以上学历，有2年及以上企业级数据平台相关系统开发经验；2．扎实的JAVA基础，熟练掌握J2EE开发及相关技术；3．熟练SQL开发，精通Mysql等分布式关系型数据库中的一种或几种；4．熟练掌握Hadoop及Map-Reduce应用开发，熟练掌握HBase、Hive、Storm、Spark等大数据开发工具中一种或几种；5．熟练掌握Kafka,Mycat，MQ等主流中间件的开发使用技术；6．熟悉Linux系统，具备Shell、Python等脚本开发能力者优先；7．乐于接受新事物，工作认真负责，能够承受一定的工作压力；8．年龄35周岁及以下。","电商,通讯电子",2000人以上,hadoop,北京
数据库开发岗,https://www.lagou.com/jobs/6749448.html,西城区,15k-20k,中国联合网络通信有限公司,1-3年,本科,绩效奖金、带薪年假、五险两金、弹性福利,主要岗位职责:1.负责电商数据库设计、开发及维护；2.制定和实施数据库运维计划；3.与开发人员共同完成SQL语句优化，编写触发器、存储过程等后台程序；4.完成领导交办的其他任务。   任职资格要求：1.有MySQL等主流关系型数据库的设计、开发及维护经验；  熟悉数据库的基础理论，掌握数据库开发工具，具备开发复杂的SQL语句的能力，具备一定的数据库架构设计能力；  2.掌握MySQL等数据库调优、核心参数设置；会MyCAT加分，有实际分库分片经验者加分；熟悉MHA、PXC、Galera等集群搭建和故障恢复，加分；  3.熟悉Linux/Unix操作系统，具备Shell/Perl/Python编程能力者优先。  4.乐于接受新事物，工作认真负责，能够承受一定的工作压力。  5.熟悉Linux/Unix操作系统，具备Shell/Perl/Python编程能力者优先。6.思路清晰，善于思考，能独立分析和解决问题；7.责任心强，具备良好的团队合作精神和承受压力能力。8.35周岁及以下。,"电商,通讯电子",2000人以上,hadoop,北京
大数据开发讲师P4（架构师级别）,https://www.lagou.com/jobs/6596408.html,海淀区,25k-50k,北京开课吧科技有限公司,5-10年,本科,弹性工作时间 出国游 年度体检,"工作职责:1、负责相关课程教学工作，按进度完成教学任务2、参与大数据课程研发和后期优化3、参与学术交流与研讨，不断提升业务水平4、定方向，定目标，定主题，定大纲5、5年以上开发经验，2年以上架构经验；6、讲授VIP的课程，课后回访和监督7、支持销售、运营、班主任的工作。任职需求：1、精通大数据离线计算生态（Hadoop、Sqoop、zookeeper，hbase，Hive、Spark、调度框架等）2、精通大数据实时计算生态（Storm、Spark、Flink,Flume、Kafka等）3、精通分布式系统、负载均衡技术、搜索技术等4、精通机器学习常见算法5、表达能力强，声音清晰自然，个性开朗，乐于与人交流,幽默风趣；6、精通Java并发编程，深入了解JVM底层原理，有较强的数据库设计及架构优化经验；7、负责新兴大数据技术的调研、研发、原理研究工作，让其成为课程产品的基础素材；8、必须有hadoop的源码阅读经验，其他大数据组件源码比如hbase，spark，kafka不限以上几种，有其他源码阅读经验.9、有大数据相关技术源码级二次开发经验者优先.10、有大型分布式平台架设经验、数据仓库架设经验优先.11、五年以上大数据工作经验。","移动互联网,教育",500-2000人,hadoop,北京
数据开发专家,https://www.lagou.com/jobs/6249438.html,海淀区,35k-45k,拉扎斯网络科技（上海）有限公司,5-10年,本科,固定13薪，发展空间大,"岗位描述1、负责饿了么新零售数据建设，参与或负责数据仓库设计、建模、研发等 2. 参与或负责业务支撑系统的数据开发和管理工作，具有研发规范、质量规范、保障规范的制定与推动实施落地的能力3. 支持指标体系建设的建设与管理4. 负责离线和实时数据应用层的搭建。岗位要求1、 从事数据仓库领域工作至少4年以上，熟悉数据仓库模型设计方法论，有分布式数据存储与计算平台应用开发经验，在大数据资产管理与治理有一定成功产品化经验；2、 熟悉Hadoop生态相关技术并有相关开发经验，精通SQL开发及SQL性能调优，熟悉基Hadoop, Hive等分布式计算平台的数据开发 ；3、 精通数据仓库建模及ETL设计开发，有较为系统的海量数据性能处理经验；；4、 具备一定的Perl、JAVA、Python等至少一门语言的开发能力，掌握UDF和Map-Reduce开发；5、 具有Spark/Flink/Storm开发经验者尤佳；6、 具备数据挖掘和机器学习算法应用经验尤佳；",消费生活,2000人以上,hadoop,北京
高级数据开发工程师,https://www.lagou.com/jobs/6803352.html,海淀区,20k-25k,深圳市酷开网络科技有限公司,3-5年,本科,福利待遇好，发展空间大,"岗位职责：1、 从事大数据平台建设开发，数据治理，分析，编码的工作。2、 负责大数据项目的核心业务设计和开发；3、 负责数据仓库建设，ETL开发工作；4、 负责流计算系统设计、开发、重构等工作；5、 随着项目发展，不断优化分布式系统架构，提高可用性，扩展性和性能；6、 调研新的大数据技术并进行应用，助力业务成长。任职要求：1、本科及以上学历，计算机相关专业毕业；2、熟练掌握java、scala、Python等开发语言，至少一门；3、熟悉大数据平台Hadoop，包括但不限于Hadoop, HBase, Hive, Kafka,Flume，ElasticSearch，Spark，Flink, Druid/Clickhouse/Kylin 等，具备3年以上开发和使用经验；4、熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；5、有Flink/Spark等开源流式计算系统开发经验者优先；6、具备良好的沟通能力和表达能力，有较强的数据敏感度，良好的沟通协调能力，能承受一定的工作压力。",移动互联网,150-500人,hadoop,北京
高级数据库开发,https://www.lagou.com/jobs/7136144.html,丰台区,25k-30k,企易共创（北京）科技有限公司,5-10年,本科,五险一金 发展空间大 领导好沟通,岗位要求：1、计算机及相关专业毕业，5年以上相关工作经验；2、熟悉Oracle、DB2、Mysql等数据库，熟练运用SQL；3、熟悉Linux，掌握常用的linux命令；4、熟悉kettle等ETL工具优先；5、熟悉BI工作流程，参与过数据仓库应用项目开发者优先；6、熟悉金融业务，有银行数据类项目开发经验者优先。岗位职责1、参与银行数据仓库相关应用系统需求分析、设计、开发；2、参与其他数据分析类项目相关应用系统需求分析、设计、测试,"金融,数据服务",15-50人,hadoop,北京
大数据开发工程师（偏java）,https://www.lagou.com/jobs/6836666.html,朝阳区,10k-15k,天阳宏业科技股份有限公司,3-5年,本科,五险一金，年假,任职要求：1）本科及以上学历，计算机或应用数学专业优先，有金融行业从业经验者优先。2）熟悉Linux操作系统并有Shell开发经验，熟悉Oracle、SQL Server等传统的关系型数据库。3）熟悉Java（偏好）/Scala语言，具有3年及以上开发经验4）熟悉Hadoop、Hive、Spark等分布式大数据技术，有Spark Streaming、Storm开发经验者优先。5）有较强的逻辑思维能力和创新精神，具备良好的沟通能力和文字表达能力。6）有较强的学习能力，对技术有钻研精神，热衷于新技术的学习和实践。7）有较强的团队合作意识，对工作有热情，能够承受压力、接受挑战。,"企业服务,金融",2000人以上,hadoop,北京
大数据运维开发工程师,https://www.lagou.com/jobs/7140598.html,东城区,20k-30k,凡普金科集团有限公司,3-5年,大专,五险一金 领导好,岗位职责：大数据系统Hadoop、Hbase、Kafka等集群日常运维，包括扩容、性能优化、备份等，确保服务和部署稳定性。任职资格：1、计算机科学/信息技术相关专业，专科以上学历；2、三年以上linux系统运维工作经验，两年以上Hadoop系统实际维护经验；3、熟悉大数据相关的技术基本原理和集群运行的基本原理（hadoop、cloudera、mapr等）;4、熟悉常见的数据库部署和操作（MySQL\mongodb\redis等）5、熟悉常用脚本语言（Python\shell等）,金融,2000人以上,hadoop,北京
