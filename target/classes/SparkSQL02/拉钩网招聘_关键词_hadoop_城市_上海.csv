job_name,job_url,job_location,job_salary,job_company,job_experience,job_class,job_given,job_detail,company_type,company_person,search_key,city
大数据开发工程师,https://www.lagou.com/jobs/6626474.html,浦东新区,11k-22k,上海商涌网络科技有限公司,3-5年,本科,学习成长快 团队氛围好发展空间大新兴行业,"职责描述： 1、参与大数据平台环境搭建，架构设计及优化，源码二次开发；2、参与基于HBase分布式数据高并发查询架构设计及优化，程序开发；3、参与基于Flink实时平台，实现数据采集，清洗和集成开发任务，并及时跟进解决问题；4、钻研最新大数据技术，能够更为深层次地理解数据技术架构。任职要求：1、计算机相关专业本科及以上学历，两年以上大数据开发工作经验；2、熟悉Linux、Unix系统及掌握基本命令；3、熟悉Hadoop，HBase，Flink，Spark及其基本理论。有过HBase实时高并发查询开发经验和Spark开发经验；4、熟悉使用SQL语句，对SQL查询优化有丰富的经验，熟悉MySQL，熟悉存储过程、函数、包、触发器等；   5、掌握Shell脚本编写，至少掌握两种及以上编程语言如Python,Java,Scala等； 6、了解高并发实时访问开发及其架构构建，具备实施调优经验；7、对Spark，Hadoop等开源的源码有过研究，对于新技术有研究热情，较强的学习能力和团队协作意识；8、有过保险/金融/医疗行业从业经验者优先。","数据服务,人工智能",50-150人,hadoop,上海
大数据开发 (MJ000024),https://www.lagou.com/jobs/5869943.html,浦东新区,15k-25k,上海剑圣网络科技有限公司,3-5年,不限,福利好；工作氛围佳,岗位职责：     1、负责大数据平台的搭建、功能设计、及核心模块的开发；2、负责指导团队成员开发，对代码质量进行监控、保证代码的可读性、易维护性，确保开发质量；3、负责大数据平台新技术的调研及技术选型。4. 对现有系统的不足进行分析，难点攻关，找到目前系统的瓶颈，改进系统架构设计，提高系统性能5. 根据用户行为分析，挖掘有价值的信息，指导公司运营和决策6、负责相关技术文档编写工作。任职要求：岗位职责：     1、负责大数据平台的搭建、功能设计、及核心模块的开发；2、负责指导团队成员开发，对代码质量进行监控、保证代码的可读性、易维护性，确保开发质量；3、负责大数据平台新技术的调研及技术选型。4. 对现有系统的不足进行分析，难点攻关，找到目前系统的瓶颈，改进系统架构设计，提高系统性能5. 根据用户行为分析，挖掘有价值的信息，指导公司运营和决策6、负责相关技术文档编写工作。任职要求：1、计算机相关专业全日制本科及以上学历，3年以上开发工作经验；2、有2年以上Java Web开发经验，能够熟练使用java编写MapReduce程序；3、2年以上大数据开发经验，对HBase，Hive，Spark，Kafka等组件原理和使用有清晰的理解；4、熟练使用hive sql，有数据仓库经验更佳；5、熟练使用scala，有scala编写SparkStreaming进行实时数据统计的经验。,"移动互联网,游戏",150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6888789.html,徐汇区,10k-20k,上海驰骛信息科技有限公司,1-3年,本科,团建活动、 带薪年假、定期体检、零食水果,"岗位职责：1. 参与大数据产品的设计和开发，包括数据的采集，清洗，预处理，存储，建模，分析挖掘等2. 根据业务用户需要分析数据，提供数据支持3. 参与公司大数据产品的运维和监控，保障数据质量和服务稳定性任职要求： 1. 具备本科以上学历, 计算机, 软件以及相关专业, 3年以上大数据开发经验2. 具备3年以上数据仓库建模和开发经验者优先3. 熟练掌握Java, 对Hadoop相关的技术和组件(HDFS, MR, Hbase, Hive, Spark, Storm, Kafka等）有全面深入了解4. 熟练掌握Shell或者Python中的一种5. 具备2年以上Spark调优经验者优先6. 具备实时计算(Kafka+Storm/Spark Streaming. 经验者优先7. 具备数据分析和数据挖掘方面经验者优先","数据服务,移动互联网",50-150人,hadoop,上海
数据产品（开发者套件方向）(J12413),https://www.lagou.com/jobs/6740744.html,闵行区,30k-40k,上海钧正网络科技有限公司,5-10年,本科,发展前景,,"移动互联网,硬件",2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6428613.html,浦东新区,14k-18k,上海海万信息科技股份有限公司,3-5年,大专,做五休二，交通便利，大牛团队,岗位职责：    1、 负责数据统计与分析的研发和维护；    2、 根据产品经理和运营团队等的统计需求，进行开发实现；    3、 负责对用户行为数据的深度挖掘，以数据指导产品改善。    岗位要求：    1、 全日制专科及以上，3年以上工作经验；    2、 Java基础扎实，熟悉主流开源框架，懂JVM调优更佳；    3、 熟悉HBase、Spark、HIVE等数据框架；    4、 熟悉Kafka、ES、Redis等数据中间件；有实时计算经验更佳    5、 良好的SQL语句功底，熟悉MySQL、PostgreSQL、Oracle数据库中的一种；    6、 逻辑清楚、快速的学习能力及良好的沟通能力。,"移动互联网,金融",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/5057134.html,静安区,10k-20k,上海海万信息科技股份有限公司,3-5年,大专,"带薪休假,节日礼金,体检旅游,年底奖金","岗位职责：1、参与公司大数据平台的研发2、负责大数据平台基础架构环境搭建，数据仓库建模，及相关运维工作3、处理日常ETL工作4、参与维护大数据平台，并能快速高效解决遇到的问题, 保障平台正常稳定运行任职要求：1、熟悉Hadoop、HBase、Hive、Spark、Flume、Kylin等开源项目的部署、性能调优；2、对Hadoop/Spark有深入理解；3、熟悉Linux系统管理工作；熟悉Shell编程，能够编写脚本解决日常问题，包括自动化的工作流设计","移动互联网,金融",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6967522.html,浦东新区,20k-30k,上海鲲驰贸易发展有限公司,3-5年,大专,"工作氛围好,发展空间大","1.参与大数据平台的各种数据产品的需求调研、（维度等）模型设计、架构及关键模块的设计和开发；2.参与数据仓库/BI需求调研和需求分析，能独立主导数据仓库、数据集市的模型设计；3.参与平台数据采集、数据传输，数据转换、规则引擎等的数据接口规范定义；4.参与搭建平台级数据治理体系；5.参与或负责大数据平台运维团队的日常系统调优及各种疑难问题排查。1.3年以上大数据开发经验，大专以上学历；2.深度理解数据开发工程师的职责和架构设计的目标、原则及取舍；3.熟悉MySQL，PostgreSQL,TSDB等主流数据库，能熟练进行SQL查询优化，有海量数据处理经验；4.熟悉数据标准管理、元数据管理、数据质量管理；5.熟悉Dataworks,Maxcompute优先；6.有电商、贸易、财务、供应链行业经验者优先。",电商,500-2000人,hadoop,上海
Java数据开发,https://www.lagou.com/jobs/7194454.html,徐汇区,20k-32k,深圳苹果树数据科技有限公司,3-5年,本科,腾讯团队,任职资格：    1、本科及以上学历，计算机相关专业；    2、3年以上JAVA开发经验，基础扎实，掌握常用的微服务开发框架，理解JVM原理，理解io、多线程、集合等基础框架，掌握面向对象设计开发;     3、精通MySQL等数据库原理及性能优化；    4、具有大数据开发经验，熟悉Python、R等语言，熟悉Spark开发，熟悉常用的大数据开发工具；    5、熟悉Unix/Linux操作系统原理、常用工具；    6、全面并且扎实的软件知识结构（操作系统、软件工程、设计模式、数据结构、数据库系统、网络安全）；    7、具备良好的分析解决问题能力，能独立承担任务和有系统进度把控能力；    8、好学、责任心强、思维缜密敏捷、良好的对外沟通和团队协作能力；    9、有海量数据和高并发开发经验者优先。,"金融,数据服务",150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/5601093.html,浦东新区,20k-40k,上海阅文信息技术有限公司,不限,本科,"Top团队,福利好,环境佳,发展快",工作职责:负责大数据BI设计和开发；负责阅文日常数据统计分析；数据仓库、数据集市的模型设计与开发；负责ETL数据准确性验证及ETL任务的优化；参与大数据平台和数据仓库的的搭建。任职资格:熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等） ；熟悉数据仓库理论与技术，对ETL及BI有概念并具有丰富的实际操作经验，熟悉ETL开发流程； 熟悉BI项目，具有数据仓库、BI系统开发经验者优先；对mysql、oracle有丰富经验，有较强的数据库脚本编程能力，有较强的存储过程编写能力； 熟练操作linux系统，熟悉shell脚本或python； 有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题； 性格积极且沉稳，勤奋严谨，强烈的进取心、求知欲和团队合作精神。,文娱丨内容,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/5740324.html,松江区,20k-40k,上海明品医学数据科技有限公司,1-3年,硕士,"技术大牛,环境好,氛围好",工作内容：1.    编程实现大数据采集、清洗等业务逻辑2.    通过数据建模实现用户需要的数据分析和挖掘功能3.    开发数据分析和挖掘相关的用户界面岗位要求：1.    数学、计算机、生物信息等相关专业硕士以上学历2.    良好的算法和数理统计相关理论基础，对数据敏感3.    熟悉Hadoop，HBase，Hive，Kylin，Kafka，Storm等数据处理相关技术，了解数据采集、清洗、建模、分析、挖掘等流程4.    掌握至少一种编程语言5.    良好的团队合作精神,"医疗丨健康,数据服务",150-500人,hadoop,上海
高级大数据开发工程师,https://www.lagou.com/jobs/7062583.html,长宁区,20k-30k,飞书数字科技（上海）有限公司,5-10年,本科,互联网广告,"岗位职责：1.主导数据ETL、数仓建设；2.主导新业务和行业的数据商业化探索和数据价值挖掘;3.负责海量数据采集、处理及存储、技术选型及架构实现；4.参与代码的实现，并带领团队追踪大数据和云计算技术的最新科技成果，并应用于内部业务实践。任职要求：1.本科及以上学历，五年以上相关行业经验；2.熟悉数据仓库产品，对数据处理、维度建模、数据分析等有深刻认识和实战经验;3.有较强的编程能力和编程经验, 精通Java，熟悉Hadoop分布式计算框架（HDFS、Hbase、Hive、Mapreduce、Storm/Spark、Flink、kudu等)；4.具备较好沟通协调能力，主动建立与业务的紧密合作，推动业务升级；5.有商业变现，DMP数仓建设和维护经验的优化。","社交,广告营销",150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6909504.html,长宁区,20k-35k,飞书数字科技（上海）有限公司,5-10年,本科,超长带薪年假 员工体检 健身卡 培训补贴,岗位职责：1、广告业务的实时，离线数据流开发；2、配合运营和产品经理做数据分析工作。 任职要求：1、6年以上大数据开发经验，有广告行业经验优先；2、熟悉云计算开发框架，Hadoop、Hive、HBase、Storm、Kafka等大数据主流工具和技术，有海量数据或海量并发的大型项目架构设计经验；3、扎实的Java（或.NET、PHP）和数据库技术基础，精通Web应用相关技术，熟悉分布式、多线程、异步处理、消息处理、搜索等中间件产品和工作机制；4、丰富的软件开发经验，深入理解各种框架工作源.,"社交,广告营销",150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6871647.html,徐汇区,15k-30k,上海思贤信息技术股份有限公司,3-5年,本科,健康体检、休闲零食、员工旅游、大牛带队,"岗位职责：
 参与基于Hadoop/Spark平台架构的设计和开发工作 ；
 负责对海量数据进行统计、分析与挖掘，不断提高系统运行效率；
 负责对数据分析及业务开发团队提供大数据技术指导和手段支撑；
 负责大数据平台的性能监控和持续优化；
 维持线上服务高效稳定，支撑业务和数据量的快速扩张;
任职资格：
 3年计算机软件行业开发经验，计算机或相关专业本科以上学历；
 具有扎实的Java或Scala开发语言基础，可以开发高效可靠的代码；
 有Hadoop和Spark实际开发经验,了解大数据组件的使用限制和应用场景，如HDFS、Yarn、HBase、Hive、Flume、Kafka、ZK、Kylin、Kudu、ES、Storm、MongoDB等;
 对分布式存储和计算原理有较深的理解；
 有实际CDH或HDP或Apache版本的Hadoop部署调优经验优先
 有参与并成功开发部署过1个日均TB级的集群项目优先","移动互联网,数据服务",50-150人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6829146.html,浦东新区,20k-40k,上海华钦信息科技股份有限公司,5-10年,本科,"外资,世界五百强","Qualifications:o3+ Years of application development and implementation experience.  o3+ years of experience with end-to-end design and delivery of Big Data Applications.oExpert in logical data modelling and relational database design.oExpert in maintain, improving and measuring the code quality, code coverage.oExpertise in writing technical documentation.oKnowledge of SDLCoNice to have – Knowledge of Risk domain (preferably Retail Risk)oStrong technical expertise on the followingJava/J2EE – Object oriented concepts, Core Java, Multi-Threading and collections.Hadoop Ecosystem (MR2, HDFS, Spark, Spark SQL , Scala,  Hive , Sqoop)Good understanding of Hadoop data storage formats (Avro, Parquet etc)Working with RDD, Datasets and Data frames.Relational Database knowledge and basic SQL Programming.Nice to have – Spring Batch ,Sprint Integration and any Java script frameworkExperience working with Linux Environment and shell scripts.Experience with GIT and any Git Remote repository tool, Branching and  Merging strategiesoExperience using the code coverage, code quality and profiling tools.Education:B.A/B.S in Computer Science or equivalent","数据服务,金融",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7213106.html,长宁区,30k-45k,同程网络科技股份有限公司,5-10年,本科,15-19个月工资 上升空间,职位描述1. 负责大数据计算平台的架构设计，以及核心功能的开发，满足实时、离线计算的需求。2. 负责产品实时计算平台的设计和开发，为个性化推荐、实时监控、运营数据分析提供数据支持。任职要求1. 扎实的Java语言基础，对JVM底层运行机制有深入了解。2. 熟练掌握Hadoop、Spark、Flink、Elasticsearch的原理特性以及适用场景，熟悉Flink实时计算开发，并具备大规模数据集的实际开发经验。3. 有大规模数据计算平台的架构设计经验，且精通大规模数据集的存储方案设计优先。4. 具备用户问题的定位及解决能力，善于归纳总结，对数据敏感。5. 思维活跃、敢于担当、乐于沟通，具有良好的团队合作精神，积极主动，能承受一定的工作压力。6. 具备搜索、推荐类系统开发经验优先,旅游,2000人以上,hadoop,上海
数据开发,https://www.lagou.com/jobs/7112062.html,黄浦区,18k-26k,深圳市小赢科技有限责任公司,3-5年,本科,专业团队 发展潜力,岗位职责：1、负责业务整体数据仓库、数据集市的模型设计与数据架构管控、仓库建设、ETL开发等，支持上层数据分析与数据应用；2、负责数据管理与治理，确保数据一致与准确性，提升业务数据计算效率；3、负责大数据平台建设及维护，包括BI分析、数据产品开发、数据工具开发及算法开发等的系统性支持；4、参与业务数据分析体系的建设，包括但不限于数据数据统计、分析与建模等，实现数据驱动业务增长的目标；5、能够独立开展数据挖掘项目，为产品和运营提供数据决策支持。任职要求：1、3年以上数仓管理及开发的相关工作经验，有数据仓库建设、数据处理、数据建模、数据分析相关经验；2、熟练掌握hadoop、Hbase、Hive、Storm、Spark Streaming、flink等大数据开发工具中一种或几种；3、熟悉shell、python、scala、java等至少一种开发语言；4、精通sql，熟悉常用的关系型数据库和非关系型数据库；5、责任心强，具备较强的学习、表达能力，善于沟通、有团队合作精神。,金融,500-2000人,hadoop,上海
高级大数据开发工程师,https://www.lagou.com/jobs/6798128.html,浦东新区,40k-60k,上海基分文化传播有限公司,3-5年,本科,六险一金；绩效奖金,工作职责：1、负责广告基础数据建设，包括数据系统搭建、基础数据模型建设、实时计算体系建设2、负责离线/实时数据报表开发，为广告产品提供大数据存储、分析、计算支持3、负责持续改进现有数据系统架构，保证系统高性能、高可用、高可扩展4、负责新技术预研，完成项目的选型和设计，项目难点攻坚任职要求：1、本科及以上学历，计算机相关专业，4年以上大数据开发经验，精通至少一门编程语言（Java、Scla、C/C++等）2、具备丰富的大规模分布式系统设计开发经验（有百亿级数据接入经验、PB级数据处理经验者优先）3、对大数据技术体系有深入的理解，精通大数据相关技术（包括但不限于Hadoop、Spark、Flink、Hive、HBase、Kafka等，熟悉源码者优先）4、有极强的责任心和技术攻坚能力，能够针对广告数据平台的疑难问题提出解决方案5、有广告业务数据体系建设开发经验者优先,文娱丨内容,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6626281.html,浦东新区,40k-60k,上海基分文化传播有限公司,3-5年,本科,六险一金；午餐补贴,工作职责：负责数据商业化方向的数据处理，主要包括：1、广告投放相关所有数据流，用户行为打点数据等；2、用户信息多维度的数据分析；3、爬虫框架；4、用户画像建立及使用等；5、数据质量、数据流程监控。  任职要求：1、本科及以上学历，4年及以上工作经验，能够根据实际业务设计开发大数据应用组件或者基于开源软件进行二次开发；2、具备深厚的分布式系统或数据库系统的理论基础、熟悉分布式计算系统的工作机制；3、对大数据基础架构和平台有深刻理解，对基于Hadoop的大数据体系有深入认识，精通大数据开发框架(Spark、Hadoop、Hive、HBase、Kafka、Sqoop、flink等)；4、对大数据平台的监控/调度方面有自我深刻的理解，自研开发过监控/调度平台的优先；5、对大数据平台的性能优化以及平台运维具用丰富经验；6、具有中大型大数据基础平台的建设经验；7、熟悉Linux/Unix环境，精通Java/C++/scala等；8、对JVM有深刻理解，并且能够运用到日常工作中；9、有极强的责任心、积极主动承担结果，能够针对大数据平台的疑难问题努力寻求解决方案。,文娱丨内容,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7207802.html,徐汇区,15k-30k,大启科技（上海）有限公司,不限,不限,加班少福利好工作地点高大上氛围轻松和谐,"工作职责
 负责公司数据平台及数据产品的开发
 结合零售行业的数据场景，参与数据仓库和BI解决方案的落地
 参与数据开发团队的方案技术选型研究
任职要求
 熟练掌握HBase Kafka Spark Hive Presto  ELK 等大数据生态技术，熟悉Hadoop的底层工作机制。
 熟练 Scala/Python/Java 其中至少一项， 具备良好的编成能力。
 熟悉 BI 数据仓库 OLAP建模 ETL等 相关技术。
 熟悉Linux环境, 及Shell脚本。
 对数据敏感，具备较强的学习能力。",软件开发,15-50人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7166675.html,徐汇区,20k-40k,大启科技（上海）有限公司,5-10年,本科,薪资高加班少，世界五百强新零售，技术大牛,"岗位职责：·       大数据平台功能的技术实现，核心代码开发及日常维护·       跟据实际业务设计开发大数据应用组件或基于开源软件进行二次开发·       编写数据清洗脚本，对流入大数据平台的数据流做梳理·       编写数据抽取脚本，提供对外数据流的输出·       为BI系统、报表平台、大数据平台等提供海量数据高性能分析技术支撑职位要求：·       本科及以上学历,  计算机相关专业，5年以上相关经验·       具备基于Hadoop的大数据体系平台开发经验，精通大数据开发框架(Spark、Hive、HBase、Kafka、Sqoop等)·       熟练掌握SQL、Scala编程语言·       具备Kylin开发经验·       具备Java开发经验·       具有大数据平台性能优化经验者优先·       具有BI，数据仓库等项目实施经验者优先·       具有敏捷项目开发经验者优先·       具有领域模型驱动开发(DDD)经验者优先·       熟悉零售行业业务，具有零售行业开发经验者优先",软件开发,15-50人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6573099.html,徐汇区,28k-40k,上海驹旗网络科技有限公司,5-10年,本科,"大牛多,气氛好","职责描述：1、负责大数据平台搭建设计和数据开发；2、基于业务需求和应用场景，抽取呈现可用数据，帮助业务需求；3、为业务线提供数据支持和服务，降低数据使用成本，让数据赋能业务。任职要求：1、本科或以上学历，计算机专业，3年以上大数据项目开发经验；2、掌握Java/Scala其中至少一种, 熟悉Spring相关框架；3、熟悉Hadoop/Hbase/Storm/Spark等分布式计算技术，熟悉其运行机制和体系结构；4、具有独立完成从方案选型设计到原型系统开发实现的能力；5、有较强的沟通表达能力，善于学习，能迅速理解产品需求；有较强的责任心和事业心，能够自我驱动；6、熟悉docker/impala/elasticsearch/mongodb等技术的优先。","移动互联网,电商",150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7179607.html,浦东新区,12k-17k,上海金亥通信设备有限公司,3-5年,大专,"五险一金,带薪休假，项目奖金",职位描述：1.负责数据产品的数仓模型设计、优化；2.负责数据模型的ETL开发及维护；3.负责面向业务的数据消费、提取、分析、报表、挖掘等系统设计和开发工作；4.负责数据全生命周期管理和数据源头回溯相关的技术开发工作；5.负责数据仓库质量控制、稽核的相关开发工作。任职资格：1、计算机专业大专及以上学历。两年以上的离线、实时、OLAP数据分析处理项目经验；2、精通SQL开发，掌握MySQl、Oracle等关系型数据库中的一种，对redis、mongoDB等数据库有一定的了解；3、具备实时处理框架的设计和开发能力，熟练掌握Storm、Spark streaming等大数据实时处理框架中的一种；4、熟悉Spark 、R、Hadoop、Hbase、Hive、Elastic Search/Solr等大数据相关技术；5、熟悉Scala、熟悉Linux开发环境，能进行shell脚本/python脚本的编写；6、两年以上数据仓库设计和ETL开发经验，熟悉数据仓库建模设计、元数据管理、数据质量监控等；7、具有较强的逻辑分析能力，高度的责任心及团队合作精神。,"企业服务,数据服务",50-150人,hadoop,上海
上海业务安全-数据开发经理,https://www.lagou.com/jobs/5909980.html,长宁区,35k-45k,北京三快在线科技有限公司,5-10年,本科,平台大、氛围好,,消费生活,2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6700601.html,浦东新区,15k-28k,上海华钦信息科技股份有限公司,3-5年,不限,全球型外资企业平台，牛人大咖云集,教育背景：本科 科班工作年限：2-4Y技能要求：1.  熟悉 hdfs、mapreduce、yarn 等 hadoop 生态体系相关技术。能独立完成集群环境的部署以及 mapreduce 程序的开发。2. 熟悉Spark 分布式计算框架原理和编程模型，zookeeper 分布式协调服务的使用。3. 熟悉Hbase， Hive 的原理，使用和性能优化策略，能够使用 SQL 进行数据分析及调优。4. 熟悉 Java or scala 语言，可以编程开发。5. 可独自完成 spark 集群环境搭建，了解 spark 核心源码实现，对 Spark-Streaming 以及 spark-Sql 有一定的了解与使用经验。 6. 熟悉Linux 系统， 使用shell完成大数据一键部署。,"数据服务,金融",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/5862517.html,闵行区,12k-24k,上海莉莉丝科技股份有限公司,3-5年,本科,"弹性工作,福利待遇好,工作氛围好",1） 大数据平台相关业务组件开发2) 根据业务需求更新大数据平台的数据架构3) 部署和维护机器学习算法平台以及算法模型流水线4 大数据平台运维1） 计算机相关专业，熟悉linux开发环境2） 熟悉常用bash命令，能够编写bash脚本。3） 熟悉python，ruby等脚本编程语言（任一）4） 了解Hive，Impala，Spark，HBase等Hadoop相关工具者5） 了解常用的容器技术，如docker，k8s等6） 有机器学习模型线上部署经验优先7） 热衷于钻研技术，热爱软件开发，工作踏实认真，责任心强，勇于接受挑战,"移动互联网,游戏",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/5900825.html,嘉定区,15k-25k,上海晋展网络科技有限公司,3-5年,本科,手游，开发，提供租房，有食堂。,工作职责 1、负责数据的采集、清洗、抽取、抽象；负责业务基础数据建模，建设业务数据仓库 2、基于海量数据的数据仓库，为业务搭建通用的查询和分析解决方案 3、梳理整体业务指标，可视化报表开发4、管理并优化存储&计算资源利用效率、监控并维护例行ETL任务 任职资格 1、计算机或相关专业本科及以上学历；2年以上大型数据仓库架构设计、模型设计、ETL设计的相关经验 2、熟悉Hadoop生态，熟悉SQL，有一定的SQL性能优化经验 3、熟练掌握Java语言，MapReduce编程，Python/Shell等脚本语言，有良好的编程习惯 4、具备大数据云平台、计算存储平台、可视化开发平台经验5、产品和业务理解力强，对数据敏感；有用户产品数据分析经验者优先。,"移动互联网,游戏",150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6719016.html,浦东新区,15k-30k,上海银科创展投资集团有限公司,3-5年,本科,上市公司,"岗位职责：1、参与数据平台的构建工作, 演进现有数据平台基础设施；2、参与数据相关的软件开发工作, 迭代现有数据运营工具；3、参与设计并构建主题化数据模型，构建集团数据仓库；3、参与数据治理规范的建立, 构建覆盖全集团的数据治理工具；4、负责或参与项目开发过程中的技术攻关和性能调优。任职要求：1、 全日制统招本科及以上，计算机、通信工程、数学等相关专业背景优先；2、 至少3年以上Java/Scala开发经验，其中有1年以上的大数据开发经验，熟悉Java Web开发框架，JVM原理，包括内存模型、类加载机制以及性能优化等；3、 熟悉HDP或CDH相关生态，对Hive/Hdfs/Yarn/Tez/Kafka等有较深的认识, 熟悉大数据架构（Spark，Hbase，Flume，ElasticSearch，Druid等）及解决方案，并有实际工作经验，对开源社区有贡献者优先；4、 熟悉虚拟化应用的部署与运维，如Rancher/Docker等技术；5、 熟练使用SQL，理解数据库原理；6、熟练使用shell/python等脚本语言开发相关运维管理工具；8、有算法及数据结构基础者优先9、具备丰富的高性能大并发场景下开发及架构经验及性能调优经验优先。","移动互联网,金融",2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7210262.html,浦东新区,12k-18k,奥解思信息科技（上海）有限公司,3-5年,本科,外企办公环境，弹性工作制，成长空间大,1.spark要求比较高，希望有1-2年。2. Java基础好，辨别项目中java有多久，希望1-2年3.211/985优先/省市重点本科。4.面试时候首先会面10分钟英文，如果英文不好的面技术不是特别强就会尽快结束面试。入职后会和印度人一起工作偶尔开会；英文好的人，技术偏弱会考虑。5. java很强 spark一般也可以考虑；,金融,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6731653.html,黄浦区,20k-40k,引粒网络科技（上海）有限公司,3-5年,本科,极佳的办公环境，发展空间前景好,工作职责:1、负责大数据BI系统设计和开发；2、负责大数据平台的优化维护、数据仓库平台的模型设计和开发维护；3、负责后台日常数据统计分析；任职资格:1、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等） ；2、熟悉数据仓库理论与技术，对ETL及BI有概念并具有丰富的实际操作经验，熟悉ETL开发流程； 3、熟悉BI项目，具有数据仓库、BI系统开发经验者优先；4、对mysql、oracle有丰富经验，有较强的数据库脚本编程能力，有较强的存储过程编写能力； 5、熟练操作linux系统，熟悉shell脚本或python； 6、有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题；,社交,15-50人,hadoop,上海
数据开发,https://www.lagou.com/jobs/6855053.html,长宁区,10k-20k,上海尚诚消费金融股份有限公司,3-5年,本科,薪酬福利健全 发展平台广阔,工作职责:1、主要从事大数据离线平台的设计以及开发工作，维护升级等等；2、负责离线的数据存储和加工处理，保证数据质量，负责数据监体系的建立和维护；3、负责海量数据的清洗、处理和挖掘工作，支持数据分析师和算法工程师的数据需求；4、负责日常数据仓库、监控、分析、性能调优、故障诊断与排除等工作；5、负责数据仓库ETL流程的优化及解决ETL相关技术问题；6、研究前沿技术，解决实际场景中的业务问题，优化离线/实时大数据计算任务的性能。任职资格:1、教育程度：全日制本科及以上学历，计算机或相关专业优先；2、工作经验：3年及以上工作经验，2年以上大数据开发经验，在金融领域或互联网领域有至少1年的从业经验，优秀者可适当放宽； 3、知识技能：熟悉Linux/Unix开发环境，精通数据库基本原理，熟悉SQL语言与shell编程，熟悉Hadoop原理，具备一定的hive、spark开发经验；4、精通数据仓库理论，具备数据仓库开发、维护经验；5、能力素质：良好的团队精神和合作意识，强烈的责任心，对工作有激情，良好的沟通能力，能吃苦耐劳；具备快速学习能力，思路清晰，善于思考。,"金融,移动互联网",150-500人,hadoop,上海
大数据开发,https://www.lagou.com/jobs/7120961.html,长宁区,15k-25k,上海尚诚消费金融股份有限公司,3-5年,本科,薪酬福利健全 发展平台广阔,"工作职责:1.  负责hive udf 的开发和维护;2.  负责hive 的库表权限管理, 基于sentry;3.  负责presto集群安装维护, 包括插件二次开发;4.  负责ES集群的安装维护和开发, 以及hive和es的数据传输;5.  负责kafka集群的安装维护, 以及流式计算开发;6.  负责其他开源工具的维护如GitLab、kafkaManager、kafakMonitor、zkui等.任职资格:1.   精通HiveSql开发，并有相关调优经验；2.   熟练使用常用的shell命令，包括ansible 运维工具；3.   熟悉大数据生态，熟练使用大数据工具,并有相关开发经验，如Sparkstreaming 、HBase、ElasticSearch、Presto、Flink等；4.   精通java开发，包括hive udf开发，并熟练使用常用开源框架或工具，如Springboot、redis、kafka、Zookeeper、maven等","金融,移动互联网",150-500人,hadoop,上海
数据BP-点评APP数据仓库开发,https://www.lagou.com/jobs/6786138.html,长宁区,25k-40k,北京三快在线科技有限公司,3-5年,本科,上市公司 核心部门 大牛云集,,消费生活,2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7191437.html,长宁区,18k-30k,上海瑛太莱信息科技有限公司,3-5年,本科,定期团建、节假日福利、年度体检等,岗位描述：1、负责完成业务和产品的对接，支持业务需求研发；2、负责完成产品的迭代升级以及底层架构的升级研发；3、完成团队安排的其他相关日常工作任职要求；4、负责产品的实时业务和离线业务的研发；5、支持开源大数据技术在数据系统中的使用，修复、优化增强大数据技术；岗位职责：1、具有分布式系统架构开发能力。熟练使用storm、spark hbase者优先。2、能够使用实时计算平台，进行实时业务数据的研发。3、能够基于已有平台进行离线业务的开发。4、有大数据应用产品研发经验，具有数据决策产品研发经验者优先。,电商,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/4247189.html,闵行区,15k-25k,上海元聚网络科技有限公司,3-5年,大专,"高薪,晋升快","工作职责：1、完成软件系统代码的实现，编写代码注释和开发文档。2、参与公司大数据产品规划,大数据处理分析平台的设计。3、负责数据分析、加工、清理、处理程序的开发                4、负责数据相关平台的搭建、维护和优化。5、根据设计文档或需求说明完成代码编写，调试，测试和维护。6、协助测试工程师制定测试计划，定位发现的问题。      7、配合项目管理人员完成相关任务目标。   任职要求：                  1、良好的java基础、熟悉大数据相关开源项目;      2、海量用户行为数据的分析挖掘，负责过大数据业务的研发和优化工作;             3、熟练使用mapreduce、Spark、Flink等计算框架进行处理离线、实时数据;             4、熟练NOSQL数据库Mongodb、HBase、Redis等;5、参与过用户画像,个性化推荐,有建模经验的优先考虑;6、有良好的敬业精神和团队合作精神,具有技术领域的探索和钻研精神,对技术开发工作有浓厚的兴趣,愿意并努力接受技术挑战或技术创新。湖北，武汉应聘，同等条件优先录取",移动互联网,150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7120616.html,长宁区,12k-20k,上海亦策软件科技有限公司,3-5年,本科,带薪年假 弹性工作制,工作职责:1.负责大数据平台的基础技术规划，平台的建设，包括环境和框架的规划搭建以及部分核心编码工作；2.负责大数据平台的数据采集、处理、存储的架构实现；3.参与业务需求调研，根据需求设计大数据解决方案并跟进具体实施项目；任职资格:1.本科及以上学历，3年以上工作经验；2.熟悉大数据解决方案包括Hadoop、Spark、Hive、Hbase、SQL-on-Hadoop等大数据解决方案；3.熟悉大数据处理等相关技术和实现方法，熟悉大数据CDH平台；4.了解Scala、spark、Python、R、C中的一种或多种语言；5.有大型数据仓库实施、大数据平台数据开发经验者优先。,数据服务,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7018492.html,徐汇区,13k-26k,上海爱可生信息技术股份有限公司,3-5年,本科,"新三板,团建,餐补,旅游","岗位职责：1、负责数据相关产品的模块设计与代码编写;2、负责大数据项目实施以及部分设计开发；3、负责大数据环境下的数据清洗、转换、建模、分析以及部分开发工作；4、负责大数据环境的部署、调优以及日常运维；任职要求：1、三年以上数据相关产品开发经验；2、熟悉Hadoop、Spark等大数据平台架构，有实际的项目开发经验；3、熟悉微服务技术，有SpringCloud、SpringCloud Alibaba等实际项目开发经验，熟悉Spring、Mybatis,、RabbitMQ等开源框架；4、熟悉主流关系型数据库系统(SQL Server、Oracle、MySQL等), 并熟练运用SQL进行数据查询管理操作以及JDBC、连接池管理的开发经验；5、有 REST API 接口经验；熟悉 HTTP、Restful API、具有大规模软件系统的设计能力；6、熟练使用Hive、HBase、Impala等大数据处理系统,了解其内部工作机制,熟悉其系统结构,有排查和解决相关技术问题的经验；7、熟悉ElasticSearch分布式搜索引擎，有实际的开发应用经验优先考虑；8、熟悉容器技术，包括 Docker，Swarm，k8s 等。9、熟练掌握Linux操作系统，能够熟练使用Linux系统命令，熟悉Shell等脚本编程；10、强烈的责任心和团队合作能力，良好的学习能力，严密的逻辑思维能力并且敢于创新和接受挑战，能够在一定压力下工作。",数据服务,150-500人,hadoop,上海
大数据开发,https://www.lagou.com/jobs/6863272.html,普陀区,25k-50k,上海序章科技有限公司,3-5年,本科,氛围好，业务快，福利多多,"岗位职责：1、对接并梳理业务需求,开发数据仓库模型,设计相关主题的事实表和维度表等；2、使用ETL工具开发数据流；3、使用BI工具以及OLAP工具进行数据可视化的开发和展现；4、深入理解用户的行为，构建用户、商品、社区的画像体系；5、负责社区Feed流推荐算法。任职要求：1、基础扎实，熟悉数据结构和算法；2、有数据库经验,熟悉SQL、了解ETL、数据仓库建模理论为佳；3、有Linux/Shell、Python、Java等编程技能加分；4、有Hive、Hadoop、Spark、Flink相关数据平台经验优先；5、有推荐系统相关经验，熟悉常用的推荐算法，有大规模海量数据机器学习/数据挖掘/计算广告/搜索相关经验者优先；6、具备良好的沟通和表达能力，对推荐的用户体验上有自己的想法，有较好的产品意识者优先。","电商,文娱丨内容",50-150人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6455095.html,浦东新区,17k-22k,奥解思信息科技（上海）有限公司,1-3年,本科,福利好,-计算机科学，信息技术或类似专业的本科或以上学历。,金融,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7029104.html,青浦区,12k-20k,上海睿翎法律咨询服务有限公司,1-3年,本科,五险一金 周末双休 年底双薪 节日福利,"岗位职责：1、负责HBase、Elasticsearch等大数据搜索平台 规划、部署、监控、系统优化等；2、负责公司大数据平台的运维管理工作,以及各类异常和故障，确保系统平台的稳定运行；3、深入理解spring cloud/boot等微服务架构，为其持续优化提供建设性意见；4、熟练使用kafka,pulsar等消息对列。任职要求：1.有扎实的数据结构和算法功底；2.精通java预研，对J2EE有深入理解，熟悉J2EE规范，有良好的代码编写习惯；3.熟悉 Kubernetes、Docker 技术，有生产级容器系统管理经验；4.掌握数据开发的各项流程，擅长数据采集、清洗等环节；5.熟悉linux开发环境，以及常用集群系统的运维；6.熟悉Mysql, mongodb等常用数据库；7.有爬虫，信息抽取，文本分类相关经验者优先；8. 自主学习能力强，有2年以上工作经验，愿意接受成长企业工作压力。","移动互联网,数据服务",15-50人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7149282.html,黄浦区,10k-20k,上海宏路数据技术股份有限公司,不限,本科,"氛围好,环境好，地铁周边，六险一金","岗位职责： 1、参与分布式服务设计及开发； 2、参与大数据组件、中间件设计及开发； 3、参与公司核心产品、项目研发，针对海量数据开发具有数据收集、统计、分析和挖掘能力的创新型产品； 4、学习并研究大数据技术、最新动向以满足产品、项目的迭代需求。   任职资格： 1、扎实的计算机基础，1-3年大数据开发经验，掌握基本设计理念，熟练应用一门以上面向对象开发语言； 2、扎实的数据结构基础，掌握常见算法； 3、对solr、elasticsearch、消息队列等中间件具备基本认识，若有相关领域研究、开发经验则更佳； 4、对关系型/非关系型数据库有一定认识，具备较好数据库的设计理念。 5、对大数据生态有较好认识，具备spark, hive, hadoop, kafka, sqoop, kylin, azkaban等大数据组件开发、调优经验； 6、有docker、k8s等容器使用经验者优先考虑； 7、具备cloudera或hortonworks平台开发、部署经验者优先考虑。 8、拥有个人博客或者有大型项目开发经验者优先考虑。 9、拥有或参与开源项目者优先考虑。 10、基础扎实的应届毕业生优先考虑、培养，共同成长； 11、具备较好的品质，秉持正直、诚实、担当、奉献的价值理念，优秀应届生也可考虑。",移动互联网,150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/5874765.html,徐汇区,20k-35k,上海乐言信息科技有限公司,3-5年,不限,业界**团队 早期期权,岗位职责1. 依据业务模型，负责大数据计算平台的架构设计，以及核心功能的开发，满足实时、离线计算的需求。 2. 负责产品实时计算平台的设计和开发，为实时监控、实时运营数据分析、个性化推荐提供数据支持。任职要求1. 本科以上学历，扎实的计算机专业基础，有3年以上大数据平台开发经验，1年以上的大数据计算/存储设计经验。 2. 熟练掌握Hadoop、Spark、Storm、HBase的原理特性以及适用场景，精通Spark实时计算开发，并具备大规模数据集的实际开发经验。 3. 有大规模数据计算平台的架构设计经验，且精通大规模数据集的存储方案设计优先。 4. 具备用户问题的定位及解决能力，善于归纳总结，对数据敏感。 5. 思维活跃、敢于担当、乐于沟通，具有良好的团队合作精神，积极主动，能承受一定的工作压力。,企业服务,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6647089.html,徐汇区,12k-24k,上海诺悦智能科技有限公司,1-3年,本科,五险一金 奖金 餐补 通讯补助等,任职要求：1.   硕士学历；2.   精通Scala、python语言，有实际编程经验，熟悉Linux 操作系统，熟练使用Shell等脚本语言3.   深入了解分布式系统、大数据平台、消息队列等高可用高弹性架构;4.   对HDFS/Yarn/HBase/Hive/Spark相关组件的性能优化和补丁跟踪等有实际经验5.   良好的英语读写能力6.   强烈的责任心和自我驱动意识，有良好的团队合作精神和沟通协调能力,数据服务,50-150人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6293360.html,浦东新区,20k-30k,钰真(上海）信息技术有限公司,5-10年,本科,跨境女装电商行业排名前三90后团队,1、负责数据分析、加工、清理，相关处理脚本和程序的开发；2、负责开发大数据工具，如报表平台、多维度分析工具、ETL平台、调度平台的研发；3、负责分布式大数据平台应用开发（Hadoop/Spark/Hive/HBase等）；4、负责大数据相关平台的维护、优化。任职要求：1、本科及以上学历，计算机相关专业，具有5年及以上的大数据ETL或数据开发经验，熟悉大数据组件的维护以及调优；2、熟练掌握Java或Python编程语言，熟悉大数据架构体系，熟悉Hadoop、HDFS、Hive、HBase、Spark、Kafka等技术中的一个或者多个，熟悉Sqoop、DataX等数据导入工具；3、能熟练使用Hive、HBase、Spark等加工和处理数据，有海量数据处理经验；4、有数据仓库开发经验/BI系统开发经验优先；5、有电商行业数据处理与分析平台开发经验者优先。,"电商,其他",150-500人,hadoop,上海
数据平台开发工程师,https://www.lagou.com/jobs/5292274.html,徐汇区,20k-35k,腾讯科技（深圳）有限公司,3-5年,本科,发展空间大，行业前景广阔，公司福利靠谱,"岗位职责:
 负责看点及内容中台的整体数据体系架构设计及建设；
 负责数据实时检索分析平台的架构和建设;
 负责数据采集、数据分析及业务数据挖掘等；
岗位要求:
 3年以上软件开发经验，1年以上数据平台相关开发及架构设计经验；
 对大数据基础架构和平台有深刻理解，具备Hadoop生态圈核心组件（Hadoop, hive, Hbase等）项目应用研发经验;
 熟悉大数据相关基础组件如Spark, Kafka, Druid, ElasticSearch等，具备源代码级问题解决和集群优化改造能力者优先；
 熟悉分布式存储和NoSQL数据库技术，有实际生产项目应用经验；
 熟悉主流数据库技术（如GP, Mysql等），精通SQL，有一定SQL编码及调优经验；
 具备丰富的数据分析，挖掘和数据仓库建模的项目实践经验者优先",社交,2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7198176.html,浦东新区,15k-20k,深圳市博奥特科技有限公司,3-5年,本科,薪资高，待遇好,"工作职责:1.理解并合理抽象业务需求,发挥数据价值,参与业务数据项目数据分析及及精通hpl并实现各类复杂场景开发;2.熟练使用python,shell,Java(udf等)实现hive开发工作,熟练使用hadoop,hbase，hive,spark.sqoop等;任职资格:1.全日制本科以上学历,2年以上树仓,大数据分析相关经验,有金融和互联网行业经验优先,统计,数字,计算机专业；2.熟练数据仓库实施方法论,深入了解数据仓库体系,并支撑过实际业务场景;3.主动好学,谦虚,具有高度责任感,抗压能力和团队合作精神,具有良好的沟通合作技巧;","移动互联网,金融",150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6881862.html,浦东新区,15k-25k,申朴信息技术（上海）股份有限公司,3-5年,大专,五险一金、周末双休、项目稳定、工作环境好,任职要求：毕业5年以上，大专以上学历，学历学信网可查，必查，报表相关。1. 熟悉大数据仓库建模理论和相关模型，有一定的数据仓库建设经验2. 精通oraclesql和hadoop平台的hivesql开发和调优，有千万级别以上数据处理经验3、有扎实的数据模型建模理论和实践经验，精通hadoop平台上的数据仓库和数据集市建设4、有保险领域工作经验优先考虑,金融,150-500人,hadoop,上海
数据开发,https://www.lagou.com/jobs/7112605.html,徐汇区,17k-20k,上海魔卡信息科技有限公司,5-10年,大专,节假日福利，年终奖,1:数据库脚本创建，存储过程，触发器等数据库编程；2:数据库优化，包括sql优化，索引及其它优化手段；3:负责数据的提取，统计分析，数据挖掘。4:从事数据库开发工作，五年以上经验；5:熟练掌握Oracle数据库存储过程开发，SQL脚本的设计和开发；6:做过报表开发工作者优先考虑,金融,50-150人,hadoop,上海
高级大数据开发工程师,https://www.lagou.com/jobs/6190884.html,浦东新区,20k-30k,上海喜马拉雅科技有限公司,5-10年,本科,年终奖丰厚 扁平化 技术氛围好,职位描述：1.  为海量数据的处理和分析提供高效解决方案2.  研究Hadoop/Spark/Hbase/Hive等开源项目，对线上任务进行调优，并开发通用组件3.  维持线上服务高效稳定，支撑业务和数据量的快速扩张职位要求：1.  扎实的计算机系统和算法基础知识；良好的英文阅读能力2.  扎实的Java、Scala语言基础，对JVM运行机制有深入了解3.  熟悉Hadoop、Spark并有丰富的开发经验4.  对常见开源框架代码有研究5.  熟悉SQL和noSQL的设计和开发6.  熟悉企业应用设计模式、面向对象的分析和设计技术，包括设计模式、UML建模等7.  善于思考，能独立分析和解决问题，热衷于互联网技术的研究和创新8.  责任心强，具备良好的团队合作精神9.  有深入研究过Hadoop/Spark源码者优先10.  有OLAP系统设计经验者优先,"移动互联网,文娱丨内容",2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7161557.html,浦东新区,25k-45k,亿贝软件工程（上海）有限公司,5-10年,本科,外企 互联网 大数据,"Position is located in eBay China Center of Excellence (CCOE) in Shanghai in the Engineering team of the Big Data organization. The main focus of this position is to design, implement and operate a fully managed, reliable and scalable data solution or SaaS (Software as a Service) platform, designed and built to specific customer requirements while still adhering to standard and consistent architecture patterns, fully monitored 24x7, hassle free for the customers, managed through the lifecycle seamlessly without any business impact and to demonstrate a much better cost-benefit ratio. Responsibility: 
 Design and implementation of components, applications and services of data solution.
 Drive and contribute to build the high availability, scalability and manageability of ETL data pipeline solutions.
 Do DevOps and Debug and provide hot fixes on data quality issues.
 Work with domain customers to provide full support on our platform products, data analysis, ETL, reporting.
 Define and execute test cases to ensure top quality of product releases.
 Provide timely and effective production support.
 To build the Centre of Excellence in-house to drive third party support & license cost to zero.
 To build data services platform using newer streaming technologies and open source like Elasticsearch, Hadoop, Kafka.
 Job Requirement: 
 Strong background on BI,  data warehousing design, end2end ETL solution implementation and post-implementation support.
 Strong experience on data model design, distributed computing development experience
 Good experiences on DevOps.
 Strong passion on open source solution design and development in Java
 Strong engineering skills: modular design, data structures, algorithms, building tools, testing, and operational aspects.
 Strong communication skills, pragmatic approach to the choice of tools and platforms
 Basic Qualification: 
 Solid academic background, well-known university (985 or 211) or overseas universities.
 8 +years working experience for Bachelor, 5 + years for Master
 Good verbal and written English communication skills
 Strong in SQL Script languages
 Good in JAVA and Script languages
 Experience with building BI or DW platform
 Experience with Unix-like systems, such as Linux and/or SunOS",电商,2000人以上,hadoop,上海
大数据前端开发(J12992),https://www.lagou.com/jobs/6958504.html,闵行区,25k-35k,上海钧正网络科技有限公司,3-5年,本科,发展前景,,"移动互联网,硬件",2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6944144.html,浦东新区,15k-25k,上海新萌网络科技有限公司,3-5年,本科,核心组,"1、使用大数据组件对海量数据进行开发与维护2、对大数据组件进行调优（hbase,hdfs,yarn,spark,jstorm,kafka,flume,azkaban,hive等）3、支撑各业务线数据需求以及实时离线计算需求，维护优化各个大数据组件平台稳定高效运行4、有一定的对大数据组件进行源码调整的能力任职要求：1、具有三年及以上大数据开发经验，熟练使用hbase,hive,flume,spark,mr,storm,kafka中的一种以上大数据组件2、熟练掌握linux常规命令与工具3、对Hadoop、HBase等源码有研究优先4、熟悉java，有并发应用或者分布式应用软件开发经验优先5、熟练使用shell或python编程6、良好的系统分析、架构设计能力7、对数据敏感、对新技术敏感8、对工作踏实，负责，有一定的抗压能力，有一定的团队沟通能力，能吃苦耐劳",社交,500-2000人,hadoop,上海
TS-数据开发工程师,https://www.lagou.com/jobs/6727378.html,虹口区,20k-40k,顺丰科技有限公司,3-5年,本科,职位发展前景大，福利高,职责描述：1.负责设计落地数据ETL、收集、关联和计算；2.负责整合数据，挖掘需要的数据信息；3.负责系统的营运指标报表开发、营运日常数据获取；任职要求：1.计算机相关专业，本科及以上学历，3年以上相关工作经验，具有互联网、大数据开发经验；2.熟悉hadoop、hbase、hive等其中一个或者多个技术；3.熟悉大数据领域的解决方案形态，数据仓库建模和设计，ETL设计思路，海量分布式数据处理架构；4.熟悉常见主流数据库系统；5.阅读并改写过hadoop/spark源码优先；6.语言方面熟悉python、php者优先；7.良好的沟通能力，有团队合作精神和责任感。加分项：1.参与过BI系统设计与开发；2.熟悉git等开发管理工具，熟悉Unix/linux系统；3.有较好的SQL性能调优经验。,"软件开发,数据服务",2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6736108.html,徐汇区,15k-20k,上海众言网络科技有限公司,1-3年,本科,发展空间领导nice能力提升主人翁角色,"职责描述：1、负责大数据平台相关产品的设计，开发、文档撰写和项目改进；2、参与大数据平台上业务应用的功能设计及架构规划； 职位要求：1、计算机、数学等相关专业本科以上学历，2年以上相关工作经验；2、精通Hadoop体系结构、对Hadoop生态圈有较全面了解；3、熟悉大数据开发框架，熟练使用HDFS/HBase/Hive/Spark/Spark Streaming/Kafka/Flume等相关技术；有多个或多年大数据项目经验；4、能够使用Java、Scala中至少一门语言进行数据处理;5、熟悉Linux系统以及Shell脚本语言；6、精通MySql,Redis,ES,Mongo等开源缓存和数据库中间件7、具有一定的数据库设计能力,能够撰写规范的技术文档；8、掌握常用的设计模式和架构模式,能够熟练使用建模工具进行系統设计；9、具备良好的自学能力、沟通能力、独立解决问题的能力，有责任心以及团队合作精神；10、有机器学习、数据挖掘经验者优先；11、有（Capture Data Change,CDC）流式处理平台debezium经验优先",移动互联网,150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6953288.html,长宁区,18k-35k,云账户（上海）智能科技有限公司,3-5年,本科,公司福利好,12薪+4次季度奖金（每次0.5-3个月薪资）+年终奖金（2-8个月薪资）期权激励补充商业保险免费自助午/晚餐公司6公里内租房/购房补贴清华大学授课、华为高管培训(租房/购房补贴： 公司2公里范围之内1900元/月，6公里范围之内1200元/月）岗位职责：1、负责公司ToC项目数据平台设计和开发；2、负责构建大数据BI系统的分析和研发工作；3、对大数据平台的性能优化以及平台运维具用丰富经验;4、同产品团队积极协作，并能根据需求转化为合理高效的技术解决方案；5、负责相关项目开发文档的撰写与维护。任职要求：1、本科或以上学历，计算机相关专业；2、对大数据基础架构和平台有丰富的开发经验；3、扎实掌握一门开发语言，熟练掌握常用数据结构；4、对常用大数据组件有应用经验和较深刻的理解；5、有较强的团队合作意识，具备良好的独立思考能力。,数据服务,150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6914130.html,静安区,20k-25k,易居（中国）企业管理集团有限公司,3-5年,本科,上市公司、创新项目、发展空间大,"岗位职责：1、深入理解公司业务与技术架构，参与规划、建设房地产数据中台，负责日常数据模型设计及ETL开发等；2、主动跟进新业务及业务发展过程中出现的业务问题，对接产品及业务，提供高效的数据支持；任职资格：1、计算机或相关专业本科以上学历，具有扎实的编程基础理论知识；2、熟悉数据仓库建设理论，并有相关实践经验；3、精通SQL，熟练掌握MySql、Oracle、PostgreSQL等至少一种主流关系数据库；有复杂存储过程和sql优化能力的优先；4、具备良好的coding素养和习惯，熟悉Java/Python/Shell中的一种或多种；5、熟悉hadoop及生态（hdfs、hbase、hive等），理解背后工作原理；了解其他常用技术（spark, impala, GreenPlum，presto, Elasticsearch等)；6、对元数据管理、数据质量管理有一定理解，能够保障数据标准及质量符合用户预期；7、具备良好的团队协作精神，良好的沟通能力。","移动互联网,房产家居",2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6740049.html,黄浦区,25k-35k,百联全渠道电子商务有限公司,5-10年,本科,绩效奖金、 带薪年假、午餐补助、岗位晋升,岗位职责：1、优化现有大数据集群的架构和性能；保证系统的安全、稳定、高效运行；2、负责大数据产品（如CDP等）的架构设计和开发，以及对外数据服务的开发工作；3、与产品经理、测试工程师等其他团队沟通合作，保证大数据产品研发工作的质量和进度；4、参与新技术的技术难题的攻关，带动团队年轻成员共同成长。 岗位要求：1、计算机、数学相关专业全日制本科以上学历；  2、至少5年以上大数据应用系统的开发和设计经验；有知名互联网公司、零售或电商行业工作经验优先；3、熟悉Hadoop，熟练掌握ElasticSearch、HBase、Hive、Flume、Kafka、Flink等大数据技术；4、熟悉实时计算引擎，具有丰富的Spark、Spark Streaming的开发经验；  5、精通Linux环境，精通Java/ Scala开发；具备分布式系统或数据库系统的理论基础，熟悉分布式计算系统的工作机制；   6、善于表达，思维活跃，性格开朗，责任感强。,"电商,消费生活",500-2000人,hadoop,上海
高级大数据开发工程师,https://www.lagou.com/jobs/3316937.html,青浦区,15k-30k,圆通速递有限公司,3-5年,本科,上市公司，前景好，氛围好，待遇好,"岗位职责：1、流式计算平台的整体架构设计；2、负责技术攻关和创新技术引用，开发具有数据分析、数据挖掘能力的创新型产品；3、负责提升基于Hbase数据存储集群的高可用性、高性能、高扩展特性；4、负责设计和建立基于Storm或Spark实时数据处理框架；5、研究Hadoop/Spark/Hbase/Hive等开源项目，对线上任务进行调优，并开发通用组件；6、维持实时大数据平台高效稳定。 任职要求：1、本科及以上，计算机、软件工程、统计学、数据挖掘、机器学习等相关专业，2年以上大数据架构经验；2、扎实的Java、Scala语言基础，对JVM运行机制有深入了解；熟悉Hadoop、Spark并有丰富的开发经验； 3、熟练使用java语言，并掌握spring、mybatis等开源J2EE框架。使用java、scala、python等开发语言中的一种，有python和scala实际使用经验更佳； 4、有hadoop和spark实际开发经验。了解大数据组件的使用限制和应用场景，如hdfs,yarn,hbase,hive,flume,kafka,zk,impala,kylin,kudu,ES,Storm、MongoDB等。5、熟悉mysql、ElasticSearch、Redis等关系型或NoSQL数据库，了解应用场景和使用限制。有实际调优经验者更佳。6、熟悉linux常用命令，有实际CDH或HDP或apache版本的hadoop部署经验者优先； 7、熟悉并行计算或者分布式计算，熟悉Spark框架,熟练掌握RDD，SQL, Streaming, MLLIB，SparkR编程；8、英文文档阅读无障碍、熟练掌握常用设计模式、熟练使用maven、git；9、有深入研究过Hadoop/Spark源码者优先；10、深入理解MapReduce工作原理，HDFS分布式文件系统架构；熟练掌握Hadoop/Hive/HBASE的运维和调优方法； 11、掌握或使用过Storm、Spark、flume、kafka等工具；",物流丨运输,2000人以上,hadoop,上海
高级大数据开发工程师,https://www.lagou.com/jobs/6225719.html,青浦区,20k-30k,圆通速递有限公司,5-10年,本科,上市公司，大牛团队，发展空间广阔,"岗位职责：1. 负责大数据Hadoop/Spark平台的架构和运维保障工作。2. 负责大数据Hadoop/Spark平台的业务监控、应急响应和容量规划等工作。3. 负责保障大数据Hadoop/Spark平台高效稳定运行，支撑业务量的高速增长。4. 负责大数据需求的架构设计。任职要求：1、大数据开发或运维5年以上相关经验，熟悉分布式计算技术理论，具有大数据架构和设计实践经验，对现有行业主要产品的相关技术有深刻研究和了解有底层源码贡献或阅读者优先。2、熟练掌握Hadoop技术栈开发运维，包括hbase,hive,spark,yarn,kafka等。3、熟悉Java或Scala，掌握高性能程序设计方法，有高并发应用开发经验。4、熟悉CDH的运维调优。必须要有实际操作经验。  5、熟悉Linux系统，能够熟练使用shell脚本处理工具.6、深入理解Hdfs/Hive/Spark/HBase/Kylin/Presto其中的一个或者两个的内部运行机制，熟悉源码优先考虑。",物流丨运输,2000人以上,hadoop,上海
APM大数据开发工程师,https://www.lagou.com/jobs/6592908.html,徐汇区,25k-50k,腾讯科技（深圳）有限公司,3-5年,本科,福利待遇/年终奖/职业发展,"岗位职责：1. 负责WeTest APM大数据平台的后台架构方案的选型、设计和开发；2. 负责数据处理流程的设计、开发和持续优化；3. 负责大数据处理模块核心功能的开发。岗位要求：1. 计算机相关专业，具有3年以上大数据工具的使用和开发经验；2. 熟悉Unix/Linux操作系统下的C/C++/Java，Python，Go，Shell中的一种或多种语言； 3. 熟悉MySQL开发，熟悉TCP/IP协议相关知识，精通网络编程；4. 熟悉面向对象的大型分布式系统设计与开发；5. 熟悉Hadoop,HBase,Spark,Storm,Elasticsearch,Kafka等大数据处理平台流程；6. 有过互联网行业大规模后台或大数据平台建设及优化实际工作经历者优先。",社交,2000人以上,hadoop,上海
数据开发,https://www.lagou.com/jobs/7209496.html,杨浦区,15k-20k,北京新才教育科技有限公司,3-5年,本科,五险一金，双休,"1. 本科及以上学历，计算机、数学相关专业，3年以上开发工作经验；2. 在搜索系统、推荐系统或广告等方向有3年以上算法研发经验，有排序或召回等实际项目经验；3. 有 Hadoop / Spark 等大规模分布式计算使用经验；4. 熟悉 Linux 开发环境，熟练使用 Python / Scala / Java等语言；有扎实的编程基础和工程实践；5. 善于思考和学习，对有挑战性的问题充满激情，具有良好的团队合作精神和较强的沟通能力以及执行力必须具备技能要求：
 在搜索系统、推荐系统或广告等方向有3年以上算法研发经验，有排序或召回等实际项目经验；
 有 Hadoop / Spark 等大规模分布式计算使用经验；","软件开发,物联网",50-150人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7204737.html,浦东新区,11k-22k,上海域起网络科技有限公司,应届毕业生,本科,六险二金、带薪年假、周末双休,岗位职责: 1. 参与大数据平台的开发和维护；2. 实时/离线数据的处理。任职条件: 1. 计算机相关专业，希望近期可实习，且每周出勤至少4天；2. 熟悉Python/Java编程，熟练使用SQL，有相关项目经验；3. 熟悉linux操作系统及开发环境，会写Shell脚本；4. 了解Hadoop相关技术，了解Airflow/Azkaban等调度框架；5. 优秀的英文阅读能力，学习能力。,"移动互联网,游戏",150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6942609.html,闵行区,17k-22k,弘衍信息科技（上海）有限公司,1-3年,本科,作五休二，项目前景好,职位描述：1、基于业务需求，持续进行数据模型和算法的分析优化2、应用机器学习等方法，从海量客户数据中挖掘潜在的规律与关系3、建立和完善分析体系，跟踪模型的实施，优化算法和分析策略，提供建设性建议4、推进推荐、数据挖掘、机器学习技术在行业数据的应用 岗位要求：1、数学、统计、计算机等相关理科专业，全日制本科及以上学历； 2、二年以上海量数据下数据挖掘和算法实施相关工作经验；3、熟练运用python或者spark、SAS进行数据建模，熟悉hiv、hadoop大数据处理技术的优先考虑；4、有教育领域经验的优先考虑,"教育,企业服务",15-50人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7216190.html,浦东新区,15k-20k,天津所托瑞安汽车科技有限公司,3-5年,本科,全额五险一金，周末双休，午餐补助，年终奖,岗位职责：1、 精通常见数仓（维度建模，范式建模）建模理论，并有数仓实际设计开发经验2、负责数据平台数仓的设计、规划、建设、实施、管理，包括离线、实时的数据架构、数据模型规划、数据质量保障；3、深入理解数据业务，分析用户需求，负责数据平台核心数据资产内容的设计与开发工作，实现高质量数据的互通与共享；4、数据仓库模型的ETL实施，ETL性能优化，主导技术难题攻关；5、针对数据一致性、准确性、及时性，制定数据管理与治理机制，监督保障数据的生产与运维任职要求：1.从事大数据开发或挖掘领域至少3年以上，熟悉数据仓库模型设计与ETL开发经验，掌握维度建模设计方法，具备海量数据处理经验；2.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发工具与方法、数据质量、主数据管理；3.熟悉数据库技术，熟练运用SQL及其他语言，能高效的与业务团队进行沟通；4.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop 、Hive 、Spark 、Flink 、Storm、Kafka等大数据生态系统5.对常规统计与机器学习问题具有一定的理解，熟悉常用的模型，有数据挖掘相关工作经验者优先；6.熟悉Linux系统，掌握一门或多门编程语言，如Java、Python、Shell；7.有线上大数据开发经验,"硬件,移动互联网",50-150人,hadoop,上海
数据开发,https://www.lagou.com/jobs/7190620.html,黄浦区,26k-40k,上海聚勉网络科技有限公司,5-10年,本科,发展前景,工作职责1、全面深入理解公司各类现有数据，洞察现有数据体系与客户业务匹配中的待优化点，并不断改善；2、负责建设并完善数据管理体系，涵盖数据生命周期的标准、模型、质量和数据存取全流程；3、负责数据仓库的设计、开发、维护，有效管理整合各类数据；4、负责基于公司大数据平台进行开发，并对数据进行优化处理，支撑业务需求；5、负责公司及行业数据技术标准制定和落地。工作要求1、全日制本科及以上学历，计算机、数学相关专业；有3年以上数据领域相关工作经验；2、熟悉数据仓库方法论、理解维度建模，有ETL相关开发工作经验，能够牵头完成数据管理相关工作；3、有分布式平台相关开发经验，如Hadoop、Spark、Storm等；4、具有强烈的求知欲，有较强的沟通和组织协调能力，具备良好的文档编写能力；5、有数据服务公司技术管理背景或相关数据平台开发工作经验，熟悉证券行业数据治理者优先。,电商、通讯电子,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7214671.html,杨浦区,16k-20k,北京新才教育科技有限公司,3-5年,不限,周末双休,岗位职责：1. 负责基于大数据个性化推荐的开发和优化;2. 负责模型调优和实际业务场景中的落地工作;3. 应用机器学习等技术，为用户提供推荐和排序，提升推荐效果，改进用户体验。任职资格：1. 本科及以上学历，计算机、数学相关专业，3年以上开发工作经验；2. 在搜索系统、推荐系统或广告等方向有3年以上算法研发经验，有排序或召回等实际项目经验；3. 有 Hadoop / Spark 等大规模分布式计算使用经验；4. 熟悉 Linux 开发环境，熟练使用 Python / Scala / Java等语言；有扎实的编程基础和工程实践；5. 善于思考和学习，对有挑战性的问题充满激情，具有良好的团队合作精神和较强的沟通能力以及执行力,"软件开发,物联网",50-150人,hadoop,上海
0231G9-资深大数据开发工程师-上海,https://www.lagou.com/jobs/6973773.html,浦东新区,11k-20k,中国平安人寿保险股份有限公司,3-5年,本科,"五险一金,年终分红,节日福利,员工旅游",,金融,2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6937797.html,静安区,18k-28k,北京九章云极科技有限公司,3-5年,本科,AI行业，Geek氛围，大牛多，技术前沿,"岗位职责 1.  负责公司实时流产品研发，开发分布式实时计算处理系统，数据处理和分析架构；2.  完成系统框架和核心代码的实现，负责解决开发、生产过程中的技术问题；3.  参与系统架构设计、规划，制定运维解决方案（调度、弹性扩容、容灾等）；任职资格 1. 本科及以上学历，三年以上开发经验；2. 精通java, scala等编程语言；3. 熟悉Linux的主要常用命令使用方法以及常用服务；4. 丰富的数据结构和算法经验，较强的编码能力；5. 有大规模分布式服务经验，较强的问题解决能力。加分项：1. 强烈的责任心与求知欲，开源社区的活跃贡献者优先；2. 熟悉Hadoop生态和常见的开源分布式计算/存储相关技术，包括但不限于Flink，Yarn, Hbase，Spark等；3. 具有微服务架构经验，有实际模型部署服务经历者优先。",数据服务,150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7209685.html,杨浦区,10k-15k,上海晏鼠计算机技术股份有限公司,1-3年,本科,公司氛围好,"工作内容：1.基于Hadoop/Hbase/Spark/Hive的大数据离线/实时数据平台的开发和维护；2.参与公司大数据平台的数据仓库系统建设；3.参与公司大数据集群的性能优化，以及大数据平台架构的整体设计与改进；4.参与对数据挖掘及业务开发团队提供技术支持，协助方案规划；5.参与大数据平台相关技术攻关和创新技术引用。任职要求：1.计算机相关专业，本科及以上学历；2.2年以上Java或Scala编程经验，熟悉流行的大数据编程框架，有大数据处理和应用开发的相关经验；3.精通Hive,hbase,mongoDB,redis等关系型数据库和非关系型数据的使用和优化；4.熟悉Linux系统，精通Shell脚本语言；5.了解Hadoop相关技术的部署维护及安全管理；6.较强的学习能力以及快速解决问题的能力。",消费生活,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/5836286.html,浦东新区,13k-20k,申朴信息技术（上海）股份有限公司,3-5年,本科,五险一金,1、  熟练掌握HIVESQL开发语言，精通HIVESQL优化，并能结合数据仓库的最佳实践和前沿理论，不断调整、优化仓库设计。2、   优秀的职业素养，善于主动思考和行动。3、  有承压能力和良好的结构化问题解决能力。4、  互联网、银行、信用卡、保险等金融机构或主流金融公司工作经验优先考虑。,金融,150-500人,hadoop,上海
KCK-WEB前端开发工程师(数据可视化),https://www.lagou.com/jobs/7182329.html,浦东新区,15k-20k,深圳前海微众银行股份有限公司,3-5年,本科,五险一金 绩效奖金 带薪年假,岗位职责：        1、负责业务系统的前端项目开发，参与代码优化和架构演进（包括PC端和移动端）；        2、发现并解决项目中、工作中的痛点问题；        3、带领团队持续高效的参与项目迭代。        注：此岗位为上海灾备中心岗位。任职要求：1、本科及以上学历，3年及以上Web前端开发经验；        2、能够熟练运用 HTML、CSS、JavaScript 构建高性能的 Web 应用程序；        3、前端基础扎实，熟悉vue.js.并了解底层原理实现；        4、精通前端开发技术和工具，对前端组件化、模块化、工程化有深入的见解和实践；        5、注重用户体验，改善界面可用性和效率，在前端性能优化方面有深入研究；        6、对css/JavaScript性能优化、解决多浏览器兼容性问题有一定的经验；        7、有敬业精神、责任意识、团队合作精神；        8、了解 svg，canvas，WebGL 技术，有数据可视化经验者优先。,金融,2000人以上,hadoop,上海
大数据基础架构开发,https://www.lagou.com/jobs/4151257.html,长宁区,25k-50k,上海寻梦信息技术有限公司,3-5年,本科,"福利好,大牛多,成长快","我们希望您能：1.负责大数据架构相关组件的开发、维护和优化2.负责大数据平台运维管理工具系统的设计和实现3.确定大数据架构的整体技术路线和架构走向，新技术的调研和落地岗位要求：1.熟练掌握Java/Scala，3年以上开发经验2.熟悉大数据离线计算生态体系，对HDFS、MapReduce、Yarn、Hive、Spark等开源组件有深入研究3.熟悉日志采集传输、消息队列相关技术，对Kafka、Flume、Fluentd等开源组件有深入研究4.对于OLAP系统和实时实时数据服务有深入研究5.具有以上组件的patch, 二次开发经验优先","电商,移动互联网",2000人以上,hadoop,上海
交易营销数据开发(T000174),https://www.lagou.com/jobs/7060039.html,长宁区,30k-60k,上海寻梦信息技术有限公司,3-5年,本科,技术大牛多，成长空间大，大流量场景,"岗位职责：1.参与交易系统架构演进的设计和开发工作，独立负责各业务模块的需求对接和技术改造。2.担任重点项目的技术负责人，设计技术方案，协调和对接各方技术资源完成方案落地，并撰写高质量的开发文档。3.负责提炼交易相关的公共组建和基础服务，为各业务系统提供稳健的基础支撑。4.带领并辅导新人完成日常开发和系统维护工作，帮助新人成长。   任职要求1.本科及以上学历,有3年以上的互联网行业工程研发经验优先。2.JAVA功底扎实，熟悉业界流行的开源框架和组件并有一定的理解深度。3.参与过大规模业务系统的架构设计和开发，熟悉高并发分布式系统的设计和应用；熟悉MySQL、Redis、ElasticSearch等主流存储引擎的原理，具备相关的性能调优能力。4.责任心强，思路清晰，技术视野开阔，对业界新技术敏感，喜欢钻研，具有良好的学习能力并注重团队合作。","电商,移动互联网",2000人以上,hadoop,上海
大数据开发,https://www.lagou.com/jobs/6300552.html,静安区,18k-35k,上海倍业信息科技有限公司,1-3年,本科,年度旅游、年度体检 、年度调薪,1、参与实时大数据平台的分布式数据存储与计算开发，打造稳定可靠的平台化、可视化、自动化交互式平台2、设计开发大数据产品，包括实时计算平台、数据审核平台、数据监控平台、数据标签化处理平台；3、负责数据仓库/数据平台的技术性维护工作，处理数据相关业务需求的实现与支持4、 负责提升Haddoop/Spark/Druid/Hive/Hbase集群的高可用性、高性能特性岗位要求：1、 计算机相关专业，全日制本科及以上，1年以上大数据开发经验2、 对流式计算、离线计算有深刻理解，精通MapReduce，Spark，Spark Streaming，Storm数据分析引擎至少一种的原理与使用，熟练应用kafka、redis等消息中间件/缓存技术3、 精通hadoop、druid、hive、hbase等大数据/时序数据库存储和技术的一种或多种的原理与使用4、 熟练应用python、java、scala等一种或多种开发语言进行数据仓库应用的开发，有2年以上实际项目经验5、 熟悉数据仓库/数据平台理论体系，熟悉建设数据仓库/数据集市相关方法论6、 对数据和业务逻辑映射敏感，梳理优化数据产品业务功能的逻辑7、 有hadoop、spark、druid、hbase等相关技术源码研究经验和成果的，优先考虑,"移动互联网,广告营销",15-50人,hadoop,上海
数据仓库开发工程师,https://www.lagou.com/jobs/6900408.html,浦东新区,18k-25k,宏信金服（天津）信息科技有限公司,5-10年,本科,扁平化管理 领导nice 福利好,"工作职责:-负责公司数据仓库、数据集市的数据模型设计-参与公司数据仓库ETL规则设计和开发-参与公司数据仓库需求调研和需求分析-参与公司生产报表的开发制作 职责要求:-3年以上数据仓库建设经验-熟悉数据仓库建设方法论, 熟悉大型数据仓库架构和模型设计，精通ETL开发-精通SQL开发及SQL性能调优，熟悉基于Hadoop, Hive等分布式计算平台的数据开发。-熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、性能调优等-良好的沟通与表达能力和自我驱动力-熟悉数据库容量规划和分表设计方法，有海量数据库设计和支持经验优先；-熟悉MaxCompute开发工具者优先；有金融、财务、风险类行业经验者优先；有Tableau开发经验者优先",金融,50-150人,hadoop,上海
ETL开发工程师（数据仓库）,https://www.lagou.com/jobs/7022596.html,浦东新区,20k-25k,上海鲲驰贸易发展有限公司,3-5年,大专,"工作氛围好,发展空间大","1.参与大数据平台的各种数据产品的需求调研、（维度等）模型设计、架构及关键模块的设计和开发；2.参与数据仓库/BI需求调研和需求分析，能独立主导数据仓库、数据集市的模型设计； 3.参与平台数据采集、数据传输，数据转换、规则引擎等的数据接口规范定义； 4.参与搭建平台级数据治理体系； 5.参与或负责大数据平台运维团队的日常系统调优及各种疑难问题排查。1.3年以上ETL开发经验，大专以上学历； 2.熟悉数据仓库方法论，有2年以上数据仓库建模经验； 3.熟悉MySQL，PostgreSQL,TSDB等主流数据库，能熟练进行SQL查询优化，有海量数据处理经验； 4.熟悉数据标准管理、元数据管理、数据质量管理； 5.熟悉Dataworks,Maxcompute优先； 6.有电商、贸易、财务、供应链行业经验者优先。",电商,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7108369.html,浦东新区,12k-18k,广东方纬科技有限公司,3-5年,本科,五险一金，年终奖金，项目奖金，旅游体检,职位描述：岗位职责：1、3年以上Java开发经验，具备Spring boot、Spring cloud使用经验；2、2年以上hadoop/hbase/elasticsearch/flink/kafka开发经验；3、熟悉至少一种数据库(PostgreSQL/Oracle/Mysql)， 精通SQL，具备大数据处理经验优先；（1） 懂Hadoop平台监控、管理、维护、优化；（2） 对hadoop分布式体系有较深刻了解；（3）  具备Linux、CentOS常用服务。,移动互联网,50-150人,hadoop,上海
高级大数据开发工程师,https://www.lagou.com/jobs/6827642.html,闵行区,25k-40k,上海触乐信息科技有限公司,3-5年,本科,美股上市公司，团队牛人多,岗位职责：1.参与用户增长平台数据产品和应用的数据开发，打造**体验的数据产品；2.基于公司业务，构建业务模型和算法，发掘数据的价值，推动业务增长；3.负责离线和在线数据的采集、清洗和加载，助力数据化运营业务，构建丰富多样的运营场景应用；任职要求：1.2年及以上大数据处理领域开发经验，计算机相关专业本科及以上学历；2.熟练掌握Python/Java/Scala编程语言，代码实现能力强；3.能灵活运用SQL实现海量数据加工处理 ，并有优化数据计算执行效率的能力；4.能够根据复杂业务场景进行数据建模；5.具有Hadoop/Spark/Flink开发与应用经验，熟悉Kafka/Flume等消息通道和数据采集技术，熟练掌握Hadoop/Hive/Spark及Spark SQL等大数据技能；6.善于协作，学习能力强，拥有严密的逻辑思维能力、良好的理解和表达能力、较强的抗压能力。,"移动互联网,数据服务",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6408034.html,黄浦区,25k-50k,简阳联盟凯睿企业管理有限公司,5-10年,本科,平台好 福利好 大牛多,1.搭建大数据平台、及相关公共服务2.负责离线/实时的数据存储和加工处理，包括业务数据、行情数据3.负责非结构化数据处理方案，并根据业务场景引入分析模型，挖掘商业价值4.对数据进行业务分析，灵活运用可视化工具展示分析结果5.参与产品与应用的数据研发，制定整体数据接入规范6.研究前沿技术，解决实际场景中的业务问题，持续优化数据处理、分析、展示方式,"企业服务,人工智能",150-500人,hadoop,上海
资深数据开发工程师,https://www.lagou.com/jobs/7145567.html,长宁区,20k-40k,携程计算机技术（上海）有限公司,5-10年,本科,发展前景大,"职位描述: 研发高可靠、高可扩展、易用的公司统一大数据平台，包括数据中台生产工具类产品(类似阿里dataworks),大规模工作流调度、异构数据交换和同步、数据质量、数据安全、统一元数据中心, 等核心大数据平台和工具链的研发和性能优化。 任职要求 
 有Hive，Kafka，Datax，Zeus, MapReduce，Spark，Flink, Airflow, Presto等两种以上1年以上使用和优化经验
   2. 参与或主导过大型数据平台建设项目，对大数据平台有一定的整体感知和把控能力    3. 熟悉主流的Java开源框架，对Netty、Spring、Tomcat等框架有深入的了解和使用    4. 精通多线程编程，熟悉常见的缓存、消息队列等中间件，熟悉MySQL；    5. 熟悉分布式基本原理，对高可靠，高并发，高吞吐系统特性有一定理解    6. 本科及以上学历，计算机相关专业，三年以上工作经验。符合以下条件优先：    1. 研究过开源代码并有代码贡献。    2. 主导或参与过数据相关产品的后端开发，对大数据技术（比如Hadoop、Spark、Flink等）有一定的了解。   3.有前端开发经验的优先",旅游,2000人以上,hadoop,上海
数据开发 (MJ000023),https://www.lagou.com/jobs/6715312.html,徐汇区,15k-30k,上海米哈游网络科技股份有限公司,1-3年,本科,"六险一金,年终多薪,技术牛人,扁平氛围",岗位职责：1. 参与公司内部大数据平台的建设；2. 参与构建统一的数仓分层架构，并支持各种业务取数要求；3. 满足公司各部门日常数据需求。岗位要求：1. 计算机或相关专业，本科及以上学历；2. 至少精通一门面向对象的编程语言，深入理解其思想；3. 有良好的数据结构知识和算法基础；4. 有强烈的求知欲，学习能力强；5. 有大数据处理项目经验1年以上；6. 熟悉Hadoop，Hive，Spark，Kafka，Hbase等工具使用。,"移动互联网,游戏",500-2000人,hadoop,上海
数据开发 (MJ000023),https://www.lagou.com/jobs/6945993.html,徐汇区,20k-40k,上海米哈游网络科技股份有限公司,1-3年,本科,"技术牛人多,扁平化,年终多薪,六险一金",岗位职责：1. 参与公司内部大数据平台的建设；2. 参与构建统一的数仓分层架构，并支持各种业务取数要求；3. 满足公司各部门日常数据需求。岗位要求：1. 计算机或相关专业，本科及以上学历；2. 至少精通一门面向对象的编程语言，深入理解其思想；3. 有良好的数据结构知识和算法基础；4. 有强烈的求知欲，学习能力强；5. 有大数据处理项目经验1年以上；6. 熟悉Hadoop，Hive，Spark，Kafka，Hbase等工具使用。,"移动互联网,游戏",500-2000人,hadoop,上海
高级大数据开发工程师,https://www.lagou.com/jobs/7108881.html,闵行区,17k-32k,上海扩博智能技术有限公司,5-10年,本科,人工智能 智慧零售 带薪年假,"工作职责:1、扩博大数据平台研究与开发，编写符合规范的开发设计等技术文档，代码开发，单元测试等2、对接业务部门，完成业务数据治理（包括产品SKU数据，图片数据，标注数据，模型数据）以及BI需求开发工作  职位要求：1、计算机相关专业，三年以上互联网行业公司大数据平台后端开发和设计经验2、熟练使用大数据Hadoop平台及其相关生态组件HBase/Hive/Spark，熟悉Azure Data Factory, HDInsight, Power BI是加分项3、技术基础扎实，有较强的分析和解决问题能力，精通C#/Java/Python/Go中的至少一种编程开发4、有强烈的上进心和求知欲，善于学习和运用新知识，有良好的团队意识和较强的抗压能力","移动互联网,数据服务",50-150人,hadoop,上海
数据开发工程师（DMP用户方向）,https://www.lagou.com/jobs/7126008.html,浦东新区,25k-50k,上海阅文信息技术有限公司,3-5年,本科,上市公司,,文娱丨内容,500-2000人,hadoop,上海
高级后端开发工程师-广告数据平台,https://www.lagou.com/jobs/6043760.html,徐汇区,20k-40k,北京字节跳动科技有限公司,1-3年,本科,六险一金，免费三餐，租房补贴，职业大牛,,文娱丨内容,2000人以上,hadoop,上海
大数据平台开发工程师,https://www.lagou.com/jobs/5529142.html,普陀区,25k-35k,叽里呱啦文化传播（上海）有限公司,3-5年,本科,"与牛人一起,团队简单,阿姨做饭",职位描述:1.负责大数据架构相关组件的开发、维护和优化2.负责搭建分布式计算平台、查询引擎、中间件；3.确定大数据架构的整体技术路线和架构走向，新技术的调研和落地岗位要求：1.熟练掌握Java/Scala，3年以上开发经验2.熟悉hadoop生态圈及hdfs、hive、kafka、spark、flink等开源产品；3.熟悉hbase、spark、ES等组件；4.精通Java有较强的编码能力，能独立解决技术,"移动互联网,教育",500-2000人,hadoop,上海
高级开发运维工程师（DBA）/数据库专家,https://www.lagou.com/jobs/7063896.html,长宁区,20k-32k,上海脉多信息技术有限公司,5-10年,大专,准上市公司、公司稳定，氛围好,"高级开发运维工程师（DBA）/数据库专家职位描述：1. 数据库的维护计划制定及日常维护检查;2. 数据库备份、恢复的监控和管理，运行性能跟踪及故障处理;3. 数据库的安全和权限管理;4. 数据库的规划和部署，数据库的迁移和升级;5. 对SQL Server数据库等其他开源数据库的管理与优化工作.任职要求：1. 大专及以上学历，计算机或相关专业;2. 丰富的数据库开发运维等相关经验，五年以上SQLServer运行管理工作经验;3. 熟悉SQL Server的运行机制和体系架构，有较强的数据库设计能力；4. 精通SQL Server数据库的管理，备份和恢复，数据容灾，灾难恢复;5. 熟悉SQL Server数据库集群; 精通数据库优化工作;6. 熟悉Linux操作系统,至少掌握一门脚本语言;7. 有大型网站和系统数据库管理经验者优先;8. 熟悉PostgreSQL，MySQL等开源数据库，熟悉NoSQL，Redis等相关技术优先；9. 思维敏捷，有良好的团队精神和协作能力，积极主动，乐于接受挑战，对新技术有学习热情。10、熟悉阿里云、腾讯云的RDS数据库","硬件,软件开发",50-150人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6556686.html,宝山区,10k-15k,北京众标智能科技有限公司上海分公司,1-3年,本科,"靠谱团队,大数据,待遇优厚",职位描述1. 负责公司数据处理、数据标准和数据仓库建模工作，对各类内外部数据源能进行有效分析评估，有序系统地进行管理和融合；2. 制定ETL相关的整体方案和运行过程，参与数据平台架构的设计、开发、流程优化及解决ETL相关技术问题；3. 参与客户需求分析，理解业务场景和目标，构建合适的数据挖掘和分析模型，并编写统计分析批量程序；4. 负责公司各类数据库的管理和性能优化。职位要求1. 计算机及相关专业本科学历，2年以上数据挖掘、ETL或数仓相关工作经验；2. 熟练使用Oracle、MySQL、PostgreSQL等主流数据库，具有较强的SQL编写、优化能力，熟悉存储过程编写，有一定Python脚本编写经验；3. 熟悉数据仓库、数据治理的方法论，有一定的数据建模能力，有Kettle等经验者优先；4. 有责任感，工作耐心细致；良好的数据敏感度、逻辑分析及问题解决能力；良好的沟通能力和团队精神，快速学习能力。,"电商,企业服务",50-150人,hadoop,上海
数据仓库开发工程师(J12165),https://www.lagou.com/jobs/7105590.html,浦东新区,18k-28k,上海二三四五网络科技有限公司,3-5年,本科,上市公司，六险一金，平台好发展空间大,,"数据服务,移动互联网",500-2000人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6642187.html,浦东新区,15k-20k,北京兰亭高创科技有限公司,1-3年,本科,五险一金、年终奖、发展空间大、晋升机会多,"1. 参与数据仓库的搭建2. 负责数据仓库需求分析、建模设计、数据流设计、ETL开发与测试3. 负责ETL数据准确性验证、及时处理生产环境异常问题及ETL任务的优化## 任职要求v3:1. 本科或以上学历2. 1-3年数据仓库相关工作经验，熟悉数据仓库相关技术，如 ETL、报表开发，具备数据分析技术并具有相关项目经验；3. 熟悉SQL,熟悉主流数据库技术，如Oracle、MySql、SQLServer、redshift、vertica等4. 有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题5. 学习能力强，良好的理解和表达能力，较强的抗压能力6. 有财务数据分析经验者优先","电商,消费生活",500-2000人,hadoop,上海
数据库开发工程师,https://www.lagou.com/jobs/4233683.html,浦东新区,9k-17k,上海金亥通信设备有限公司,不限,大专,"13薪,5险1金",要求：1、1-5年数据库开发经验2、至少熟悉oracle数据库，精通存储过程的开发，熟悉PL/SQL优化。3、熟悉linux shell脚本语言4、熟悉数据清洗，ETL技术优先。5、熟悉电信数据开发者优先。6、大专及以上学历,"企业服务,数据服务",50-150人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/7092367.html,浦东新区,15k-30k,盛趣信息技术（上海）有限公司,不限,本科,五险一金、餐补、交补、商业保险、带薪年假,岗位职责1. 负责实时和离线数据平台的建设和优化，不断提高系统运行效率及稳定性； 2. 负责实时计算、运维监控等大数据平台相关子系统开发； 3. 为数据开发人员和数据分析师提供大数据技术指导，解决大数据平台应用中遇到的技术难题；任职资格1. 计算机或相关专业本科及以上学历，2年以上大数据相关工作经验； 2. 熟悉Hadoop、Spark、Kafka、Hive、Hbase、Flume、Elasticsearch等大数据相关技术和工作原理；3. 扎实的Java基础，熟悉Spring boot/Spring cloud等微服务开发框架；4. 有大数据平台相关项目的实际开发和调优经验； 5. 对大数据技术有强烈兴趣，思路开阔，喜欢钻研新技术；,"移动互联网,游戏",2000人以上,hadoop,上海
数据库开发工程师,https://www.lagou.com/jobs/6412881.html,浦东新区,14k-22k,深圳市金证科技股份有限公司,3-5年,本科,"证券项目,环境好,股票期权","岗位职责：1、负责整个工程项目的需求交流和实施;2、负责软件系统安装部署、升级维护；3、负责项目业务代码编写。任职要求：1、本科及以上学历，计算机相关专业毕业；2、3年以上数据库实施经验,精通主流数据库oracle,sqlserver等;3、精通SQL语言编写与优化，熟悉使用存储过程、索引、触发器等；4、性格外向，能承压,沟通能力较强，有很强的团队合作精神,具备证券、金融项目经验优先。",金融,2000人以上,hadoop,上海
大数据开发工程师(J11494),https://www.lagou.com/jobs/7077230.html,普陀区,15k-30k,秒针信息技术有限公司,3-5年,本科,更多福利可与HR详谈,,"数据服务,广告营销",2000人以上,hadoop,上海
后端数据开发工程师,https://www.lagou.com/jobs/6806416.html,长宁区,20k-40k,翼健（上海）信息科技有限公司,5-10年,本科,发展快速；晋升空间；股权激励,岗位描述1. 配合产品经理，参与数据平台发展各阶段产品需求分析和功能设计；2. 基于确定的产品功能需求，参与平台后端系统架构设计、接口定义实现及测试、构建部署和运维等各阶段工作；3. 根据产品或技术实现发展需要，按需进行一些新技术的研究，并评估将其引入现有平台实现的可行性。 任职资格1. 本科及以上学历，至少3年及以上的实际开发经验；2. 熟练掌握C/C++/Python/Java/Go/Javascript其中至少2种及以上程序设计语言，并且自认为具有良好的编程素养；3. 熟练掌握常用的数据结构及算法；4. 熟悉Linux系统开发，熟悉网络编程、文件系统，有分布式系统开发经验；5. 应具有熟练的技术领域相关的英文文献阅读能力；6. 有良好的沟通能力和团队合作能力，能够自主驱动，具备良好的问题定位分析能力。,医疗丨健康,50-150人,hadoop,上海
数据开发岗,https://www.lagou.com/jobs/7201508.html,浦东新区,13k-26k,拉勾猎头,3-5年,本科,大平台,﻿1..构建法律、风控业务数据仓库（分层建设、主题模型、元数据管理、性能和效率优化） 2.从数据采集，数据建模，到数据应用全流程参与设计与开发 3.优化数据生产链路，提高数据时效性 4.实时数仓、特征工程、用户画像等系统的设计和开发。﻿1. 本科以上学历，计算机相关专业，3年以上工作经验。 2. 熟悉网络协议栈，数据结构与算法以及数据库性能优化与操作系统原理  3. 编程功底扎实，熟练掌握Python，Hive，SQL等语言，有较强的ETL开发经验者优先 4. 掌握大数据相关技术，如Hadoop/Hbase/Spark／hive/flink引擎等技术，良好的逻辑思维能力和沟通能力； 5. 熟悉数据仓库架构及原理，能独立进行数据仓库数据建模； 6. 熟悉数据仓库建设方法论： a：了解数仓分层建设方法； b：了解主题建设方法，能抽象主题、建设模型、物理化并调整效率和性能；,"移动互联网,企业服务",500-2000人,hadoop,上海
数据开发岗（上海）,https://www.lagou.com/jobs/7125736.html,浦东新区,13k-26k,拉勾猎头,3-5年,本科,大平台,﻿1..构建法律、风控业务数据仓库（分层建设、主题模型、元数据管理、性能和效率优化） 2.从数据采集，数据建模，到数据应用全流程参与设计与开发 3.优化数据生产链路，提高数据时效性 4.实时数仓、特征工程、用户画像等系统的设计和开发。﻿1. 本科以上学历，计算机相关专业，3年以上工作经验。 2. 熟悉网络协议栈，数据结构与算法以及数据库性能优化与操作系统原理  3. 编程功底扎实，熟练掌握Python，Hive，SQL等语言，有较强的ETL开发经验者优先 4. 掌握大数据相关技术，如Hadoop/Hbase/Spark／hive/flink引擎等技术，良好的逻辑思维能力和沟通能力； 5. 熟悉数据仓库架构及原理，能独立进行数据仓库数据建模； 6. 熟悉数据仓库建设方法论： a：了解数仓分层建设方法； b：了解主题建设方法，能抽象主题、建设模型、物理化并调整效率和性能；,"移动互联网,企业服务",500-2000人,hadoop,上海
大数据平台开发工程师,https://www.lagou.com/jobs/6751525.html,虹口区,17k-24k,民生人寿保险股份有限公司,3-5年,本科,发展平台、五险一金、领导好,工作职责：1、要求能自主完成大数据平台功能模块的设计、开发、性能调优；2、负责日常数据模型的理解、技术方案设计、技术开发与测试；3、负责编制与产品或项目相关的技术文档。任职资格：1、理工科相关专业，本科以上学历，3-5年经验，计算机专业优先；2、具有保险行业工作经验，熟悉寿险业务者优先，有过监管报送系统的开发经验者优先；3、熟悉oracle、mysql等主流工具、技术，熟悉Hadoop、Spark、Flink、Kafka、Flume、HBase等大数据组件的原理，有大型项目开发经验，有系统优化和故障排错的经验和能力；4、熟悉Linux Shell开发，熟悉ClickHouse/Druid/Kudu者优先。,金融,2000人以上,hadoop,上海
Java/Scala大数据开发工程师,https://www.lagou.com/jobs/7148878.html,浦东新区,18k-30k,上海擎创信息技术有限公司,5-10年,本科,大数据量、复杂的业务场景,"岗位职责： 1. 负责共研及实施项目的开发工作 2. 完成开发相关文档 3.完成PM安排的开发工作，有独立开发能力和钻研精神   岗位要求： 1. 计算机以及相关专业本科及以上学历，3年以上Java或Scala开发经验； 2. 熟悉主流的开发框架，如Spring，SpringMVC, REST+JSON等开发能力 3. 熟悉Maven的使用、理解Maven的原理与使用技巧，熟练用Git进行代码版本控制 4. 熟练使用Mysql, Orale等关系型数据库，有大批量数据快速处理与优化经验 5.熟悉常用设计模式，架构模式，并有创新思维；熟练掌握面向对象开发技术，如能够对系统设计有独特的见解优先考虑 6. 具备较好的编码习惯，熟悉并能使用常见的设计模式； 7. 熟悉Zookeeper、Kafka、Elasticsearch及相关开发经验者优先 8.对Linux操作系统熟练掌握，熟悉shell等脚本编程 9.参与过分布式高性能服务的设计开发过程，有大规模分布式系统的实践经验者优先考虑 10、熟悉大数据开发有spark、flink及hadoop经验优先11.工作主动积极，责任心强，具有良好的沟通协作能力和团队合作意识，能承受较大的工作压力","企业服务,数据服务",50-150人,hadoop,上海
0821NX-投资大数据仓库开发专家,https://www.lagou.com/jobs/6735782.html,浦东新区,25k-40k,平安养老保险股份有限公司,3-5年,本科,"五险一金,带薪年假,节日福利,绩效奖金",工作职责工作职责 :1. 负责投资大数据仓库设计2. 业务数据体系采集及处理流程的设计、业务模型设计、数据分析及数据建模3. 优化现有数据平台，提升数据处理效率及智能化运维的能力4. 参与业务需求讨论，可协助用户梳理业务规则并系统落实化5. 数据可视化开发，提升用户体验6. 按照编码规范对代码进行检视，并编写单元测试案例、集成测试案例任职要求1. 统招全日制大学本科及以上学历2. 5年以上数据库开发经验，3年以上大数据仓库建设与研发经验； 3. 根据业务需求设计数据仓库模型，熟悉离线、实时数据采集、加工方法；4. 熟悉数据仓库和数据建模相关技术细节，有编程经验，熟悉Scala/Python等语言；5. 了解Hadoop或 Spark生态相关技术，包括HDFS、Hive、Spark、Flink等；6. 有较强的学习能力，良好的团队协助精神，沟通协调能力； 7. 有证券金融相关项目背景优先考虑。,金融,2000人以上,hadoop,上海
大数据开发主管,https://www.lagou.com/jobs/7203395.html,浦东新区,35k-55k,上海银科创展投资集团有限公司,5-10年,本科,上市公司,1.      岗位职责：a)      负责大数据开发团队的管理工作。b)      负责大数据平台的架构设计和开发工作。满足实时、离线计算的需求；满足数据分析和在线应用报表的高效快速查询需求。c)      负责大数据平台的运维和性能调优，确保平台的稳定运行。d)      结合业务场景和流程，制定数据治理规范，确保数据完整性、准确性和及时性。2.      能力要求：a)      本科以上学历b)      5年以上工作经验，3年以上的大数据团队管理经验，条件特别优秀者可适当放宽。c)      3年以上大数据平台基础架构、开发、运维、调优经验。熟悉大数据领域相关生态，对Hadoop/MapReduce/Hbase/Hive/Kafka/Spark /Yarn等有较深的认识。d)      精通Java语言编程，3年以上Java/Scala开发经验。熟悉Java、Java Web、JVM原理，包括内存模型、类加载机制以及性能优化等，拥有Java Web开发经验；e)      熟练使用python或者shell等脚本语言，熟练进行Linux的运维操作；f)       熟悉虚拟化应用的部署与运维，如Docker、K8S、Swarm等技术g)      处理的数据量级在20TB级别以上h)      熟悉以下数据引擎或者框架中的一种及以上：presto【优先】、Impala、sparksql、Clickhouse、kylin、GreenPlum、MPP。,"移动互联网,金融",2000人以上,hadoop,上海
资深数据仓库开发工程师,https://www.lagou.com/jobs/6699485.html,黄浦区,15k-30k,引粒网络科技（上海）有限公司,3-5年,本科,极佳的办公环境，发展空间前景好,岗位职责：1．基于分布式平台的0-1数据仓库模型设计及实现；2．负责ETL开发、优化、技术攻关，以及BI报表开发工作；3．负责数据项目的开发、推进和优化；4．配合算法开发相关数据产品、工具的设计；5.   协助建立数据模型，对数据进行清洗、挖掘、优化及统计。岗位要求：1．3-5年数据仓库实施经验，ETL实施经验，认可数据产生价值；2．理解数据库原理，熟练使用至少一种关系数据库管理系统，如Mysql、Oracle、DB23．熟练掌握 Shell、Python、Perl 或其它任何一门脚本语言；4．精通一种或多种分布式平台，理解计算框架，如hadoop、hive，如mapreduce5．具备较强的业务理解能力和项目管理、推动力强6. 具有MYSQL、ORACLE等至少一种大型数据库的应用开发经验，熟悉数据标准管理、元数据管理、数据质量管理；对整体数据有综合的把控能力以下背景优先： 1．海量数据仓库架构和实施经验2．熟练掌握java/scala/R 等语言中的至少1种，使用以上技术参与数据产品和工具的开发经验，或其他大中型系统设计和开发经验,社交,15-50人,hadoop,上海
09310J-大数据平台开发工程师,https://www.lagou.com/jobs/6766718.html,徐汇区,15k-25k,平安健康保险股份有限公司,3-5年,本科,"五险一金,绩效奖金,节日福利,带薪年假",,金融,500-2000人,hadoop,上海
大数据开发工程师（上海）,https://www.lagou.com/jobs/7142977.html,长宁区,30k-60k,北京奇艺世纪科技有限公司,3-5年,本科,双休，发展前景好,岗位职责：1、负责爱奇艺海外视频业务数据仓库的构建； 2、负责数据模型的设计，ETL实施、ETL性能优化、ETL数据监控以及一系列技术问题的解决； 3、深入理解常用的数据建模理论，可独立把控数据仓库的各层级设计； 4、大数据的离线和实时处理，可以进行海量数据模型的设计、开发。 任职要求：1、本科及以上学历，计算机或数理统计相关专业；2、3年以上企业级数据仓库建模经验，有数据挖掘，机器学习，推荐相关经验优先；3、熟练掌握Hive/SQL，熟练掌握Hadoop及Map-Reduce应用开发，熟悉Hive、Spark、Flink等大数据开发工具中一种或几种；4、熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖掘和数据可视化；5、具有较好的逻辑思维能力和创新能力，对未知领域有浓厚的好奇心。 温馨提醒：如果 7 天内您没有收到爱奇艺的面试邀请，那么目前我们不会安排您参加后续的面试环节，感谢您的理解和对爱奇艺的关注与认可。,文娱丨内容,2000人以上,hadoop,上海
高级数据仓库开发工程师,https://www.lagou.com/jobs/6234379.html,浦东新区,15k-20k,上海招赢电子商务有限责任公司,5-10年,本科,带薪年假 节日补贴 高低温补贴 年度体检,岗位职责1. 负责数据仓库和数据集市模型的设计，整理相关文档并制定实现方案；2. 负责数据模型的具体落地实现和后续优化；3. 负责数据抽取、转换、加载脚本的开发与测试；4. 负责ETL任务的调度设计、配置和优化；5. 负责各业务部门的日常数据需求及分析需求； 任职资格1. 熟悉Sqlserver、Mysql、DB2等常用数据库，熟练SQL编程2. 熟悉常用的ETL工具，如Informatica、SSIS等；3. 熟悉数据仓库方法论，有2年以上数据仓库建模经验；4. 有大数据经验优先；5. 较强的沟通能力、团队协作和责任心。,电商,150-500人,hadoop,上海
大数据开发工程师（python）,https://www.lagou.com/jobs/6419008.html,浦东新区,30k-35k,上海贝耳塔信息技术有限公司,3-5年,本科,股票期权 年终奖 五险二金 前沿科技,岗位职责：1、负责用户行为分析、客户画像、智能推荐等相关大数据分析及运算开发；2、负责大数据分析体系的规划、设计和建设；3、收集、整理、分析、统计各类数据指标；4、负责大数据分析、自然语言处理、机器学习探索和实现； 任职要求：1、本科及以上学历，3年及以上大数据开发经验，软件工程/计算机/通信/数学等相关专业；2、能熟练使用 python脚本语言开发；3、熟悉Oracle、Sqlserver、Postgre等关系型数据库；4、有hadoop、spark、flink等至少一种大数据平台的使用经验；5、有用户行为分析、客户画像、智能推荐、数据仓库建设、商业数据分析、增长项目经验者优先。6、具备较强的表达能力和抽象总结能力，具备极强的逻辑思维能力；7、有自然语言处理、机器学习经验者优先；,金融,50-150人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6995554.html,黄浦区,15k-30k,深圳智融信达科技有限公司,1-3年,本科,高额奖金,岗位职责：1. 整理加工海量金融数据以便挖掘有效信号；2. 开发维护数据平台，确保交易能够稳定高效进行；3. 与基金经理合作开发辅助工具。任职要求：国内外名校毕业1. 熟练运用python的数据清洗、加工技术；2. 熟悉MySQL的使用和常见优化；3. 处理事情细心、有耐心，有良好的沟通技能；4. 有良好的团队合作意识。 加分项：1. 熟悉数据处理语言底层原理，懂得优化数据处理算法；2. 有金融大容量数据处理经验或分布式存储经验；3. 对于接触新鲜事物习惯探究并理解其原理。,"移动互联网,数据服务",50-150人,hadoop,上海
大数据开发工程师(J10517),https://www.lagou.com/jobs/6591512.html,徐汇区,15k-25k,秒针信息技术有限公司,3-5年,本科,带薪年假 团队氛围极佳,工作职责:1.负责基础数据及通用数据资产建设，通过数据+算法+工程化能力，处理、萃取和自动化加工数据，服务AI和BI场景。2.参与大数据基础架构和技术体系的规划建设，包括统一采集、数据资产建设与管理和数据质量及稳定性保障体系等。任职资格:1.本科及以上学历，5年以上开发经验，3年以上大数据开发经验，精通数据仓库建模、ETL设计开发，有数据质量与数据治理相关经验。2.有从事分布式数据存储与计算平台应用开发经验，站在全局基础数据和通用数据建设角度，耐得住短期无业务结果的寂寞。3.具备实际的大数据业务开发经验，熟悉Hadoop/Spark/Flink等流批数据处理的开发经验。3.具备实时流计算数据开发经验，尝试过流批数据处理与融合，及全栈开发经验优先。4.具备一定的Python语言的开发能力，具备机器学习算法能力尤佳。5.良好的思维逻辑性和语言表达能力，以及良好的项目沟通和协调能力。,"数据服务,广告营销",2000人以上,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6015861.html,徐汇区,20k-35k,宜家（中国）投资有限公司,3-5年,本科,员工餐厅 企业年金 超长年假 外企福利,"职责描述：• Responsible for designing, building, testing and maintaining data systems, making sure the data structure, ingestion and processing systems, supporting digital product teams’ requirements and user needs;• Responsible for implementing methods to improve data reliability, efficiency and quality;• Act as technical expert in regard to integration and connectivity methods, protocols, security and practices for data management systems;• Responsible for designing and creating the optimal data pipeline;• Work closely with data architects/scientists and other stakeholders on future data handling technologies, including input on risks, costs, benefits;任职要求：• Expert experience with mainstream RDBMS like MySQL(mandatory), PostgreSQL, Oracle and NoSQL such as Redis, HBase;• Familiar with the distributed database architecture, ability to design the OLTP with high availability, scalability and performance; solid hands-on experience with distributed DB products in mainstream Cloud environment like AliCloud DRDS or GCP spanner;  • Extensive experience in big data acquisition, pre-processing, storage, and cleansing technologies including Hadoop (HDFS, MapReduce, Yarn,..), Kafka, Sqoop, Spark, Flink and etc;• Experience with programming languages: Java, Python or Shell;     • Knowledge of Graph Database like Neo4j is a plus;",消费生活,2000人以上,hadoop,上海
BI数据开发工程师,https://www.lagou.com/jobs/4620567.html,浦东新区,10k-20k,深圳市博奥特科技有限公司,3-5年,大专,"金融企业,数仓,银行项目,长期稳定",2. 负责大数据平台系统的稳定3. 负责大数据项目开发和维护。4. 负责软件系统的功能模块设计及相关过程文档的编写。5. 参与研究大数据技术应用解决方案等。6. 应用模块、WEB、接口开发，编写相关文档。7. 完成DB/REDIS/接口设计文档8. 完成上级领导交办的其他各项事宜2、有良好的代码书写、注释和单元测试习惯3、熟练使用oracle数据库，有redis，rabbitMQ，spring，zookeeper等经验者优先4、熟悉Linux操作系统，掌握常用的Linux命令，熟悉脚本编程Shell/Python优先5、熟练掌握hadoop、hbase、hive、oozie、sqoop等；6、负责平台数据提取、数据挖掘及数据分析，具有良好的商业敏感度和优秀的数据分析技能，能够解决复杂的商业问题。7、主动好学，具备良好的沟通合作技巧，较强的责任心及团队合作精神，并有一定领导经验8、熟练掌握数据结构，操作系统，数据库原理等,"移动互联网,金融",150-500人,hadoop,上海
大数据开发实习生,https://www.lagou.com/jobs/7149391.html,黄浦区,4k-5k,上海宏路数据技术股份有限公司,不限,本科,"氛围好,环境好，地铁周边，六险一金","岗位职责：                                  1、负责基于Hadoop（CDH、HDP）平台架构的开发； 2、针对海量的数据开发具有数据收集、统计、分析和挖掘能力的创新型产品； 3、基于MapReduce、Spark等的大数据开发； 4、学习和研究大数据技术最新动向以满足产品、项目的需求。  任职资格 1、计算机相关专业本科及以上； 2、软件基础理论知识扎实，具有良好的数据结构、算法功底； 3、学习了解过大数据相关技术 (MapReduce, Spark, Hive, HBase...) 优先 4、有个人开源项目或参与开源项目者优先； 5、每周可实习5天优先考虑。",移动互联网,150-500人,hadoop,上海
数据库开发工程师,https://www.lagou.com/jobs/7164518.html,长宁区,17k-20k,上海合阔信息技术有限公司,3-5年,本科,全额缴纳五险一金，市区地铁口,数据库开发工程师职位描述：  1.  SQL Server数据库的各项工作：包括高可用架构、监控、数据库性能调优、备份恢复、故障诊断等；  2.  擅长编写SQLServer和Oracle存储过程，设计表结构，SQL语句优化、数据建模等；  3. 具备一定的业务需求分析理解能力，能够通过客户的业务需求描述整理成开发语言描述；  4. 编写并及时更新运维文档、系统FAQ、操作手册等相关文档；  5. 配合其他部门进行数据处理、查询、统计和分析工作。  6. 对SQL查询性能分析与调优，排错，保证数据安全；  7. 按要求进行定制化的报表开发。任职要求：  1. 本科以上学历，计算机及相关专业，3年以上数据库开发或DBA工作经验，有海量数据库构架经验者优先；  2. 3年及以上云平台数据库系统运维经验，对大型数据库系统架构具有良好的认识；  3.  精通关系型数据库表结构，能够快速学习数据表关系，学以致用；  4. 具备一定的业务需求分析理解能力，能够通过客户的业务需求描述整理成开发语言描述；  5.  熟练掌握PowerBI 或 Reporting Server其中之一的报表开发能力；  6. 有责任意识，具有踏实、耐心、细致的工作心态，有良好的沟通能力和团队协作能力，能承受工作压力。,"企业服务,移动互联网",15-50人,hadoop,上海
大数据实时开发工程师,https://www.lagou.com/jobs/7218509.html,长宁区,20k-35k,北京恒远鑫达投资管理有限公司,3-5年,本科,薪资高,职位描述：1、负责实时大数据平台的架构设计与落地；2、负责预测、推荐、风控、客户画像等实时大数据应用服务的开发迭代；3、参与数据管理服务、数据存储服务、数据查询服务、数据流转服务等特定的实时大数据服务产品的开发迭代；4、负责系统稳定性和流程优化，不断改善和提高系统的稳定性。职位要求：1、扎实的计算机专业基础，对常用数据结构有深刻的理解，优秀的代码编写、算法设计能力及良好的开发习惯；2、两年以上开发和设计经验，熟悉Java/C++/Python等至少一种开发语言，熟悉Spring框架，有丰富开发经验者优先；3、深入理解SparkStreaming、Storm、Flink等实时组件，有实时相关项目经验；4、理解关系数据库、消息队列、分布式缓存等技术，能够灵活应用进行系统设计，有相关产品系统开发经验者优先；5、优秀的系统分析和问题解决能力，能够攻克复杂的系统难题；6、良好的沟通表达能力和团队协作能力，勤奋好学，能够承受一定的压力；7、向开源社区贡献过源码者优先。,金融,500-2000人,hadoop,上海
高级Java开发工程师（数据技术）,https://www.lagou.com/jobs/7205752.html,黄浦区,27k-39k,贝壳金科控股有限公司,5-10年,本科,五险一金，带薪年假,"岗位指责：1. 负责与三方公司做数据对接，为业务提供统一的三方接口服务2. 保障三方对接平台的稳定性和可靠性3. 基于开源产品对大数据工具进行二次开发，保障大数据平台的易用性和稳定性任职要求：1. 具备扎实的计算机理论基础, 对数据结构及算法有较强的功底2. 精通Java语言编程，具备优秀的系统Debug/Profiling能力和经验3. 熟悉Spring Boot,Spring Cloud等后端开发系统4. 良好的沟通协作能力，支持跨团队沟通4. 有React antd 或者 Vue 开发经验者优先5. 熟悉Hadoop/Kafka/Flink/Spark/TiDB等开源大数据技术者优先6. 有强烈上进心和责任心，学习适应能力强，乐观自信，能挑战自我不断追求卓越",金融,500-2000人,hadoop,上海
大数据开发工程师 (MJ001024),https://www.lagou.com/jobs/7152163.html,黄浦区,21k-39k,贝壳金科控股有限公司,不限,本科,五险一金，带薪年假,"岗位职责：1、理解数据的产品应用场景逻辑，通过统计方法和通用分布式框架工具语言如Spark,TiDB，不断加强数据服务质量；2、负责数据清洗、转换、建模等工作,对海量用户行为数据通过Spark/Flink等进行离线和实时处理；3、参与企业级数据仓库、数据建模等数据开发工作。4、业务数据报表设计、开发及日常维护任职要求：1、丰富的数据仓库建模经验，具有良好的数据分析思维；2、精通SQL，熟练使用MySQL/Hive/Oracle中至少一种数据库3、熟悉大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖掘和数据可视化4、能够自驱，有创新意识，对数据价值应用思路清晰，沟通能力强5、有Spark、hive、TiDB等大数据sql引擎实战经验者优先6、了解java web开发；掌握基础java开发者优先",金融,500-2000人,hadoop,上海
Python数据开发工程师,https://www.lagou.com/jobs/7167639.html,浦东新区,25k-35k,上海微创软件股份有限公司,5-10年,本科,六险一金工作环境nice技术前沿,"ElectrifAi-Python数据开发工程师 项目描述成立于2004年，是人工智能和机器学习领域的领导者，为行业带来了革命性变化，以帮助客户转变其业务。作为业界首创，ElectrifAi已围绕开源和Spark体系的计算引擎重新设计了其技术平台，该引擎可进行大规模的分布式数据处理和机器学习，并具有嵌入式Zeppelin笔记本功能。现在，ElectrifAi的数据科学家及其客户可以使用任何编程语言对数据进行编码和访问。Docker Containers和Kubernetes的结合使ElectrifAi能够大规模构建和部署混合云企业解决方案，在数周而不是数月内即可看到结果，从而显着增加了企业实现价值的时间。客户来自世界上许多最大的企业和政府部门，其中包括：强生，T移动，美国政府，诺华，安大略省教师退休金计划，万事达卡，花旗银行，美国运通卡，Mercy医院，Bon Secours和联合航空。ElectrifAi可以协助客户将不同的混乱数据转化为实用的见解，从而解决日常问题并通过提高利润，提高绩效和降低风险来推动业务发展。ElectrifAi对全球**行业的公司产生了积极影响，这些行业包括：政府，医疗保健，金融服务，旅行和款待，电信，CPG岗位内容• Design, build and launch efficient & reliable data pipelines to move and transform data.• Securely source external data from numerous partners.• Design scalable implementations of the models developed by Data Scientists.• Optimize existing pipelines and maintain of all domain-related data pipelines.• Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data.岗位要求• BA/BS in Computer Science, Engineering, Mathematics or related field.• 3+ years of SQL (Oracle, Vertica, Hive, etc.) experience and relational databases experience (Oracle, MySQL).• 3+ years of experience in custom or structured ETL design, implementation and maintenance.• Proficiency in Python, minimum 3 years of Python development experience.• Hands-on experience with different data warehouse and processing technologies such as Spark.• Experience working in very large data warehouse environments.• Experience working with applied scientists on machine learning modeling.• Good oral English","企业服务,移动互联网",2000人以上,hadoop,上海
数据开发专家,https://www.lagou.com/jobs/7172255.html,浦东新区,25k-35k,上海上湖信息技术有限公司,5-10年,本科,数据集大，团队牛人多,职位描述1.参与平台数据仓库规划、架构及研发，包括离线、实时的数据模型规划，建设PB级的数据集市和数据平台； 2.数据仓库模型的ETL实施，ETL性能优化、技术攻关等3.参与平台数据治理相关工作，负责数据质量、数据一致性及稳定性保障等建设 ； 4.参与平台标签体系、数据产品与应用的数据研发，发掘数据价值，以数据驱动业务不断发展 。职位描述1.5年以上相关工作经验，计算机等相关专业本科以上学历，具有丰富的数据建模实践经验。2.精通业务建模、数据仓库建模、精通ETL设计开发，具备体系化的数据质量与数据治理相关经验，有大型项目相关领域深入实践经验，能独立主导完成某一业务领域的整体模型设计，具备跨域的沟通协调能。3.精通大数据技术，如MAPREDUCE、HIVE、YARN、SPARK、FLINK等，深入了解背后的实现原理，并能够调优。4.良好的思维逻辑性和语言表达能力，以及良好的项目沟通和协调能力。5.具备一定的JAVA、Python语言的开发能力。,金融,2000人以上,hadoop,上海
Python开发工程师-大数据平台,https://www.lagou.com/jobs/7214961.html,浦东新区,15k-25k,上海上湖信息技术有限公司,1-3年,本科,团队年轻发展空间大重视技术大数据平台,"全日制本科以上学历。软件，计算机等相关专业（211,985优先）。扎实的数据结构，算法等基础知识。熟练使用Python，有1年以上django，flask或sanic的开发经验，有高并发场景项目开发经验。熟悉RMDBS，熟练使用MySQL，Oracle。有较强团队协作经验，有使用git等版本控制工具经验。有较强的自我驱动力，快速自主学习能力。责任心强，良好的跨团队合作能力。有金融风控项目工作经验更佳。",金融,2000人以上,hadoop,上海
数据开发工程师（上海）,https://www.lagou.com/jobs/7203009.html,浦东新区,12k-22k,联洋国融（北京）科技有限公司,3-5年,本科,公司有强大背景，稳定 有安全感,岗位职责：1. 负责离线计算任务的部署、资源调度和常态化运行；2. 负责对业务方提交的代码寻找可能存在的性能瓶颈，进行性能优化；3、负责底层数据治理、常规的测试与统计任务等；职位要求：1. 熟悉主流的云计算和大数据产品(Hadoop/Hive/Spark/Flink/Hbase/ES等)，了解kerberos权限认证、调度系统等相关组件；2. 两年及以上数据仓库建模经验，熟悉数据治理、元数据管理、数据质量监控等；3. 掌握spark分布式计算原理，能根据执行计划或pyspark代码分析可能存在的性能瓶颈；对技术怀有强烈热情，有优化的思维和习惯,数据服务,50-150人,hadoop,上海
大数据高级开发工程师,https://www.lagou.com/jobs/7014700.html,浦东新区,45k-60k,善诊（上海）信息技术有限公司,3-5年,本科,空间大，机会多,岗位职责：1、负责数据仓库规划建设，数据处理和开发工作；2、参与大数据平台的数据架构和ETL流程设计；3、参与构建和维护离线/实时计算平台、分布式调度等平台的架构和开发；4、对接产品和业务人员，深入了解业务背景，抽象业务需求，参与数据服务层的设计和开发；岗位要求：1、重点本科及以上学历，3年以上大数据开发经验，1年以上数据仓库工作经验；2、精通Java/Python/Scala等至少一门语言，熟悉Linux/Unix系统；3、熟悉Hadoop、Spark、Hive、HBase、ElasticSearch等相关技术，并有丰富的开发经验；4、熟悉数据仓库的开发流程、数据仓库的建模理论以及数据层级关系，有数据仓库架构设计经验者优先；5、有强烈的技术热情、良好的逻辑分析能力、工作责任感，不是仅仅把技术作为谋生的手段，有良好的团队合作、创新精神；,"移动互联网,医疗丨健康",150-500人,hadoop,上海
数据开发工程师（直播）,https://www.lagou.com/jobs/7004879.html,杨浦区,25k-40k,上海哔哩哔哩科技有限公司,3-5年,本科,大平台 双休,"工作职责：基于对业务的深入理解，实现一系列数据分析模型和相关需求开发支撑。职位要求：1、精通Hadoop/MapReduce/Hive,有一定的hql/sql性能调优经验；2、有日志采集、海量数据处理、数据仓库建模、ETL等经验，熟悉storm、hbase、flume、kafka；3、熟悉Java，有MySQL相关开发经验；4、有较强的业务理解能力，能快速将业务问题转化成具体的技术解决方案;有大型互联网数据分析处理经验优先考虑，有大型日志处理分析优先考虑；5、有数据仓库建设经验者优先。","移动互联网,文娱丨内容",2000人以上,hadoop,上海
数据分析开发工程师（数据挖掘/分析方向）,https://www.lagou.com/jobs/6382612.html,闵行区,25k-40k,上海阑途信息技术有限公司,3-5年,本科,独角兽 大牛云集 临近地铁 多次调薪,岗位职责:1.负责公司大数据挖掘和数据分析工作，分析解读用户数据/运营数据，搭建大数据应用体系；2.负责公司app内流量转化分析和运营，协同算法团队，持续提升转化效果；3.负责用户、门店、车等画像标签挖掘；   工作要求:1.本科以上学历，数学，统计学，计算机，运筹学等相关专业优先；2.熟悉各类数据分析统计方法，并具有一定的解决业务问题的实践经验；3.熟练使用R、Python或SQL等编程工具，了解hadoop及spark等数据计算平台；4.具有较强的数据推理及分析能力、具有较强的执行力及创新能力；5.具有较强的互联网业务分析能力和主动思考意识，可以体系化分解业务问题，并用数据给出合理答案；,汽车丨出行,2000人以上,hadoop,上海
资深大数据开发工程师,https://www.lagou.com/jobs/7140897.html,虹口区,25k-35k,上海维信荟智金融科技有限公司,3-5年,本科,带团队 氛围好,"工作职责：1、基于hadoop/spark平台架构设计及开发工作2、大数据平台的框架设计及核心代码编写3、基于spark Streaming流式计算的设计及开发4、对海量数据进行收集、存储、管理、分析、建模5、对海量用户数据进行统计分析挖掘，不断提升系统系统运行效率6、负责大数据平台的监控及优化，针对持续增长的数据提供相应的解决方案任职资格:1、四年以上开发经验，三年以上大数据开发经验2、扎实的Java/Scala或Python语言基础，可开发高效可利用的代码，了解虚拟机性能优化策略，熟练代码管理工具。3、具有丰富的Spark开发经验4、熟练使用Hive/Impala/Hbase/Kafka/Flume等大数据相关组件,对分布式储存计算有较深入了解5、熟练编写Shell，Sql,具有Sql优化能力6、严密的数学思维、突出的分析和归纳能力、优秀的沟通表达能",金融,2000人以上,hadoop,上海
高级数据开发工程师,https://www.lagou.com/jobs/6725117.html,浦东新区,20k-30k,上海七猫文化传媒有限公司,3-5年,本科,公司发展前景好、岗位空间大、领导nice,"岗位职责：1. 参与七猫大数据系统的基础架构和技术体系的规划建设，包括数据采集平台、数据存储体系、数据质量及稳定性保障体系等；2. 参与数据处理流程的设计、开发和持续优化，包括数据ETL、存储、流批处理和实时查询等；3. 负责大数据平台的后端研发工作，包括后台架构方案的选型、设计和开发，要求开发的系统具有高性能和高可用性。任职要求：1、计算机、通信、数学、统计相关专业本科及以上学历，计算机或相关专业，大数据方向3年（至少2年大数据平台）以上相关工作经验；2、有Java项目开发经验，Java基础扎实，熟悉面向对象和设计模式，熟悉Java开源框架，如Spring、Struts等；3、具备丰富的大型互联网日志采集系统设计或架构经验，具备较扎实的理论基础和工程能力，熟悉HTTP、HTTPS等协议；4. 熟悉Hadoop、Zookeeper、HBase、Hive、Flume、Kafka、Sqoop、Spark、MapReduce、HDFS、Druid等开源项目的原理和使用方法, 并有处理TB级以上数据的项目经验；5、有算法实践经验，能够熟练应用算法做数据特征分析及数据建模的优先，基于大数据平台结合算法有精准营销等数据分析挖掘实际成功案例者优先；6、有较强的沟通表达能力，善于学习，能迅速理解产品需求；有较强的责任心和事业心，有严密的逻辑思维，有追求卓越的精神，能够自我驱动。我们的福利：1、提供免费早餐+午餐补贴+提供加班餐2、定期提供健康体检+免费入职体检3、年假+春节带薪路程假4、五险一金+补充商业医疗保险5、通讯补贴+交通补贴","移动互联网,文娱丨内容",150-500人,hadoop,上海
数据开发工程师（网络金融）,https://www.lagou.com/jobs/7126095.html,浦东新区,12k-22k,交银企业管理服务（上海）有限公司张江高科技园区分公司,5-10年,本科,银行 品牌,主要职责：（一）承担数据需求的分析、开发、测试工作，确保项目进度和质量。（二）参与系统的维护和优化工作，配合各业务方定位数据问题并及时修复处理。 岗位要求：（一）3年以上数据开发经验。对数据处理、数据建模、数据分析等有深刻认识和实战经验。（二）熟悉数据库原理，了解主流数据库产品，熟练运用SQL，掌握MapReduce编程，Shell/Perl等脚本语言，有实际开发经验者优先。（三）具备较强的分析、设计能力，独立思维能力，良好的沟通能力、架构设计表达能力、团队合作能力。乐于沟通、协作，具备高度的自我学习能力。（四）理解银行总体信息科技架构，熟悉银行业务模式者优先。（五）具备过多语种SDK开发经验。(C#、PHP） 有以下架构设计经验优先录用：（一）深刻理解API开放平台的架构设计，如平台组件、应用场景、运营方式、安全控制等，并对业界领先的API开放平台（如淘宝开放平台、微信开发接口）有深入研究或者设计经验。（二）参与设计过中、大型API开放平台架构，并参与研发和落地。（三）理解银行总体信息科技架构，熟悉银行业务模式；具有主动创新意识，对于金融行业API开放意义和模式有充分见解。,"移动互联网,金融",2000人以上,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6688592.html,浦东新区,15k-25k,上海新萌网络科技有限公司,3-5年,本科,"发展平台,扁平化,晋升机会,福利待遇","工作职责：1. 参与/负责数据仓库ETL（数据抽取、加载、清洗、转换）处理任务的设计和开发工作2. 参与/负责数据报表的设计和开发工作3. 参与/支持相关BI业务分析的开发和实施工作注：精通shell，有hadoop大数据环境经验,有使用一些组件的经验sqoop datax hive spark azkaban等。岗位要求：1.掌握数据库基本知识,对数据库内部结构有较深理解和认识2.精通mysql数据库及mysql存储过程,具有数据模型设计的能力3.精通sql语句编写,具有1年以上基于数据库开发的经验4.具备数据挖掘,数据迁移,ETL处理,sql语句优化,海量数据处理的工作经验5.熟悉Linux操作系统常用命令6.工作严谨细致,有责任心,勤奋踏实,善于思考问题,具有团队合作精神，能承受一定的工作压力;7.精通hadoop及相关组件，如:sqoop datax hive spark azkaban。8.有良好的人际关系和沟通能力，有大型项目经验优先；",社交,500-2000人,hadoop,上海
Python数据开发工程师,https://www.lagou.com/jobs/6096855.html,普陀区,15k-30k,上海牛咖信息科技有限公司,3-5年,本科,"领导逗比,氛围欢乐,扁平结构,绩效奖金","岗位职责：1. 参与/负责数据仓库ETL（数据抽取、加载、清洗、转换）处理任务的设计和开发工作；2. 参与/负责数据报表的设计和开发工作；3. 参与/支持相关BI业务分析的开发和实施工作；4. 精通Python/Go开发语言；5. 参与/支持BI后台页面开发;任职要求：1. 计算机、统计学、数学、应用数学相关专业优先；2. 善长多核并行开发;3.掌握数据库基本知识,对数据库底层结构有较深理解和认知；4.善长MongoDB、Mysql、Redis等数据库地使用,具有数据模型设计的能力；5.精通SQL语句编写,并具备优化能力；6.熟悉Linux操作系统常用命令；7.有Hadoop、Spark等海量数据处理工具的工作经验优先；8.有ClickHouse的使用经验优先；9.工作严谨细致,有责任心,勤奋踏实,善于思考问题,具有团队合作精神，能承受一定的工作压力。","移动互联网,社交",150-500人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/7158580.html,浦东新区,20k-40k,美银宝网络信息服务（上海）有限公司,3-5年,本科,外企福利好，发展前景大,"The Data Engineer will be based out of Shanghai office and will support in the development and execution of strategic transformation programs & initiatives, strategic engineering architecture design, resource allocation, and platform performance monitoring.  Ideal candidate is a technologist who believes that use of technology is in its infancy and the best is yet to come. The nature of role is strategic, analytical and highly collaborative, working with team members across the World and as a liaison for Global projects. Responsibilities: ·       Build scalable systems, lead technical discussions, participate in code reviews, guide the team in engineering best practices. Must be able to write quality code and build secure, highly available systems. 75% of the job requires production quality coding.·       Provide technical insights and contribute to the definition, development, integration, test, documentation, and support across multiple platforms ·       Highly detailed with a systematic approach, sense of responsibility and strong, positive customer focus. ·       Must be results focused and highly energetic to drive the defined team and organizational goals·       Establish a consistent, project management framework and development processes to deliver high quality software, in rapid iterations, for business partners in multiple geographies·       Manage a team that designs, develops, troubleshoots and debugs software programs for databases, applications, tools, networks etc.·       Must have demonstrably strong interpersonal and communication skills (both written and verbal), to include speaking clearly and persuasively in positive or negative situations·       Experienced in balancing production platform stability, feature delivery, and retirement of technical debt across a broad landscape of technologies Qualifications:·       Undergraduate degree in Computer Engineering or equivalent from a leading university and preferably with a Masters or MBA·       5+ years of post-college working experience as a developer and architect in Engineering, or Data-Mining organization·       4+ years of Hadoop / ETL experience is required·       4+ years of strong SQL working experience is required·       4+ years of SPARK/HIVE experience is preferred·       2+ years of Linux/Unix/Python coding experience (including scripting) is required·       Strong conceptual and creative problem-solving skills; ability to work with considerable ambiguity; ability to learn new and complex concepts quickly. Relentlessly resourceful and scrappy·       A great communicator, strong project management skills, and superb attention to details·       Mandarin and English speaking mandatory","移动互联网,金融",2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7134451.html,杨浦区,20k-40k,上海跃橙文化传播有限公司,3-5年,本科,Dataworks、大数据集群运维,工作职责:1、大数据平台工具如调度系统、数据质量系统等的开发、维护，大数据基础平台的维护和调优；2、数据埋点系统的开发和维护；3、负责海量数据分析、挖掘、加工、清理、处理程序的开发；1、计算机相关专业，本科及以上学历，3年以上大数据相关工作经验；2、熟悉Linux/Unix系统环境下的操作，熟悉Java、Scala、Python编程语言的一种或多种，至少有3年以上开发使用经验；3、熟悉阿里云集群（MaxCompute、DataWorks）产品及使用调优，有实际操作经验；4、精通Hadoop，Spark，Flink，HBase，Hive，Kafka，Druid等大数据组件的原理和调优，至少有3年以上的运维和开发经验；5、熟悉Flink、Spark Streaming，对于实时计算平台的架构设计有一定的理解，熟悉Flink优先；6、熟悉OLAP、OLTP引擎如Druid、Kylin、Presto，熟悉主流数据整合、治理技术和工具；7、熟悉Spring Boot框架，并能熟练开发后台程序；8、熟悉日志采集系统，对个性化埋点系统有一定经验；,移动互联网,50-150人,hadoop,上海
数据库开发工程师,https://www.lagou.com/jobs/7191940.html,浦东新区,12k-18k,北京联龙博通电子商务技术有限公司,3-5年,本科,餐补 周末双休 五险一金 带薪年假,岗位职责：1、负责具体需求对业务数据进行统计、包括实时和离线数据，在合理时间内生成文本或报表形式的统计结果；2、参与需求分析；3、根据业务需求整合优化数据平台，主动思考不断优化；4、配合团队完成相关任务任职要求：1、需要工作经验3年以上，最好有金融行业项目经验2、熟练掌握SQL语法、窗口函数用法，熟练编写ORACLE或Mysql存储过程3、最好有大数据相关如hadoop、sparksql等基础技能,"移动互联网,电商",2000人以上,hadoop,上海
052191-大数据开发工程师（经纪业务）,https://www.lagou.com/jobs/6019827.html,徐汇区,15k-30k,平安证券股份有限公司,3-5年,本科,"五险一金,绩效奖金,年终分红,定期体检",,金融,2000人以上,hadoop,上海
银行数据仓库开发工程师,https://www.lagou.com/jobs/7216750.html,浦东新区,8k-15k,神州数码融信软件有限公司,1-3年,本科,发展前景,1、具备1-2年以上Oracle数据库开发经验；2、熟练使用Linux操作系统，具有shell、python或者perl脚本开发经验；3、有Java前端项目开发经验者优先；4、熟悉数据OLAP相关技术，对数据处理、数据建模、数据分析等有深刻认识和实战经验5、具有数据仓库、ODS、BI商务智能项目经验者优先，具有金融行业项目背景者优先；6、具有强烈的责任感，良好的沟通和表达能力，优秀的抗压能力。7、熟悉监管报送优先工作职责：1.软件开发版本迭代，代码功能实现。2.配合项目团队开发完成生产环境版本投产。3.能够承担独立模块的开发任务。,金融,2000人以上,hadoop,上海
大数据开发（网络金融）,https://www.lagou.com/jobs/7053412.html,长宁区,30k-45k,交银企业管理服务（上海）有限公司张江高科技园区分公司,5-10年,本科,年终奖，银行，补充医疗，公积金,职责：负责据平台建设项目的管理、需求分析、开发实施及维护和优化，确保数据质量，合理规划给外围系统的数据支持。主要工作：1.         负责大数据平台建设项目的需求分析，设计系统架构和物理数据模型，确保技术方案符合相关要求；2.         制定项目实施计划，跟进监督项目执行，保证项目顺利完成；3.         负责并组织协调大数据平台的运维和变更管理，制定并安排系统扩容，确保系统容量和性能满足业务要求；4.         落实监控源数据结构变更机制，组织源数据变更导致的相关调整工作；5.         负责分析和调研新增源数据的业务、数据和功能，梳理与现有系统数据的关联；6.         负责整合、提炼、规划给外围系统的数据支持，确保提供数据的时效性；7.         制定数据质量跟踪监控机制，确保数据准确、完整、一致；8.         制定大数据平台的技术规范，完善相关技术文档；9.         指导和培训团队成员，组织技术骨干攻克技术难点，提升团队能力。资质要求：1.         统招全日制本科及以上学历，计算机相关专业；2.         数据仓库或大数据相关工作经验3年及以上，具有金融行业、互联网行业大数据实施相关经验优先；3.         熟悉关系型数据库，熟悉数据仓库和ETL；4.         熟练使用Linux系统，熟练掌握JAVA/Scala和SQL等编程语言；；5.         具有基于Hadoop的大数据平台的使用和管理能力，熟悉主要组件及其功能，如Hadoop、MapReduce、Hive、Spark、Flink、kafka及HBase等，具有相关认证者优先；6.         具有较强的逻辑思维能力和独立思考能力，具备高度的自我约束和学习能力，能够承担较大的工作压力和责任；7.         具备较强的计划、组织和沟通协调能力，具备良好的文档撰写能力。,"移动互联网,金融",2000人以上,hadoop,上海
253121-数据开发工程师,https://www.lagou.com/jobs/6934563.html,浦东新区,13k-26k,上海陆家嘴国际金融资产交易市场股份有限公司,应届毕业生,本科,"五险一金,带薪年假,节日福利",,金融,2000人以上,hadoop,上海
高级/资深JAVA开发-实时数据工程师（识货）,https://www.lagou.com/jobs/6732436.html,杨浦区,20k-40k,虎扑（上海）文化传播股份有限公司,3-5年,不限,发展空间广阔、晋升完善、地铁周边、大平台,岗位职责1. 独立完成中小型项目的系统分析、设计，核心功能的设计与代码模板编写，开发与维护系统核心模块；2. 技术难题攻关，持续提升核心系统在高并发、下的高处理性能，保证系统的安全、稳定、快速运行；职位要求1. 三年以上大规模分布式系统应用架构设计与研发经验，扎实的Java编程基础、数据结构和算法，熟悉掌握常用的Java类库及框架，如多线程、并发处理、I/O与网络通讯，Spring、Mybatis等;系统排障经验丰富，可以快速排查定位问题；至少对高并发、分布式、缓存、jvm 调优、序列化、微服务等一个或多个领域有过深入研究，并且有相关实践经验。2. 熟练MySQL应用开发，熟悉数据库原理和常用性能优化技术，熟悉常用中间件的原理、使用场景以及限制2. 具备良好的识别和设计通用框架及模块的能力，具备系统调优、性能调优等技能，对疑难技术问题具备较强的排查能力；3. 熟悉unix/linux操作系统，对常用命令运用娴熟，能够根据实际需要快速编写shell脚本；4. 对技术有激情，喜欢钻研，能快速接受和掌握新技术，有较强的独立、主动的学习能力，良好的沟通表达能力和团队协作能力；5. 熟悉常用的大数据组件，如Hadoop、Hive、ElasticSearch、Kafka、Storm、Spark、Flink等，有过大数据产品开发经验优先；,"移动互联网,文娱丨内容",500-2000人,hadoop,上海
数据库开发工程师,https://www.lagou.com/jobs/7182674.html,长宁区,15k-20k,上海氪信信息技术有限公司,1-3年,本科,人工智能,【岗位职责】1、参与项目实施过程中的数据源分析，从业务逻辑中提炼并计算指标，并能够完成相关的ETL开发；2、参与数据平台的BI工作，包括业务端的数据收集、汇总，以合理且友好的方式输出数据；3、参与其他团队的数据对接工作，包括数据输入、输出，接口的对接等。【岗位要求】1、计算机相关专业毕业，本科及以上学历，2年及以上相关工作经验；2、熟悉数据库查询语言，包括但不限于hive/oracle/mysql等;3、掌握Python等数据分析常用语言的能力;4、较强的逻辑分析能力，思路清晰、思维缜密，有良好的团队合作能力；5、具备数据仓库或管理信息系统ETL和数据可视化开发经验者优先；6、具备大数据Hadoop相关组件(spark/Hive/Kafka等)Hadoop生态知识者优先。,人工智能,50-150人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/7025727.html,静安区,40k-80k,上海知息科技有限公司,3-5年,本科,硅谷风 工程师文化 国际化 精英团队,"Who We AreSmartNews is a leading mobile app of news aggregation services. It analyzes millions of articles to deliver most engaging information with high quality in near-real time fashion to millions of users around the world. The data platform team plays a key role of accelerating the products/business developments by building a highly efficient and flexible data platform for analytical, operational and machine learning purposes. The team mission is to create high-level, easy-to-use data services for simplifying access, integration and consolidation of various data sets, and also to build efficient platforms for executing data pipelines of massive scales of TB per day..ResponsibilitiesDesign and build highly efficient, scalable and secured data platforms as the foundation that can power data driven applications in the domains of data-analytics and AI across the companyDesign and build consolidated and integrated high-level data services to help application-developers and data scientists to leverage data for innovations and decision makingDrive architectural decisions and implementation of Data Platform teamLead cross team/cross functional discussions and drive alignment on technology strategyAble to effectively resolve conflict while navigating complex decisionsDefine the bar for data quality and processing efficiency of data platform/services while balancing business impact, operational overhead and cost benefits of design and architectural choicesLead by example to build a culture of engineering excellence and innovationMinimum QualificationsOver 4 years of experience in highly scalable backend development with 2 years of relevant experiences in data platform/servicesAble to distill complex problems and drive toward creative solutions. Able to have deep end-to-end understanding of sophisticated distributed systems/data pipelines and can proactively detect problems and make/implement improvement suggestionsCan solve challenging engineering problems systematically across different services/platformsCapable of designing high quality frameworks/toolings to reduce redundancy and ineffectiveness across components/servicesAble to demonstrate strong leadership and set as an example at team level for engineering excellenceAble to thrive in a dynamic environment where goals and requirements may be changingStrong coding skills in Java, C++ or PythonExperience with open source data platforms including Hive/Flink/Spark, etcExperience with highly scalable data platform/service (>TB/day level)Preferred QualificationsExperience with open source data platforms including Hive/Flink/Spark, etcExperience with highly scalable data platform/service (>TB/day level)","电商,人工智能",150-500人,hadoop,上海
中级大数据开发工程师,https://www.lagou.com/jobs/7119709.html,浦东新区,15k-20k,世纪怡嘉软件科技有限公司,3-5年,本科,周末双休，年终奖，五险一金，加班补贴,岗位职责：1、根据开发规范与流程完成系统设计、编码、测试以及相关文档的编写；2、负责系统部分核心代码开发、维护; 主流程代码设计、编码工作；3、负责日常联调工作，辅助日常协查工作；任职要求：1、3年以上相关经验，全日制本科学历，计算机相关专业优先；2.技术能力需要会springboot、kafka、zookeeper、redis3.精通基于springboot的应用开发；能够结合大数据技术组建进行一定的数据开发。4.有银行信用卡业务经验优先。,"移动互联网,电商",150-500人,hadoop,上海
Python大数据开发实习生（2021春招）,https://www.lagou.com/jobs/6849245.html,闵行区,6k-8k,上海莉莉丝科技股份有限公司,应届毕业生,本科,"发展空间大,工作氛围好",岗位职责:1、 负责广告数据/投放系统的功能组件研发2、 负责部分广告数据的分析、清洗等工作3、 负责部分广告投放平台接口对接4、 负责与前端以及产品端协作，共同推进项目研发任职资格:1、计算机相关专业本科及以上学历2、熟悉数据结构与算法，基础扎实3、熟悉python flask、django等web至少一种框架4、熟悉至少一种数据库系统，如mysql、postgresql5、熟悉linux操作系统管理，熟练编写脚本6、具备对工作的正向态度、责任心，有较强的学习、沟通与协作能力，能承受一定的工作压力加分项：1、较强的学习理解和沟通能力，有自己的 作品 / 博客 / github 等2、熟练使用 Git3、熟悉hadoop/spark等分布式系统,"移动互联网,游戏",500-2000人,hadoop,上海
资深大数据开发工程师,https://www.lagou.com/jobs/6607837.html,浦东新区,25k-45k,艾欧史密斯（中国）热水器有限公司,不限,本科,薪资高 六险一金 免费零食健身 云存储,"【岗位职责】负责数据集群统一的资源分配和管理；负责大数据实时检索分析平台的开发、建设和优化；基于业务场景，推进批处理、实时流计算框架的研发优化；跟踪开源大数据框架、新算法框架的技术选型及平台化预研及架构。【任职要求】5年以上大数据系统开发，设计，架构经验；精通Java/Scala/Golang中至少一门语言；熟悉大数据相关技术：Hadoop,Hive,HBase,ZooKeeper,Spark,ELK,Kafka，并阅读过相关源码；管理过数据量上T级别，大规模数据集群，开发，优化并管理过上T级别的大数据作业；有机器学习、统计学背景的优先。",其他,2000人以上,hadoop,上海
高级大数据测试开发工程师,https://www.lagou.com/jobs/7150416.html,浦东新区,18k-30k,上海擎创信息技术有限公司,5-10年,本科,智能运维领域的领跑者,岗位职责：1，根据测试工作需求编写测试工具、编写测试用例；2，执行服务端和移动端的功能测试、接口测试、性能测试、自动化测试；3，与产品部门，开发部门工作紧密配合。致力于提高测试覆盖度以保证产品快速高质量上线；4，维护现有的自动化测试框架。任职要求：1、本科及以上学历，英语四级及以上，工作经验5-10年，计算机、通信、电子等相关专业，计算机专业优先；2、有较好的测试思维、主动性。熟悉测试流程，能够独立设计并执行测试用例，保证项目质量和进度；3、了解基本的运维知识和相关linux命令或WEB系统基本通信原理和浏览器基本相关知识；4、拥有一年的大数据性能测试经验；5、熟悉loadrunner、jmeter等性能测试工具；6、熟练掌握SQL语法，对Hadoop、spark、hive有实际经验者优先；7、有代码开发基础，会shell/python/scala/java等语言，做过自动化测试优先；8、有搜索、大数据、分布式系统等业务领域测试开发经验者优先。,"企业服务,数据服务",50-150人,hadoop,上海
大数据开发实习生,https://www.lagou.com/jobs/7101046.html,闵行区,5k-7k,唯品会（中国）有限公司,应届毕业生,本科,"弹性工作,包三餐,大牛带队,转正机会","工作职责负责大数据平台及相关大数据组件的二次开发及维护工作，数仓开发和优化，保证平台各核心服务运行的稳定、高效。任职要求1.本科及以上学历，计算机和电子信息相关专业。2.大数据相关语言有一定基础：SQL，Java，Scala。3.理解大数据相关组件(Spark,Hive,Hadoop等)的优先考虑。4.阅读过相关大数据组件源码的优先考虑。5.熟练应用Linux常用命令，有过shell编程经验。",电商,2000人以上,hadoop,上海
后端开发工程师（侧重数据采集）,https://www.lagou.com/jobs/7196570.html,浦东新区,12k-20k,上海链投信息科技有限公司,1-3年,本科,公司前景好，锻炼机会多，团队氛围好,工作职责：1.根据产品需求，完成通用、业务部件的设计、编码和集成。2.根据业务及产品需求，设计并实现数据采集程序。3.维护数据采集系统，负责系统部署并保障其稳定运行。4.配合业务系统集成相关数据，确保数据正确、规范。5.负责对数据采集系统进行缺陷修复、功能优化。6.负责优化数据采集系统架构，确保其稳定支持业务发展。7.负责数据清洗及处理，制定数据规范，编撰数据字典，为数据特征工程奠定基础8.保持对数据处理技术的调查研究，不断提升自身技术实力。职位要求：1.具备深厚编程功底，熟练运用Windows和Linux。2.精通Java编程，能够独立完成在Windows和Linux上运行的多线程网络程序开发。3.精通数据库和数据结构设计，能够处理数据存取性能问题。4.深刻理解HTTP(S)、HTML、ECMAScript，具有编写互联网爬虫经验。5.精通Selenium，能够熟练运用其特性进行数据采集。6.熟悉WebMagic或其它爬虫工具之一。7.具备数据特征工程知识者优先。8.熟悉某种非关系型数据库，熟悉分布式计算和分布式存储原理优先。,金融,15-50人,hadoop,上海
大数据开发（爬虫类、后端开发类、全栈类）,https://www.lagou.com/jobs/6845342.html,静安区,35k-55k,易得碧计算机技术（上海）有限公司,3-5年,本科,扁平化管理,"岗位职责:负责大数据流水线中的批量处理调度任务和实时流式处理任务的开发；负责大数据应用及相关产品的各类服务开发，并在功能迭代上能够快速输出；研究前沿开发技术，对产品及服务持续改进和优化。任职资格:具有3年以上大数据相关开发经验；熟悉Scala, Java, Python等开发语言之一，精通SQL；熟悉API开发，有Spring、AWS Lamda、AWS API Gateway等开发经验了解大数据组件Hadoop, Hive, Spark, Spark Streaming, Presto, Hbase, Kafka, Zookeeper, Airflow等，熟悉Mysql；了解大数据流水线架构，包括批处理ETL和实时流数据处理；参与过大数据平台产品的开发，包括数据中台、数据仓库、查询分析平台、实时流应用，推荐系统、用户画像、交易系统风控等；有全栈经验者优先（前后端开发、devops）；有爬虫开发经验者优先；良好的分析能力和团队协作能力，积极主动，乐于接受挑战和持续学习，能应对突发应急情况。","金融,软件开发",150-500人,hadoop,上海
前端开发实习生（可转正）-数据产品/可视化,https://www.lagou.com/jobs/6760140.html,闵行区,6k-10k,北京字节跳动科技有限公司,不限,本科,弹性工作,,文娱丨内容,2000人以上,hadoop,上海
高级数据开发,https://www.lagou.com/jobs/7140421.html,浦东新区,15k-25k,北京高伟达钽云科技有限公司,5-10年,大专,"五险一金,补充医疗险，餐补","1.精通关系型数据库Oracle，对SQL查询优化，熟悉PL/SQL,熟悉存储过程、函数、包、触发器等的开发；2.熟悉会计，了解基金公司、上市公司年报；3.熟悉赢时胜估值系统（估值4.5数据结构）；4.熟悉数据建模，完成需求调研分析、数据源梳理、整体设计；5.有良好的团队合作精神，沟通表达能力强，能很好的理解客户需求；6.有至少7年以上岗位工作经验；7.学习能力强，善于总结思考。","移动互联网,电商",2000人以上,hadoop,上海
大数据资深开发,https://www.lagou.com/jobs/7166625.html,闵行区,60k-70k,天寶集團控股有限公司,5-10年,本科,知名企业 持牌公司 全牌照,"本科及以上学历，具备扎实的数学和计算机编程功底；8年以上工作经验，5年以上大数据相关工作经历；
 严密的数据思维，优秀的问题分析能力，热衷技术创新；
 掌握Hadoop，HBase，Hive或Spark等主要大数据技术；具有用户画像及用户管理相关领域大数据开发经验者优先；
 优秀的建模能力，在模型特征提取，模型建立/评估/部署/监控上具有丰富的实践经验；
 具有丰富的大数据商业实战经验，具备企业大数据处理业务场景分析、解决方案实施，综合技术应用经验；具有金融行业大数据相关工作经历者优先；
 具有良好的学习和研发能力，针对大数据技术与应用场景相融合，推动应用研发落地、技术支持与创新；
 有互金公司大数据/风控/模型开发经验优先。","移动互联网,社交",2000人以上,hadoop,上海
大数据开发实习生,https://www.lagou.com/jobs/6842065.html,闵行区,4k-5k,百姓网股份有限公司,应届毕业生,不限,技术成长、mentor优秀、团队氛围好,岗位职责：1. 参与公司核心大数据产品的开发工作；2. 关注大数据领域的新技术，尝试和引进新技术，以持续进化大数据平台的技术架构；3. 基于百姓网大数据平台上开发数据应用，为业务赋能。 任职要求：1. 2021/2022年应届毕业生优先，计算机相关专业，成绩优秀；2. 熟悉Java开发语言，熟练掌握基本的数据结构及算法；3. 有较强的Linux操作能力，熟练使用shell、sql；4. 熟悉Hadoop生态系统的常用组件，掌握Hadoop生态中的一种或几种的大数据技术者优先；5. 具有娴熟的沟通技巧，执行力强，具有优秀的团队合作精神、敬业精神；6. 善于思考，愿意倾听，工作不局限于分配给自己的工作，有较强的自驱力和成长意愿；7. 至少一周可以工作4天，能保证实习至少4个月。,移动互联网,500-2000人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6907417.html,虹口区,10k-20k,怡峰商务咨询（上海）有限公司,1-3年,本科,不加班不加班不加班，零食不断,工作职责1、完成基于数据平台的业务项目的开发、实施和维护工作；2、参与报表开发3、参与数据开发，实时数据及离线数据同步清洗工作；任职资格1、计算机相关专业，本科及以上学历；2、3年以上数据开发相关工作经验，熟悉开源报表工具，如Metabase等；3、熟练掌握SQL语言，掌握MongoDB，PostgreSql等数据库，有一定的SQL调优经验；4、有一定的ETL开发经验，熟悉开源ETL工具，如kettel等；5、至少熟练掌握Shell、Java、Python等编程语言中的两种；6、有一定服务器部署运维经验；7、具备良好的团队合作精神，良好的沟通能力,"社交,消费生活",15-50人,hadoop,上海
高级大数据开发工程师,https://www.lagou.com/jobs/7075116.html,浦东新区,17k-32k,中国电信股份有限公司云计算分公司,3-5年,大专,大数据 人工智能,岗位职责：1、负责大数据基础平台的组件研发与性能优化；2、负责大数据Pass平台、资源调度等容器相关服务的平台研发及应用研发；3、负责大规模数据集群的运维平台开发，包括大规模Hadoop集群的自动化、可视化、一体化部署、运维运营等；4、根据业务需求参与技术预研并推动技术落地。任职资格：1、全日制统招本科及以上学历，计算机类专业优先；2、五年以上软件研发经验，至少两年以上大数据相关系统研发经验；3、有扎实的Java语言基础，熟悉Linux系统，能够熟练使用shell/python/ansible脚本处理工具，具备成熟的调优经验；4、对大数据相关组件如HDFS、YARN、Ambari 、Spark、Hbase、Flink、Hive，Kafka等2至3种组件的架构与底层实现有一定理解；有开源社区参与经验、Kubernetes集群运维经验及相关的源码开发经验优先；5、诚实守信、作风踏实严谨、责任心强；具备良好团队协作能力精神；学习能力强，善于解决复杂问题；6、35周岁（含）以下，身心健康；7、过往工作业绩优秀者、有知名互联网/IT、AI、云服务等相关行业头部企业有工作经验者，年龄、工作年限可适当放宽。,数据服务,500-2000人,hadoop,上海
资深数据库开发,https://www.lagou.com/jobs/5812971.html,浦东新区,8k-15k,上海嘉扬信息系统有限公司,3-5年,大专,五险一金、绩效奖金、年终奖金、员工旅游,【岗位职责】负责EHR项目的实施或运维变更项目，确保运维项目高效运行。1. 负责项目的具体实施或运维和重大变更项目的工作；2. 协助项目经理控制项目进度和质量；3. 为团队成员提供相应的技术指导；【任职要求】1. 专科及以上学历；2 计算机、信息系统管理等相关专业；3 三年以上软件项目实施或运维经验；4 熟练应用SQL Server，Oracle数据库开发，熟练数据库增删改查、写存储过程、函数、触发器、视图等；5 具有良好的质量意识及文档编写能力；6 具备良好的沟通协调能力，团队合作精神，责任心强；7 有同行业实施和维护经验者优先；,移动互联网,150-500人,hadoop,上海
数据库开发/技术支持岗,https://www.lagou.com/jobs/5042576.html,浦东新区,5k-8k,上海嘉扬信息系统有限公司,1-3年,大专,"五险一金,免费班车,员工旅游,交通补贴",【岗位职责】1、负责老客户项目的维护工作；2、做必要的需求收集和分析工作，解决客户在软件使用过程中的各种问题；3、根据客户需求，运用SQL数据库语法，进行系统的二次开发；4、培训甲方公司系统操作人员，使其掌握系统操作方法。【任职要求】1、统招本科学历，计算机相关专业；2、具有良好的SQL Server或Oracle数据库编程基础；3、逻辑分析能力强，善于解决问题；4、具有较强的学习能力和良好的沟通能力；5、工作积极主动、能在压力下工作，具有团队合作精神；6、具有相关ERP等行业软件实施或维护经验优先。,移动互联网,150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7127479.html,闵行区,15k-25k,上海电科电器科技有限公司,3-5年,本科,工业互联网，完善的薪酬福利体系，上市公司,"岗位职责：负责设计、实现和测试工业互联网系统中的大数据分析应用。岗位要求：1、计算机或相关专业，全日制本科及以上学历。2、3年以上Java、Python或Scala软件开发经验。3、熟悉MySQL、Oracle等关系型数据库，及MongoDB、Cassandra等非关系型数据库。4、 熟悉Hadoop、Spark、Flink等大数据组件和数据挖掘工具。5、熟悉Kettle、DataX等ETL工具。6、具备Linux, Windows等操作系统知识。7、了解Subversion, Git, Maven，Jira，Confluence等工具链。8、 高度责任感和团队合作精神。 薪资为平台发布需要，具体以实际面试情况为准！","人工智能,物联网",150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7018906.html,黄浦区,10k-20k,武汉理工数字传播工程有限公司,5-10年,本科,16薪、补充医疗险、节日福利、周末双休,岗位要求：1. 负责各种网络资源数据的采集、清洗、整合和大数据的分布式存储；2. 负责大数据类产品的系统分析与架构设计，配合产品经理完成产品的快速研发与交付；3. 负责大数据平台各组件的性能优化工作和部分设计、开发文档的编写工作；4. 负责大数据项目的开发、维护等工作；5. 负责大数据相关数据架构规划、数据建模、数据库设计以及大数据产品研发工作，并为应用开发团队提供技术支持、模型分析；6. 熟悉Hadoop、Hive 、Spark、Hbase 、Storm、Flume、ElasticSearch、Neo4J、Kafka等框架组件，深刻理解分布式数据处理技术原理；7. 熟练掌握Java、Python、Scala等语言中的一种。岗位职责：1.5年以上相关工作经验；2.参与大数据分布式应用系统服务器端或客户端软件开发工作（需求开发、故障解决和性能优化等）；3.承担建设基于Hadoop/Spark生态的大数据离线/实时处理平台；4.参与业务数据、生产日志的抽取、转储、检索等相关工作；5.跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景。,"移动互联网,电商",150-500人,hadoop,上海
实时大数据开发,https://www.lagou.com/jobs/7002598.html,徐汇区,25k-30k,上海一条网络科技有限公司,3-5年,本科,平台佳 技术大咖,岗位职责：1、负责大数据平台的规划设计，负责spark、flink、hadoop集群的开发、调优、监控；2、负责数据基础架构和数据处理体系（实时和离线）的升级和优化，不断提升系统的稳定性和效率；3、挖掘数据层面的业务价值，开发实现数据相关报表，推动产品、业务优化改进任职要求：1、本科以上学历，计算机或相关专业，2年以上大数据平台工作经验；2、熟练掌握Java或Scala开发；3、熟悉Hadoop平台相关技术原理（Spark、Flink、Kafka、HDFS、Yarn、Hive、Mapreduce等）；4、了解Linux操作系统及常用命令，具备基本的系统运维经验；5、具备线上Hadoop集群运维经验者优先；6、有vertica数据库使用经验，优先考虑7、具备数据仓库领域知识和技能者优先，包括但不局限于：数据建模、元数据管理、数据开发测试工具与方法、数据质量管理；8、具有快速定位问题的能力和较强的学习能力；9、能自我驱动，有较强的沟通能力及团队合作精神，强烈的责任感及进取精神,电商,150-500人,hadoop,上海
数据开发,https://www.lagou.com/jobs/7120233.html,浦东新区,20k-30k,青岛有住信息技术有限公司,3-5年,本科,大平台背景平台,"1、负责基于数据仓库的数据服务的设计及开发;2. 根据公司业务特点，辅助规划业务相关的数据主题模型建模与设计实现:3熟悉数据仓库常用建模理论,熟悉数据仓库的数据分类主题及建模和ETL的开发，根据项目数据应用需求场录，设计合理、高效、准确的数据加工流程与算法；4.根据架构求设计数据仓库各层方案并实现;5、协助制定数据治理规范，建立数据治理的流程、规范和方法;6.负责ETL流程的设计与实现；参与数据廉层能力的工具化，确保数据平台稳定研发及演进岗位要求：全日制统招本科及以上学历;3年及以上相关工作经验，2年以上传统数仓或大数据数仓建设与研发经验:精通Oracle. MySQL等传统关系关系数据库，精通Oracle PL/SQL的开发及调优;精承ktel等开源ETL工具:熟悉Hadoop生态相关技术栈有一定的元数据管理、数据质量管理、调度系统管理经验:熟练学握ava. Scala Python等至少1种语言:有互联网金融传统金融行业数据仓库建设经验者优先;有良好的沟通能力和极强的责任心，有定的工作承压能力。","房产家居,电商",50-150人,hadoop,上海
IT业务分析专员（数据库开发及维护）,https://www.lagou.com/jobs/7108592.html,徐汇区,10k-20k,上海曼伦商贸有限公司,1-3年,本科,**快消品牌电商 公司重点项目,【工作内容】1.负责对业务需求深入理解，制定解决系统方案及相应供应商开发实施工作;2.负责SQL server数据库相关工作的实施和日常运维问题处理；3.负责TM1、Power BI与数据库的对接，数据清洗、传输与维护工作；4.部门要求的其他工作。【任职要求】1.本科以上学历，计算机相关专业；2.具备数据库经验，能够熟练使用SQL；3.熟练使用office（尤其熟练应用excel和ppt）4.有SQL server，Power BI及TM1工作经验优先考虑；5.英语听说读写熟练；6.能适应工作需要的出差；,"电商,消费生活",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6522872.html,静安区,15k-25k,上海晶确科技有限公司,3-5年,本科,弹性工作、下午茶、工作氛围好、发展空间大,"Responsibilities：1、参与大数据平台的研发；2、负责系统设计代码的编写；3、负责海量数据的清洗、处理和挖掘工作，支持数据分析师和算法工程师的数据需求；4、参与维护大数据平台，并能快速高效解决遇到的问题, 保障平台正常稳定运行；5、完成上级交办的其他工作。Requirements：1、3年以上相关工作经验，大学本科以上学历；2、熟悉掌握hadoop、hive、hbase、MapReduce、Flume、Kafaka、Sqoop、Zookeeper，spark core，spark Sql等大数据相关技术；熟悉Kylin等开源项目、性能调优；3、能独立架构大数据系统能力，熟悉Linux操作系统；4、熟悉Linux系统工作；熟悉Python编程，掌握Java/Scala其中至少一种，能够编写脚本解决日常问题，包括自动化的工作流设计；5、熟悉BI项目，具有数据仓库BI系统开发经验，较强的sql能力。综合：1、工作态度积极主动，有一定的抗压能力。2、优秀的自我管理和学习能力，进取心强。3、善于与他人合作，良好的团队合作意识。4、有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题。加分项：熟悉Hadoop生态和常见的开源分布式计算/存储相关技术，包括但不限于Flink，Yarn, Hbase，SparkSQL等。",数据服务,50-150人,hadoop,上海
大数据开发工程师(J10443),https://www.lagou.com/jobs/7028349.html,浦东新区,15k-25k,上海驻云信息科技有限公司,3-5年,本科,超多年假 年终奖 免费零食 做五休二,"工作职责:岗位职责：1、参与数据平台的构建工作,演进现有数据平台基础设施；2、参与数据相关的软件开发工作,迭代现有数据运营工具；3、负责或参与项目开发过程中的技术攻关和性能调优。任职资格:1、全日制统招本科及以上，计算机、通信工程等专业背景优先；2、2年以上的大数据开发经验，熟悉zeppelin flink spark等大数据中间件的使用和部署；3、熟悉虚拟化应用的部署与运维并有实际经验，如k8s/Docker等技术；4、熟练使用shell/python等脚本语言开发相关运维管理工具；5、有算法及数据结构基础者优先。","移动互联网,企业服务",150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7192400.html,浦东新区,15k-30k,卓望数码技术（深圳）有限公司,5-10年,本科,扁平化管理 项目稳定 待遇好,1、基于业务需求之上，进行数据仓库的模型设计，以实现最佳的数据存储和检索、维护2、基于多种来源的海量数据，设计高可靠、高性能的数据采集、清洗、统计计算等解决方案3、与需求方确定需求，把业务需求转为技术要求，对需求开发任务进行分解，管控开发的进度及质量4、参与系统的日常监控维护，及时解决大数据相关应用中的技术问题、数据问题，对应用进行优化改进技能要求：1、熟悉数据仓库系统的建设开发，熟悉数据仓库模型设计、数据架构设计2、熟悉Hive数据仓库应用的开发，能够从模型设计、存储设计、SQL脚本、参数配置等方面对Hive数据处理进行优化；熟悉Hive/Spark/MR的原理，对Hive/Spark/MR运行过程中的问题定位及解决有丰富经验3、了解大数据技术栈，对Hadoop/Hbase/Sqoop/flume/spark/kafka/elasticsearch等技术有部署及应用经验，能够解决应用中的各类问题4、熟悉oracle/mysql/postgresql中的任一数据库，熟悉java/scala/python中的任一编程语言5、熟悉Linux操作系统的使用，了解shell脚本编程6、有一定的英文阅读能力，能够阅读一般的英文技术文档7、有较强的责任心及执行能力，工作认真细致，并具有良好的学习能力、团队沟通与协作能力,"信息安全,数据服务",2000人以上,hadoop,上海
Java开发（大数据方向）,https://www.lagou.com/jobs/6171530.html,浦东新区,14k-28k,瞬联软件科技（北京）有限公司,不限,本科,六险一金 带薪休假 免费体检,我们正在寻找在大规模分布式系统开发、Spring引导、Spring引导批处理框架和作业调度系统方面具有丰富背景和经验的聪明和热情的软件开发人员。 工作职责：构建/实施人工智能产品（如聊天机器人），为平台客户提供支持 与我们的高级开发人员合作，支持团队的产品开发 打造多种工具，促进应用平台的发展  工作要求： 计算机科学或相关技术学科学士、硕士或博士（或同等学历） 非常扎实的Java编程技能（至少2年以上Java编程经验） 具备弹性搜索知识/经验优先 有自然语言处理经验者优先。 熟悉的流行开源框架（如Spring、ZooKeeper、Redis等）。 聪明、快速、主动。,"移动互联网,企业服务",500-2000人,hadoop,上海
数据仓库开发工程师/技术经理,https://www.lagou.com/jobs/7104342.html,静安区,18k-30k,北京九章云极科技有限公司,3-5年,本科,AI行业，Geek氛围，大牛多，技术前沿,"职位要求： 1. 计算机相关专业，3年以上工作经验，有较丰富的数据仓库，熟悉DW/BI项目系统架构和基础知识2. 有一定的ETL项目经验，熟练使用ETL工具之一，如 informatica，Kettle等 3. 熟练常用大数据相关技术如Hadoop、Spark，Scala，丰富的Aliyun数据平台使用经验 4. 有Python,Java等开发经验5. 能够熟悉使用英语沟通6. 有踏实的态度、良好的沟通能力、较强的理解能力、具有团队精神详细要求如下：Must have skillsBS in Computer Science, Statistics, Information Systems or another quantitative fieldExpert understanding of ETL for both on premise and cloud data sources. Ideally have hands-on experience in SQL data integrationSource, profile, track, implement, test and load ETL processes using SQL. Have a superb understanding of data warehousingHave hands-on scripting experience using Python and other open source technologies.Have practical experience integrating system between private data warehouse instance hosted on AliCloudAble to source and connect different data sources to provide a better unified view for accurate analytics solutions and recommendationsExperience running sprints and development end to end (I.e. sourcing raw data, integration to AliCloud, testing and finally creating the insights)Help build ETL packages, data flows and data processes. Solid experience in AliCloud (RDS etc.) and Big Data tools, such as Spark, Hadoop and Scala.Nice to have experiencePrior working experience with AWS - any or all of EC2, S3, EBS, ELB, RDS, EMR, Apache Parquet will be advantageous but not essentialExperience working with DevOps tools such as JIRAData scheduling and orchestration tools like Control M, Oozie, Airflow or others would be advantageousLinux/Unix skills and Exposure to Data Security concepts and best practicesUsing ETL with SSIS, DataStage or InformaticaPersonal characteristics:Great communication skills and able to read/write EnglishLove mathematics and enjoy solving problems",数据服务,150-500人,hadoop,上海
数据仓库开发资深工程师,https://www.lagou.com/jobs/7146741.html,黄浦区,20k-35k,众安在线财产保险股份有限公司,3-5年,本科,"上市公司,互联网保险,六险一金,福利完善","岗位职责：1.负责业务需求,参与业务模块开发，参与数据仓库模型设计，数据仓库脚本开发；2.负责对接业务进行业务数据需求整理，需求开发以及部分业务数据分析3.负责数据采集，任务调度等ETL工作4.有良好的沟通能力，和团队协作能力任职资格：1.要求5年以上工作经验，2年以上互联网/互联网金融的数据开发经验；2.熟悉Linux基本操作命令；3.熟悉Hive sql,有丰富的sql查询优化经验；4.熟悉数据仓库、数据集市模型设计方法论，并有实际模型设计；5.熟练使用Shell/Python/Scala/Flink SQL等语言中的一种者优先考虑；6.有互联网数据研发、海量数据处理分析、OLAP项目开发经验者优先",金融,2000人以上,hadoop,上海
Java开发资深工程师（数据平台部）,https://www.lagou.com/jobs/7146688.html,黄浦区,20k-35k,众安在线财产保险股份有限公司,5-10年,本科,"上市公司,互联网保险,六险一金,福利完善",工作内容：1. 参与数据平台组的项目设计、开发。如 a.车险项目，支持车险定价、核保、续保业务的数据分析、计算。b.数据服务平台项目，负责内外部数据的对接、分发，支持全公司各业务线使用2. 参与新项目的需求分析、讨论，制定技术方案，并推动项目上线岗位要求:1. Java基础扎实，5年以上开发经验，熟练掌握I/O、多线程、Socket编程；对JVM原理有全面的了解。2. 熟练掌握Spring、ibatis等主流的开发框架，精通OO，AOP，设计模式，拥有领域模型抽象能力；3. 熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息等机制；能对分布式常用技术进行合理应用，解决问题；4. 具备高并发、高性能的分布式系统的开发经验，对各种开源的框架及软件（Zookeeper，Redis，Kafka/RocketMq，Nginx）有深入的了解；5. 熟悉互联网微服务架构，如 Dubbo、Spring Cloud，以及 DevOps，在工作中能熟练的使用。6. 对技术有强烈的好奇心和激情，学习能力强,金融,2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6841183.html,浦东新区,15k-25k,上海华钦软件技术有限公司,3-5年,本科,双休，福利待遇好等,1.3年及以上工作经验2.熟练掌握大数据，懂spark和Hadoop3.英语良好4.有金融或银行互联网等相关经验,"金融,企业服务",500-2000人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/2544576.html,浦东新区,20k-40k,上海海知智能科技有限公司,3-5年,本科,人工智能领域最前沿 硅谷技术大牛,岗位职责：1. 负责设计、开发、维护、重构分布式的网络爬虫，包括调度、抓取、维护、验证等爬虫工作；2. 负责抽取算法和数据库建模的调研和设计，保证抽取、去重、分类、解析、增量融合入库等流程之后的数据结果；3. 根据产品的数据需求，调研数据源，给出爬取建议，调研并建立数据模型，优化算法和工作流程。岗位要求1. 计算机相关专业本科以上学历；2. 至少2年以上在Linux服务上做开发的经验，至少1年以上爬虫、搜索、数据库建模的开发经验，熟练掌握Java/Python/C/Go任意编程语言，优先考虑Python；3. 精通爬虫抓取原理及技术，熟悉搜索引擎，精通正则表达式，从结构化的和非结构化的数据中获取信息，有网站开发经历加分，有搜索开发经验加分；4. 熟悉关系型（mysql/postgresql）、非关系型数据库（mongodb/cassandra/hbase/elasticsearch）、缓存数据库（redis/memcached），有过建模和使用经验；5. 具有分布式、多线程/协程/进程的编程经验，有可证明的良好编码习惯，github有个人项目加分；6. 逻辑思维优秀，有良好的沟通能力和语言表达能力。,"移动互联网,数据服务",50-150人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6901229.html,浦东新区,18k-22k,上海盘古餐饮管理有限公司,5-10年,本科,五险一金 双休 带薪年假 员工内部折扣,"1. 负责业务需求,参与业务模块开发，参与数据仓库模型设计，数据仓库脚本开发；2.  负责对接业务进行业务数据需求整理，需求开发以及部分业务数据分析；3.  负责数据采集，任务调度等ETL工作；4、负责对各业务线数据提供可视化BI开发与支持；职位要求：1.  全日制本科/以上学历，计算机或数学相关专业；2. 5年及以上数据开发经验；3. 拥有丰富的离线数仓分层设计和使用经验，具有实时数仓使用经验者更佳；4. 拥有较好的SQL编写和优化能力，且Shell能力尚可；5. 拥有丰富的Hadoop、Spark、Flink等技术栈；6. 至少熟悉一种常用的BI工具；7. 熟悉Java、Scala等多门开发语言，有过Spring boot开发经验者更佳。8. 良好的沟通能力、团队合作精神,优秀的学习能力、分析问题和解决问题的能力。安排远程视频面试，可选择在家办公模式",消费生活,2000人以上,hadoop,上海
Java开发工程师 - 大数据量处理,https://www.lagou.com/jobs/7198797.html,长宁区,20k-30k,泰为信息科技（上海）有限公司,5-10年,本科,国外出差 弹性工作 上市公司,"工作职责/Job Responsibility:1.      参与产品开发管理过程，为创建best product提供专业的建议，2.      团队合作，与同事一起参与产品开发的整个生命周期。包括: 原型，设计，实现。开发出高性能，可扩展，易于维护的数据处理平台。3.      使用敏捷开发方式，协调本地及美国团体，推动产品高质量按时交付。4.      编写高质量的代码，设计文档，单元测试。 职位要求/Requirement:1.      具有计算机相关专业的本科或硕士学位。2.      具有J2SE/J2EE软件设计开发经验(> 4年)。3.      熟练掌握Java, 以及至少掌握以下2种知识技能：大规模数据处理，Spring，Docker开发。4.      精通性能优化相关领域，包括多线程，数据结构，算法，性能优化等5.      具有良好的沟通能力，包括书面英语及口语。6.      具有良好的代码开发风格习惯。7.      具有很强的分析和解决问题能力。自学能力强，能自我激励，态度积极正面，不抱怨。8.      如果具有GIS 工具(QGIS, ArcGIS)相关经验优先考虑。9.      如果具有AWS/Ali cloud经验优先考虑。10.  如果具有Lucene/Solor或其他搜索引擎方面的经验优先考虑。",移动互联网,150-500人,hadoop,上海
资深大数据开发工程师 (MJ000029),https://www.lagou.com/jobs/6654368.html,浦东新区,30k-45k,上海七牛信息技术有限公司,5-10年,本科,六险一金、绩效奖金、弹性工作,"职责描述：1.负责数据集群统一的资源分配和管理；2.负责大数据实时检索分析平台的开发、建设和优化；3.基于业务场景，推进批处理、实时流计算框架的研发优化；4.跟踪开源大数据框架、新算法框架的技术选型及平台化预研及架构。任职要求：1.5年以上大数据系统开发，设计，架构经验；2.精通java;scala;golang中至少一门语言；3.熟悉大数据相关技术：Hadoop, Hive, HBase, ZooKeeper, Spark, ELK, Kafka，并阅读过相关源码；4.管理过数据量上T级别，大规模数据集群，开发，优化并管理过上T级别的大数据作业；5.有机器学习、统计学背景的优先。","移动互联网,数据服务",150-500人,hadoop,上海
大数据开发工程师（高级以上） (MJ000209),https://www.lagou.com/jobs/6991703.html,浦东新区,30k-45k,上海七牛信息技术有限公司,5-10年,本科,弹性工作 绩效奖金 免费健身,"工作内容：负责大数据实时检索分析平台的开发、建设和优化基于业务场景，推进批处理、实时流计算框架的研发优化；跟踪开源大数据框架、新算法框架的技术选型及平台化预研及架构。岗位要求：5年以上大数据系统开发，设计，架构经验精通java/scala/golang中至少一种语言熟悉大数据相关技术：Hadoop, Hive, Spark, FLINK, Kafka，并阅读过相关源码管理过数据量上T级别，大规模数据集群，开发，优化并管理过上T级别的大数据作业。","移动互联网,数据服务",150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/4648083.html,浦东新区,15k-25k,上海浦东发展银行股份有限公司信用卡中心,1-3年,本科,"潜力,高薪",1.计算机及相关专业本科以上学历。2.掌握数据建模语言，并且具有良好的建模能力；熟悉hadoop生态系统，熟练应用hive、spark、hbase、ES等。3.有分布式大数据平台开发经验，对CDH/HDP等大数据集群的应用、运维和调优有相当的经验。4.拥有良好的沟通能力和团队协作能力，勇于接受挑战，自我驱动，具备较强的学习能力、创新应用能力。5.三年及以上海量数据的数据挖掘、机器学习算法建模经验，具有较强的数据整合，数据分析/挖掘和解决业务问题的能力。,金融,2000人以上,hadoop,上海
资深大数据开发工程师,https://www.lagou.com/jobs/6989937.html,徐汇区,25k-40k,上海游昆信息技术有限公司,5-10年,本科,大数据行业 TB级数据存量,岗位职责：1、 负责大数据平台的数据开发工作，能够配合数据分析师在机器学习方面提供支撑；2、 负责数据仓库的数据治理能力平台的设计和开发；3、 跟踪新技术发展，能够引入合适的技术为业务提供服务； 任职要求：1、 计算机相关专业，本科及以上学历；2、 至少具备3年以上大数据开发相关工作经历，以及数据仓库建设经验；3、 熟悉大数据平台生态组件，有TB级及以上大规模数据处理经验；4、 有优秀的 Java/Scala 编码能力，熟悉Hadoop和 Spark 开发，精通SQL；5、 学习能力强，思路清晰，理解力强，自我驱动力强；6、 需要具备良好的团队合作精神，良好的沟通能力； 加分项：1、 有Hadoop、Spark、Hive、HBase深入源代码分析经验；具备机器学习、数据挖掘算法相关经验；,"数据服务,广告营销",150-500人,hadoop,上海
大数据开发（云南出差岗）,https://www.lagou.com/jobs/7113953.html,浦东新区,20k-40k,亮风台（上海）信息科技有限公司,5-10年,本科,五险一金、年终奖、扁平化管理、绩效奖金,"岗位职责：1、负责智慧高速相关项目的需求分析、架构设计、核心框架及组件的编码等开发工作；2. 主要负责对数据平台进行开发，数据优化以及高效率分布式计算；3、能独立完成大数据系统的整体架构设计，开发，维护，数据优化工作。岗位要求：1、25-40岁，计算机、软件、电子、信息、自动化等相关专业，统招本科及以上学历，3年Java工作经验，至少2年以上大数据开发经验；2、熟悉MQ（kafka， rabbitMQ）；熟悉Hbase， 有Hadoop， Spark分布式计算平台开发经验；3、熟悉 Redis， PGSQL, Mysql， 分库分表，读写分离；熟悉Netty，对TCP/IP了解优先；4、掌握Spring MVC， 熟悉Spring Boot，Spring Cloud；","移动互联网,数据服务",150-500人,hadoop,上海
数据库开发工程师,https://www.lagou.com/jobs/6923815.html,浦东新区,10k-18k,深圳市法本信息技术股份有限公司,3-5年,本科,朝九晚六,1.计算机相关专业毕业2.有相关工作经验，从事过数据库开发、数据仓库开发、hadoop大数据开发3.精通SQL应用/SQL性能调优 或 精通HIVE-SQL/SPARK-SQL优化4.思路清晰，能清楚描述工作内容，沟通顺畅5.责任心强，工作积极性高6.按照业务需求，制定完成需求分析及开发，测试任务；7.参与系统需求和架构设计评审，保证系统的稳定性；8.参与开发任务的效果评估；9.解决开发过程中的复杂技术问题；,"企业服务,软件开发",2000人以上,hadoop,上海
大数据开发实习生,https://www.lagou.com/jobs/6774372.html,松江区,3k-5k,上海闵行区青悦环保信息技术服务中心,不限,大专,"有师傅带,实习证明,职业路径多,进步快",职位描述：工作职责:1、协助资深研发工程师参与大数据系统设计和开发；2、负责大数据平台的优化维护、协助进行数据仓库平台的模型设计和开发维护；3、负责后台日常数据统计分析；任职资格:1、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等） ；2、熟悉数据仓库理论与技术，对ETL及BI有概念并具有丰富的实际操作经验，熟悉ETL开发流程； 3、熟悉BI项目，具有数据仓库、BI系统开发经验者优先； 4、熟练操作linux系统，熟悉shell脚本或python； 5、有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题；,数据服务,少于15人,hadoop,上海
JAVA开发工程师（大数据业务）,https://www.lagou.com/jobs/6875144.html,徐汇区,10k-20k,东方财富信息股份有限公司,1-3年,本科,上市公司,,金融,2000人以上,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/7085371.html,黄浦区,10k-15k,上海赫禾汽车服务有限公司,1-3年,本科,mysql，数据库开发,"岗位职责：1、 mysql 数据库的etl开发；2、参与数据仓库架构的设计及开发；3、参与数据仓库etl流程优化及解决etl相关技术问题4、参与公司业务报表开发。近一年无大数据相关项目，非大数据开发岗岗位要求：1、计算机相关专业，本科以上学历，有较好的英文阅读能力；2、良好的团队合作精神，较强的沟通能力和理解能力；3、熟悉主流数据库技术，如mysql、 oracle、sql server等；4、熟练运用SQL实现数据加工处理，及存储过程的编写；  5、精通etl架构，有一定的etl开发经验，了解日常作业的部署和调度；6、至少熟悉一种etl开发工具，如SSIS,datastage,informatica,kettle等；7、熟悉tableau,SSRS，echarts，datav等报表开发工具者优先。",物流丨运输、企业服务,50-150人,hadoop,上海
数据库开发工程师,https://www.lagou.com/jobs/6288130.html,浦东新区,6k-12k,卓沃信息技术（上海）有限公司,1-3年,本科,13薪、团建活动、一年2次加薪机会,岗位职责：1、根据产品需求，进行Oracle数据库存储过程等脚本开发； 2、负责系统功能模块数据库端的代码编写，代码维护工作； 任职要求：1、一年及以上数据库开发经验，了解常用的数据库对象及其作用； 2、熟悉关系型数据库、SQL、存储过程、触发器等；至少熟悉大型数据库Oracle、DB2、Sqlserver其中一种； 3、有ETL设计、数据仓库设计、维度设计、常用前端展现工具、数据挖掘工具者优先考虑； 4、工作认真、负责，有良好的团队合作精神，良好的分析能力与沟通技巧。5、客户全部为大型金融企业，对个人职业发展有极好的帮助。工作地址上海市浦东新区南泉北路1029号19楼,"电商,数据服务",150-500人,hadoop,上海
数据库开发工程师（上海）,https://www.lagou.com/jobs/7187203.html,徐汇区,9k-14k,浙江联保网络技术有限公司,1-3年,本科,五险一金，带薪年假，岗位晋升，项目奖金,岗位职责：1、从事相关软件系统（客户活动分析型系统）的研发工作；2、负责不同数据来源的数据清洗设计开发，数据质量管理、开发工作；3、负责工程相关软件系统数据应用工作。任职要求：1、大学本科及以上学历；态度责任心强；2、两年以上Oracle/MySQL等至少一种关系型数据库开发经验，熟悉SQL性能调优，存储过程的开发工作；3、熟悉至少一门编程语言，比如Java等；4、熟悉ETL过程和工具，有数据仓库/BI相关开发经验者优先。工作地点：上海市徐汇区宜山路700号c3栋203室,"移动互联网,电商",50-150人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6880040.html,徐汇区,13k-18k,深圳市拓保软件有限公司,3-5年,本科,五险一金，年假，年终奖,1、计算机相关专业优先，三年以上开发经验2、至少熟悉一门开发语言，比如：Java、Scala、Shell、Python等3、熟悉 Oracle，熟练掌握常见SQL、NoSQL数据库设计和优化；4、至少熟悉一种数据同步工具，如：KETTLE、DataStage、Sqoop等5、对大数据系统、分布式服务系统有一定了解、有企业大数据服务的互联网从业经历者优先，有健康险或是保险行业BI经验的优先6、熟悉大数据处理相关技术（Hadoop、Hive、Spark、Hbase等）的优先,数据服务,2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7205568.html,虹口区,15k-18k,上海威士顿信息技术股份有限公司,3-5年,本科,智能制造 大项目 稳定成长 烟草行业,"1、掌握数据库Mysql\Oracle\SqlServer，熟练掌握使用常用的SQL语言，并有应用其处理数据经验者；2、熟悉linux操作系统的使用，对常用命令比较熟悉者；职位要求：1、具备扎实的计算机理论基础，对数据结构及算法有较强的功底。2、具有丰富的数据加工处理经验，对数据处理、数据清洗、数据建模、数据分析等有深刻认识和实战经验。3、有时序数据处理开发经验者，如：influxdb，opentsdb。4、精通多线程编程，有分布式开发经验值优先。5、精通使用Python,Spark,Java,Pig等开发，有系统的源码阅读经历，有开源社区开发经验者优先。6、熟悉常用的大数据组件，如：Sqoop、Kafka、Zookeeper、flume、solr、Kylin、ElasticSearch、azkaban、phoenix、StreamSets等。7、有平台搭建和平台优化经验者优先。","移动互联网,企业服务",150-500人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/7160666.html,虹口区,15k-25k,上海豹云网络信息服务有限公司,5-10年,本科,年终奖、平台快速发展,岗位职责：1，负责公司大数据平台开发和实现，包括并不限于离线和实时平台的搭建和实现、数据的调度平台、数据质量和数据安全等。2、负责大数据相关新技术的调研，关注大数据技术发展趋势、研究开源技术、将新技术应用到大数据平台，推动数据平台发展；岗位要求：1、计算机、数学等专业本科及以上学历；具有5年及以上数仓建设和数据平台研发相关工作经验；2、具有扎实的大数据的理论功底，基于Hadoop的大数据体系有深入认识，具备相关产品的理论知识和实践经验（Hadoop、Hive、HBase、Spark、Storm、Flume、Kafka、ES、Kylin等）； 3、有过阿里云MaxComputer、DataWorks等相关经验者优先；4，有程序开发经验，精通一种或多种开发语言，例如Java、Python、Scala等5、自驱力强、优秀的团队意识和沟通能力，对新技术有好奇心，学习能力和主动性强，有钻研精神，充满激情，乐于接受挑战；6、有过互联网公司大数据数仓设计和大数据平台设计和开发工作经验者优先,金融,50-150人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/5434732.html,静安区,10k-16k,上海海万信息科技股份有限公司,3-5年,本科,五险一金，带薪年假，年终奖，旅游节日礼金,1、 使用大数据相关的技术（HIVE，hadoop，hdfs）解决业务相关问题；2、 利用大数据平台实现对数据的分析和处理；3、 负责各类离线系统的业务调研，并与公司其他部门负责沟通协调；4、 负责协助完成离线系统中数据上下层衔接处理工作；5、 负责各类离线系统数据的开发、部署等工作,"移动互联网,金融",500-2000人,hadoop,上海
大数据开发,https://www.lagou.com/jobs/3431632.html,静安区,12k-18k,上海海万信息科技股份有限公司,3-5年,大专,"五险一金,旅游体检,年终奖,过节费",岗位职责：1、 负责大数据业务需求开发；2、 负责大数据平台系统设计和开发；3、 参与数据平台的监控、维护及优化。 基本要求：1、 计算机相关专业本科及以上学历，2年及以上数据开发经验；2、 精通Hadoop相关技术，包括Mapreduce，Hive，Spark，Storm等；3、 熟悉shell，python等至少一种脚本语言使用；4、 对大数据技术和开发有热情，工作认真负责，有较强的学习能力和团队合作意识；5、 有实时计算平台开发或NoSQL工作经验者优先。,"移动互联网,金融",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7214505.html,黄浦区,15k-30k,上海华钦信息科技股份有限公司,3-5年,不限,六险一金，周末双休,1. 2-5 Y big data的工作经验 （大数据+Java）2. 熟悉 hdfs、mapreduce、yarn 等 hadoop 生态体系相关技术。能独立完成集群环境的部署以及 mapreduce 程序的开发。    熟悉Spark 分布式计算框架原理；    熟悉数据库Oracle，能够使用 SQL 进行数据分析及调优；3. 熟悉 Java 语言，可以编程开发；4. 熟悉Linux系统 shell脚步部署；5.本科及以上学历，学信网可查,"数据服务,金融",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6808046.html,浦东新区,18k-25k,上海华钦信息科技股份有限公司,3-5年,本科,15天年假，房贷补贴，六险一金,"职位描述：Key responsibilities :-          Responsible for developing regulatory reporting application.-          Follow instruction from team lead or senior team member to get assigned job done on time with good quality.-          Be able to handle task independently with good patience, clear mind. Qualifications :-          Bachelor or above degree in computer science, information technology, or similar.-          Solid computer science fundamentals in data structure, algorithms.-          2 ~ 5 years of software development experience.-          Solid knowledge of core java.-          Good knowledge on RDBMS like Oracle/MySQL etc, knowing NoSQL like MongoDB is a plus.-          Good knowledge on Spark and also familiar with Spark ecosystem like Hadoop/Impala/Hive etc.-          Have experience in solving data process in big data approach, be able to locate the potential problem, tune performance.-          Good written and verbal communication skills is preferred.","数据服务,金融",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6474375.html,浦东新区,10k-20k,奥解思信息科技（上海）有限公司,1-3年,本科,13薪 全额缴纳社保公积金,主要职责：负责开发监管报告应用程序。遵循团队领导或高级团队成员的指示，按时完成分配的工作，并保持良好的质量。能够独立处理任务，耐心好，头脑清晰。资格：计算机科学、信息技术或类似专业本科以上学历。扎实的计算机科学基础，数据结构，算法。2~5年软件开发经验。扎实的核心Java知识。熟悉Oracle/MySQL等RDBMS，熟悉MongoDB等NoSQL优先。熟悉Hadoop/Impala/Hive等优先考虑。有解决大数据方法中数据处理的经验，能够定位潜在问题，调整性能。英语有良好的书面和口头沟通能力者优先。,金融,500-2000人,hadoop,上海
公共数据-数据开发工程师,https://www.lagou.com/jobs/5878337.html,长宁区,25k-45k,北京三快在线科技有限公司,3-5年,本科,上市公司 核心部门 大牛云集,,消费生活,2000人以上,hadoop,上海
公共数据-前端开发工程师,https://www.lagou.com/jobs/6016172.html,长宁区,25k-40k,北京三快在线科技有限公司,3-5年,本科,上市公司 核心部门 大牛云集,,消费生活,2000人以上,hadoop,上海
数据库开发工程师,https://www.lagou.com/jobs/6754528.html,浦东新区,15k-20k,奥解思信息科技（上海）有限公司,3-5年,本科,外企、六险一金、午晚两餐、快速晋升、薪酬,"1. 根据亚太区业务部门需求，从事大型数据库集群的架构设计、实施、部署和维护； 2. 参与新项目开发过程中数据模型设计； 3. 对相关应用项目的前期分析、方案设计、研究开发、实施应用提供支持； 4. 负责项目开发过程中存储过程、包、函数的编写； 5. 负责数据库相关文档编写。任职要求1. 本科及以上学历；2. 2年以上数据库开发或者ETL相关经验，熟悉Oracle，精通数据库原理和SQL；3. 有大型数仓的设计经验者优先考虑；4. 具备良好的沟通和团队合作能力5. 良好英语沟通能力, 通过大学英语六级优先考虑",金融,500-2000人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6356775.html,浦东新区,15k-25k,上海新萌网络科技有限公司,1-3年,本科,"发展平台,扁平化,晋升机会,福利待遇","工作职责：1. 参与/负责数据仓库ETL（数据抽取、加载、清洗、转换）处理任务的设计和开发工作2. 参与/负责数据报表的设计和开发工作3. 参与/支持相关BI业务分析的开发和实施工作注：精通shell，有hadoop大数据环境经验,有使用一些组件的经验sqoop datax hive spark azkaban等。岗位要求：1.掌握数据库基本知识,对数据库内部结构有较深理解和认识2.精通mysql数据库及mysql存储过程,具有数据模型设计的能力3.精通sql语句编写,具有1年以上基于数据库开发的经验4.具备数据挖掘,数据迁移,ETL处理,sql语句优化,海量数据处理的工作经验5.熟悉Linux操作系统常用命令6.工作严谨细致,有责任心,勤奋踏实,善于思考问题,具有团队合作精神，能承受一定的工作压力;7.精通hadoop及相关组件，如:sqoop datax hive spark azkaban。8.有良好的人际关系和沟通能力，有大型项目经验优先；",社交,500-2000人,hadoop,上海
测试开发实习生-抖音大数据方向（可转正）,https://www.lagou.com/jobs/5687410.html,闵行区,2k-4k,北京字节跳动科技有限公司,应届毕业生,本科,弹性工作，免费三餐，租房补贴，扁平管理,"职位职责：1、负责抖音与火山国际版线上质量数据的分析建模、问题发现、问题归因；2、面向超大规模数据问题，每天处理海量增量数据；3、改进现有工具或开源项目，并推动适合的技术应用于生产；4、指导并带领初级工程师共同完成测试开发任务。职位要求：1、有大数据处理经验，编程能力较好；2、熟悉大数据处理工具/框架中的一项或多项，包括但不限于Hadoop, Mapreduce, Hive, Storm, Spark, Druid, kafka, hbase, canal，ES等；3、有较强的学习能力和抽象能力，有强烈的求知欲、好奇心和进取心，能及时关注和学习业界最新技术；4、对开源社区有过贡献者优先，请在简历上说明。",文娱丨内容,2000人以上,hadoop,上海
高级测试开发工程师-抖音大数据方向,https://www.lagou.com/jobs/5681095.html,闵行区,25k-50k,北京字节跳动科技有限公司,3-5年,本科,六险一金，高薪期权，弹性工作，免费三餐,"职位职责：1、负责抖音与火山国际版线上质量数据的分析建模、问题发现、问题归因；2、面向超大规模数据问题，每天处理海量增量数据；3、改进现有工具或开源项目，并推动适合的技术应用于生产；4、指导并带领初级工程师共同完成测试开发任务。职位要求：1、经验3年以上，学历本科及以上；2、有大数据处理经验，编程能力较好；3、熟悉大数据处理工具/框架中的一项或多项，包括但不限于Hadoop, Mapreduce, Hive, Storm, Spark, Druid, kafka, hbase, canal，ES等；4、有较强的学习能力和抽象能力，有强烈的求知欲、好奇心和进取心，能及时关注和学习业界最新技术；5、对开源社区有过贡献者优先，请在简历上说明。",文娱丨内容,2000人以上,hadoop,上海
大数据开发实习生,https://www.lagou.com/jobs/7216865.html,浦东新区,3k-4k,上海基分文化传播有限公司,应届毕业生,本科,发展空间大,,文娱丨内容,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6978935.html,浦东新区,13k-20k,深圳市博奥特科技有限公司,3-5年,本科,金融项目经验，薪资待遇好,"大数据开发初，中，高3个级别，学信网可查1. 3年大数据工作经验，熟悉hive,spark组件2.数据采集，能快速融入开发任务3.做过Java开发的优先","移动互联网,金融",150-500人,hadoop,上海
高级数据开发工程师（商业化）,https://www.lagou.com/jobs/6292467.html,杨浦区,15k-30k,上海哔哩哔哩科技有限公司,3-5年,本科,团队优秀，大牛多，发展好，前景佳,工作职责：1、广告产品的DMP用户画像平台搭建2、广告产品的商业智能BI系统搭建3、数据产品基础设施的架构、研发、优化职位要求：1、5年以上大数据及分布式计算研发经验，对海量数据、数据仓库技术具有浓厚的兴趣；2、熟悉Oracle 、Mysql等关系型数据库，能独立完成数据仓库结构设计、ETL设计和开发；3、熟悉Hadoop 、Spark、Storm、Flink、Kafka、Redis等分布式计算架构体系；4、熟悉Impala、Druid等实时OLAP大数据查询和分析系统；5、熟悉Linux 环境，熟悉 Shell脚本开发，能进行分布式环境的搭建、日常维护和问题处理；6、热衷开源社区，有开源作品者优先；有优秀技术博客者优先。,"移动互联网,文娱丨内容",2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6841873.html,松江区,15k-30k,海尔集团,3-5年,本科,大平台、稳定性高，薪酬福利完善,职责：大数据平台及产品设计开发，包括数据采集、存储、算法调用、处理、展示，支撑业务场景运用1、负责大数据平台的ETL开发工作；2、数据产品设计及研发，对外接口api数据来源开发；3、数据采集、存储、分析、挖掘、可视化报表等开发；4、参与大数据的设计、开发、部署、自动化运维和数据分析等工作；四、关键能力/经验1、五年以上大数据相关技术：Hadoop/flume/Hive/HBase/ZooKeeper/Spark/MapReduce等经验；2、丰富的数据仓库及数据平台的开发经验，精通数据仓库建模及ETL设计开发；有较为系统的海量数据性能处理经验；3、具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力优先；；4、具备个性化推荐，排名、搜索，机器学习、人工智能等相关工作经验优先；5. 学习能力强，能独立解决问题，善于学习总结,"物联网,电商",2000人以上,hadoop,上海
数据平台java开发工程师,https://www.lagou.com/jobs/6403054.html,长宁区,28k-55k,上海远景科创智能科技有限公司,5-10年,本科,上班弹性 福利好 奖金多 技术好,岗位职责1. 负责数据平台的研发；2. 负责Hadoop/Spark/Hive/Kafka/Flume等组件的性能优化、功能扩展、框架研发；3. 负责开发和优化数据采集、传输、存储、计算、查询等子系统；4. 负责数据产品的需求沟通、系统设计开发以及开源社区新特性调研，促进平台的优化创新；任职资格1. 扎实的计算机基础，熟悉常用的数据结构和算法，熟悉Linux/Unix环境以及常用命令；2. 至少3年的Java开发经验，熟悉多线程、IO、网络编程以及常用的开源框架（如：Struts2、Spring）；,"人工智能,物联网",500-2000人,hadoop,上海
数据平台java开发工程师（TSDB方向）,https://www.lagou.com/jobs/6402184.html,长宁区,30k-55k,上海远景科创智能科技有限公司,5-10年,本科,上班弹性 福利好 奖金多 技术好,岗位职责1. 负责数据平台TSDB方向的研发；2. 负责Hadoop/Spark/Hive/Kafka/Flume等组件的性能优化、功能扩展、框架研发；3. 负责开发和优化数据采集、传输、存储、计算、查询等子系统；4. 负责数据产品的需求沟通、系统设计开发以及开源社区新特性调研，促进平台的优化创新；任职资格1. 扎实的计算机基础，熟悉常用的数据结构和算法，熟悉Linux/Unix环境以及常用命令；2. 至少两年的Java开发经验，熟悉多线程、IO、网络编程以及常用的开源框架（如：Struts2、Spring）。,"人工智能,物联网",500-2000人,hadoop,上海
数据开发高级工程师,https://www.lagou.com/jobs/6966084.html,青浦区,18k-35k,申通快递有限公司,3-5年,本科,发展平台大 包住 晋升机会,1、构建结算业务分析体系，基于体系监测业务发展态势，针对数据表现主动发现业务风险，定位并协助业务解决问题2、通过专项分析，输出专项分析报告，为业务发展提供策略和建议，并可以形成数据分析产品或数据化运营工具3、与相关团队协作进行数据建模工作，推动业务部门的数据化运营1、3-5年工作经验，本科以上学历，有统计学背景或有互联网相关的数据分析工作经验优先；2、精通SQL或其他可视化软件；3、具有至少用一种语言去查询数据的经验；4、具有从数据查询，聚合，分析到可视化的整套实践经验；,消费生活,2000人以上,hadoop,上海
大数据高级开发工程师（推荐系统方向）,https://www.lagou.com/jobs/6627288.html,浦东新区,20k-40k,上海喜马拉雅科技有限公司,3-5年,本科,公司规模大 福利待遇好 晋升空间大,,"移动互联网,文娱丨内容",2000人以上,hadoop,上海
大数据高级开发工程师(J11538),https://www.lagou.com/jobs/6626334.html,浦东新区,20k-40k,上海喜马拉雅科技有限公司,3-5年,本科,公司规模大 福利待遇好 晋升空间大,,"移动互联网,文娱丨内容",2000人以上,hadoop,上海
大数据运维开发,https://www.lagou.com/jobs/6677778.html,虹口区,18k-35k,上海掌小门教育科技有限公司,3-5年,本科,奖金丰厚,岗位职责：1、负责大数据平台自动化运维体系的实施，提升自动化水平；2、负责基于大数据平台的资源、 监控 、 告警、数据等系统的整合3、负责自动化工具编写，提高运维效率和质量；4、协助相关数据平台类工具链的开发、部署及优化迭代；任职要求：1、统招本科及以上学历，计算机相关专业，3年及以上Linux环境下后台开发运维经验，基础知识扎实；2、熟悉数据结构和算法，Python 或 Java 基础扎实，熟悉 Python 或 Java 常见框架，至少熟悉Ansible、SaltStack中的一种自动化运维工具，具有Django，Flask等框架开发经验；3、熟悉 Linux 编程环境和常用的编程，调试工具，具有DevOps系统搭建及开发经验(必须)，包括但不限于自动化运维平台、CMDB、自动发布平台，有基于Python的全栈开发经验尤佳；4、熟悉Hadoop大数据生态圈及各组件的原理，并有实际部署维护经验以及调优经验；包括但不限于HDFS、YARN、Spark、Flink、Druid、HBase、Kerberos、Hive、Zookeeper、Greenplum等；5、学习能力强，喜欢钻研，具有良好的沟通及协调能力，注重团队合作,"移动互联网,教育",2000人以上,hadoop,上海
数据库开发工程师,https://www.lagou.com/jobs/5771670.html,浦东新区,8k-15k,福建顶点软件股份有限公司,1-3年,本科,六险一金、员工旅游、节日福利、生日福利,1、开发和维护基于Oracle数据库的管理系统项目，以支持公司的业务发展；2、负责公司应用数据库的测试，设计、开发、部署、维护和优化，数据库表结构和SQL优化；3、针对用户需求，提出系统解决方案，并负责完成开发工作。职位要求：1、计算机相关专业本科及以上学历，2年以上工作经验，具备一定需求分析经验；2、具有良好的沟通协调能力、团队合作精神以及创新能力，工作执行力强，能按时、高质量地完成工作任务；3、 熟悉Oracle数据库结构，精通PL/SQL，能进行存储过程的开发和优化；4、系统掌握数据库原理和知识，精通SQL语法规则和特点，具备SQL调优实践经验；5、精通Oracle数据库设计，能编写规范的数据库设计文档；6、具有金融行业产品（尤其是TA系统）开发、实施、运维经验的优先考虑；7、具有担任项目经理经历的优先考虑。,"移动互联网,企业服务",500-2000人,hadoop,上海
高级数据开发工程师（上海）,https://www.lagou.com/jobs/7177138.html,浦东新区,15k-25k,北京高伟达钽云科技有限公司,5-10年,大专,优厚的福利,"1.精通关系型数据库Oracle，对SQL查询优化，熟悉PL/SQL,熟悉存储过程、函数、包、触发器等的开发；2.熟悉数据建模，完成需求调研分析、数据源梳理、整体设计；3.有良好的团队合作精神，沟通表达能力强，能很好的理解客户需求；","移动互联网,电商",2000人以上,hadoop,上海
资深大数据开发工程师,https://www.lagou.com/jobs/7196917.html,闵行区,30k-50k,范式云（北京）零售科技有限公司,5-10年,本科,福利齐全，发展空间大,"【岗位职责】1、负责实时、离线大数据应用的设计、重构、优化，主导技术难题攻关；2、负责并参与大数据应用需求分析、功能模块详细设计，完成系统业务功能实现、测试及维护工作；3、参与线上应用系统的环境升级、运维监控、性能调优；4、推动跟进业务线需求，为改善系统的功能积极提出建议。 【岗位要求】1、统招全日制本科以上学历, 计算机专业优先；2、5年以上Java开发经验2、两年以上Hadoop实施及大数据批量或实时处理分析经验，；3、熟悉基于Hadoop的Java开发，熟悉Linux系统，熟悉HBase者优先；4、熟悉各种NoSQL产品,对分布式架构熟悉者优先5、独立的思维能力，乐于沟通、协作，具备高度的自我约束能力、学习能力和表达能力；","企业服务,消费生活",15-50人,hadoop,上海
数据开发工程师（上海）,https://www.lagou.com/jobs/6880002.html,浦东新区,20k-30k,上海淇毓信息科技有限公司,3-5年,本科,上市公司，3-9个月年终奖,职责：1、负责360金融数据中台常规业务数据开发和支持；2、参与对各业务线数据提供可视化BI开发与支持；3、参与部分数据中间件和基础服务的开发与维护；4、与小伙伴们一起实践业界热门组件和技术（Flink、Spark、Clickhouse、Kudu等）.职位要求：1、全日制本科/以上学历，计算机或数学相关专业；2、3年及以上数据开发经验或4年及以上混合开发经验（2年及以上数据）；3、拥有丰富的离线数仓分层设计和使用经验，具有实时数仓使用经验者更佳；4、拥有较好的SQL编写和优化能力，且Ｓhell能力尚可；5、拥有丰富的Hadoop、Spark、Flink等技术栈；6、至少熟悉一种常用的BI工具，熟悉tableau更佳；7、熟悉Java、Scala等多门开发语言，有过Spring  boot开发经验者更佳。,金融,500-2000人,hadoop,上海
数据库开发工程师,https://www.lagou.com/jobs/7084803.html,浦东新区,15k-20k,上海恒生聚源数据服务有限公司,3-5年,本科,发展空间大,1、产品开发。在开发工期内，完成需求开发，并与业务部门协同完成验证、上线，主要我编写存储过程、触发器、函数等2、技术支持，对数据库中因脚本运行产生的数据问题进行定位、排查及解决。3、协助DBA处理数据库性能调优4、大数据相关技术储备，基于Python完成业务逻辑构建。,"金融,数据服务",500-2000人,hadoop,上海
数据仓库开发工程师,https://www.lagou.com/jobs/6260928.html,闵行区,25k-38k,淘宝（中国）软件有限公司,应届毕业生,本科,大平台，知名企业，阿里,"岗位职责:1、理解业务, 并根据业务进行抽象和数仓建模2、对数据质量和数据使用效率负责3、制定和推行数据规范, 持续优化数据质量和相关文档 岗位要求: 1、本科及以上学历, 计算机以及相关专业优先, 至少2 年及以上互联网公司数仓建设经验2、 熟悉 SQL语言, 了解 Hive/SparkSQL/Presto 等运行机制以及体系结构, 有较好的 SQL 性能优化经验3、思路清晰, 对数据敏感4、了解数仓建模理论, 并能够根据实际业务场景进行数仓建模5、熟悉Shell/Python 等至少一门脚本语言6、良好的沟通和团队协作能力, 自我驱动",电商,2000人以上,hadoop,上海
数据开发实习生,https://www.lagou.com/jobs/7126950.html,浦东新区,2k-4k,上海基分文化传播有限公司,应届毕业生,本科,有转正机会；餐补；房补,工作职责：负责数仓模型开发以及日常数据治理职位要求：1. 计算机或者统计学相关专业2. 熟悉hadoop/Hive/Spark工具系统3. 熟练掌握Java/Python等至少一种语言，具备良好的coding习惯和代码风格4. 优秀的逻辑思维能力，强烈的责任心和主动Push能力5. 较好的沟通、学习和自驱能力，积极的工作态度,文娱丨内容,500-2000人,hadoop,上海
java开发工程师（大数据方向）,https://www.lagou.com/jobs/6900999.html,青浦区,14k-25k,上海则一供应链管理有限公司,3-5年,本科,年轻团队 带薪年假 做五休二 法定假日,"岗位职责：1. 负责大数据开发平台建设，构建数据开发、管理和服务的统一平台2. 负责数据的数据仓库建设和数据分析，支持业务场景和应用解决方案开发任职要求1. 计算机或相关专业本科及以上学历，3年以上软件开发经验，精通Java开发。2. 熟练掌握常用的关系型数据库、非关系性数据库和数据仓库，具有SQL性能优化经验；；3. 熟悉Spring、Spring mvc、Spring Boot、mybaits、Struts、hibernate等框架中的一两种或以上 熟悉Redis的开源中间件技术4. 熟悉Jetty、Tomcat、Nginx等应用服务器的配置与运用；5. 了解微服务开发理念、实现技术，熟悉常见设计模式，熟练掌握SSH开发框架，熟悉多线程编程；6. 熟悉Maven项目管理工具SVNGit等其中一种版本管理工具;7. 熟悉Hadoop/Spark/Hive/HBase等大数据工具，对数据处理、数据建模、数据分析等有认识和实战经验,有过大型数据平台建设者优先；8. 思维敏捷，对新技术敏感，有较强的钻研学习能力；9. 具备良好的团队协同、沟通交流及抗压能力，善于独立分析和解决问题。",其他,500-2000人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6912186.html,长宁区,30k-50k,上海寻梦信息技术有限公司,3-5年,本科,公司发展势头良好,岗位职责：1、深入理解流式sql原理及应用场景，并实现完备的流式sql功能；2、负责流式sql查询优化、运行时优化、问题诊断等；3、负责流计算引擎flink的调度优化、执行优化，支撑高吞吐、大状态作业的稳定运行；4、负责实时计算在业务上的应用，如实时多维分析、实时异常监控排查等；5、负责业务线实时数仓的规划、设计以及建设；任职要求：1、本科及以上学历，2年及以上大数据相关开发经验；2、熟悉大数据实时计算生态体系，对hdfs、flink、spark等有深入理解；3、有flink，数据库，sql查询优化，性能优化相关经验者优先；4、具有清晰数据分析思路，有认真的技术态度，积极沟通，懂得团队协作；,"电商,移动互联网",2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7037170.html,浦东新区,20k-35k,平安银行股份有限公司,3-5年,本科,"平台稳定
福利不错",岗位职责：1）根据业务需求实时/批量采集数据、加工处理后落地到公司的大数据平台。2）开发基于公司各类结构化、半结构化、非结构化数据的数据分析和挖掘应用。3）参与公司数据平台建设，持续研发和优化数据平台的各项功能。任职要求：1）本科及以上学历，计算机专业优先，有金融行业从业经验者优先。2）熟悉Linux操作系统并有Shell开发经验，熟悉Oracle MySql等传统的关系型数据库。3）熟悉Java/Scala/Python语言，具有3年及以上开发经验，有Python数据分析、自动化、分布式爬虫开发经验者优先。4）熟悉Hadoop、Hive、Spark等分布式大数据技术，有Spark Streaming、Flink开发经验者优先。5）有较强的逻辑思维能力和创新精神，具备良好的沟通能力和文字表达能力。6）有较强的学习能力，对技术有钻研精神，热衷于新技术的学习和实践。7）有较强的团队合作意识，对工作有热情，能够承受压力、接受挑战。,金融,2000人以上,hadoop,上海
高级数据仓库开发工程师,https://www.lagou.com/jobs/4648122.html,浦东新区,25k-35k,上海浦东发展银行股份有限公司信用卡中心,3-5年,本科,"高薪,大平台",职位描述：工作职责：1、负责公司内部数仓分层逻辑模型的设计、建设与维护，构建可扩展的数据仓库底层模型2、负责公司数据处理流程的优化、定位并解决有关技术问题3、参与制定公司数仓规划、数据研发规范、以及数据治理体系管理方案 岗位要求：1、5年以上数据仓库工作经验，熟悉数据仓库模型设计方法论，有实际搭建公司层级数仓的经验，有互联网公司或者金融企业数仓建设经验优先2、精通数据仓库有关领域知识，例如元数据管理、主数据管理、ETL工作流、SQL性能调优等3、精通SQL、熟悉Shell、具备海量数据加工经验，熟悉Hive/Flink/Spark等开源大数据工具优先4、有较强的问题抽象、概括、总结能力，独立思考并能以产品的思路提出解决方案5、具有较好的沟通理解能力，团队协作和创新能力6、有一定团队管理经验优先。,金融,2000人以上,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6829236.html,闵行区,20k-30k,珠海市万维纵横投资发展有限公司,5-10年,本科,500强,"职位描述： 1、深入理解公司业务与技术架构，参与建设万纬物流数据中台； 2、根据需求，使用已有数据建立完善的指标体系，支撑业务运营与决策，完成数据仓库逻辑建模，为业务部门提供数据支持，输出分析图表或报表； 3、负责数据清洗、加工、分类等数据开发工作，并能根据产品需求完成数据分析、数据挖掘； 4、负责跟产品经理等沟通数据需求，规划梳理落地数据服务产品； 5、使用Java对数据服务及其附属软件平台类产品进行设计和开发； 6、与供应商（OTWB）进行数据对接，接口对接。  任职要求：  必须项： 1.本科及以上学历，数学、统计、物理、计算机等理工科专业毕业，3年以上工作经验，2年以上Java实际开发经验，有扎实的数据库功底； 2.熟练掌握 SQL Server, PostgreSQL, Oracle, Mysql 等任意一种数据库，有优秀的sql编写和优化能力，熟练使用存储过程; 3.熟练掌握主流 ETL 工具中的一种或多种； 4.熟练使用Java，具备良好的编码习惯； 5.有数据仓库开发与维护工作经验（主导或参与）。  加分项： 1.熟悉主流报表平台研发工具，如FinReport，Tablau，PowerBI等数据分析可视化工具； 2.有物流行业软件研发经验者优先； 3.有传统行业数据服务部门工作经验者优先（交通运输、银行、证券等）； 4.对 SQL Server 及其相关产品（SSIS、SSAS、Azure数据服务系列产品等）有深入了解者优先； 5.善于沟通，能够深入了解业务、挖掘业务问题和痛点； 6.思维敏捷，良好的逻辑分析能力及问题解决能力，良好的跨团队沟通及推动能力，强烈的自我驱动意识。",移动互联网,2000人以上,hadoop,上海
大数据应用开发工程师,https://www.lagou.com/jobs/6528181.html,浦东新区,20k-30k,上海浦东发展银行股份有限公司信用卡中心,3-5年,本科,"五险一金,绩效奖金,团队氛围好,稳定平台",工作职责： 负责同算法工程师协作，将基于Python语言、PySpark语言的模型改写成基于Java语言或Scala语言的模型代码，同时完成模型与模型中心的集成部署。任职要求： 1）本科及以上学历，计算机、数学、统计学或相关专业； 2）3年及以上相关岗位工作经验； 3）熟悉机器学习包括LR、GBDT、CNN、RandomForest、XGBoost等算法原理，了解至少一种深度学习框架（例如Tensorflow/Torch/Caffe）及其算法原理。 4）编码能力强，精通Java/Scala其中一门语言，有较强的工程能力；熟悉Hadoop生态或者Spark等分布式处理平台，有大数据处理经验； 5）责任心强、沟通能力佳，乐于技术创新，善于思考，执行能力强。6）有智能运维、风控相关业务领域经验优先,金融,2000人以上,hadoop,上海
数据库开发工程师,https://www.lagou.com/jobs/7160400.html,浦东新区,10k-18k,上海中畅信息科技有限公司,3-5年,本科,大项目 年轻团队 氛围好 活动多,"岗位职责：1、负责数据库产品的开发，按业务逻辑编写SQL(ORACLE、SQLSERVER)。2、参与公司项目数据库架构设计,及相关文档的撰写，数据库备份恢复，同构/异构数据库迁移；3、负责数据库的维护和优化，数据库表结构和SQL优化4、已有生产环境的日常监控，处理相关生产问题。5、根据业务部门需求，编写SQL脚本，从不同数据源，按需从数据库中整合相关数据。6、为业务需求部门提供技术支持，解答相关疑问。7、完成技术文档归档。任职要求：1、本科及以上学历，计算机相关专业毕业，学信网有备案，入职必查（民教网及民信网学历勿扰）；1、3年及以上数据库工作经验；2、熟悉主流数据库oracle，mySQL等关系型数据库，精通oracle数据库；3、精通SQL语句编写与优化，精通存储过程、索引、触发器等使用，熟悉数据库的备份恢复及数据迁移；4、精通数据库性能分析和测试，有数据库优化，存储性能优化的经验；5、具备高度的责任心，工作认真，细致，能承受压力，具备良好的沟通能力、有证券， 金融项目经验优先。","金融,数据服务",50-150人,hadoop,上海
大数据应用开发,https://www.lagou.com/jobs/6569430.html,浦东新区,20k-35k,上海数禾信息科技有限公司,3-5年,本科,行业领先 补充公积金 大牛多 弹性不打卡,"【岗位职责】1、负责实时、离线大数据应用的设计、重构、优化，主导技术难题攻关；2、负责并参与大数据应用需求分析、功能模块详细设计，完成系统业务功能实现、测试及维护工作；3、参与线上应用系统的环境升级、运维监控、性能调优；4、推动跟进业务线需求，为改善系统的功能积极提出建议。 【岗位要求】1、统招全日制本科以上学历, 计算机专业优先；2、5年以上Java开发经验2、两年以上Hadoop实施及大数据批量或实时处理分析经验，；3、熟悉基于Hadoop的Java开发，熟悉Linux系统，熟悉HBase者优先；4、熟悉各种NoSQL产品,对分布式架构熟悉者优先5、独立的思维能力，乐于沟通、协作，具备高度的自我约束能力、学习能力和表达能力；6、有金融行业、互联网行业数据项目实施经验者优先。",金融,500-2000人,hadoop,上海
数仓/数据仓库/ETL高级开发工程师,https://www.lagou.com/jobs/4213328.html,浦东新区,15k-30k,上海数禾信息科技有限公司,3-5年,本科,"移动金融,未来金矿,精英团队,助力成长",数禾科技，上市公司分众传媒（股票代码002027）旗下互联网金融子公司，团队成员来自于招商银行、中国银联、大众点评、群硕科技等知名金融互联网企业。公司致力于成为中国最有影响力的个人/家庭财务管理的科技金融企业，现已面市APP产品包括：还呗－低息代还信用卡，千万用户之选拿铁智投－优质基金理财，智能投资顾问用户量正处于快速增长趋势，详询我司官网或分众传媒旗下楼宇/框架/电影院等广告展示，也可关注微信公众号(huanbei_loan、lattebank)、官网(http://www.lattedata.com)工作职责：1.   熟悉数据仓库体系架构、建模理论和模型设计思路，能用于项目实践。2.  负责数据仓库模型设计和优化，基于Hadoop／Hive／Python参与数据仓库ETL开发工作。岗位要求: 1.   三年以上数据仓库／ETL／数据处理相关开发经验。2.  具备MySQL、Oracle或Hive等主流平台的数据开发及调优经验，熟悉Python优先。3.   具备良好的学习能力，善于沟通，具备较强的业务推动能力和执行力。4.   对技术有激情，对代码有苛刻要求。5.   有良好的快速学习能力和团队协作能力。6.   有产品意识，善于沟通，积极主动，能够以目标为导向理解工作中相关任务的处理优先级关系。,金融,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/5933759.html,徐汇区,20k-40k,上海触乐信息科技有限公司,3-5年,硕士,"10亿用户量,美资上市公司","岗位职责：1、负责ROI模型建立和优化；2、构建数据仓库，服务于用户画像、推荐等系统。3、支持运营、产品对业务上相关的需求，提供数据驱动和决策的能力。4、对用户数据进行高效的ETL，通过数据挖掘构建用户画像。5、核心类数据的可视化展示。6、客户端数据收集的相关工作。 岗位要求：1、 统计、计算机或相关专业的学士学位。2、2年以上的大数据处理、数据挖掘等相关领域的科研/开发经验。3、 熟练使用Linux或者类似POSIX系统。4、熟悉MapReduce, Hadoop, Pig, Spark, HBase, Hive等分布式相关的技术及组件。5、极强的编程能力：熟练掌握Python（Java或者Scala），具备迅速处理复杂的数据和实现复杂的算法的能力。6、很强的自我驱动力、结果导向并极具责任感。7、有激情、毅力，正能量。8、有良好沟通能力和团队协作精神。","移动互联网,数据服务",500-2000人,hadoop,上海
大数据开发工程师（上海）,https://www.lagou.com/jobs/7131308.html,徐汇区,16k-24k,深圳市易博天下科技有限公司,3-5年,本科,双休；五险一金；年终奖金；团队氛围好,1.构建及实施公司BI项目；2. 参与大数据处理系统或应用的设计、开发、维护。  3. 参与大数据相关项目建设，参与架构讨论并推进技术演进和优化；4. 开发数据统计系统，为实时监控、实时运营数据分析、个性化推荐提供数据支持。任职资格：1. 计算机相关专业本科及以上学历，3年以上大数据项目经验。2. 精通Java编程，具备扎实的数据结构与算法功底。3. 熟练掌握Hadoop、Spark、Storm、HBase的原理特性以及适用场景，精通Spark实时计算开发，并具备大规模数据集的实际开发经验。 4. 有大规模数据计算平台的架构设计经验，且精通大规模数据集的存储方案设计优先。 5. 具备用户问题的定位及解决能力，善于归纳总结，对数据敏感。 6. 思维活跃、敢于担当、乐于沟通，具有良好的团队合作精神，积极主动，能承受一定的工作压力。,"移动互联网,消费生活",150-500人,hadoop,上海
数据仓库开发工程师,https://www.lagou.com/jobs/6751989.html,浦东新区,25k-50k,深圳平安综合金融服务有限公司,5-10年,本科,带薪年假，年度旅游、体检,岗位职责： 1、基于分布式大数据平台，支持银行数字化运营战略2、包括但不限于：ETL流程开发、优化、报表设计、作业调度和持续维护、数据模型开发中数据支持任职要求：1、  全日制本科以上学历，计算机、数学、统计等相关专业，3年以上数据仓库开发经验；2、  具有较强的逻辑思维能力、良好的沟通能力、良好的执行能力；3、  精通Oracle、SqlServer、Mysql等主流关系数据库中一种；4、  精通数据仓库的开发和设计，精通数据建模、ETL过程、元数据管理等数据仓库主要环节；5、  能使用Java、Python或其他语言编写MapReduce优先；6、  具有hive性能调优经验优先；7、  有金融、保险、互联网金融等业务背景者优先,金融,2000人以上,hadoop,上海
大数据产品开发工程师,https://www.lagou.com/jobs/7137277.html,杨浦区,15k-30k,优刻得科技股份有限公司,3-5年,不限,互联网行业 福利完善,工作职责：1负责云上大数据产品架构设计与开发2跟踪并解决用户使用产品过程中的问题3.跟踪大数据社区发展动态任职资格：1熟练掌握java开发，熟悉常用的JAVA开源框架（Spring/Spring Boot等）2.熟悉Hadoop/spark/flink/presto/elasticsearch/greenplum/kylin/hbase其中之一的原理、架构和应用3.熟悉一门脚本语言（Shell、Python、JavaScript等）4熟悉Linux开发环境，熟悉常用的命令以及运维工具5.有基于开源的大数据做二次开发经验的优先6.有数据集成/数据开发/数据治理经验的优先,企业服务,500-2000人,hadoop,上海
数据库开发,https://www.lagou.com/jobs/7064873.html,杨浦区,15k-30k,益盟股份有限公司,3-5年,本科,福利待遇好，发展空间大,职位信息1、根据产品需求，进行Sqlserver、Mysql数据库存储过程等脚本开发；2、负责系统功能模块数据库端的代码编写，代码维护工作；3、及时有效处理系统bug；4、负责基于数据仓库的数据服务的设计及开发；5、负责配合开发人员制定项目技术方案开发数据、ETL任务配置.岗位技能要求1、计算机及相关专业专科及其以上学历毕业； 2、3年及以上数据库开发与管理经验；3、熟悉关系型数据库、SQL、存储过程、触发器、索引的应用；4、有金融软件项目经验优先，有一定编程能力（Python/C++/Java等）经验优先；5、工作认真、负责，有良好的团队合作精神，良好的分析能力与沟通技巧。,"金融,移动互联网",500-2000人,hadoop,上海
后端数据开发工程师,https://www.lagou.com/jobs/7029391.html,长宁区,22k-40k,翼健（上海）信息科技有限公司,3-5年,本科,五险一金、商业保险、牛人团队、弹性工作,岗位描述：1. 配合产品经理，参与数据平台发展各阶段产品需求分析和功能设计；2. 基于确定的产品功能需求，参与平台后端系统架构设计、接口定义实现及测试、构建部署和运维等各阶段工作；3. 根据产品或技术实现发展需要，按需进行一些新技术的研究，并评估将其引入现有平台实现的可行性。 任职要求：1. 本科及以上学历，至少3年及以上的实际开发经验；2. 熟练掌握C/C++/Python/Java/Go/Javascript其中至少2种及以上程序设计语言，并且自认为具有良好的编程素养；3. 熟练掌握常用的数据结构及算法；4. 熟悉Linux系统开发，熟悉网络编程、文件系统，有分布式系统开发经验；5. 应具有熟练的技术领域相关的英文文献阅读能力；6. 有良好的沟通能力和团队合作能力，能够自主驱动，具备良好的问题定位分析能力。,医疗丨健康,50-150人,hadoop,上海
资深JAVA开发工程师(大数据开发方向),https://www.lagou.com/jobs/6626360.html,长宁区,20k-40k,携程计算机技术（上海）有限公司,3-5年,本科,五险一金 节假日福利 带薪年假 年终奖,1、 负责大数据相关的应用开发；2、 负责数据仓库工具和服务的开发及优化迭代；3、 参与实时数仓的开发及运维；4、 参与调研开源大数据存储、计算引擎在数据仓库建设和应用的可行性，以及后续的实施落地；5、 参与相关应用trouble shooting及优化。 任职要求：1、本科及以上学历，计算机相关专业，五年以上软件开发工作经验；2、三年以上JAVA开发经验，熟悉设计模式，具备面向对象的设计思路；3、熟悉软件开发流程、体系结构、具备良好的编码风格和文档能力；4、熟悉webservice、Restful、socket、线程、并发等开发知识，有后台框架开发或前端开发经验者优先；5、熟悉主流关系型数据库，具备复杂SQL编写及优化能力，熟悉MongoDB、Hbase等NOSql数据库者优先；6、了解MR、Spark、Flink等计算框架一种或多种，理解内部原理及有生产实践者优先；7、了解Kafka、Presto、HIVE、ElasticSearch等大数据组件中的一种或者多种者优先；8、了解Linux系统，具有一定的运维shell脚本开发能力。,旅游,2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6740508.html,浦东新区,20k-30k,上海蒙玺投资管理有限公司,1-3年,本科,发展前景好、免费班车、上班氛围轻松愉悦,1. 开发数据处理程序，用于清洗整理海量金融数据2. 数据生产环境运维，确保数据生产程序稳定运行3. 与基金经理、策略研究员合作开发辅助工具岗位要求：1. 国内外知名高校计算机或相关专业毕业2. 熟练运用python，有一定Python性能优化经验者加分3. 熟悉MySQL、ORCALE等数据库，有分布式存储经验者加分4. 处理事情细心、有耐心，有良好的沟通技能5. 有良好的团队合作意识,金融,15-50人,hadoop,上海
高级数据开发工程师,https://www.lagou.com/jobs/6749489.html,杨浦区,18k-36k,上海夺汇网络技术有限公司,3-5年,本科,跨境支付B轮企业获奖创新企业,岗位描述：1. 负责核心数据仓库和集市建设，数据ETL的设计、开发与性能优化，负责业务需求的需求理解、数据探查和分析；2. 负责大数据平台的仓库模型设计，数据模型建模 ；3. 建立实时和离线大数据处理流程，整合算法模型进行数据处理。岗位要求：1. 熟悉python或者Java其中一门开发语言，熟悉hive/hadoop等分布式计算技术，熟悉其运行机制和体系结构，有MR作业编写经验优化。2. 灵活运用SQL实现海量数据ETL加工处理 ，有较好的SQL性能调优经验；3. 有一定的数据分析和挖掘能力，能从海量数据提炼核心结果，及时发现和分析其中隐含的变化和问题，有数据分析、挖掘、清洗、建模和BI分析的经验优先；4. 熟悉数据仓库领域知识和技能者优先，包括但不局限于：数据集市设计、元数据管理、数据质量、主数据管理5. 思路清晰，对数据敏感，有良好的沟通表达能力和跨团队协作能力 ；6. 三年及以上数据开发相关经验,"移动互联网,金融",150-500人,hadoop,上海
数据库开发工程师,https://www.lagou.com/jobs/6097590.html,嘉定区,10k-16k,上海派拉软件股份有限公司,3-5年,本科,年终13薪、年度体检、年度旅游、团建,岗位职责：1、主要是编写SQL和存储过程；2、协助开发人员排查相关问题，线上数据运维，数据同步等。职位要求：1.熟悉MySQL、Oracle数据库2.熟悉Linux、Shell、Python3.熟悉Hadoop、Yarn、Spark、Hive、HBase、Datalake等大数据技术4.熟悉阿里云RDS、DRDS、AnalyticDB、MaxCompute、E-MapReduce者优先5.有DBA证书者优先6.三年以上相关工作经验。,数据服务,150-500人,hadoop,上海
前端开发经理（人工智能/大数据/云计算）,https://www.lagou.com/jobs/2740330.html,长宁区,30k-60k,亚信联创科技（中国）有限公司,5-10年,本科,"技术加管理,汇cto,运用新技术,人工智能","工作内容负责公司的前端技术选型及预研；负责公司 web & mobile web 前端产品开发及架构设计工作；负责公司前端技术团队的人员培养；制定团队开发规范，编写易读、易维护、高质量、高效率的代码；review框架代码质量；负责带领团队完成产品/项目的设计与编写，并参与核心程序模块的编写。职位要求4年以上Web前端开发经验，其中至少一年以上技术负责人角色经验；精通HTML/CSS/Javascript,Ajax,React等前端技术，能轻松写出符合W3C标准的模块化代码；熟悉TypeScript优先；熟悉至少一门后端技术（Go优先），对性能优化及浏览器内核有一定研究；具备较强的工作主动性和学习进取精神，技术视野广阔，对业界的发展动态有比较密切的关注；精通前端领域，能结合业务特点提出前后端解决方案；有团队意识,沟通顺畅、责任心强、抗压能力强,有主导前端技术方案设计的能力和经验。","移动互联网,数据服务",2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/5813425.html,黄浦区,20k-30k,华扬联众数字技术股份有限公司西安分公司,3-5年,本科,公司是领域龙头，拥有海量数据，前景广阔。,"职位描述
 数据体系建设，构建强壮高效的数据处理系统
 为业务部门提供在线和离线的数据产品及模型
岗位要求
 计算机相关专业本科以上学历，有良好的计算机专业基础知识；
 具有数据仓库和数据建模的相关经验，熟练掌握至少一种分布式计算框架，如hadoop、spark、flink等，并理解其架构和工作原理；
 熟练掌握Java/Scala/Python中的一种或多种；
 具有良好的沟通和团队协作能力，对技术持有开放的态度和热情
关于公司华扬联众于2017年8月2日在上交所上市，股票代码603825，总部在北京。 华扬联众全国数据技术中心（HDTC）整合了华扬联众核心数据与技术资源，立志为客户与合作方带来更高效，更具竞争优势的数字营销，实现“数据思维创造的行动力”。HDTC目前已经拥有超过80位数据工程师及分析研究人员，并将在新的架构目标中持续加大投入。于西安、南京、上海各地均设有研发中心。主要研发数字广告等相关的技术产品，产品用户覆盖至全国。多条产品线缺开发工程师； 您关心的
 双休；
 六险一金、年底双薪；
 每年一次调薪；
 每年一次出国旅游；
 年度旅游、各种节假日+圣诞节放假；
 十天带薪年假、七天带薪病假；
 结婚津贴、baby津贴、定时电影票等等；
 每月两次公司内部分享培训。","数据服务,文娱丨内容",2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6121631.html,浦东新区,14k-18k,上海海万信息科技股份有限公司,3-5年,本科,"五险一金,体检旅游,年终奖金,节日礼金","岗位职责：1、负责大数据平台数据处理脚本编写、测试、投产；2、负责业务需求的数据分析，数据集市模型设计（维度建模）；3、负责生产问题核查；4、熟悉敏捷开发流程。任职资格：1、3年以上hadoop平台开发经验，精通hive,hbase,熟悉spark；2、两年以上数仓开发经验;3、有crm、客户类数据处理项目实施经验更佳；4、精通shell、java、sql、python等语言。","移动互联网,金融",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/3687206.html,徐汇区,12k-20k,上海海万信息科技股份有限公司,3-5年,本科,"五险一金,年终奖,体检旅游,过节费",技能要求：1. 计算机，统计，信息，数学等相关专业本科及以上学历；2. 熟悉使用SQL，熟悉至少一种数据库软件，如：HIVE、ORACLE、MYSQL等；3. 对数字敏感、有商业意识，能够通过数据发掘有价值的信息；4. 有数据可视化能力，能够制作高效精准的数据图表，有效传递信息；5. 熟悉的分析报告撰写与汇报能力；6. 有ETL开发或数据仓库实施经验者优先。工作职责：1. 负责数据分析体系的规划和建立，通过数据分析对用户进行分层，为产品、运营、风控等部门提供指导意见；2. 负责渠道推广、运营活动的成本及收益分析，计算ROI，并提出优化建议；3. 处理临时性数据分析需求。,"移动互联网,金融",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/5812383.html,浦东新区,15k-30k,上海华钦信息科技股份有限公司,3-5年,本科,"六险一金,最新技术,海量数据,弹性工作","Job Responsibilities· Big data collection, extract, transformation and storage, support business intelligence.· Design and develop big data solutions to help product and business teams to make data driven decisions.· Support end-to-end efforts to design, development and implementation data integration processes.· Has strong programming development background, master of Unix, Python.· Building data processing applications within Hadoop System using Java, Python, Shell or Hive, Spark should be common knowledge to the big data engineer. Requirements:· Bachelor¡¯s Degree in Computer Science or equivalent degree· Good understanding of data warehousing concepts including data modeling, ETL· Knowledge of Hadoop ecosystem open software such as Hive/Spark/HBase/ES· Knowledge of a programming language such as Shell/Python/Java· Demonstrate fast learning ability, have sense to delivery on time· Demonstrate good team work","数据服务,金融",500-2000人,hadoop,上海
大数据开发,https://www.lagou.com/jobs/7184438.html,浦东新区,18k-28k,上海华钦信息科技股份有限公司,3-5年,本科,13薪 六险一金,工作内容：该角色主要负责开发和验证中国的定期和临时监管报告需求。确保及时向监管经理提供数据文件，确保及时向中国监管机构（包括中国人民银行和国家外汇管理局）提交定期报告；提供技术指导，为跨多个平台（Unix、Python、Hadoop、SAP、Teradata、Informatica）提供定义、开发、集成、测试、文档和支持； 人员要求：1. 4Y+ Hadoop 开发工作经验；（根据市场资源分布，2年以上相关经验我们开始推荐。）2. 对数据库Teradata/Oracle/SQL熟练使用应用；    之前项目背景中最好要有支付/财务等项目背景或对财务/支付行业术语有knowledge，如果没有也可以先推荐试试3. 英文读写熟练 能听敢说即可，hiring manager是欧洲人 其他合作的同事是印度和中国人，全程英语面试。,"数据服务,金融",500-2000人,hadoop,上海
到店技术-高级系统开发工程师-数据业务,https://www.lagou.com/jobs/6201169.html,长宁区,30k-45k,北京三快在线科技有限公司,5-10年,本科,丰富的业务场景，专业的团队,,消费生活,2000人以上,hadoop,上海
到店技术-数据开发工程师-到综,https://www.lagou.com/jobs/6972468.html,长宁区,20k-30k,北京三快在线科技有限公司,3-5年,本科,技术成长,,消费生活,2000人以上,hadoop,上海
大数据开发实习生,https://www.lagou.com/jobs/6606452.html,闵行区,8k-10k,北京字节跳动科技有限公司,不限,本科,休闲下午茶,,文娱丨内容,2000人以上,hadoop,上海
数据开发工程师 — 视频会议,https://www.lagou.com/jobs/6695682.html,闵行区,20k-30k,北京字节跳动科技有限公司,1-3年,本科,职业大牛,,文娱丨内容,2000人以上,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/5970494.html,浦东新区,18k-22k,上海浦东发展银行股份有限公司信用卡中心,3-5年,本科,"加班补助,绩效奖金,五险一金,团队氛围好",岗位职责：1、与各业务部门进行沟通，撰写数据加工逻辑的文档；2、根据部门业务以及需求，完成数据的抽取与加工逻辑的开发；3、协助项目组各类数据的汇总和分析 岗位要求：1、2年以上数据相关开发工作经验；2、对数字敏感，具备较强的逻辑思维能力，良好的沟通与创新能力；3、具有良好的洞察力，善于分析和解读数字，并将洞察分析和业务逻辑相结合；4、熟练使用SQL/EXCEL/SPSS/SAS语言中的一种以上;5、有良好的沟通能力，有责任心和团队意识。,金融,2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7023957.html,静安区,18k-25k,上海汉得信息技术股份有限公司,5-10年,本科,做五休二 五险一金,"1. 5年以上大数据相关工作经验，本科或以上学历2. 熟悉Linux，精通Java/Scala开发语言3. 精通/Flink or Spark Streaming/Pulsar or Kafka/, 熟悉大数据技术栈如/ZooKeeper/Flume/Hive/HDFS/Spark/Redis4. 对性能调优，算法效率和分布式计算的资源管理机制有较深的理解5. 熟悉并行计算或者分布式计算原理，了解高并发、高稳定性、可线性扩展、海量数据的系统特点和技术方案6. 有至少一个完整端到端的基于实时分布式消息的实时计算建设经验7. 熟悉常用数据库中的一种，如SQLServer/MySQL/Oracle8. 对零售行业有经验者优先9. 具备良好的沟通能力、快速学习能力、有责任心、工作积极主动，具有团队协作能力","企业服务,数据服务",2000人以上,hadoop,上海
数据中台开发总监/经理,https://www.lagou.com/jobs/7159029.html,松江区,30k-50k,云汉芯城（上海）互联网科技股份有限公司,5-10年,本科,公司已盈利 晋升机制完善 加班少,岗位职责：1.负责公司的数据中台战略的落地，负责数据中台产品、服务的技术规划、架构及落地实现；2.负责中台数据治理、建模、架构，支撑数据在多业务场景的应用；3.负责项目的分析、技术设计和技术选型，带领团队保质保量完成项目；4.理解公司整体业务，分解数据中台战略规划，能够有效结合业务，持续完善数据服务体系，解决业务问题；5、完成上级交付的其他工作；6、遵守公司规章制度以及相关法律法规。任职资格：1.本科及以上学历，计算机或相关专业；2.有过数据中台建设经验，熟悉数据中台规划，有相关的思维体系；3.熟悉数据仓库模型设计，熟悉数据建模，有实战经验；4.有大数据处理经验，熟悉Hodoop生态技术；5.精通Python、PHP语言，熟悉Go语言；6.沟通能力强，积极、正直，业务敏感，服务意识强，做事结果导向；,电商,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6763486.html,杨浦区,30k-40k,千寻位置网络有限公司,3-5年,不限,补充医疗 补充公积金 16薪,岗位职责：1. 负责运维监控大数据计算平台研发：架构和服务设计、业务开发、性能优化和成本管理等工作；2. 负责公司产品线服务可用率体系的处理逻辑开发、优化、自动化和品质维护等工作；3. 负责海量监控数据的处理以及挖掘的研发工作；4. 负责基于公司业务数据设计和开发排障分析平台。 任职条件：1.熟练掌握Java语言，对函数式编程范式或语言（如Scala，Haskell等）有较深的理解和实践者优先考虑；2. 熟悉常用的大数据处理框架，如Spark/Flink，有阿里云大数据产品使用优先考虑；3. 对分布式/高并发系统的设计与实现有较强的理解，有相关项目经验者优先考虑；4. 熟练掌握NoSQL数据库，消息队列，负载均衡等技术；5. 对时序数据处理有相关项目经验；,移动互联网,500-2000人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6843923.html,,25k-30k,海尔集团,不限,本科,10002,,"物联网,电商",2000人以上,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6331439.html,闵行区,18k-30k,上海易路软件有限公司,3-5年,本科,弹性工作，高薪绩效，带薪年假，股权激励,"1、负责公司数据仓库及数据集市搭建； 2、搭建HR领域数据平台、数据产品、数据服务开发； 3、使用Tableau，Finereport 等进行数据类报表开发，为公司数据可视化产品的设计提供建议； 4、支持建设线上数据产品。岗位要求：1、计算机或相关专业本科及以上学历，有2年以上数据仓库开发经验； 2、熟悉 ETL 数据处理流程以及ETL的调度部署，熟练使用 DataX、Kettle 等主流ETL工具； 3、熟练掌握Python、Scala、Java 之一； 4、熟练使用 Tableau, Finereport, Cognos 等一种前端展现工具，能够独立完成报表任务开发； 5、精通 Postgresql、MySQL、HBase 等数据库，熟悉海量数据处理及性能优化； 6、有人力资源业务数据处理经验者优先。","移动互联网,企业服务",150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7178068.html,虹口区,20k-35k,威比网络科技（上海）有限公司,3-5年,本科,大平台，福利待遇好，发展空间大,"工作职责：1、数据仓库开发，主要是根据实际业务需要开发spark，flink，hive等；任职要求： 1、3-5年相关经验，具备实时处理框架的设计和开发能力，熟练掌握Storm、Spark streaming,flink 等大数据实时处理框架中的一种;2、熟悉Spark 、Flink、Hadoop、Hbase、Hive等相关技术;3、熟悉Scala,Java,python、熟悉Linux开发环境，能进行shell脚本的编写;4、熟悉数据仓库开发流程;5、具有较强的逻辑分析能力,擅长跨部门沟通协调能力。6、具有实际大数据项目的成功经验者优先考虑","移动互联网,教育",2000人以上,hadoop,上海
大数据开发工程师（Java/golang）,https://www.lagou.com/jobs/7050899.html,虹口区,20k-30k,拉勾猎头,3-5年,本科,发展稳定,"岗位职责：  1.承担领导交付的任务，负责带领工程小组针对需求进行设计及开发； 2.研究及追踪技术演进，并带领小组进行技术尝试；  3.参与管理各项技术框架及设计。大数据衍生平台开发与维护；  数据可视化系统开发与设计；  与数据仓库对接的元数据管理系统、业务系统开发﻿ 任职要求： 1. 4年以上工作经验，本科及以上学历，计算机/软件相关专业优先； 2. 工作积极主动、耐心细心，能承受一定的工作压力，有很好的学习能力及强烈的责任心和团队合作的精神； 3. 有ELK技术栈、Kafka、列式存储或Zookeeper的开发经验加分； 4. 态度良好，不排斥提携后进者，有大数据平台Java开发经验最佳； 5. 熟悉设计模式、范型、数据结构及主要排序算法,具有热诚，能主动参与技术项目； 6. 熟悉主流后端开发框架优先，如Spring、Hibernate或MyBatis等技术； 7. 熟悉主流数据库技术，如MySQL/PostgreSQL/Oracle等，有SQL调优经验优先，有NoSQL应用经验优先。","移动互联网,企业服务",500-2000人,hadoop,上海
bi数据库开发,https://www.lagou.com/jobs/6643278.html,浦东新区,13k-20k,深圳市博奥特科技有限公司,3-5年,本科,五险一金，国定假日带薪休假，每月下午茶等,16年前统招本科毕业，必须学信网可查真实学历，双证齐全。1，熟练使用SQL进行数据库查询，以及开发ETL程序。 2.掌握Hive/Oracle/Mysql/Sqlserver等至少一种关系型数据库。 3.会一种报表工具优先，Tableau优先，熟悉数据分析工具，Python优先 4.有较强的学习能力，性格活泼开朗，可塑性强 5.可以和客户和业务人员进行良好的沟通,"移动互联网,金融",150-500人,hadoop,上海
大数据开发工程师n,https://www.lagou.com/jobs/7198997.html,杨浦区,20k-30k,上海妙克信息科技有限公司,3-5年,本科,工作有趣，有挑战，有成就感,1.负责大数据实时流计算的任务开发。2.基于实时流计算的语言，如flink、flinkSQL、spark、sparkstreaming等的开发。任职要求：1.精通flink、spark等实时流计算语言，有实际开发经验。2.熟悉各介质开发特性，如binlog介质canal、maxwell；消息队列kafka、MQ等;3.熟悉各数据存储介质，如hdfs、kudu、mysql等。4.良好团队协作和沟通能力;5.3年及以上实时流开发经验,"移动互联网,教育",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7128898.html,浦东新区,14k-18k,上海易苏信息科技有限公司,3-5年,本科,派驻在**的正泰研究院，长期稳定,"大数据软件工程师（工业物联网）此职位派驻在**的正泰研究院，长期稳定负责设计、实现和测试工业互联网系统中的大数据分析应用。基本要求：l  计算机或相关专业，全日制本科及以上学历。l  3年以上Java、Python或Scala软件开发经验。l  熟悉MySQL、Oracle等关系型数据库，及MongoDB、Cassandra等非关系型数据库。l  熟悉Hadoop、Spark、Flink等大数据组件和数据挖掘工具。l  熟悉Kettle、DataX等ETL工具。l  具备Linux, Windows等操作系统知识。l  了解Subversion, Git, Maven，Jira，Confluence等工具链。l  高度责任感和团队合作精神。","移动互联网,企业服务",50-150人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6424839.html,浦东新区,18k-20k,奥解思信息科技（上海）有限公司,3-5年,本科,弹性工时 年底奖金 晋升空间,"Key responsibilities :- Responsible for developing regulatory reporting application.- Follow instruction from team lead or senior team member to get assigned job done on time with good quality.- Be able to handle task independently with good patience, clear mind.Qualifications :- Bachelor or above degree in computer science, information technology, or similar.- Solid computer science fundamentals in data structure, algorithms.- 2 ~ 5 years of software development experience.- Solid knowledge of core java.- Good knowledge on RDBMS like Oracle/MySQL etc, knowing NoSQL like MongoDB is a plus.- Good knowledge on Spark and also familiar with Spark ecosystem like Hadoop/Impala/Hive etc.- Have experience in solving data process in big data approach, be able to locate the potential problem, tune performance.- Good written and verbal communication skills is preferred.",金融,500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/5866564.html,浦东新区,16k-20k,上海海万信息科技股份有限公司,3-5年,本科,"节日礼金,五险一金,体检旅游,年底双薪",岗位职责：    1、基于Oracle或大数据平台环境进行数据开发，可根据需求分析说明书、设计说明书完成数据仓库中间层、数据集市等开发，具备协同开发能力；2、负责与用户沟通、澄清需求，验证底层数据，编写需求和设计文档；3、根据业务进行数据仓库建设，保证指标口径的统一完善；4、与团队形成良好沟通，有效传达设计意图，并持续跟进设计的调整和优化                                                                               任职资格：1、本科及以上学历，计算机相关专业，3年及以上数据开发工作经验； 2、3年及以上企业级数据仓库设计、开发经验，深入了解数据仓库设计理念及建模方法；3、熟悉hadoop生态圈常用技术及底层原理，精通hive sql开发和调优；4、熟练使用oracle或mysql等关系型数据库，有sql和存储过程开发及其调优经验，5、熟悉ETL开发流程、熟悉主流的ETL和BI工具；6、思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力,"移动互联网,金融",500-2000人,hadoop,上海
大数据开发,https://www.lagou.com/jobs/5886975.html,浦东新区,12k-20k,上海海万信息科技股份有限公司,3-5年,不限,"五险一金,过节福利,生日礼金,旅游、体检",大数据应用开发1：2年以上数据开发经验，有金融项目经验者优先2：掌握hadoop，yarn的基本原理3：掌握hive，spark，sparksql的基本原理                      4：熟练使用azkaban/ozzie调度平台或其他                      5：熟悉使用sqoop，datax等ETL工具                        6：有良好的编码习惯                                                   大数据组件开发 1：1年以上javawab开发经验，2年以上大数据开发经验   2：掌握hadoop，yarn的基本原理                               3：掌握hbase，es，redis的基本原理                          4：掌握kafka，zookeeper的基本原理                            5：熟练使用sqoop，datax等ETL工具                            6：有良好的编码习惯,"移动互联网,金融",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7199268.html,浦东新区,17k-21k,上海华钦信息科技股份有限公司,3-5年,本科,六险一金 十三薪,工作年限：2-4Y技能要求：1.  熟悉 hdfs、mapreduce、yarn 等 hadoop 生态体系相关技术。能独立完成集群环境的部署以及 mapreduce 程序的开发。2. 熟悉Spark 分布式计算框架原理和编程模型，zookeeper 分布式协调服务的使用。3. 熟悉Hbase， Hive 的原理，使用和性能优化策略，能够使用 SQL 进行数据分析及调优。4. 熟悉 Java or scala 语言，可以编程开发。5. 可独自完成 spark 集群环境搭建，了解 spark 核心源码实现，对 Spark-Streaming 以及 spark-Sql 有一定的了解与使用经验。 6. 熟悉Linux 系统， 使用shell完成大数据一键部署。英语读写熟练 听说不作要求,"数据服务,金融",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7117390.html,浦东新区,20k-30k,上海华钦信息科技股份有限公司,3-5年,本科,十三薪。六险一金 十四天带薪年假,1. 3-5 Y big data的工作经验2. 熟悉 hdfs、mapreduce、yarn 等 hadoop 生态体系相关技术。能独立完成集群环境的部署以及 mapreduce 程序的开发。    熟悉Spark 分布式计算框架原理；    熟悉数据库Oracle，能够使用 SQL 进行数据分析及调优；3. 熟悉 Java 语言，可以编程开发；4. 熟悉Linux系统 shell脚步部署；5. 英文流利，hiring manager是印度人 其他合作的同事都是外国人,"数据服务,金融",500-2000人,hadoop,上海
数据开发,https://www.lagou.com/jobs/6567399.html,长宁区,25k-50k,北京三快在线科技有限公司,3-5年,本科,大平台， 股票，带薪年假,,消费生活,2000人以上,hadoop,上海
金融数据产品开发,https://www.lagou.com/jobs/6921074.html,浦东新区,1k-2k,弘则弥道（上海）投资咨询有限公司,应届毕业生,本科,发展前景,岗位职责：1. 负责弘则研究金融大数据产品的后端开发/前端开发；2. 能用应用技术，持续改进优化现有产品，打造一流的金融数据产品；3. 负责文档编写，调试以及测试。任职要求：1. 本科以上学历，计算机相关专业；2. 熟悉Python语言开发，熟悉pandas，能够熟练编写数据处理相关程序；3. 熟悉MySQL，熟练使用SQL操作数据库，能够编写较为复杂的查询语句；4. 熟悉Django等python  web框架；5. 熟悉HTML CSS Javascript 能够编写体验较为丰富的前端页面；6. 熟悉Vue，react等前端框架，有交互式图表经验者优先。,"移动互联网,金融",50-150人,hadoop,上海
Java大数据开发,https://www.lagou.com/jobs/3819377.html,浦东新区,25k-50k,支付宝（杭州）信息技术有限公司,不限,硕士,"大数据,互联网金融",我们作为蚂蚁数据技术平台部，需要面对全蚂蚁的数据问题，迎接每天P级别的数据处理；同时需要提供低延时，高可用的数据服务。岗位描述：1、负责系统实施，推进大数据数据处理和机器学习预测落地，用于保障蚂蚁全系统的资金安全和高可用等领域； 2、独立完成大型项目的系统分析设计，并负责核心模块研发； 负责完成系统Code Review的任务，确保相关代码的有效性和正确性，并能够通过Code Review提供相关性能以及安全的建议； 3、参与低延时大数据实时计算系统建设，提供工程保证，并可以对具体算法提供建议； 4、对业界在机器学习和数据挖掘等领域有一定预判，促进团队在数据收集的基础上，落实数据智能化分析。岗位要求：1、有强烈的技术热情，工作责任感； 2、有创新精神，乐于和热于技术钻研。思维严谨，逻辑清晰，具备批判性思维能力和习惯； 3、具备扎实的计算机专业基础，包括算法和数据结构、操作系统、计算机体系结构、计算机网络、数据库等； 4、扎实的Java/C/C++基础，良好的编程素养，对代码美感有追求，有一定的分布式开发调试经验；5、熟悉Hadoop/Map-Reduce/MPI/Spark分布式计算框架，熟悉spark streaming、sklearn、tensorflow等优先，对实时计算框架spark/flink有调优经验，且有海量数据处理经验优先；,"金融,移动互联网",2000人以上,hadoop,上海
资深JAVA开发（有数据开发能力）,https://www.lagou.com/jobs/6941332.html,浦东新区,30k-50k,连尚（北京）网络科技有限公司,5-10年,不限,"弹性工作,技术驱动,福利待遇好","【岗位职责】1、负责内部产品的功能规划、需求分析设计、技术实现和用户体验；2、负责所属模块的代码开发、调试与维护工作；3、积极响应客户需求并进行开发/定制化开发和交付；4、参与公司产品的架构优化，性能优化并辅助其他模块进行技术实现；5、完成其他各类技术开发任务。【岗位要求】1、3年以上Java开发经验，Java基础扎实，熟练掌握数据结构、java动态代理、反射、多线程等相关技术，掌握常用的设计模式，编码认真严谨规范；2、熟悉使用Spring、SpringBoot、Mybatis、dubbo、motan、zookeeper等开源框架；3、熟悉分布式、缓存、消息等机制；熟悉redis, mongodb,hbase,ES等主流NOSQL存储开源项目；4、熟悉至少一种常用数据库的应用开发，如Oracle、Sql Server、MySQL；5、有一定的linux基础，能够熟练使用linux常用工具及命令；6、熟悉常用的RabbitMQ、ActiveMQ、kafka、redis等消息中间件技术；7、熟悉HDP或CDH相关生态，对Hadoop/Hive/Hdfs/Yarn/Tez/Kafka等有较深的认识, 熟悉大数据架构（Spark，Hbase，Flume，ElasticSearch，Druid等）及解决方案，并有实际工作经验者优先；","移动互联网,消费生活",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/7011983.html,浦东新区,15k-25k,上海南天电脑系统有限公司,3-5年,本科,节日福利、午饭补贴、年度旅游、年度体检,1、在线、离线、流处理等大数据场景应用设计2、结合业务流程建模、进行数据统计分析场景的方案设计与架构调优3、参与核心模块研发，大数据平台的搭建，系统调试、集成与实施4、建立和维护大数据平台技术标准规范，指导开发人员编写、优化相关代码任职资格: 1、正规大学本科以上学历，3年以上的大数据相关研发或者架构经验。 2、对海量数据传输、存储、计算相关技术有深刻理解，精通大数据技术架构开发、搭建、维护以及调优3、具备基于Hadoop分布式计算框架（HDFS、MR、Hive、Kafka、Storm、Spark、Flink等）的应用架构设计与研发经验，务必熟悉JStorm4、具备CDH或华为FusionInsight等大数据平台实际项目经验 5、熟悉mysql/oracle等关系型数据库开发或运维、优化的优先考虑6、熟悉logstash/flume、elasticsearch、HBase、OpenTSDB等大数据采集和存储分析工具的优先考虑，务必熟悉OpenTSDB、elasticsearch其中一种 7、熟悉zookeeper/redis等分布式协调和nosql数据库的使用优先考虑8、熟悉Linux/Unix系统，精通至少一门编程语言Java/Shell/Python/Scala/C++等9、有较强的沟通、团队协作及学习能力。,"数据服务,移动互联网",500-2000人,hadoop,上海
数据开发工程师（网络金融）,https://www.lagou.com/jobs/7051411.html,浦东新区,12k-24k,交银企业管理服务（上海）有限公司张江高科技园区分公司,5-10年,本科,"周末双休,交通补助,餐补",岗位职责：（一）承担数据需求的分析、开发、测试工作，确保项目进度和质量。（二）参与系统的维护和优化工作，配合各业务方定位数据问题并及时修复处理。岗位要求：（一）本科及以上学历，3年以上数据开发经验。对数据处理、数据建模、数据分析等有深刻认识和实战经验。（二）熟悉数据库原理，了解主流数据库产品，熟练运用SQL，掌握MapReduce编程，Shell/Perl等脚本语言，有实际开发经验者优先。（三）具备较强的分析、设计能力，独立思维能力，良好的沟通能力、架构设计表达能力、团队合作能力。乐于沟通、协作，具备高度的自我学习能力。（四）理解银行总体信息科技架构，熟悉银行业务模式者优先。（五）具备过多语种SDK开发经验。(C#、PHP）,"移动互联网,金融",2000人以上,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/7176473.html,杨浦区,15k-30k,益盟股份有限公司,5-10年,本科,公司平台大，发展机会多，公司气氛赞。,1、负责数据相关产品的模块设计与代码编写;2、负责大数据项目实施以及部分设计开发； 3、负责大数据环境下的数据清洗、转换、建模、分析以及部分开发工作； 4、负责大数据环境的部署、调优以及日常运维； 任职要求： 1、三年以上数据开发经验，211或985院校毕业； 2、熟悉Hadoop、Spark等大数据平台架构，有实际的项目开发经验； 3、熟悉微服务技术，有SpringCloud、SpringCloud Alibaba等实际项目开发经验，熟悉Spring、Mybatis、RabbitMQ等开源框架； 4、熟悉主流关系型数据库系统(SQL Server、Oracle、MySQL等) 并熟练运用SQL进行数据查询管理操作以及JDBC、连接池管理的开发经验； 5、强烈的责任心和团队合作能力，良好的学习能力，严密的逻辑思维能力并且敢于创新和接受挑战，能够在一定压力下工作。,"金融,移动互联网",500-2000人,hadoop,上海
数据中台开发总监,https://www.lagou.com/jobs/7108823.html,松江区,30k-50k,云汉芯城（上海）互联网科技股份有限公司,5-10年,本科,平台稳定 晋升体系 培训体系,岗位职责：1、负责公司的数据中台战略的落地，负责数据中台产品、服务的技术规划、架构及落地实现；2、负责中台数据治理、建模、架构，支撑数据在多业务场景的应用；3、负责项目的分析、技术设计和技术选型，带领团队保质保量完成项目。4、理解公司整体业务，分解数据中台战略规划，能够有效结合业务，持续完善数据服务体系，解决业务问题；5、遵守公司规章制度以及相关法律法规。任职资格：1、本科及以上学历，计算机或相关专业；2、有过数据中台建设经验，熟悉数据中台规划，有相关的思维体系；3、熟悉数据仓库模型设计，熟悉数据建模，有实战经验；4、有大数据处理经验，熟悉Hodoop生态技术；5、精通Python、PHP语言，熟悉Go语言；6、沟通能力强，积极、正直，业务敏感，服务意识强，做事结果导向。,电商,500-2000人,hadoop,上海
大数据实时开发（flink 方向）,https://www.lagou.com/jobs/6680175.html,虹口区,15k-25k,上海魅奈儿科技有限公司,3-5年,本科,氛围轻松、待遇优厚、地铁零距离、团队优秀,"职责描述1.负责项目的需求分析、概要设计、详细设计，技术文档的编写；2.负责开发框架的搭建、改进，协助完成项目的测试、系统交付工作，对项目实施提供支持；3.负责跟进软件系统安全、稳定、维护和性能优化等工作；4.分布式技术研究，及关键技术的开发工作；5.相关数据平台系统的开发与调试以及后期优化；6.负责搭建行业产品大数据的存储、调度、计算等框架以及主要代码编写。任职要求1.计算机、通信等相关专业，全日制本科以上学历；2.IT相关行业3年以上工作经历；3.具备1年以上大数据开发经验，能够针对flink熟练编写代码；4.具备3年以上Java开发经验，熟悉JDBC，XML，Web Services 和设计模式；5.具备Springboot，Mybatis开发框架应用经验；6.具备Tomcat或WebLogic等中间件技术/产品使用经验；7.熟悉MySQL, PostgreSQL, mongoDB，influx等数据管理技术中的一种或几种；8.有良好的操作系统、数据结构和软件编程算法功底，熟悉主流技术框架、分布式、缓存等相关技术，在安全、高性能、高可用、稳定性等方面丰富的经验；9.阅读过Hadoop, Hive, HBase, Spark, Flink, ElasticSearch, Kafka, Kylin等常见大数据组件的源码或做过二次开发者优先；10.熟悉Spring Cloud/Istio等微服务框架，具备1年以上微服务设计、开发经验，能在Dock、K8s环境部署和管理微服务者优先；11.优秀的技术开发能力，且有极佳的团队合作和沟通能力，工作积极主动，自我驱动能力强，主动思考，心态开放，思路清晰。","硬件,人工智能",50-150人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6090756.html,闵行区,20k-40k,上海永辉超市有限公司,3-5年,本科,晋升通道合伙人 分红 免费下午茶,"岗位职责：1、负责基于Hadoop/Spark平台的业务需求开发、设计；2、负责各业务方向数据服务对外接口的开发；3、负责行业定制类大数据应用系统的设计和研发。任职要求：1、统招本科或以上学历，计算机、数据挖掘等相关专业，工作至少3年以上；2、熟悉Hadoop生态环境，掌握Spark、MapReduce等分布式计算引擎，有流计算经验者优先。3、熟悉Java开发，有脚本语言（shell,python)开发经验者优先；4、掌握常用数据库，以及HBase、Redis、Elastic Search等开源大数据存储技术，并能结合不同的业务场景深入使用；5、了解Java Web开发框架；6、对解决具有挑战性的问题充满激情，具有良好的分析问题和解决问题的能力。",企业服务,2000人以上,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6843565.html,虹口区,25k-35k,上海互信金融信息服务有限公司,5-10年,本科,弹性工时,工作内容：1.数据服务团队关键岗位；负责数据仓库建模、数据库优化、数据分析平台设计、数据部署、数据抽取等etl的设计，编写专业的系统设计文档； 2.负责规划管理业务数据指标体系； 对于it系统应对大数据量所要求的性能指标从数据模型和部署等方面给出设计和持续的优化支持；3.负责电商大数据分析和建设相关系统，为业务系统提供数据服务和支持。4.参与产品架构设计文档和详细设计文档的评审； 5.指导团队成员的开发；6.完成上级领导安排的其他任务。 任职要求： 1.有传统数仓或大数据相关分析产品的开发落地经验； 2.有分布式系统分析及架构设计经验，有大型计算集群的基础设施开发维护经验； 3.熟悉开源数据平台及相关技术，如：Hadoop、Spark、Spark Streaming、Python、Azkaban、Kafka、ES、HBase等; 4.有BI工具使用经验者优先，如Tableau、FineBI等； 5.统招教育背景，至少5年以上相关从业经验。,金融,50-150人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6621407.html,浦东新区,14k-24k,大连晶和信科技有限公司,5-10年,本科,本项目是金融类项目，周末双休，无加班,1.熟练掌握Oracle、Hadoop（包括hive）、linux shell等后端研发技术；2.具备数据分析和数据架构设计能力，掌握文本等非结构化数据处理方法。3.工作经验5年+，要求本科学历，计算机相关专业，有金融工作经验优先考虑，有带队经验。4.学信网本科以上学历，计算机相关专业,"其他,移动互联网",150-500人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6508645.html,浦东新区,15k-23k,上海华钦信息科技股份有限公司,3-5年,本科,以能力定福利,3年以上工作经验。精通IT技能和技术经验，包括SQL Server 或Oracle 或Sybase，SQL。ETL工具如SSIS（SQL Sever Integration Services）、熟悉数据库原理，有数据建模，数据库设计经验本一以上学历，计算机专业优先英语四级以上，可读写，可简单口语,"数据服务,金融",500-2000人,hadoop,上海
大数据开发工程师,https://www.lagou.com/jobs/6471664.html,浦东新区,25k-45k,上海华钦信息科技股份有限公司,5-10年,本科,福利待遇好，平台大，,要求：1，至少3年以上大数据开发经验，spark熟练，可以用Java熟练开发spark；2，统招本科以上学历，学信网可查，3，英文可进行部分技术交流，熟练文档邮件。,"数据服务,金融",500-2000人,hadoop,上海
数据库开发（报表开发）,https://www.lagou.com/jobs/6121797.html,浦东新区,10k-15k,上海海万信息科技股份有限公司,3-5年,不限,"五险一金,体检旅游,年终奖金,节日礼金",1、数据库精通，ORACLE数据库2、参与过数据仓库项目，了解数据仓库建模，数据更新策略3、加分项：有SQL调优经验，有定时任务管理经验，有报表开发经验,"移动互联网,金融",500-2000人,hadoop,上海
数据开发,https://www.lagou.com/jobs/6312349.html,静安区,10k-16k,上海海万信息科技股份有限公司,3-5年,大专,大平台,岗位职责：1、 负责数据统计与分析的研发和维护；2、 根据产品经理和运营团队等的统计需求，进行开发实现；3、 负责对用户行为数据的深度挖掘，以数据指导产品改善。任职要求：1、 全日制专科及以上，3年以上工作经验；2、 Java基础扎实，熟悉主流开源框架，懂JVM调优更佳；3、 熟悉HBase、Spark、HIVE等数据框架；4、 熟悉Kafka、ES、Redis等数据中间件；有实时计算经验更佳5、 良好的SQL语句功底，熟悉MySQL、PostgreSQL、Oracle数据库中的一种；6、 逻辑清楚、快速的学习能力及良好的沟通能力。,"移动互联网,金融",500-2000人,hadoop,上海
软件开发工程师（大数据方向）,https://www.lagou.com/jobs/6189200.html,浦东新区,20k-30k,上海农村商业银行股份有限公司,3-5年,本科,发展前景好，福利待遇好,岗位职责：1、负责大数据相关系统平台的设计、开发及快速迭代；2、负责平台数据模型、指标、生命周期的设计和管理；3、基于对商业银行业务模式的深入理解，发掘数据价值。应聘条件：1、35周岁及以下，全日制本科及以上学历，计算机、应用数学、统计学等相关专业；2、3年及以上软件开发工作经验，1 年及以上大数据系统开发、设计经验，熟练掌握C/C++、JAVA等主流开发语言；具备金融行业业务分析、模型设计、数据挖掘、金融统计等相关工作经验的优先。3、熟悉SAS、R、Python等主流挖掘分析工具；掌握机器学习基本理论以及多种机器学习算法，具备模型调优能力；4、具备良好的团队合作能力、沟通能力和综合分析能力，学习能力强，承压能力强，工作责任心强。有创新思维，对数据技术和业务发展有高度敏感性。5、获得全国计算机技术与软件专业技术资格（水平）考试的中级高级证书者优先。,金融,500-2000人,hadoop,上海
数据与数据平台开发经理 - 上海,https://www.lagou.com/jobs/6769550.html,黄浦区,30k-50k,普华永道中天会计师事务所（特殊普通合伙）北京分所,5-10年,本科,行业翘楚+精英相伴+卓越培训+ 探索创新,"岗位要求:
 5-8年或以上技术相关工作经验，乙方为主；
 具备丰富的对企业客户的销售经验，3年以上客户销售和客户管理经验；
 具备丰富的为企业客户设计数据治理解决方案和平台的经验，对元数据管理、主数据管理、数据标准和数据安全等有深入的理解；
 具备平台或数据类项目管理经验，担任过此类项目的项目经理，管理过10人以上项目实施团队，熟悉项目管理目标、要求、方法与流程；
 具备数据中台或数据平台、数据仓库与数据治理项目实施经验，担任过此类项目的架构师或开发组组长，熟知项目实施方法，有能力参与、指导现场实施工作，以及对客户进行培训；
 具备保险核心系统项目实施经验，担任过此类项目的架构师或开发组组长，熟知微服务架构，熟知项目实施方法，有能力参与、指导现场实施工作，以及对客户进行培训；
 具备出色的沟通与组织协调能力，有能力负责客户沟通、需求确认、项目汇报。",金融,2000人以上,hadoop,上海
数据库开发/DBA工程师,https://www.lagou.com/jobs/6718205.html,浦东新区,7k-12k,南京嘉环科技有限公司,1-3年,本科,"周末双休，五险一金,节日福利,团队活动",技能要求：DBA，MySQL，Oracle，POSTGRESQL，GAUSSDB，GREENPLUM岗位职责：1.负责数据库系统的运行维护、管理和性能调优；2.负责系统软、硬件的部署、监控及优化；3.参与系统需求调研、SQL开发、测试；4. MYSQL服务器的性能优化，故障排查，备份与恢复等日常操作。任职要求：1.具有2年以上大型数据库（oracle/mysql/gaussDB/postgreSQL/Greenplum）工作经验；2.熟练掌握数据库优化原理和方法论，熟练掌握数据库优化工具；3.熟悉以上至少1种数据库备份、恢复、复制、双活等高可用技术的架构和原理；4.熟悉Linux和Shell脚本优先；5.具有OCP、OCM、华为大数据HCIE认证优先；,"企业服务,数据服务",2000人以上,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6754782.html,徐汇区,10k-15k,上海讯真信息科技有限公司,3-5年,大专,发展前景佳,岗位职责： （1）负责大数据平台中资源编目信息的收集、整理、完善和导入等数据治理相关工作； （2）负责原始数据的收集、整理及追踪完善等数据治理工作； （3）负责运维保障大数据平台中各类数据汇聚、资源挂接等数据管理工作； （4）负责提供数据汇聚工作技术支持（如SQL编写及数据服务接口开发等）。 任职要求： （1）具有数据治理或大数据平台管理的工作经验； （2）熟悉数据采集、存储、清洗、分析及挖掘等方面的相关技术及相应的技术提供方； （3）熟悉主流数据库技术，如Oracle、SqlSQL语言； Server、MySQL及PostageSQL等； （4）熟悉ETL架构，了解日常作业的部署和调度，熟悉ETL开发工具，如Datastage、Congos及Kettle等； （5）了解多项大数据处理/分析相关的工具/框架，如Hadoop、 MapReduce、Hive、Storm、Spark、kafka及HBase等。,电商,50-150人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6739847.html,浦东新区,20k-30k,上海蒙玺投资管理有限公司,1-3年,本科,优越的办公环境，薪资高福利待遇优,1. 开发数据处理程序，用于清洗整理海量金融数据2. 数据生产环境运维，确保数据生产程序稳定运行3. 与基金经理、策略研究员合作开发辅助工具岗位要求：1. 国内外知名高校计算机或相关专业毕业2. 熟练运用python，有一定Python性能优化经验者加分3. 熟悉MySQL、ORCALE等数据库，有分布式存储经验者加分4. 处理事情细心、有耐心，有良好的沟通技能5. 有良好的团队合作意识,金融,15-50人,hadoop,上海
高级、资深数据仓库开发工程师,https://www.lagou.com/jobs/7134258.html,杨浦区,20k-35k,上海跃橙文化传播有限公司,3-5年,不限,Dataworks、数据仓库,"工作职责:1、参与数据仓库/数据集市的建设，持续集成相关工具产品，以及搭建大数据业务基础计算层等相关工作；2、参与数据仓库的架构设计和研发，挖掘数据价值，建设与管理百 PB 级的数据平台和服务系统，实现高质量数据的互通与共享；3、 负责ODS以及数据仓库逻辑模型、物理模型的分析与设计，参与制定核心模型的演进路线；4、 负责数据类项目技术设计及技术实现规范的编制，指导开发团队进行项目设计、项目实现；5、基于数据驱动构建企业的数据模型以及面向应用产品与分析的应用层模型设计开发。岗位要求:1、计算机相关专业，本科及以上学历，从事数据仓库领域至少 4 年以上；2、 熟悉数据仓库模型设计与 ETL 开发经验 ，掌握常用建模设计方法，具备海量数据加工处理（ETL）相关经验；3、 有从事分布式数据存储与计算平台应用开发经验，熟悉hadoop及生态（hdfs、hbase、hive、spark等）并有相关实践经验着优先4、 熟悉数据仓库领域知识和技能者优先，有DW/BI架构体系中某些领域的专项建设经验，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；5、 有良好的业务及产品感觉，可以站在使用者角度设计技术产品。主动并乐于了解日常业务，具备从日常业务中发现问题并解决问题的能力；6、 熟悉各种 NoSQL 产品（如Redis、MongDB等),对分布式架构熟悉者优先7、 对数据敏感、对技术敏感,逻辑清晰思维敏捷，有研究的意识和直觉者更佳； 8、 性格积极乐观，诚信，有较强的语言表达能力及跨部门间沟通能力；具备强烈的进取心、求知欲及团队合作精神;",移动互联网,50-150人,hadoop,上海
大数据开发工程师（上海）,https://www.lagou.com/jobs/5644650.html,黄浦区,15k-20k,广州汇智通信技术有限公司上海分公司,1-3年,本科,福利好，领导NICE,岗位工作范围和职责：1、负责海量(万亿级别)数据的分析、处理、开发工作；2、根据业务需求，负责模型的建立和实现；3、参与公司大数据平台上业务应用的功能设计，负责相关产品的设计、开发、文档撰写和项目改进；专业知识和技能要求：1、本科及以上学历，计算机、应用数学、人工智能、模式识别、自控、统计、运筹学专业，具备扎实的数据结构和算法功底；2、熟悉常用数据挖掘算法（聚类、分类、回归、关联规则、图模型）等算法原理，具备实际的大数据建模经验；3、熟悉hadoop分布式计算平台，熟悉hive等开源框架，具有实际开发经验；4、掌握至少一种编程语言（java/scala/python），具有良好的编码习惯，简练的编码风格；5、较强的数据敏感度，能从海量数据中挖掘出数据核心价值；6、严密的数据思维、突出的分析归纳能力和表达能力；7、富有创新精神，充满激情，乐于接受挑战，良好的沟通技巧和团队合作名称； 公司福利：1、全年年收入约14.5个月工资，另外约有1.2万左右的现金福利；2、六险一金，员工年度健康福利体检；其中住房公积金按照月度工资总额的12%购买；3、五天7小时工作制，带薪年假、各类法定节假日、有薪假及出差探亲假等；4、各类过节福利、节日礼品、生日礼品、慰问品等；5、差旅费、差旅津贴、业务招待费、通讯补助、用餐补助、保密补贴等；6、每月不定期暖心下午茶，部门不定期旅游、聚餐；7、公司设有健身房、篮球场、乒乓球室、壁球室等休闲设施，并定期组织各类业余活动。,"信息安全,数据服务",500-2000人,hadoop,上海
数据平台开发工程师,https://www.lagou.com/jobs/6112553.html,杨浦区,20k-40k,上海流利说信息技术有限公司,3-5年,本科,美股上市 人工智能 不打卡 硅谷文化,"职位描述：* 主导大数据平台内部服务的研发；* 独立负责数据产品的开发工作，对系统质量负责；任职要求：* 至少2年以上相关经验，计算机相关专业，熟悉常用算法以及数据结构，熟悉多线程，网络编程等知识;* 熟悉 Web 开发技术, HTML/Javascript/HTTP/REST，以及 React;* 熟练掌握目前主流开源框架（SpringBoot, SpringCloud, Mybatis 等）；* 熟悉 Java、JVM，有 Hadoop/Spark/Hbase 等大数据工具的使用经验优先；* 有开源项目源码阅读经验优先；* 具有良好的学习和沟通能力，强烈的责任心，有团队合作意识，对自己负责的事有 ownership；",教育,2000人以上,hadoop,上海
数据开发资深工程师（数据管理组）,https://www.lagou.com/jobs/7111065.html,黄浦区,18k-35k,众安在线财产保险股份有限公司,5-10年,本科,管理扁平，发展空间大,岗位职责：参与数据平台产品与应用的数据研发，发掘数据商业价值，打造**体验的数据产品；负责全链路实时/离线数据建模和生产、数据架构治理、和数据风险管理。参与数据平台数据仓库架构设计与研发，建设公共数据平台和服务系统，实现高质量数据的互通与共享；参与公司对外输出的项目的数据技术支持，包括但不限于售前咨询培训，售后架构设计和项目建设，并保障服务满意度；任职要求1、从事数据仓库或挖掘领域至少5年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握维度建模设计方法，具备海量数据处理经验；2、熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；3、熟悉数据库技术，熟练运用SQL及其他语言，能高效的与技术团队进行沟通；4、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，如Hdfs、Mapreduce、Hive、Hbase、Spark、Storm、Flink；5、熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，如Java、Python、Shell；6、良好的商业嗅觉，有丰富的数据分析经验，较强的数据、平台、技术理解能力；7、良好的语言沟通与表达能力，自我驱动。,金融,2000人以上,hadoop,上海
数据开发资深工程师（数据管理组）,https://www.lagou.com/jobs/7110387.html,黄浦区,18k-35k,众安在线财产保险股份有限公司,5-10年,本科,管理扁平，发展空间大,岗位职责：参与数据平台产品与应用的数据研发，发掘数据商业价值，打造**体验的数据产品；负责全链路实时/离线数据建模和生产、数据架构治理、和数据风险管理。参与数据平台数据仓库架构设计与研发，建设公共数据平台和服务系统，实现高质量数据的互通与共享；参与公司对外输出的项目的数据技术支持，包括但不限于售前咨询培训，售后架构设计和项目建设，并保障服务满意度；任职要求1、从事数据仓库或挖掘领域至少5年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握维度建模设计方法，具备海量数据处理经验；2、熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；3、熟悉数据库技术，熟练运用SQL及其他语言，能高效的与技术团队进行沟通；4、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，如Hdfs、Mapreduce、Hive、Hbase、Spark、Storm、Flink；5、熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，如Java、Python、Shell；6、良好的商业嗅觉，有丰富的数据分析经验，较强的数据、平台、技术理解能力；7、良好的语言沟通与表达能力，自我驱动。,金融,2000人以上,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6932563.html,杨浦区,16k-25k,上海同济技术转移服务有限公司,不限,硕士,年薪资待遇：20万-30万,职位描述：1） 参与中心新一代智能规划大数据平台研发；2） 理解数据分析需求，构建自动化的数据分析流程；3） 能够优化数据分析相关算法，并进行高效的编码实现；4） 基于Web应用开发，建立持续集成的数据分析平台。  任职资格：硕士及以上学历，计算机软件相关专业，具有扎实的数据结构和算法知识；  技能要求： 1） 熟练使用Python语言，熟悉Django或Flask等一种以上；2） 熟悉Requests、SQLAlchemy、Scikit-learn、Pandas、Shapely和PIL等数据获取、清洗、存储和分析模块；3） 熟悉结构型和非结构型数据库，有过PostgreSQL或MongDB等一种以上数据库使用经验；4） 一年以上工作经验，具有数据挖掘、空间数据可视化、Hadoop、DevOps等相关经验者优先。 简历邮箱：*******************,"企业服务,教育",15-50人,hadoop,上海
初级数据库开发,https://www.lagou.com/jobs/6865668.html,虹口区,6k-9k,上海鸿冠信息科技股份有限公司,1-3年,大专,"团队氛围,职位发展好",主要职责:1、根据应用分析需求，进行数据统计开发工作；2、查证及解决各类数据质量问题。能力要求:1、熟悉SQL脚本编写，熟知关系型数据库原理；2、熟悉oracle、mysql或db2等任一主流数据库；3、工作认真负责、积极进取、具有团队精神。,移动互联网,150-500人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6680462.html,闵行区,20k-25k,上海聪盛网络科技有限公司,3-5年,本科,免费早餐、免费零食、项目奖金、加班补贴,岗位职责：1、根据业务需求，进行数仓日常数据分析、数据报表开发； 2、使用 Hive 进行数据处理及数据模型构建； 3、维护和保障数据平台和集群稳定运行和日常运维； 4、具备良好的分析问题和解决问题的能力； 5、具备较强的沟通能力和逻辑表达能力，良好的团队合作精神和主动沟通意识；任职资格：1、计算机相关专业本科及以上学历； 2、熟练使用SQL（MySQL / HiveSQL / PrestoSQL / SparkSql）； 3、熟练数据库/数据仓库分层设计、宽表设计、星型模型设计等； 4、熟悉hadoop、Hive、HDFS等常用大数据组件，能进行错误分析和维护调整优化； 5、有游戏相关业务分布式数据仓库、大数据平台维护等相关经验者优先。,"游戏,移动互联网",150-500人,hadoop,上海
大数据资深开发工程师,https://www.lagou.com/jobs/6362496.html,浦东新区,23k-28k,上海巧房信息科技有限公司,5-10年,本科,行业领先,工作职责:1.负责大数据平台的基础技术规划，平台的建设，包括环境和框架的规划搭建以及核心编码工作。2.负责大数据平台的数据采集、处理、存储的架构实现。3.负责开源大数据平台与产品和相关技术的研究。4.参与业务需求调研，根据需求设计大数据解决方案并跟进具体实施项目。岗位要求：1.计算机相关专业，3年以上工作经验，2年以上大数据架构设计经验。2.熟悉大数据解决方案包括Hadoop、Spark、Hive、Hbase等大数据解决方案。3.深刻理解大数据处理等相关技术和实现方法，有架构和设计实践经验。4.熟悉分布式存储和非结构化数据相关NoSQL或NewSQL等数据库技术，例如Neo4J、 Hbase、 Redis、 MongoDB 等。5.精通Java、Scala、Python、R、C中的一种或多种语言，有Java开发经验者优先。6.熟悉Linux系统，能够在Linux环境中熟练地部署、配置和开发大型复杂的平台软件，熟练使用shell/python脚本处理问题。7.有大型数据仓库实施、大数据平台数据开发经验者优先。,"移动互联网,企业服务",150-500人,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6236150.html,普陀区,20k-35k,上海羽如贸易有限公司,5-10年,本科,奢侈品跨境电商；管理扁平；发展好；福利好,1、创建和维护最佳数据管道架构。2、组装满足功能/非功能业务需求的大型复杂数据集。3、识别，设计和实施内部流程改进：自动化手动流程，优化数据交付，重新设计基础架构以实现更高的可扩展性等。4、使用SQL和阿里云Data Work - 数据集成、数据开发及数据服务技术构建从各种数据源中优化提取，转换和加载数据所需的基础架构。5、构建利用数据管道的分析工具，为客户获取，运营效率和其他关键业务绩效指标提供可操作的见解。6、与包括执行，产品，数据和设计团队在内的利益相关方合作，协助处理与数据相关的技术问题并支持其数据基础架构需求。7、为分析和数据科学家团队成员创建数据工具，帮助他们构建和优化我们的产品成为创新的行业领导者。8、与数据和分析专家合作，争取在我们的数据系统中实现更强大的功能。 岗位要求1、具有高级工作SQL知识和使用关系数据库，查询创作（SQL）以及熟悉各种数据库的经验。2、体验构建和优化“大数据”数据管道，架构和数据集。3、体验对内部和外部数据和流程进行根本原因分析，以回答特定业务问题并确定改进机会。4、与使用非结构化数据集相关的强大分析技能。5、构建支持数据转换，数据结构，元数据，依赖性和工作负载管理的流程。6、从大型online/offline数据集中操作，处理和提取值的成功历史。7、有关消息队列，流处理和高度可扩展的“大数据”数据存储的工作知识。8、在动态环境中支持和与跨职能团队合作的经验。9、3~5年以上数据工程师经验的候选人，计算机科学和统计学相关专业优先。具有以下软件/工具经验的优先：    *使用大数据工具的经验：阿里云DataWork，Kafka等。    *使用关系SQL和NoSQL数据库的经验，包括阿里云分析型数据库 PostgreSQL版。    *具有数据管道和工作流管理工具的经验：阿里云DataWork等。    * 阿里云云服务经验：ECS，RDS，RDS，Redis等待。    *面向对象/对象函数脚本语言的经验：Python，Java等,移动互联网,150-500人,hadoop,上海
数据开发专家,https://www.lagou.com/jobs/5552642.html,长宁区,30k-50k,北京三快在线科技有限公司,5-10年,本科,"发展空间大,技术大牛多",工作职责：-构建美团点评金融数据仓库（分层建设、主题模型、元数据管理、性能和效率优化）；-金融相关BI系统建设，规划并带领小伙伴试错、成长，做离业务最近的数据BI系统；-金融数据仓库OLAP体系搭建，建设TB级高效在线分析应用；-金融数据日常需求开发，与分析师、PM、OP一起感知变化，实现高效的数据运营；-调研和实践热门数据仓库组件和技术（kylin、spark、storm、实时数仓......）；-指导初级数据工程师的工作。职位要求：-计算机相关专业本科以上学历；-熟悉数据仓库建设方法论，包括但不限于：-分层（ODS、base、fact、topic、cube）建设方法；-主题建设方法，能独立抽象主题、建设模型、物理化并调整效率和性能；-常用的BI系统建设方法，熟练使用主流BI工具，理解其实现原理、使用什么技术解决什么问题；-熟练掌握 SQL，理解 Hive/MySQL/Oracle 原理和调优方法，有独立处理大规模数据/日志的经历；-有两年以上数据仓库(DW) / 商业智能(BI) / 数据统计相关工作经验；-熟练掌握 Java / Python / PHP 中至少一种编程语言；-优先：有支付系统、财务系统、金融系统、风控安全研发经验者；-优先：有新人导师、团队管理经验者。,消费生活,2000人以上,hadoop,上海
大数据开发工程师-SH(J10236),https://www.lagou.com/jobs/5828653.html,浦东新区,25k-30k,秒针信息技术有限公司,3-5年,本科,大数据,"工作职责:1、 从事大数据平台建设开发，数据治理，分析，编码的工作。2、 负责大数据项目的核心业务设计和开发；3、 随着项目发展，不断优化分布式系统架构，提高可用性，扩展性和性能；4、 调研新的大数据技术并进行应用，助力业务成长；任职资格:1、熟悉Linux/Unix操作系统，熟练掌握java/scala/go/python/php等一种或多种编程语言；2、熟悉 Hadoop EcoSystem，包括但不限于Hadoop, HBase, Hive, Kafka, Flume，ElasticSearch，Spark，Storm, Druid/Presto/Impala 等，具备2年以上开发和使用经验；3、了解Oracle、MySQL、SQL Server、DB2至少一种数据库软件，熟练使用SQL完成常规取数，使用Linux Shell、Python脚本初步处理数据；4、学习能力强，适应能力好，主动性强，抗压能力强，团队协作意识强，能适应一定程度的加班；5、具备良好的沟通能力和表达能力，有较强的数据敏感度，良好的沟通协调能力，能承受一定的工作压力。","数据服务,广告营销",2000人以上,hadoop,上海
大数据开发工程师（资产托管）,https://www.lagou.com/jobs/6843493.html,静安区,20k-25k,国泰君安证券股份有限公司,3-5年,本科,国内领先地位的知名券商公司,岗位职责        1、参与数据管理体系设计，数据建模管理、数据采集管理、数据清洗管理、数据质量管理、数据发布管理等业务及技术框架及流程；          2、负责业务需求管理和场景设计；      3、负责数据平台的开发及运维，保障系统稳定及数据质量；      4、负责撰写相关系统开发文档。     任职要求        1、全日制本科及以上学历，计算机相关专业，3年以上数据建模及系统开发经验；      2、精通数据库设计，熟练掌握Java开发语言，有大型项目的开发经验；      3、具备数据分析和数据挖掘方面经验；      4、有金融机构数据管理、数据开发经验优先考虑。,金融,2000人以上,hadoop,上海
数据智能中心Java开发专家（上海、北京）,https://www.lagou.com/jobs/6807193.html,普陀区,30k-50k,拉扎斯网络科技（上海）有限公司,5-10年,本科,大数据、高并发,职责1. 负责DIC大数据部门算法工程、数据产品、大数据工具相关的后端研发工作2. 参与发掘和分析业务需求，进行系统核心方案设计3. 参与核心代码编写，确保性能、质量和安全4. 参与生产环境维护，确保系统可用性岗位要求1. 本科及以上学历，扎实的计算机基础。2. 有过复杂、高并发或大数据量系统的架构设计和优化经验，尤其是深度参与过互联网业务架构设计的优先，拥有和工作年限相称的广度和（或）深度。3. 5年及以上工作经验，长期使用JAVA及开源框架进行项目开发，并有一定得项目管理经验；深入使用Java，熟悉掌握常用的Java类库及框架，如多线程、并发处理、I/O与网络通讯，Spring、Mybatis等;系统排障经验丰富，可以快速排查定位问题；至少对高并发、分布式、缓存、jvm 调优、序列化、微服务等一个或多个领域有过深入研究，并且有相关实践经验。4. 精通 MySQL 应用开发，熟悉数据库原理和常用性能优化技术，熟悉常用中间件的原理、使用场景以及限制。6. 具备良好的业务感觉，能够站在业务、产品的角度深入发掘内在逻辑，进行合理的抽象与建模，做出合适的架构设计决策7. 具备良好的分析解决问题能力，能独立承担任务和有系统进度把控能力7. 具备很强的学习能力，对技术有好奇心，有热情，有渴望8. 熟悉常用的大数据组件，如ElasticSearch、Kafka、Storm、Spark、Flink等，有过大数据产品开发经验优先。,消费生活,2000人以上,hadoop,上海
Java开发（要会Oracle数据库）,https://www.lagou.com/jobs/6751725.html,浦东新区,15k-20k,奥解思信息科技（上海）有限公司,3-5年,本科,全额公积金社保商业保险 外企弹性时间,"Job Description This is a great opportunity to work on Funds  FSTP Processing.  These builds form an important part of the IBOR Phase 2 functionality requested by ASI as part of the Atlantic Programme to on-board and integrate the legacy Aberdeen portfolio book onto Citi platforms.  The SSM changes are needed for both the current production services together with  expanded IBOR and regulatory reporting services. This incorporates the new processing of  Global Loans TBA and CP/CD products which are critical builds for ASI Client onboarding. Technical Skills• 2-3 years hands on experience with Java Technologies. Core Java – multi threading, collections, annotations, generics, data structures.. Server side programming Database:  Oracle, SqlServer, Mongo DB.. Framework:  Spring..• Well versed in Agile/TDD.• Expert level in OO design• Excellent attention to detail and strong communication skills.",金融,500-2000人,hadoop,上海
生态金融 - 风险管理 - 数据开发,https://www.lagou.com/jobs/7075046.html,长宁区,20k-40k,北京三快在线科技有限公司,3-5年,本科,大平台，弹性工作,,消费生活,2000人以上,hadoop,上海
大数据运维开发工程师（上海）,https://www.lagou.com/jobs/6902876.html,静安区,16k-32k,天津英才酷信息科技有限公司,3-5年,本科,大企业、行业前景好、牛人带队、发展空间大,工作职责：1.参与客户需求及数据调研，数据对接方案设计；2.参与项目实施工作，协助客户完成数据接入工作；3.为客户提供技术支持，解决客户使用 API 以及数据处理工具时遇到的问题；4.准确地将客户需求传达给产品研发团队，并进行必要的整理和归纳。1.负责公司大数据平台的搭建、维护、监控并具备排错能力2.熟悉Hadoop、Hbase、Hive、Impala、Flume、Zookeeper、kafka、Spark、ELK等开源项目3.有AWS或其他云平台使用和管理相关的经验4.精通Linux操作系统的配置、管理及优化，shell编程，能够独立排查及解决操作系统层面的问题岗位要求：1.本科或本科以上学历，计算机相关专业；2.有一年以上的实施经验或测试经验或开发经验；3.有大数据相关经验者优先；4.逻辑清晰，有工程师思维和较强的协作能力；5.快速学习能力；主动性强。,数据服务、软件开发,500-2000人,hadoop,上海
数据库开发工程师（DBA）,https://www.lagou.com/jobs/6659985.html,长宁区,18k-25k,携程计算机技术（上海）有限公司,1-3年,本科,发展前景,"工作职责：
 主要负责项目中MySQL数据库相关的设计、调优工作
 日常数据库监控、优化、排障，协助开发解决遇到的数据库问题；
任职资格： 
 本科及以上学历，至少2年MySQL运维、开发经验。能够熟练阅读英文文档；
 熟悉MySQL内部原理，复制等技术，具备较好的日常排障、性能调优的能力；
 熟悉Linux操作系统，熟悉python、perl任一种脚本语言；
 具备独立分析问题、解决问题的能力，有良好的团队合作能力和主动性。",旅游,2000人以上,hadoop,上海
高级数据开发软件工程师,https://www.lagou.com/jobs/6908911.html,嘉定区,15k-25k,上海冰风网络科技有限公司,3-5年,本科,五险一金 餐饮补贴 节日福利,"岗位职责：1、负责数据技术中心实时处理系统开发2、负责项目开发文档编写与存档3、参与业务需求讨论与理解任职资格：1、 了解或熟悉Hadoop / Spark / Kafka/Storm 等分布式系统，熟悉实时处理2、 熟悉Redis/MySql/HBase等存储系统3、 熟悉Java/Python/Scala等开发语言4、 熟悉大规模数据处理、高并发或分布式系统相关知识，熟悉JVM性能优化, 有后端服务优化相关经验较强的沟通能力和逻辑思维能力, 积极的工作态度和良好服务意识，了解游戏行业优先5.计算机相关专业优先",游戏,50-150人,hadoop,上海
数据仓库开发工程师,https://www.lagou.com/jobs/6733705.html,嘉定区,20k-30k,上海冰风网络科技有限公司,3-5年,不限,五险一金 餐饮补贴 每周水果 节日福利,"岗位描述：1. 负责数据仓库应用产品设计和开发工作；2. 负责数据仓库建模、数据预处理子系统的设计和开发；3. 负责数据仓库ETL流程的优化及解决ETL相关技术问题。岗位要求：1. 熟练数据仓库的ETL的开发和数据建模，3年数据仓库实施经验；2. 熟悉linux脚本语言，如Python，PHP，Shell,Perl等，精通python优先；3. 精通sql开发和优化，有丰富的mysql/Inforbright等数据库开发经验；4. 熟悉数据库建模方法和元数据管理的原理，能独立承担部分系统分析及设计工作，具有大型数据仓库和ETL开发、实施的经验，游戏、互联网行业经验优先；5. 有互联网公司或海量数据处理工作经验，熟悉数据分析和挖掘经验者优先。",游戏,50-150人,hadoop,上海
大数据开发工程师(J11222),https://www.lagou.com/jobs/6748903.html,长宁区,15k-25k,秒针信息技术有限公司,3-5年,本科,下午茶 培训体系完善 办公环境nice,,"数据服务,广告营销",2000人以上,hadoop,上海
数据报表开发经理/高级经理(J10079),https://www.lagou.com/jobs/6948752.html,黄浦区,25k-30k,睿智合创（北京）科技有限公司,5-10年,本科,3-6个月年终奖，七险一金，期权激励,,"金融,数据服务",150-500人,hadoop,上海
大数据golang开发工程师,https://www.lagou.com/jobs/6817201.html,浦东新区,30k-50k,上海基分文化传播有限公司,3-5年,本科,良好的团队氛围，开阔的职业前景,负责大数据部数据流的平台开发和组件开发，主要包括：1：logserver等数据采集收集器的迭代开发；2：kafka 相关的组件和平台的开发；3：flink平台工具的开发；4：hadoop生态的系统组件的开发；等等任职要求：1、能够根据实际业务设计开发大数据应用组件或者基于开源软件进行二次开发;2、熟悉Linux/Unix环境，精通Java/Go/scala等;3、具备3年以上的分布式系统平台的开发经验、熟悉分布式计算系统的工作机制;4、对大数据基础架构和平台有开发经验，对基于大数据数据流组件开发框架(Kafka、Elasticsearch、flink、hadoop生态等)深入理解；5、对大数据平台的性能优化以及平台运维具用丰富经验;6、具有中大型大数据基础平台的建设经验;7、对JVM有深刻理解，并且能够运用到日常工作中;8、有极强的责任心、积极主动承担结果，能够针对大数据平台的疑难问题努力寻求解决方案;,文娱丨内容,500-2000人,hadoop,上海
大数据开发工程师（java/go/scala）,https://www.lagou.com/jobs/6822546.html,浦东新区,30k-50k,上海基分文化传播有限公司,3-5年,本科,良好的团队氛围，开阔的职业前景,负责大数据部数据流的平台开发和组件开发，主要包括：1：logserver等数据采集收集器的迭代开发；2：kafka 相关的组件和平台的开发；3：flink平台工具的开发；4：hadoop生态的系统组件的开发；等等任职要求：1、能够根据实际业务设计开发大数据应用组件或者基于开源软件进行二次开发;2、熟悉Linux/Unix环境，精通Java/Go/scala等;3、具备3年以上的分布式系统平台的开发经验、熟悉分布式计算系统的工作机制;4、对大数据基础架构和平台有开发经验，对基于大数据数据流组件开发框架(Kafka、Elasticsearch、flink、hadoop生态等)深入理解；5、对大数据平台的性能优化以及平台运维具用丰富经验;6、具有中大型大数据基础平台的建设经验;7、对JVM有深刻理解，并且能够运用到日常工作中;8、有极强的责任心、积极主动承担结果，能够针对大数据平台的疑难问题努力寻求解决方案;,文娱丨内容,500-2000人,hadoop,上海
大数据开发SRE,https://www.lagou.com/jobs/6765566.html,杨浦区,18k-35k,国际商业机器（中国）有限公司,5-10年,不限,新项目，有机会去新加坡或者深圳客户端,"Site reliability engineering (SRE) and Chaos engineering    Must have:    Experience with high availability, scalability, and  performance systems.    Experience with distributed  architecture, SOA, microservices   and Platform-as-a-Service (PaaS).    Experience with Core Java 8, Cloud Foundry (or equivalent), Amazon   Web Services (or equivalent), relational and  non-relational databases, and Linux, Unix systems.   Big data experience is the  key too,which needs:Strong experience in Hadoop, Spark and Python. Strong experience in Data Pipelines and CI/CD tools.    Able to talk to business people for any issue related to   Hadoop cluster Requirements .   Nice to have:    Experience with Banking will be an added advantage.    Experience with managing cloud architecture based   environment is highly desired.    Experience in Agile and Test Driven Development (TDD)   methodologies.","电商,数据服务",2000人以上,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/7175911.html,徐汇区,25k-35k,小米科技有限责任公司,3-5年,本科,数据开发,工作内容：1.负责公司大数据离线、实时平台（如Hadoop/Hive/Storm/Spark）的建设、优化2.负责开发大数据工具，如报表平台、多维度分析工具、ETL平台、调度平台的研发；3.负责数据可视化分析平台设计和开发任职要求：1. 3年以上大数据基础架构相关工作经验，有数据仓库建设的相关工作经验；2.扎实的Java、Scala语言基础，对JVM运行机制有深入了解；3.熟悉Hadoop、Spark，Flink并有丰富的开发经验；有深入研究过Hadoop/Spark/ES/Flink源码者优先4.熟悉SQL和noSQL的设计和开发，熟悉SQL性能调优；5.善于思考，能独立分析和解决问题，热衷于新技术的研究和创新；6.责任心强，沟通能力好，具备良好的团队合作精神；,硬件,2000人以上,hadoop,上海
上海事业群-数据库开发岗,https://www.lagou.com/jobs/5778546.html,浦东新区,15k-30k,建信金融科技有限责任公司,不限,本科,银行系金融科技；职业前景好；六险一金,一、基本条件1.遵规守法，诚信廉洁，具有良好的个人品质和职业道德，无违纪违法记录、无不良从业记录。2.有敬业精神，团结合作，责任心强，有执行力，具备良好的沟通和表达能力。3.具有全日制大学本科及以上学历，获得学士及以上学位，需求分析岗位要求金融相关专业，其他岗位要求信息技术相关专业；部分岗位要求具有全日制硕士及以上学历。4.拥有行业一流金融机构或科技公司从业经验者优先。5.年龄不超过35周岁。6.身体健康，具有良好的心理素质。二、具体岗位描述及要求1.负责数据库设计开发，基于应用场景，设计并应用最佳实施方案。 2.配合研发制定ORACLE/MYSQL数据库技术方案，分库分表策略，数据迁移方案。3.具备丰富的ORACLE、Mysql和其他主流开源数据库开发和管理经验，精通Oracle、Mysql等数据库原理、方法和技术，较强的故障诊断和性能调优能力。4.精通SQL语句的优化，服务器的性能参数调整。5.将特别优先考虑掌握数据库的高性能、高可用设计方法和实现原理，具有大并发场景下数据库架构设计经验者。,"金融,软件开发",2000人以上,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/7103791.html,嘉定区,8k-10k,华诺威汽车零部件（上海）股份有限公司,1-3年,大专,五险 软件开发,岗位职责：1、负责Mysql数据库设计、搭建、维护、迁移等工作；2、负责对数据库进行管理、运维及监控；3、负责数据库优化，并能根据业务需求，提供高可用、高性能、可扩展、稳定可靠的数据库解决方案；要求：1、计算机相关专业本科以上学历；2、有2年以上的数据库工作经验；3、精通 SQL 语法及Shell脚本，拥有PHP 语言开发经验；4、熟悉LNMP开发环境（能独立配置和调试服务器环境）、Web开发流程、具备软件架构设计能力；5、有CRM、ERP及电子商务类互联网系统的开发经验优先；6、具备良好的沟通能力和文字表达能力，有较强的团队协作能力。,其他,50-150人,hadoop,上海
数据分析开发实习生,https://www.lagou.com/jobs/6630178.html,浦东新区,2k-4k,上海谆视网络科技有限公司,应届毕业生,不限,热点项目、经验积累,"大数据开发、大数据分析类似岗位职责：1、数据监测开发、数据指标或报表的统计开发、数据查询等相关的所有数据需求2、可视化开发、EXCEL/PPT中数据展示梳理，掌握并熟练使用EXCEL（函数、数据透视表、各种类型的图，如柱状图、折线图等），了解Tableau等BI相关软件3、依据需求进行探索性的分析、分析报告  职位要求：1、大专以上学历，在校生，统计学、计算机或工程技术背景，精通SQL/Python等数据语言进行ETL、统计分析工作；2、熟悉使用各种数据库或大数据平台各种库以及表操作，能够熟练搭建简单的计算平台集群3、熟悉数据爬虫开发的优先考虑4、善于倾听, 沟通, 思考和归纳, 耐心细致、认真负责5、实习4个月以上，一周5天以上（可以允许周末调配一天），实习是按天计薪，能够适应一定程度的加班",文娱丨内容,少于15人,hadoop,上海
大数据开发工程师（Python）,https://www.lagou.com/jobs/6986184.html,杨浦区,15k-20k,上海诺亚金融服务有限公司,1-3年,本科,企业文化积极向上 平台发展成熟稳健,岗位职责：1.负责大数据平台后台产品的研发与运营； 2.负责大数据产品的后台管理系统研发； 3.参与AI算法工程化。 岗位要求： 1.精通LinuxUnix平台上的Python开发； 2.熟悉Flask Django等Python框架； 3.精通关系型数据库中的一种，具备SQL调优能力，了解NoSQL优先； 4.熟悉Apache Superset，具有一定前端开发能力者优先； 5.具备良好的分析解决问题能力能独立承担任务和有系统进度把控能力； 6.有良好的团队合作能力富有工作激情，善于沟通热爱开发事业。加分项：1. 有Java或Scala开发经验2. 有Hive/Impala UDF开发经验。,金融,2000人以上,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6240068.html,浦东新区,10k-18k,上海海万信息科技股份有限公司,3-5年,不限,"五险一金,节日礼金,绩效奖金",岗位职责：1、 负责数据统计与分析的研发和维护；2、 根据产品经理和运营团队等的统计需求，进行开发实现；3、 负责对用户行为数据的深度挖掘，以数据指导产品改善。岗位要求：1、 全日制本科及以上，3年以上工作经验；2、 Java基础扎实，熟悉主流开源框架，懂JVM调优更佳；3、 熟悉HBase、Spark、HIVE等数据框架；4、 熟悉Kafka、ES、Redis等数据中间件；有实时计算经验更佳5、 良好的SQL语句功底，熟悉MySQL、PostgreSQL、Oracle数据库中的一种；6、 逻辑清楚、快速的学习能力及良好的沟通能力。,"移动互联网,金融",500-2000人,hadoop,上海
高级数据仓库开发工程师,https://www.lagou.com/jobs/6628500.html,黄浦区,20k-30k,众安在线财产保险股份有限公司,5-10年,本科,外滩办公 大牛多,岗位职责：1.负责根据需求，参与数据仓库模型设计，数据仓库脚本开发；2.负责用户画像，BI等数据产品的实时/离线数据模型汇总开发；3.负责对接业务进行业务数据需求整理和业务数据分析；4.负责同时需参与数据采集，任务调度等数据仓库工作；任职资格：1. 要求5年以上工作经验，3年以上互联网/互联网金融的数据开发经验；2. 有数据分析经验优先考虑；3.熟悉Linux操作命令，能编写常用Shell或Python脚本；4.熟悉Hive sql有丰富的Hive sql性能调优经验；有丰富的sql查询优化经验;5.熟悉Hadoop/Hive/Spark/Hbase/Kylin/Sqoop/ oozie或azkaban等大数据相关技术；6.熟悉数据仓库、数据集市模型设计方法论，并有实际模型设计及ETL开发经验；7.至少熟练使用Shell/Python/Perl等脚本语言中的一种；8.有互联网数据研发、海量数据处理分析、OLAP项目开发经验者优先,金融,2000人以上,hadoop,上海
数据库运维开发(J13135),https://www.lagou.com/jobs/7060631.html,闵行区,25k-40k,上海钧正网络科技有限公司,3-5年,本科,发展前景,,"移动互联网,硬件",2000人以上,hadoop,上海
后台研发工程师（数据开发平台）(J12593),https://www.lagou.com/jobs/7036158.html,闵行区,30k-40k,上海钧正网络科技有限公司,5-10年,本科,发展前景,,"移动互联网,硬件",2000人以上,hadoop,上海
大数据开发工程师-支付方向(T000141),https://www.lagou.com/jobs/7065042.html,长宁区,20k-40k,上海寻梦信息技术有限公司,1-3年,本科,薪资高，奖金丰厚，包食宿，福利好,"岗位职责：1.参与财务数据体系架构和建设。2.负责基于Hadoop大数据平台的数据开发、建模。3.建立业务模型，对海量数据进行挖掘、优化及统计。任职要求：1. 熟悉Hadoop, Hive, HBase, Spark, Storm, Kafka等大数据相关开源系统, 熟悉ETL过程，掌握Kimball的维度建模设计方法，有两年以上的Hive, Spark的实践经验，有实时开发经验者加分2. 有较强的数据敏感性，有较强的数据分析能力3. 逻辑思维能力强，做事仔细认真，对新技术有较强的求知欲望","电商,移动互联网",2000人以上,hadoop,上海
高级Java后端开发工程师(大数据方向),https://www.lagou.com/jobs/4151366.html,长宁区,20k-40k,上海寻梦信息技术有限公司,不限,本科,"大牛多,成长快,福利好",我们希望您能：1.负责大数据服务及产品相关系统的架构&开发，系统承载数据报表、工具平台、数据服务及大数据可视化相关项目2.负责基于企业级数据仓库构建的大数据应用的后端设计和开发，参与需求分析，系统分析及详细设计岗位要求：1.1年以上Java语言编程经验，Java基础扎实，理解IO、多线程、集合等基础知识，对JVM原理有一定的了解2.熟悉Python/Shell等一种或多种脚本语言3.熟悉MySQL等数据库技术，对SQL优化有一定的经验4.有Java服务端开发经验，熟悉Spring、MyBatis等常用Java开源框架5.了解分布式系统的设计开发，有Hadoop、Storm、Spark、Pig、Sqoop、HBase、Hive、ZooKeeper、ElasticSearch等相关开发经验佳6.热爱大数据行业，熟悉相关技术栈，认同大数据驱动业务发展理念，对沉淀大数据领域的数据应用研发经验有热情加分项：1.对数据仓库/数据平台具有一定了解2.熟悉数据可视化，有报表平台、OLAP系统开发建设经验,"电商,移动互联网",2000人以上,hadoop,上海
大数据开发（实时计算方向）(T010083),https://www.lagou.com/jobs/6714514.html,长宁区,30k-60k,上海寻梦信息技术有限公司,3-5年,本科,发展空间大，年底多薪,"岗位职责1、负责业务数据和用户行为日志的实时采集、计算、存储、服务，为业务团队提供直接数据决策;2、采集用户的实时行为，计算实时用户画像数据，为线上业务提供数据支持；3、负责部门实时计算体系架构建设。   任职要求1、掌握实时计算技术体系包括数据采集、计算引擎flink、 spark streaming等,对实时计算所涉及的事务、容错、可靠性有深入理解 并有实际项目经验；2、熟悉 hadoop 生态包括 hdfs/mapreduce/hive/hbase,熟悉 kafka 等实时开源工具并有项目经验；3、熟悉 mysql 等关系型数据库,熟悉 redis 内存数据库,熟悉 linux 系统;4、熟练使用 sql,熟悉 java等编程语言；5、有良好的沟通能力和自我驱动动力,具备出色的规划、执行力,强烈的责任感,以及优秀的学习能力。","电商,移动互联网",2000人以上,hadoop,上海
数据仓库开发工程师（商业化方向）(T0195),https://www.lagou.com/jobs/6691222.html,长宁区,20k-40k,上海寻梦信息技术有限公司,1-3年,本科,"平台大,大牛多,氛围好",岗位职责：1、参与建设拼多多商业化数据体系，持续集成相关工具产品，满足多方业务需要；2、参与拼多多商业化数据仓库的架构设计和研发，挖掘数据价值，建设与管理百PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；3、助力数据化运营业务，构建丰富多样的BI应用；4、对数据采集、数据融合、数据质量、数据应用链路有深入理解。任职要求：1、熟悉数据仓库模型设计，具备ETL开发经验 ，掌握Kimball的维度建模设计方法，具备海量数据加工处理经验；2、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察HDFS、MapReduce、Hive、HBase；3、熟悉数据仓库领域知识和技能者优先，对数据质量管理有独到的见解；4、具有商业化领域经验或者电商行业经验，有业务sense，能够通过梳理设计业务模型发现业务问题，并驱动业务目标实现；5、熟悉各种NoSQL产品，对分布式架构熟悉者优先；具有图数据库开发经验者优先；6、对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先。,"电商,移动互联网",2000人以上,hadoop,上海
数据应用开发工程师（安全方向）(T010033),https://www.lagou.com/jobs/6694970.html,长宁区,25k-50k,上海寻梦信息技术有限公司,1-3年,本科,"平台大,大牛多,氛围好",岗位职责：1、 负责公司安全相关日志管理和分析；2、 负责公司数据安全开发；任职要求：1、熟练使用JAVA/C++/Python/Scala其中任一编程语言，熟悉Linux工作环境；2、熟悉Hadoop/HDFS/HIVE/Spark/Flink/Storm等，对系统任务应用有优化经验优先；3、对机器学习或统计学习理论有了解；4、较好的数理基础和逻辑思维能力，有安全背景知识或实践经验者优先。,"电商,移动互联网",2000人以上,hadoop,上海
资深大数据开发工程师（平台方向）,https://www.lagou.com/jobs/6906975.html,浦东新区,30k-50k,上海阅文信息技术有限公司,5-10年,本科,五险一金；定期团建；优秀团队,,文娱丨内容,500-2000人,hadoop,上海
大数据开发工程师（平台方向）,https://www.lagou.com/jobs/6874657.html,浦东新区,20k-40k,上海阅文信息技术有限公司,3-5年,本科,五险一金；定期团建；优秀团队,,文娱丨内容,500-2000人,hadoop,上海
大数据开发实习生,https://www.lagou.com/jobs/6731776.html,黄浦区,3k-6k,引粒网络科技（上海）有限公司,不限,本科,极佳的办公环境，发展空间前景好,工作职责:1、协助资深研发参与大数据BI系统设计和开发；2、负责大数据平台的优化维护、协助进行数据仓库平台的模型设计和开发维护；3、负责后台日常数据统计分析；任职资格:1、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等） ；2、熟悉数据仓库理论与技术，对ETL及BI有概念并具有丰富的实际操作经验，熟悉ETL开发流程； 3、熟悉BI项目，具有数据仓库、BI系统开发经验者优先； 4、熟练操作linux系统，熟悉shell脚本或python； 5、有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题；,社交,15-50人,hadoop,上海
高级数据仓库开发工程师,https://www.lagou.com/jobs/6225636.html,青浦区,20k-30k,圆通速递有限公司,5-10年,本科,上市公司，大牛团队，发展空间广阔,"工作职责：1、参与数据仓库架构的设计及开发；2、负责数据仓库建模、数据预处理的设计和开发；3、负责海量数据的ETL开发，抽取成各种数据需求；4、定义数据指标、数据模型并落地实现及优化；任职要求：1、专业要求：计算机，数学，统计及相关专业,本科学历、五年数据仓库设计开发经验、三年以上带领团队经验；2、熟悉数据及数据库结构，有丰富的数据仓库开发经验；3、具有扎实的数据库编程基础，精通SQL,PowerDesigner, ERWin, 优化SQL过程；4、熟练掌握数据仓库建模理论及主题，数据集市设计架构原理；5、熟悉teradata，greenplum等mpp数据库，5年及以上模型设计或开发经验；6、具有Hadoop、Spark、kafka、hbase、zookeeper等大数据生态圈实际开发经验；7、拥有实时流处理经验，掌握Storm等实时处理框架8、良好的分析能力与沟通能力；9、能够积极创新， 乐于面对挑战，负责敬业；10、优秀的团队合作精神；诚实， 勤奋， 严谨。",物流丨运输,2000人以上,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6278268.html,青浦区,18k-28k,圆通速递有限公司,5-10年,本科,上市公司，前景好，晋升空间广阔，待遇好,工作职责:1.熟练掌握存储过程、函数的编写；2.负责日常报表开发；3.精通SQL语句，对SQL查询优化有丰富的经验；4.搭建和部署ETL调度工具、搭建和部署相关报表；5.负者Greenplum函数开发，并持续维护优化；6.负责整理和归档所做开发的文档，负责优化已有报表。任职资格:1.本科或以上学历，计算机、数学或相关专业，4年以上开发维护经验；2.熟练使用Oracle、Greenplum数据库，具有函数、存储过程的实际设计开发经验；3.熟悉主流ETL开发工具，如：Informatica、Kettle；4.了解UNIX、LINUX、AIX操作系统；5.具有BI、Hadoop、greenplum、Oracle开发经验。,物流丨运输,2000人以上,hadoop,上海
数据开发工程师,https://www.lagou.com/jobs/6320542.html,青浦区,12k-24k,圆通速递有限公司,3-5年,本科,"上市公司,项目激励,扁平管理,发展空间广","工作职责:1、负责大数据产品部的数据开发相关工作；2、根据产品设计文档，设计开发方案并实施；3、对初级开发进行指导；任职资格:1. 计算机相关专业本科及以上学历，3年及以上数据开发经验;2. 熟练掌握SQL,掌握SQL优化技巧,使用过Greenplum,具备GP开发经验;3. 熟悉Hadoop/Spark分布式计算框架，熟练掌握HQL或SparkSQL，具有良好的代码风格;4. 较强的分析和解决问题能力，沟通协调能力，具有团队精神和一定的抗压能力。5. 有JAVA、scala开发经验者优先。",物流丨运输,2000人以上,hadoop,上海
ORACLE数据库开发,https://www.lagou.com/jobs/7049681.html,浦东新区,7k-14k,上海嘉扬信息系统有限公司,1-3年,本科,五险一金、绩效奖金、年终奖金、员工旅游、,【岗位职责】1、负责软件的日常运维工作，高效高质量解决项目运维中的技术问题；2、为客户变更需求提供可行性方案，运用数据库语法实现系统的二次开发；3、协助商务追踪订单款项并共同维护好客户关系；【任职要求】1、全日制理工科专业背景，计算机相关专业优先；2、具有良好的Oracle数据库编程基础，熟练运用数据库语法语句；3、逻辑分析能力强，善于解决问题；4、具有较强的学习能力和良好的沟通能力；5、工作积极主动、具有团队合作精神。,移动互联网,150-500人,hadoop,上海
公共-大数据系统开发工程师,https://www.lagou.com/jobs/6246271.html,长宁区,25k-45k,北京三快在线科技有限公司,3-5年,本科,上市公司 大牛云集 核心部门,,消费生活,2000人以上,hadoop,上海
Hadoop架构师,https://www.lagou.com/jobs/6842903.html,长宁区,40k-60k,上海远景科创智能科技有限公司,5-10年,本科,上班弹性 福利好 奖金多 技术好,"职位描述：职位描述：1、负责大数据架构设计、技术选型、技术难点攻关；2、负责大数据产品在企业中规划与落地；3、负责大数据安全技术方案与落地职位要求：1、具备扎实的计算机理论基础, 对数据结构及算法有较强的功底。2、精通Java语言编程，具备优秀的系统Debug/Profiling能力和经验，熟悉常见的面向对象设计模式，具备优秀的系统架构设计能力。3、精通多线程编程。有分布式开发经验值优先。4、精通HDFS/Yarn/HBase/Hive/Spark中任意一种，有系统的源码阅读经历。有开源社区开发经验者优先。5、熟悉常用的大数据组件，如：Kafka、Zookeeper、Ranger、KMS、Kylin、ElasticSearch、Ozone等。6、熟悉Kubernetes者优先","人工智能,物联网",500-2000人,hadoop,上海
前端开发工程师-数据产品,https://www.lagou.com/jobs/6565288.html,闵行区,20k-40k,北京字节跳动科技有限公司,3-5年,本科,六险一金,,文娱丨内容,2000人以上,hadoop,上海
前端开发工程师-数据可视化,https://www.lagou.com/jobs/6565290.html,闵行区,20k-40k,北京字节跳动科技有限公司,3-5年,本科,六险一金,,文娱丨内容,2000人以上,hadoop,上海
数据产品经理-开发套件方向,https://www.lagou.com/jobs/5905057.html,徐汇区,15k-30k,北京字节跳动科技有限公司,1-3年,本科,弹性工作，免费三餐，租房补贴，带薪休假,,文娱丨内容,2000人以上,hadoop,上海
前端开发工程师-大数据,https://www.lagou.com/jobs/5683158.html,徐汇区,20k-40k,北京字节跳动科技有限公司,3-5年,本科,弹性工作，免费三餐，租房补贴，带薪休假,,文娱丨内容,2000人以上,hadoop,上海
前端开发高级工程师-大数据,https://www.lagou.com/jobs/5507773.html,徐汇区,20k-40k,北京字节跳动科技有限公司,3-5年,本科,弹性工作，免费三餐，租房补贴，带薪休假,,文娱丨内容,2000人以上,hadoop,上海
数据仓库开发高级工程师,https://www.lagou.com/jobs/5121860.html,徐汇区,20k-40k,北京字节跳动科技有限公司,3-5年,本科,六险一金，弹性工作，免费三餐，过亿用户,,文娱丨内容,2000人以上,hadoop,上海
数据平台-大数据开发套件服务端高级工程师,https://www.lagou.com/jobs/5121144.html,黄浦区,20k-40k,北京字节跳动科技有限公司,1-3年,本科,六险一金，弹性工作，免费三餐，餐补,,文娱丨内容,2000人以上,hadoop,上海
前端开发实习生-大数据平台,https://www.lagou.com/jobs/5120722.html,徐汇区,6k-10k,北京字节跳动科技有限公司,不限,本科,弹性工作，免费三餐，租房补贴，休闲下午茶,,文娱丨内容,2000人以上,hadoop,上海
后端开发实习生-大数据平台,https://www.lagou.com/jobs/5120720.html,徐汇区,6k-10k,北京字节跳动科技有限公司,不限,本科,弹性工作，免费三餐，租房补贴，休闲下午茶,,文娱丨内容,2000人以上,hadoop,上海
Hadoop研发工程师,https://www.lagou.com/jobs/5119441.html,徐汇区,35k-70k,北京字节跳动科技有限公司,1-3年,本科,六险一金，免费三餐，租房补贴,,文娱丨内容,2000人以上,hadoop,上海
